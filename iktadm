#! /usr/bin/env python3
# Requires: python3 (>= 3.6)
# Requires: python3-natsort
# Requires: python3-openssl
# Requires: python3-paramiko

# pylint: disable=line-too-long

"""
This program is used to install, upgrade and uninstall control planes for Kubernetes clusters,
and to perform various other administrative tasks

For usage, see:
	iktadm help
"""

import errno
from getpass import getuser
from glob import glob
import os
import re
import shutil
import socket
import subprocess
import sys
import tempfile
import yaml

try:
	from natsort import natsorted
except ModuleNotFoundError:
	sys.exit("ModuleNotFoundError: You probably need to install python3-natsort; did you forget to run ikt-install?")

from ikttypes import DictPath, FilePath, SecurityPolicy
from iktpaths import HOMEDIR, BINDIR
from iktpaths import DEPLOYMENT_DIR, IKT_HOOKS_DIR
from iktpaths import ANSIBLE_PLAYBOOK_DIR, ANSIBLE_INVENTORY
from iktpaths import DEFAULT_THEME_FILE, IKT_CONFIG_FILE, IKT_INSTALLATION_INFO_FILE, KUBE_CONFIG_FILE

from commandparser import parse_commandline

from ansible_helper import ansible_configuration, ansible_get_inventory_dict, ansible_set_vars
from ansible_helper import ansible_run_playbook_on_selection, ansible_add_hosts, ansible_print_play_results

import iktio
from iktio import download_files, mkdir_if_not_exists, scan_and_add_ssh_keys

import iktlib # pylint: disable=unused-import
from iktlib import check_deb_versions, deep_get, execute_command, execute_command_with_response, iktconfig

from kubernetes_helper import kubectl_get_version

from iktprint import iktinput, iktinput_password, iktprint, init_iktprint

import checks

import about
PROGRAMDESCRIPTION = "Setup or teardown a Kubernetes cluster"
PROGRAMAUTHORS = "Written by David Weinehall."

DEFAULT_CNI = "cilium"
DEFAULT_POD_NETWORK_CIDR = "10.244.0.0/16"

no_password = False

prepare_targets = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/prepare_passwordless_ansible.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/install_packages.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/prepare_control_plane.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/add_kubernetes_repo.yaml",
		],
		"deb_packages": [
			"docker.io",
		],
	},
	"localhost": {
		"pretty_name": [("host system", "programname")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/prepare_passwordless_ansible.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/add_kubernetes_repo.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/install_packages.yaml",
		],
		"deb_packages": [
			"ansible",
			# If available
			# "ansible-mitogen",
		],
	},
}

setup_control_plane_targets = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/install_packages.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/kubeadm_setup_control_plane.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/fetch_kube_config.yaml",
		],
		"deb_packages": [
			"kubeadm",
			"kubectl",
			"kubelet",
			"kubernetes-cni",
		],
		"deb_packages_held": [
			"kubeadm",
			"kubectl",
			"kubelet",
		],
	},
	"localhost": {
		"pretty_name": [("host system", "programname")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/install_packages.yaml",
		],
		"deb_packages": [
			"kubectl",
		],
		"deb_packages_held": [
			"kubectl",
		],
	},
}

upgrade_control_plane_targets = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/kubeadm_upgrade_control_plane.yaml",
		],
	},
	"localhost": {
		"pretty_name": [("host system", "programname")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/install_packages.yaml",
		],
		"deb_packages": [
			"kubectl",
		],
		"deb_packages_held": [
			"kubectl",
		],
        },
}

teardown_control_plane_targets = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/teardown_cni.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/kubeadm_teardown_control_plane.yaml",
		],
	},
}

purge_control_plane_targets = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/kubeadm_purge.yaml",
		],
		"deb_packages": [
			"kubeadm",
			"kubectl",
			"kubelet",
			"kubernetes-cni",
		],
		"deb_packages_held": [
			"kubeadm",
			"kubectl",
			"kubelet",
		],
	},
}

def rebuild_installation_info(state = None):
	"""
	If the installation info file doesn't exist, but a cluster already exists and it's part of the inventory,
	this function will try to rebuild the installation info file

		Parameters:
			state (str): The installation state
	"""

	cluster_name = None
	distro = None
	version = None

	controlplanes = __selection_control_planes()
	if controlplanes is None or len(controlplanes) == 0:
		iktprint([("", "default")])
		iktprint([("Critical:", "critical"), (" No control plane defined in inventory; cannot rebuild installation info. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	deb_versions = check_deb_versions(["kubeadm"])
	if len(deb_versions) == 0 or deb_versions[0][1] == "<none>":
		iktprint([("", "default")])
		iktprint([("Critical:", "critical"),
			  (" Failed to get kubeadm version; are you sure there's a kubeadm-based cluster installed? Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)
	else:
		version = deb_versions[0][1]
		distro = "kubeadm"

	cluster_name = get_cluster_name()
	update_installation_info(cluster_name = cluster_name, distro = distro, version = version, requested_version = "<none>",
				 state = state, phase = "<none>", phase_skiplist = [], cni = "<FIXME>", pod_network_cidr = "<FIXME>")

def get_installation_info(cluster_name = None):
	"""
	Return installation info for a cluster, or prepares a new entry if no entry exists yet

		Parameters:
			cluster_name (str): The name of the cluster to get information for
		Returns:
			info (dict): A dictionary with information about a cluster
	"""

	info = None

	try:
		with open(IKT_INSTALLATION_INFO_FILE, "r", encoding = "utf-8") as f:
			info = yaml.safe_load(f)
	except FileNotFoundError:
		pass

	if info is None and cluster_name is None:
		raise Exception("cluster_name cannot be None when the installation_info file is empty")

	if info is None or info.get("installation_target") is None or (info.get("installation_target") is not None and cluster_name is not None and cluster_name not in info):
		if info is None:
			info = {}
		info["installation_target"] = cluster_name
		info[cluster_name] = {
			"distro": "<none>",
			"version": "<none>",
			"requested_version": "<none>",
			"state": "<none>",
			"phase": "<none>",
			"phase_skiplist": [],
			"cni": "<none>",
			"pod_network_cidr": "<none>",
			"cri": "<none>",
		}
	elif info.get("installation_target") is None and cluster_name is not None:
		# Old format file; transition it
		tmpinfo = info.copy()
		tmpinfo.pop("cluster_name")
		info = {}
		info["installation_target"] = cluster_name
		info[cluster_name] = tmpinfo

	return info

# pylint: disable-next=too-many-arguments
def update_installation_info(cluster_name = None, distro = None, version = None, requested_version = None,
			     state = None, phase = None, phase_skiplist = None, cni = None, pod_network_cidr = None, cri = None):
	"""
	Update installation info for a cluster

		Parameters:
			cluster_name (str): The name of the cluster to update information for
			distro (str): The distribution used during installation (currently the only supported distro is kubeadm)
			version (str): The current version of Kubernetes
			requested_version (str): The requested version of Kubernetes
			state (str): The installation state
			phase (str): The installation phase
			phase_skiplist (list[str]): A list of phases to skip
			cni (str): The CNI to use
			pod_network_cidr (str): The CIDR to use for the pod network
			cri (str): The CRI to use
		Returns:
			info (dict): The updated installation info
	"""

	info = get_installation_info(cluster_name = cluster_name)

	if cluster_name is None:
		cluster_name = info.get("installation_target")

	if info.get("installation_target") is None:
		info["installation_target"] = cluster_name

	if distro is not None:
		info[cluster_name]["distro"] = distro
	if version is not None:
		info[cluster_name]["version"] = version
	if requested_version is not None:
		info[cluster_name]["requested_version"] = requested_version
	if state is not None:
		info[cluster_name]["state"] = state
	if phase is not None:
		info[cluster_name]["phase"] = phase
	if phase_skiplist is not None:
		info[cluster_name]["phase_skiplist"] = phase_skiplist
	if cni is not None:
		info[cluster_name]["cni"] = cni
	if pod_network_cidr is not None:
		info[cluster_name]["pod_network_cidr"] = pod_network_cidr
	if cri is not None:
		info[cluster_name]["cri"] = cri

	with open(IKT_INSTALLATION_INFO_FILE, "w", encoding = "utf-8") as f:
		f.write(yaml.dump(info, default_flow_style = False, sort_keys = False))

	return info

def check_and_print_status(retval):
	"""
	A wrapper that prints OK if retval is True
	and NOT OK and aborts if retval is False
		Parameters:
			retval (bool): True on success, False on failure
	"""

	if retval == True:
		iktprint([("OK", "ok")])
	else:
		iktprint([("NOT OK", "notok"), ("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

def patch_cni_flannel(cni_path, pod_network_cidr):
	"""
	Patch the configuration for Flannel

		Parameters:
			cni_path (str): The path to the CNI configuration to patch
			pod_network_cidr (str): The CIDR for the pod network
	"""

	# Ideally we should patch this using a round-trip capable YAML parser,
	# such as ruamel
	sedstr = fr's#^\(.*"\)Network": "10.244.0.0/16",$#\\1Network:": "{pod_network_cidr}",#'
	args = ["/usr/bin/sed", "-i", "-e", sedstr, cni_path]
	check_and_print_status(execute_command(args))

# XXX: We should convert all of cni_data to use this format instead,
#      and move all of this code to a separate file to allow it to be used both from iku and iktadm
cni_upgrade_data = {
	"cilium": {
		"executable": {
			"version_command": ["cilium", "--context", "<<<context>>>", "version"],
			# Safe
			"version_regex": r"^cilium-cli: (v)(\d+)(\.)(\d+)(\.)(\d+) .*$",
			"candidate_version_url": "https://raw.githubusercontent.com/cilium/cilium-cli/master/stable.txt",
			# Safe
			"candidate_version_regex": r"(v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"url": "https://github.com/cilium/cilium-cli/releases/download/<<<version>>>/cilium-linux-<<<arch>>>.tar.gz",
			"checksum_url": "https://github.com/cilium/cilium-cli/releases/download/<<<version>>>/cilium-linux-<<<arch>>>.tar.gz.sha256sum",
			"checksum_type": "sha256",
			"filename": "cilium",
		},
		"CNI": {
			"version_command": ["cilium", "--context", "<<<context>>>", "version"],
			# Safe
			"version_regex": r"^cilium image \(running\): (v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"candidate_version_command": ["cilium", "--context", "<<<context>>>", "version"],
			# Safe
			"candidate_version_regex": r"^cilium image \(default\): (v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"upgrade": ["cilium", "--context", "<<<context>>>", "upgrade"],
			"install": ["cilium", "--context", "<<<context>>>", "install"],
		}
	}
}

cni_data = {
	"antrea": {
		"url": "https://raw.githubusercontent.com/antrea-io/antrea/main/build/yamls/antrea.yml",
		"type": "yaml",
		"filename": "antrea.yaml",
	},
	"calico": {
		"url": "https://docs.projectcalico.org/manifests/calico.yaml",
		"type": "yaml",
		"filename": "calico.yaml",
	},
	"canal": {
		"url": "https://docs.projectcalico.org/manifests/canal.yaml",
		"type": "yaml",
		"filename": "canal.yaml",
	},
	"cilium": {
		"version_url": "https://raw.githubusercontent.com/cilium/cilium-cli/master/stable.txt",
		"url": "https://github.com/cilium/cilium-cli/releases/download/<<<version>>>/cilium-linux-<<<arch>>>.tar.gz",
		"checksum_url": "https://github.com/cilium/cilium-cli/releases/download/<<<version>>>/cilium-linux-<<<arch>>>.tar.gz.sha256sum",
		"checksum_type": "sha256",
		"type": "installer",
		"filename": "cilium",
		"command": ["cilium", "--context", "<<<context>>>", "install"]
	},
	"flannel": {
		"url": "https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml",
		"type": "yaml",
		"filename": "flannel.yaml",
		"patch_cni": patch_cni_flannel,
	},
	"kube-router": {
		"url": "https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter.yaml",
		"type": "yaml",
		"filename": "kube-router.yaml",
	},
	"weave": {
		"url": "https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s-1.11.yaml",
		"type": "yaml",
		"filename": "weave.yaml",
	},
}

def substitute_string(string, substitutions):
	"""
	Substitutes substrings in a string

		Parameters:
			string (str): The string to perform substitutions on
			substitutions (dict): A dict where key is the substring to match against, and value is the replacement for that substring
		Returns:
			string (str): The string with substitutions performed
	"""

	for key, value in substitutions.items():
		if string is None or value is None:
			continue
		string = string.replace(key, value)
	return string

def substitute_list(strlist, substitutions):
	"""
	Substitutes substrings in all strings in a list

		Parameters:
			string (list[str]): A list with the strings to perform substitutions on
			substitutions (dict): A dict where key is the substring to match against, and value is the replacement for that substring
		Returns:
			list[str]: The list of strings with substitutions performed
	"""

	for key, value in substitutions.items():
		strlist = [s.replace(key, value) for s in strlist]
	return strlist

def check_version_from_url(url, version_regex):
	"""
	Given a URL download a text file and treat the first line that matches version_regex as a version number

		Parameters:
			url (str): A URL
			version_regex (str): A regex
		Returns:
			version (str): The version number, or None in case of failure
	"""

	version = None
	if url is not None:
		with tempfile.TemporaryDirectory() as td:
			check_and_print_status(download_files(td, [(url, "version.txt", None, None)], permissions = 0o600))
			with open(f"{td}/version.txt", encoding = "utf-8") as f:
				versionoutput = f.readlines()
				_version_regex = re.compile(version_regex)
				for line in versionoutput:
					tmp = _version_regex.match(line)
					if tmp is not None:
						version = tmp.groups()
						break
	return version

def check_version_from_executable(command, args, version_regex):
	"""
	Given a path to an executable, the arguments needed to show version information,
	and a version_regex, return the executable version

		Parameters:
			command (str): A path to an executable
			args (list[str]): A list of arguments necessary to show version information
			version_regex (str): A regex
		Returns:
			version (str): The version number, or None in case of failure
	"""

	version = None

	security_policy = SecurityPolicy.ALLOWLIST_RELAXED
	fallback_allowlist = ["/bin", "/sbin", "/usr/bin", "/usr/sbin", "/usr/local/bin", "/usr/local/sbin", f"{HOMEDIR}/bin"]

	try:
		cpath = iktio.secure_which(command, fallback_allowlist = fallback_allowlist, security_policy = security_policy)
	except FileNotFoundError:
		cpath = None

	if cpath is not None:
		result = execute_command_with_response([cpath] + args)

		if result is not None:
			versionoutput = result.splitlines()
			_version_regex = re.compile(version_regex)
			for line in versionoutput:
				tmp = _version_regex.match(line)
				if tmp is not None:
					version = tmp.groups()
					break
	return version

def __upgrade_cni(cni, upgradetype, context):
	"""
	A helper that is used when upgrading a CNI; it can either upgrade the CNI itself or a helper executable

		Parameters:
			cni (str): The CNI to upgrade
			upgradetype (str): Valid options CNI, executable
			context (str): The cluster context
	"""

	if upgradetype not in ("CNI", "executable"):
		raise Exception(f"Unknown upgradetype {upgradetype}; this is a programming error.")

	# FIXME: for now we hardcode this
	arch = "amd64"
	version_command = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#version_command")
	version_command_regex = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#version_regex")
	candidate_version_url = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#candidate_version_url")
	candidate_version_command = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#candidate_version_command")
	candidate_version_regex = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#candidate_version_regex")
	download_url = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#url")
	download_checksum_url = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#checksum_url")
	download_checksum_type = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#checksum_type")
	command_filename = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#filename")
	install_command = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#install")
	upgrade_command = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#upgrade")

	version_substitutions = {
		"<<<arch>>>": arch,
		"<<<context>>>": context,
	}

	version = None
	if version_command is not None:
		iktprint([("\n• ", "separator"), (f"Checking {upgradetype} version", "action")])
		version = check_version_from_executable(version_command[0],
							substitute_list(version_command[1:], version_substitutions), version_command_regex)

	candidate_version = ""
	if candidate_version_url is not None:
		iktprint([("\n• ", "separator"), (f"Checking {upgradetype} candidate version", "action")])
		candidate_version = check_version_from_url(substitute_string(candidate_version_url, version_substitutions), candidate_version_regex)
	elif candidate_version_command is not None:
		iktprint([("\n• ", "separator"), (f"Checking {upgradetype} candidate version", "action")])
		candidate_version = check_version_from_executable(candidate_version_command[0],
								  substitute_list(candidate_version_command[1:], version_substitutions),
								  candidate_version_regex)

	if download_url is not None and command_filename is not None:
		if version is None or version < candidate_version:
			version = "".join(candidate_version)

			iktprint([("\n• ", "separator"), (f"Downloading {upgradetype} ", "action"), (f"{version}", "version")])

			substitutions = {
				"<<<version>>>": version,
				"<<<arch>>>": arch,
				"<<<context>>>": context,
			}

			download_url = substitute_string(download_url, substitutions)
			download_checksum_url = substitute_string(download_checksum_url, substitutions)

			if upgradetype == "CNI":
				mkdir_if_not_exists(DEPLOYMENT_DIR)
				directory = FilePath(os.path.join(DEPLOYMENT_DIR, "cni"))
				permissions = 0o644
			elif upgradetype == "executable":
				directory = BINDIR
				permissions = 0o755
			mkdir_if_not_exists(directory)
			check_and_print_status(download_files(directory, [(download_url, command_filename, download_checksum_url, download_checksum_type)], permissions = permissions))
		else:
			iktprint([("No newer version available.", "default")])
	elif install_command is not None and version is None:
		version = "".join(candidate_version)

		iktprint([("\n• ", "separator"), (f"Installing {upgradetype} ", "action"), (f"{version}", "version")])

		substitutions = {
			"<<<version>>>": version,
			"<<<arch>>>": arch,
			"<<<context>>>": context,
		}
		check_and_print_status(execute_command(substitute_list(install_command, substitutions)))
	elif upgrade_command is not None:
		if version is None or version < candidate_version:
			version = "".join(candidate_version)

			iktprint([("\n• ", "separator"), (f"Upgrading {upgradetype} to ", "action"), (f"{version}", "version")])

			substitutions = {
				"<<<version>>>": version,
				"<<<arch>>>": arch,
				"<<<context>>>": context,
			}
			check_and_print_status(execute_command(substitute_list(upgrade_command, substitutions)))
		else:
			iktprint([("No newer version available.", "default")])

# pylint: disable-next=unused-argument
def upgrade_cni(options, args):
	"""
	Upgrade the specified CNI to the latest version

		Parameters:
			options (list[(str, str)]): Unused
			args (list[str]): The CNI to upgrade (optional; if not specified the CNI will be taken from installation_info.yaml)
	"""

	if len(args) > 0:
		cni = args[0]
	else:
		installation_info = get_installation_info()
		cluster_name = installation_info["installation_target"]
		cni = installation_info[cluster_name]["cni"]
	if cni not in cni_upgrade_data:
		iktprint([("Upgrading ", "default"), (f"{cni}", "command"), (" is currently not supported; exiting.", "default")])
		sys.exit(errno.ENOTSUP)

	context_name = execute_command_with_response(["/usr/bin/kubectl", "config", "current-context"]).splitlines()[0]

	iktprint([("\n[Upgrading CNI]", "phase")])

	__upgrade_cni(cni, "executable", context_name)
	__upgrade_cni(cni, "CNI", context_name)

	iktprint([("\nCNI upgrade successful", "success")])

def __setup_cni(cni, pod_network_cidr, context_name, cluster_name):
	"""
	Setup a CNI

		Parameters:
			cni (str): The CNI to configure and install
			pod_network_cidr (str): The CIDR of the pod network
			context_name (str): The name of the cluster context
			cluster_name (str): The name of the cluster
	"""

	if cni not in cni_data:
		iktprint([("Error:", "error"), (f" {cni}", "argument"), (" is not a valid/supported CNI; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	version_url = deep_get(cni_data, f"{cni}#version_url")
	version_regex = deep_get(cni_data, f"{cni}#version_regex")

	version = check_version_from_url(version_url, version_regex)

	url = deep_get(cni_data, f"{cni}#url")
	if url is None:
		raise Exception(f"URL for {cni} is empty; this is a programming error.")

	checksum_url = deep_get(cni_data, f"{cni}#checksum_url")
	checksum_type = deep_get(cni_data, f"{cni}#checksum_type")

	# FIXME: for now we hardcode this
	arch = "amd64"
	substitutions = {
		"<<<version>>>": version,
		"<<<arch>>>": arch,
	}

	url = substitute_string(url, substitutions)
	checksum_url = substitute_string(checksum_url, substitutions)

	filename = deep_get(cni_data, f"{cni}#filename")
	patch_cni = deep_get(cni_data, f"{cni}#patch_cni", None)
	filetype = deep_get(cni_data, f"{cni}#type")
	if filetype is None:
		raise Exception(f"type for {cni} is missing; this is a programming error.")
	if filetype == "yaml":
		mkdir_if_not_exists(DEPLOYMENT_DIR)
		directory = FilePath(os.path.join(DEPLOYMENT_DIR, "cni"))
		permissions = 0o644
	elif filetype == "installer":
		directory = BINDIR
		permissions = 0o755
	mkdir_if_not_exists(directory)

	check_and_print_status(download_files(directory, [(url, filename, checksum_url, checksum_type)], permissions = permissions))

	cni_path = f"{directory}/{filename}"

	if patch_cni is not None:
		iktprint([("\n• ", "separator"), ("Patching “", "action"), (f"{cni}", "argument"), ("“ configuration", "action")])
		patch_cni(cni_path, pod_network_cidr)

	if filetype == "yaml":
		args = ["/usr/bin/kubectl", "apply", "--context=<<<context>>>", "-f", cni_path]
	elif filetype == "installer":
		args = deep_get(cni_data, f"{cni}#command")

	substitutions = {
		"<<<cluster>>>": cluster_name,
		"<<<context>>>": context_name,
	}

	check_and_print_status(execute_command(substitute_list(args, substitutions)))

def check_for_ssh_key():
	"""
	Check whether there's an existing public ssh key on the system already

		Returns:
			retval (bool): True if a key exists, False if no key exists
	"""

	retval = False
	files = [file for file in glob(os.path.join(HOMEDIR, ".ssh", "*.pub")) if os.path.isfile(file)]
	for file in files:
		if os.path.isfile(file) and os.path.isfile(file[:-len(".pub")]):
			retval = True
			break
	return retval

def create_ssh_key():
	"""
	Create a new ssh key (ECDSA-P521 format)

		Returns:
			retval (bool): True on success, False on failure
	"""

	if not os.path.exists(f"{HOMEDIR}/.ssh/id_ecdsa"):
		args = ["/usr/bin/ssh-keygen", "-t", "ecdsa", "-b", "521", "-f", f"{HOMEDIR}/.ssh/id_ecdsa"]
		retval = execute_command(args)
	else:
		retval = True
	return retval

def add_ssh_keys_to_authorized_keys():
	"""
	Add all public keys for this host to authorized keys on this host;
	in other words, make the host able to SSH to itself

		Returns:
			retval (bool): True on success, False on failure
	"""

	pubkey = None
	retval = False

	# Since we run create_ssh_key() before this task we can safely
	# assume that .ssh/ exists
	for item in os.listdir(f"{HOMEDIR}/.ssh"):
		if not item.endswith(".pub"):
			continue

		with open(f"{HOMEDIR}/.ssh/{item}", "r", encoding = "utf-8") as f:
			tmp = f.readlines()
			if tmp is not None and len(tmp) > 0:
				pubkey = tmp

		if pubkey is None or len(pubkey) == 0:
			continue

		exists = False

		try:
			with open(f"{HOMEDIR}/.ssh/authorized_keys", "r", encoding = "utf-8") as f:
				tmp = f.readlines()

				if tmp is not None and len(tmp) > 0:
					for line in tmp:
						if line == pubkey[0]:
							exists = True
							break
		except FileNotFoundError:
			pass

		# This either means that the key doesn't exist in the file,
		# or that authorized_keys doesn't exist at all.  Hence we open
		# with a+ to ensure that it's created if it doesn't exist.
		# While we technically only need to worry about authorized_keys
		# not existing for the first key we add, it's better not to
		# special case things
		if exists == False:
			with open(f"{HOMEDIR}/.ssh/authorized_keys", "a+", encoding = "utf-8") as f:
				f.writelines(pubkey)

		# We've added at least one public key
		retval = True

	return retval

# pylint: disable-next=unused-argument
def __task_check_and_create_ssh_key(installation_info):
	"""
	An installer task that checks whether the system has an ssh-key,
	and creates one if not

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	if check_for_ssh_key() == False:
		retval = iktinput([("Warning:", "warning"), (" No ssh key found in ", "default"), (f"{HOMEDIR}/.ssh", "path"), ("; create one now? (No will abort the installation) [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			iktprint([("\nAborting:", "error"), (" No ssh key available.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		else:
			check_and_print_status(create_ssh_key())

# pylint: disable-next=unused-argument
def __task_scan_and_add_ssh_keys(installation_info):
	"""
	An installer task that scans all specified control planes for public ssh keys
	and adds them to known hosts

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	controlplanes = get_control_planes()
	hosts = [controlplane[0] for controlplane in controlplanes]
	hosts += [f"{controlplane[0]}.local" for controlplane in controlplanes]
	hosts += [
		"localhost",
	]

	scan_and_add_ssh_keys(hosts)

# pylint: disable-next=unused-argument
def __task_add_ssh_keys_to_inventory(installation_info):
	"""
	An installer task that adds SSH keys to the iKT inventory

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	pubkey = None
	d = ansible_get_inventory_dict()
	__vars = deep_get(d, "all#vars", {})
	__authorized_keys = __vars.get("authorized_keys", [])
	found_key = False

	for item in os.listdir(f"{HOMEDIR}/.ssh"):
		if not item.endswith(".pub"):
			continue

		with open(f"{HOMEDIR}/.ssh/{item}", "r", encoding = "utf-8") as f:
			tmp = f.readlines()
			if tmp is not None and len(tmp) > 0:
				pubkey = tmp[0]

		if pubkey == None:
			iktprint([("Warning:", "warning"), (" Failed to read ", "default"), (f"{HOMEDIR}/.ssh/{item}", "path"), ("; skipping.", "default")], stderr = True)
			continue

		if pubkey not in __authorized_keys:
			__authorized_keys.append(pubkey)

		found_key = True

	if found_key == False:
		iktprint([("Error:", "error"), (" Could not find a valid public key in ", "default"), (f"{HOMEDIR}/.ssh", "path"), ("; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	__vars["authorized_keys"] = __authorized_keys
	ansible_set_vars(ANSIBLE_INVENTORY, "all", __vars)

# pylint: disable-next=unused-argument
def __task_check_and_add_ssh_keys_to_authorized_keys(installation_info):
	"""
	An installer task that adds SSH keys to authorized keys

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	add_ssh_keys_to_authorized_keys()

def install_ansible_posix():
	"""
	Install ansible-posix using ansible-galaxy; this is necessary on systems
	where the version of Ansible is too old to support certain actions.

		Returns:
			(bool): True on success, False on failure
	"""

	# Old versions of ansible-galaxy doesn't have the list command;
	# if it doesn't work we just assume that ansible.posix is missing
	args = ["/usr/bin/ansible-galaxy", "collection", "list"]
	result = execute_command_with_response(args)

	if "COLLECTION_ACTION: invalid choice" in result or "ansible.posix" not in result:
		http_proxy = deep_get(iktconfig, "Network#http_proxy", "")
		https_proxy = deep_get(iktconfig, "Network#https_proxy", "")
		no_proxy = deep_get(iktconfig, "Network#no_proxy", "")
		env = {
			"http_proxy": http_proxy,
			"https_proxy": https_proxy,
			"no_proxy": no_proxy,
		}
		args = ["/usr/bin/ansible-galaxy", "collection", "install", "ansible.posix"]
		return execute_command(args, env = env)

	return True

# pylint: disable-next=unused-argument
def __task_check_and_install_ansible_posix(installation_info):
	"""
	An installer task that installs ansible-posix

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	check_and_print_status(install_ansible_posix())

def update_apt_cache():
	"""
	Update the APT cache

		Returns:
			True on success, False on failure
	"""

	sudo_path = iktio.secure_which(FilePath("sudo"), fallback_allowlist = ["/bin", "/usr/bin"], security_policy = SecurityPolicy.ALLOWLIST_STRICT)
	apt_get_path = iktio.secure_which(FilePath("apt-get"), fallback_allowlist = ["/bin", "/usr/bin"], security_policy = SecurityPolicy.ALLOWLIST_STRICT)
	args = [sudo_path, apt_get_path, "update"]
	return execute_command(args)

def deb_compare_versions(current_version, candidate_version):
	"""
	Compare two package versions

		Returns:
			True if current version < candidate version, else False
	"""

	args = ["/usr/bin/dpkg", "--compare-versions", current_version, "lt", candidate_version]
	return execute_command(args, comparison = 1)

def __get_theme(string, default):
	"""
	Return the suitable format reference for a particular string

		Parameters:
			string (str): A string to return the format reference for
			default (str): The default format reference to use if there's no matching translation
		Returns:
			theme (str): A format reference
	"""

	translation = {
		"<none>": "none",
		"<unknown>": "unknown",
	}
	return translation.get(string, default)

def check_versions(deb_packages, version_checks):
	"""
	Check versions for all relevant software

		Parameters:
			deb_packages (list[str]): A list of debian packages
			version_checks (list[(software, args, regex)]): A list of component, the command needed to check its version, and a regex to extract the version number
		Returns:
			(deb_versions, other_versions): A tuple of utput from check_deb_versions(), (software, installed_version, "")
	"""

	other_versions = []

	# First check all Debian versions
	deb_versions = check_deb_versions(deb_packages)

	# Now check versions that need special checks
	for version_check in version_checks:
		software = version_check[0]
		args = version_check[1]
		regex = version_check[2]

		try:
			response = execute_command_with_response(args)
		except FileNotFoundError:
			other_versions.append((software, "<none>", ""))
			continue
		except subprocess.CalledProcessError:
			other_versions.append((software, "<unknown>", ""))
			continue

		if regex is None:
			installed_version = response
		else:
			tmp = re.match(regex, response)
			if tmp is not None:
				installed_version = tmp[1]
			else:
				installed_version = "<none>"
		other_versions.append((software, installed_version, ""))

	# Finally, display the gathered version information; find the longest string of each type
	# Create lists of header + all values belonging to that header, and get the length of the longest element
	slen = len(max(["Software:"] + [tmp[0] for tmp in deb_versions + other_versions], key = len))
	ilen = len(max(["Installed Version:"] + [tmp[1] for tmp in deb_versions + other_versions], key = len))

	# Print a header
	iktprint([("Software:", "header"), (f"{''.ljust(slen - len('Software:') + 2)}", "default"), ("Installed Version:", "header"), (f"{''.ljust(ilen - len('Installed Version:') + 2)}", "default"), ("Candidate Version:", "header")])
	for software, installed_version, candidate_version, _ in natsorted(deb_versions):
		iformat = __get_theme(installed_version, "version")
		cformat = __get_theme(candidate_version, "version")
		iktprint([(f"{software.ljust(slen + 2)}", "default"), (f"{installed_version.ljust(ilen + 2)}", iformat), (f"{candidate_version}", cformat)])
	print()
	for software, installed_version, candidate_version in natsorted(other_versions):
		iformat = __get_theme(installed_version, "version")
		cformat = __get_theme(candidate_version, "version")
		iktprint([(f"{software.ljust(slen + 2)}", "default"), (f"{installed_version.ljust(ilen + 2)}", iformat), (f"{candidate_version}", cformat)])

	return deb_versions, other_versions

# pylint: disable-next=unused-argument
def run_playbook(playbookpath, hosts = None, extra_values = None, quiet = False):
	"""
	Run a playbook

		Parameters:
			playbookpath (str): A path to the playbook to run
			hosts (list[str]): A list of hosts to run the playbook on
			extra_values (dict): A dict of values to set before running the playbook
			quiet (bool): Unused
		Returns:
			retval (int): The return value from ansible_run_playbook_on_selection()
			ansible_results (dict): A dict with the results from the run
	"""

	# Set necessary Ansible keys before running playbooks
	http_proxy = deep_get(iktconfig, "Network#http_proxy", "")
	if http_proxy is None:
		http_proxy = ""
	https_proxy = deep_get(iktconfig, "Network#https_proxy", "")
	if https_proxy is None:
		https_proxy = ""
	no_proxy = deep_get(iktconfig, "Network#no_proxy", "")
	if no_proxy is None:
		no_proxy = ""
	insecure_registries = deep_get(iktconfig, "Docker#insecure_registries", [])
	registry_mirrors = deep_get(iktconfig, "Containerd#registry_mirrors", [])
	retval = 0

	use_proxy = "no"
	if len(http_proxy) > 0 or len(https_proxy) > 0:
		use_proxy = "yes"

	if extra_values is None:
		extra_values = {}

	values = {
		"http_proxy": http_proxy,
		"https_proxy": https_proxy,
		"no_proxy": no_proxy,
		"insecure_registries": insecure_registries,
		"registry_mirrors": registry_mirrors,
		"use_proxy": use_proxy,
	}
	merged_values = { **values, **extra_values }

	retval, ansible_results = ansible_run_playbook_on_selection(playbookpath, selection = hosts, values = merged_values)

	ansible_print_play_results(retval, ansible_results)

	return retval, ansible_results

def run_playbooks(playbooks, hosts = None, extra_values = None):
	"""
	Run a set of playbooks

		Parameters:
			playbooks (list[(description, playbookpath)]): A list of playbooks
			hosts (str): The hosts to run the playbooks on
			extra_values (dict): Variables to set before running the playbooks
		Returns:
			True on success, False on failure
	"""

	if len(playbooks) == 0 or hosts == None:
		return True

	for string, playbookpath in playbooks:
		iktprint(string)
		retval, _ansible_results = run_playbook(playbookpath, hosts = hosts, extra_values = extra_values)

		# We don't want to continue executing playbooks if the first one failed
		if retval != 0:
			break

	return retval == 0

def __playbook_paths_from_path(path):
	"""
	Scan a directory and return a list of playbook paths

		Parameters:
			path (str): A path to a directory
		Returns:
			list[str]: A list of paths
	"""

	if path is None:
		raise Exception("No path passed to __playbook_paths_from_path; this is a programming error.")

	playbook_paths = []

	# Safe
	yaml_regex = re.compile(r"^(.*)\.ya?ml$")

	# Populate list of playbooks
	for filename in os.listdir(path):
		# Don't process backups, etc.
		if filename.startswith(("~", ".")):
			continue

		# Only process playbooks
		tmp = yaml_regex.match(filename)
		if tmp is None:
			continue

		playbook_paths.append(os.path.join(path, filename))

	return playbook_paths

def populate_playbooks_from_paths(paths):
	"""
	Populate a playbook list

		Parameters:
			paths (list[str]): A list of paths to playbooks
		Returns:
			list[(description, playbookpath)]: A playbook list for use with run_playbooks()
	"""

	playbooks = []

	# Safe
	yaml_regex = re.compile(r"^(.*)\.ya?ml$")

	for playbookpath in paths:
		# Only process playbooks
		tmp = yaml_regex.match(os.path.basename(playbookpath))
		if tmp is None:
			raise Exception(f"The playbook filename “{os.path.basename(playbookpath)}“ does not end with .yaml or .yml; this is most likely a programming error.")

		# Don't process backups, etc.
		if os.path.basename(playbookpath).startswith(("~", ".")):
			continue

		playbookname = tmp[1]
		description = None
		with open(playbookpath, encoding = "utf-8") as f:
			d = yaml.safe_load(f)
			description = [(deep_get(d[0], "vars#metadata#description"), "play")]

		if description is None or len(description) == 0:
			description = [("Running “", "play"), (playbookname, "programname"), ("“", "play")]

		# If there's no description we fallback to just using the filename
		playbooks.append(([("  • ", "separator")] + description, playbookpath))

	return playbooks

# Add all playbooks in the directory
def populate_playbooks_from_dir(path):
	"""
	Populate a playbook list from path

		Parameters:
			paths (list[str]): A directory to populate playbooks from
		Returns:
			list[(description, playbookpath)]: A playbook list for use with run_playbooks()
	"""

	playbook_paths = []

	# Safe
	yaml_regex = re.compile(r"^(.*)\.ya?ml$")

	# Populate list of playbooks
	for filename in os.listdir(path):
		# Don't process backups, etc.
		if filename.startswith(("~", ".")):
			continue

		# Only process playbooks
		tmp = yaml_regex.match(filename)
		if tmp is None:
			continue

		playbook_paths.append(f"{path}/{filename}")

	return populate_playbooks_from_paths(playbook_paths)

# pylint: disable-next=unused-argument
def __task_request_ansible_password(installation_info):
	"""
	An installer task that requests the ansible password

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	# Check whether ansible_password is defined or not
	if deep_get(ansible_configuration, "ansible_password") is None and no_password == False:
		iktprint([("Attention: ", "warning"), ("To be able to run playbooks you need to provide the ansible/ssh password.", "default")])
		iktprint([("Since the systems will be reconfigured to use passwordless sudo and ssh keys this is a one-time thing.", "default")])
		ansible_password = iktinput_password([("\nPassword: ", "default")])
		if len(ansible_password) == 0:
			iktprint([("\nError: ", "Error"), ("Empty password; aborting.")], stderr = True)
			sys.exit(errno.EINVAL)
		else:
			ansible_configuration["ansible_password"] = ansible_password

def __run_playbooks_on_selection(playbooks, selection, extra_values = None):
	"""
	A helper that runs a playbook list on a selection

		Parameters:
			playbooks (list[(description, playbookpath)]): A playbook list
			selection (list[str]): A list of hosts
			extra_values (dict): A dict of values to set before running the playbook
	"""

	check_and_print_status(run_playbooks(playbooks, hosts = selection, extra_values = extra_values))

def __selection_control_planes():
	"""
	Return a selection with all control planes

		Returns:
			(list[str]): A list of control planes
	"""

	__controlplanes = get_control_planes(fail_on_empty = False)
	return [controlplane[0] for controlplane in __controlplanes]

def __selection_localhost():
	"""
	Returns a list with the hostname of localhost

		Returns:
			(list[str]): A list with the hostname of localhost
	"""

	return [socket.gethostname()]

# pylint: disable-next=unused-argument
def __task_run_preparation_playbooks_on_localhost(installation_info):
	"""
	An installer task that runs preparation playbooks on localhost

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	selection = __selection_localhost()
	playbooks = populate_playbooks_from_paths(prepare_targets["localhost"]["playbooks"])
	extra_values = {
		"packages": prepare_targets["localhost"].get("deb_packages", []),
		"held_packages": prepare_targets["localhost"].get("deb_packages_held", []),
		"ansible_become_pass": deep_get(ansible_configuration, "ansible_password"),
		"ansible_ssh_pass": deep_get(ansible_configuration, "ansible_password"),
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

def __task_run_preparation_playbooks_on_control_planes(installation_info):
	"""
	An installer task that runs preparation playbooks on control planes

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(prepare_targets[distro]["playbooks"])
	cri = installation_info[cluster_name]["cri"]
	extra_values = {
		"packages": prepare_targets[distro].get("deb_packages", []),
		"held_packages": prepare_targets[distro].get("deb_packages_held", []),
		"ansible_become_pass": deep_get(ansible_configuration, "ansible_password"),
		"ansible_ssh_pass": deep_get(ansible_configuration, "ansible_password"),
		"cri": cri,
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

# pylint: disable-next=unused-argument
def __task_setup_bash_completion(installation_info):
	"""
	An installer task that sets up bash completion

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	args = ["/usr/bin/kubectl", "completion", "bash"]
	result = execute_command_with_response(args)
	with tempfile.TemporaryDirectory() as td:
		with open(f"{td}/kubectl", "w", encoding = "utf-8") as f:
			f.write(result)
		args = ["/usr/bin/sudo", "/usr/bin/mv", f"{td}/kubectl", "/etc/bash_completion.d/kubectl"]
		check_and_print_status(execute_command(args))

def get_cluster_name():
	"""
	Return the name of the cluster

		Returns:
			cluster_name (str): The name of the cluster
	"""
	if os.path.exists(f"{KUBE_CONFIG_FILE}"):
		with open(f"{KUBE_CONFIG_FILE}", "r", encoding = "utf-8") as f:
			d1 = yaml.safe_load(f)
	else:
		return None

	current_context = d1.get("current-context", None)
	if current_context is None:
		return None

	cluster_name = None

	for context in d1.get("contexts", []):
		if context.get("name", "") == current_context:
			cluster_name = context["context"].get("cluster", None)
			break

	return cluster_name

def __task_run_setup_playbooks_on_localhost(installation_info):
	"""
	An installer task that runs playbooks on localhost

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	cluster_name = installation_info["installation_target"]
	pod_network_cidr = installation_info[cluster_name]["pod_network_cidr"]
	selection = __selection_localhost()
	playbooks = populate_playbooks_from_paths(setup_control_plane_targets["localhost"]["playbooks"])
	extra_values = {
		"cluster_name": cluster_name,
		"pod_network_cidr": pod_network_cidr,
		"packages": setup_control_plane_targets["localhost"].get("deb_packages", []),
		"held_packages": setup_control_plane_targets["localhost"].get("deb_packages_held", []),
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

def __task_run_setup_playbooks_on_control_planes(installation_info):
	"""
	An installer task that runs playbooks on control planes

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	pod_network_cidr = installation_info[cluster_name]["pod_network_cidr"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(setup_control_plane_targets[distro]["playbooks"])
	extra_values = {
		"cluster_name": cluster_name,
		"pod_network_cidr": pod_network_cidr,
		"packages": setup_control_plane_targets[distro].get("deb_packages", []),
		"held_packages": setup_control_plane_targets[distro].get("deb_packages_held", []),
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

def __task_import_kube_config(installation_info):
	"""
	An installer task that merges a Kube config into ~/.kube/config

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	cluster_name = installation_info["installation_target"]
	config_file_name = f"{HOMEDIR}/.kube/config.{cluster_name}"
	admin_name = f"kubernetes-admin+{cluster_name}"
	context_name = f"{admin_name}@{cluster_name}"

	with open(config_file_name, "r", encoding = "utf-8") as f:
		d2 = yaml.safe_load(f)

	if os.path.exists(f"{HOMEDIR}/.kube/config"):
		with open(f"{HOMEDIR}/.kube/config", "r", encoding = "utf-8") as f:
			d1 = yaml.safe_load(f)
	else:
		d1 = dict(d2)
		# We'll be renaming things anyway, so instead of using a lot of special casing below we just empty
		# these fields
		d1["clusters"] = []
		d1["contexts"] = []
		d1["current-context"] = context_name
		d1["users"] = []

	for cluster in d1["clusters"]:
		if cluster_name == cluster["name"]:
			iktprint([("Error:", "error"), (" A cluster named ", "default"), (cluster_name, "hostname"), (" already exists in ", "default"), (f"{HOMEDIR}/.kube/config", "path"), ("; manual merge is necessary.", "default")], stderr = True)
			return

	for user in d1["users"]:
		if admin_name == user["name"]:
			iktprint([("Error:", "error"), (" A user named ", "default"), (admin_name, "hostname"), (" already exists in ", "default"), (f"{HOMEDIR}/.kube/config", "path"), ("; manual merge is necessary.", "default")], stderr = True)
			return

	for context in d1["contexts"]:
		if context_name == context["name"]:
			iktprint([("Error:", "error"), (" A context named ", "default"), (context_name, "hostname"), (" already exists in ", "default"), (f"{HOMEDIR}/.kube/config", "path"), ("; manual merge is necessary.", "default")], stderr = True)
			return

	cad = d2["clusters"][0]["cluster"].get("certificate-authority-data")
	server = d2["clusters"][0]["cluster"]["server"]
	insecure_skip_tls_verify = d2["clusters"][0]["cluster"].get("insecure-skip-tls-verify")
	cluster = {
		"cluster": {
			"server": server,
		},
		"name": cluster_name,
	}
	if cad is not None:
		cluster["cluster"]["certificate-authority-data"] = cad
	if insecure_skip_tls_verify is not None:
		cluster["cluster"]["insecure-skip-tls-verify"] = insecure_skip_tls_verify

	d1["clusters"].append(cluster)

	context = {
		"context": {
			"cluster": cluster_name,
			"user": admin_name,
		},
		"name": context_name,
	}
	d1["contexts"].append(context)

	ccd = d2["users"][0]["user"].get("client-certificate-data")
	ckd = d2["users"][0]["user"].get("client-key-data")
	token = d2["users"][0]["user"].get("token")
	user = {
		"user": {
		},
		"name": admin_name,
	}
	if ccd is not None:
		user["user"]["client-certificate-data"] = ccd
	if ckd is not None:
		user["user"]["client-key-data"] = ckd
	if token is not None:
		user["user"]["token"] = token

	d1["users"].append(user)

	with open(f"{HOMEDIR}/.kube/config", "w", encoding = "utf-8") as f:
		f.write(yaml.dump(d1, default_flow_style = False, sort_keys = False))

	check_and_print_status(True)

def __task_setup_kubeadm_cni(installation_info):
	"""
	An installer task that sets up a CNI

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	cluster_name = installation_info["installation_target"]
	cni = installation_info[cluster_name]["cni"]
	pod_network_cidr = installation_info[cluster_name]["pod_network_cidr"]
	admin_name = f"kubernetes-admin+{cluster_name}"
	context_name = f"{admin_name}@{cluster_name}"

	# If everything is successful so far we deploy the pod network
	__setup_cni(cni, pod_network_cidr, context_name, cluster_name)

# pylint: disable-next=unused-argument
def __task_drain_control_planes(installation_info):
	"""
	An installer task that drains control plains

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	controlplanes = __selection_control_planes()

	# Check if there's an API-server running that will listen to our request;
	# drain is issued during teardown--so if we're resuming a teardown the cluster
	# might already be partially deconfigured
	# XXX: This should be done on the control plane(s), not on localhost
	args = ["/usr/bin/sudo", "/usr/bin/lsof", "-i", "-P", "-n"]
	response = execute_command_with_response(args)
	running = False
	for line in response.splitlines():
		if "6443 (LISTEN)" in line:
			running = True
			break
	if running == False:
		check_and_print_status(True)
		return

	kubectl_major_version, kubectl_minor_version, _kubectl_git_version, _server_major_version, _server_minor_version, _server_git_version = kubectl_get_version()

	# Build the drain command line based on what version of kubectl is installed
	args = ["/usr/bin/kubectl", "drain", "--ignore-daemonsets"]
	if kubectl_major_version >= 1 and kubectl_minor_version >= 20:
		args.append("--delete-emptydir-data")
	else:
		args.append("--delete-local-data")
	if kubectl_major_version >= 1 and kubectl_minor_version >= 18:
		args.append("--disable-eviction")

	for controlplane in controlplanes:
		check_and_print_status(execute_command(args + [controlplane]))

# pylint: disable-next=unused-argument
def __task_uncordon_control_planes(installation_info):
	"""
	An installer task that uncordons control planes

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	controlplanes = __selection_control_planes()

	from kubernetes_helper import KubernetesHelper # pylint: disable=import-outside-toplevel
	kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

	for controlplane in controlplanes:
		iktprint([(f"  {controlplane}:", "hostname")])
		message, status = kh.uncordon_node(controlplane)
		if status in (200, 204):
			iktprint([("    Uncordoned", "success")])
			print(message)
		elif status == 42503:
			iktprint([("\n  Critical: ", "critical"), ("Cluster not available; aborting", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		else:
			iktprint([("\n  API call returned error:", "error")], stderr = True)
			iktprint([(f"    {message}", "error")], stderr = True)
			sys.exit(errno.EINVAL)

# pylint: disable-next=unused-argument
def __task_run_preupgrade_playbooks_on_localhost(installation_info):
	"""
	An installer task that runs pre-upgrade playbooks on localhost

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	selection = __selection_localhost()
	playbooks = populate_playbooks_from_paths(upgrade_control_plane_targets["localhost"]["playbooks"])
	extra_values = {
		"packages": upgrade_control_plane_targets["localhost"].get("deb_packages", []),
		"held_packages": upgrade_control_plane_targets["localhost"].get("deb_packages_held", []),
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

# pylint: disable-next=unused-argument
def __task_run_preupgrade_playbooks_on_control_planes(installation_info):
	"""
	An installer task that runs pre-upgrade playbooks on control planes

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	selection = __selection_control_planes()
	paths = __playbook_paths_from_path(os.path.join(IKT_HOOKS_DIR, "pre-upgrade.d"))
	playbooks = populate_playbooks_from_paths(paths)
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = {})

# Run upgrade playbooks on control planes
def __task_run_upgrade_playbooks_on_control_planes(installation_info):
	"""
	An installer task that runs upgrade playbooks on control planes

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	requested_version = installation_info[cluster_name]["requested_version"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(upgrade_control_plane_targets[distro]["playbooks"])
	extra_values = {
		"packages": upgrade_control_plane_targets[distro].get("deb_packages", []),
		"held_packages": upgrade_control_plane_targets[distro].get("deb_packages_held", []),
		"requested_control_plane_k8s_version": requested_version,
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

# pylint: disable-next=unused-argument
def __task_run_postupgrade_playbooks_on_control_planes(installation_info):
	"""
	An installer task that runs post-upgrade playbooks on control planes

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	selection = __selection_control_planes()
	paths = __playbook_paths_from_path(os.path.join(IKT_HOOKS_DIR, "post-upgrade.d"))
	playbooks = populate_playbooks_from_paths(paths)
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = {})

# pylint: disable-next=unused-argument
def __task_verify_that_cluster_has_no_nodes(installation_info):
	"""
	An installer task that verifies that no non-control plane nodes remain in the cluster

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	node_statuses, _kh = __get_node_info()

	if node_statuses is not None:
		for node in node_statuses:
			if "control-plane" not in node["roles"]:
				iktprint([("\nPlease delete all nodes (except the ", "warning"), ("control plane", "emphasis"), (") from the cluster before attempting a teardown.", "warning")])
				sys.exit(errno.EAGAIN)

	iktprint([("OK", "ok")])

# Run teardown playbooks on control planes
def __task_run_teardown_playbooks_on_control_planes(installation_info):
	"""
	An installer task that runs teardown playbooks on control planes

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(teardown_control_plane_targets[distro]["playbooks"])
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = {})

def __task_remove_kube_config(installation_info):
	"""
	An installer task that removes a cluster configuration from ~/.kube/config

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	cluster_name = installation_info["installation_target"]
	admin_name = f"kubernetes-admin+{cluster_name}"
	context_name = f"{admin_name}@{cluster_name}"
	d1 = None

	if not os.path.exists(f"{HOMEDIR}/.kube"):
		check_and_print_status(True)

	if os.path.exists(f"{HOMEDIR}/.kube/config.{cluster_name}"):
		os.remove(f"{HOMEDIR}/.kube/config.{cluster_name}")

	if os.path.isfile(f"{HOMEDIR}/.kube/config"):
		with open(f"{HOMEDIR}/.kube/config", "r", encoding = "utf-8") as f:
			d1 = yaml.safe_load(f)

		# This isn't perfect--there might be leftover users and contexts belonging to this cluster;
		# but we better not go on a killing spree--better leave cruft behind than remove everything.
		for i in range(0, len(d1["clusters"])):
			if d1["clusters"][i].get("name") == cluster_name:
				d1["clusters"].pop(i)
				break
		for i in range(0, len(d1["users"])):
			if d1["users"][i].get("name") == admin_name:
				d1["users"].pop(i)
				break
		for i in range(0, len(d1["contexts"])):
			if d1["contexts"][i].get("name") == context_name:
				d1["contexts"].pop(i)
				break

	# If there's no cluster left, remove the config completely
	if d1 is None or len(d1["clusters"]) == 0:
		os.remove(f"{HOMEDIR}/.kube/config")
		_dir = os.listdir(f"{HOMEDIR}/.kube")
		try:
			_dir.remove("cache")
		except ValueError:
			pass
		try:
			_dir.remove("http-cache")
		except ValueError:
			pass

		# If there's nothing else than the cache subdirectories in .kube, remove .kube too
		if len(_dir) == 0:
			shutil.rmtree(f"{HOMEDIR}/.kube")
	else:
		# Set the context to the first remaining context, if any
		if len(d1["contexts"]) > 0:
			d1["current-context"] = d1["contexts"][0]["name"]

		with open(f"{HOMEDIR}/.kube/config", "w", encoding = "utf-8") as f:
			f.write(yaml.dump(d1, default_flow_style = False, sort_keys = False))

	check_and_print_status(True)

# Run purge playbooks on control planes
def __task_run_purge_playbooks_on_control_planes(installation_info):
	"""
	An installer task that runs purge playbooks on control planes

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(purge_control_plane_targets[distro]["playbooks"])
	extra_values = {
		"packages": purge_control_plane_targets[distro].get("deb_packages", []),
		"held_packages": purge_control_plane_targets[distro].get("deb_packages_held", []),
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

def __validate_task_index(tasks, task):
	"""
	Helper that validates the installer task index
		Parameters:
			tasks (list[str]): A list of tasks
			task (int): An integer index
		Returns:
			task (int): The integer index on success; exits if the task is out of range
	"""

	try:
		task = int(task)
	except ValueError as e:
		iktprint([("Error:", "error"), (" TASK", "argument"), (f" needs to be an integer index in the range [0, {len(tasks) - 1}]. Aborting.", "default")], stderr = True)
		sys.exit(f"Exception: {e}")

	if task < 0 or task >= len(tasks):
		iktprint([("Error:", "error"), (" TASK", "argument"), (f" needs to be in the range [0, {len(tasks) - 1}]. Aborting.", "default")], stderr = True)
		sys.exit(errno.ERANGE)
	return task

def __list_phases(phases):
	"""
	Helper that lists installation phases
	"""

	for i, phase in enumerate(phases):
		tmp = [(f"{str(i).rjust(2)}: ", "emphasis")]
		tmp += phase[0]
		iktprint(tmp)

def __expand_index_list(index_list):
	indexes = set()

	for index in index_list.split(","):
		try:
			if "-" in index:
				first, last = index.split("-")
				first = int(first)
				last = int(last)
			else:
				first = int(index)
				last = first
		except ValueError as e:
			iktprint([("Error:", "error"), (f" {index}", "argument"), (" is not an integer or range of integers. Aborting.", "default")], stderr = True)
			sys.exit(f"Exception: {e}")
		for i in range(first, last + 1):
			indexes.add(i)
	return indexes

def __format_none(string, fmt):
	if string is None or string == "<none>":
		__string = ("<none>", "none")
	else:
		__string = (string, fmt)
	return __string

prepare_tasks = [
	([("Check for ssh host key and create if needed", "action")], __task_check_and_create_ssh_key),
	([("Add ssh keys for localhost and the control plane(s) to ", "action"), (f"{HOMEDIR}/.ssh/known_hosts", "path")], __task_scan_and_add_ssh_keys),
	([("Add public ssh keys to ", "action"), (f"{HOMEDIR}/.ssh/authorized_keys", "path")], __task_check_and_add_ssh_keys_to_authorized_keys),
	([("Add public ssh keys to inventory", "action")], __task_add_ssh_keys_to_inventory),
	([("Request the ansible password if necessary", "action")], __task_request_ansible_password),
	([("Install ", "action"), ("ansible.posix", "programname"), (" if necessary", "action")], __task_check_and_install_ansible_posix),
	([("Run playbooks on ", "action"), ("localhost", "hostname")], __task_run_preparation_playbooks_on_localhost),
	([("Run playbooks on ", "action"), ("control planes", "hostname")], __task_run_preparation_playbooks_on_control_planes),
]

__setup_kubeadm_control_plane_tasks = [
	([("Run playbooks on ", "action"), ("localhost", "hostname")], __task_run_setup_playbooks_on_localhost),
	([("Setup ", "action"), ("bash completion", "emphasis"), (" for ", "action"), ("kubectl", "programname")], __task_setup_bash_completion),
	([("Run playbooks on ", "action"), ("control planes", "hostname")], __task_run_setup_playbooks_on_control_planes),
	([("Import kube config", "action")], __task_import_kube_config),
	([("Setup ", "action"), ("kubeadm", "programname"), (" Container Network Interface (CNI)", "action")], __task_setup_kubeadm_cni),
]

setup_control_plane_tasks = __setup_kubeadm_control_plane_tasks

upgrade_control_plane_tasks = [
	([("Drain the ", "action"), ("control planes", "hostname")], __task_drain_control_planes),
	([("Run pre-upgrade playbooks on ", "action"), ("localhost", "hostname")], __task_run_preupgrade_playbooks_on_localhost),
	([("Run pre-upgrade playbooks on ", "action"), ("control planes", "hostname")], __task_run_preupgrade_playbooks_on_control_planes),
	([("Run upgrade playbooks on ", "action"), ("control planes", "hostname")], __task_run_upgrade_playbooks_on_control_planes),
	([("Run post-upgrade playbooks on ", "action"), ("control planes", "hostname")], __task_run_postupgrade_playbooks_on_control_planes),
	([("Uncordon the ", "action"), ("control planes", "hostname")], __task_uncordon_control_planes),
]

teardown_control_plane_tasks = [
	([("Verify that only ", "action"), ("control planes", "hostname"), (" remain in the cluster", "action")], __task_verify_that_cluster_has_no_nodes),
	([("Drain the ", "action"), ("control planes", "hostname")], __task_drain_control_planes),
	([("Run teardown playbooks on ", "action"), ("control planes", "hostname")], __task_run_teardown_playbooks_on_control_planes),
	([("Remove kube config", "action")], __task_remove_kube_config),
]

purge_control_plane_tasks = [
	([("Run purge playbooks on ", "action"), ("control planes", "hostname")], __task_run_purge_playbooks_on_control_planes),
]

def run_tasks(tasks, phase, phase_skiplist, final_state):
	"""
	Run tasks

		Parameters:
			tasks list[(themestring, task)]: A list of tasks containing tuples of describing the task (in form of a themestr) and a function reference
			phase (int): The installation phase
			phase_skiplist (set(phase)): A set of phases to skip
			final_state (str): The state to set if the task completes successfully
	"""

	installation_info = get_installation_info()

	if isinstance(phase, int):
		phase = 0

	for i in range(phase, len(tasks)):
		iktprint([("\n• ", "separator")] + tasks[i][0])
		if i not in set(phase_skiplist):
			tasks[i][1](installation_info)
		if i < len(tasks) - 1:
			installation_info = update_installation_info(phase = i)
		else:
			update_installation_info(state = final_state, phase = "<done>")

def __find_requested_version(distro, version = None):
	"""
	Based on a provided version, try to find a matching package;
	Passing None will give the latest version, passing major, minor will give the latest patch revision of that version.
	Passing an exact version will give that version.

		Parameters:
			distro (str): Currently only kubeadm is supported
			version (str): The requested version string or version substring
		Returns:
			requested_version (str): The best matching package version
	"""

	requested_version = None

	if distro == "kubeadm":
		# If version is an exact match for a package version, use it.
		# If version is a match for a package version with the package revision ("-nn") removed, use the latest matching package revision.
		# If no version is specified, use the latest package revision.
		versions = check_deb_versions(["kubeadm"])

		if len(versions) == 0:
			iktprint([("Critical: ", "critical"), ("No candidate version for ", "default"), ("kubeadm", "programname"), (" available; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		elif version is not None:
			# The list is sorted in falling order, so the first match is the one we want, since that's the newest package revision.
			for package_version in versions[0][3]:
				if package_version.split("-")[0] == version:
					requested_version = package_version
					break
				if package_version.split(".")[0] + "." + package_version.split(".")[1] == version:
					requested_version = package_version
					break
				if version.split(".")[0] == version and package_version.split(".")[0] == version:
					requested_version = package_version
					break
		else:
			requested_version = versions[0][2]
			if len(requested_version) == 0:
				requested_version = versions[0][1]

		if requested_version is None:
			iktprint([("Error:", "error"), (" Could not find a matching kubeadm package for version ", "default"), (version, "version"), ("; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
	else:
		raise Exception("No support for other distros implemented")

	_major, minor, _patchrev = requested_version.split(".")
	if int(minor) < 11:
		iktprint([("Error:", "error"), (" Kubernetes versions older than ", "default"), ("1.11", "version"), (" are not supported by ", "default"), (f"{about.PROGRAM_SUITE_NAME}", "programname"), ("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)
	elif int(minor) < 18:
		iktprint([("Warning:", "warning"), (" Kubernetes versions older than ", "default"), ("1.18", "version"), (" are not fully supported by ", "default"), (f"{about.PROGRAM_SUITE_NAME}", "programname"), (". Some features may be missing or completely broken.", "default")], stderr = True)

	return requested_version

def prepare_installation(options, args):
	"""
	Install and configure pre-requisites for a control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Options to use when executing this action
	"""

	global no_password # pylint: disable=global-statement
	confirm = True

	# We don't need a cluster name for --list-tasks, so check this first of all
	if "--list-tasks" in (tmp[0] for tmp in options):
		__list_phases(prepare_tasks)
		sys.exit(0)
	elif len(args) == 0:
		iktprint([(f"{about.ADMIN_PROGRAM_NAME}", "programname"), (": “", "default"), ("prepare", "command"), ("“ requires at least 1 arguments.", "default")], stderr = True)
		iktprint([("Try “", "default"), (f"{about.ADMIN_PROGRAM_NAME} ", "programname"), ("help", "command"), ("“ for more information.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	# Always require the user to specify the name of the cluster to operate against, even when resuming prepare;
	# this avoids a lot of hairy corner-cases and attempts to figure out what cluster the user intended to operate against
	cluster_name = args[0]

	installation_info = get_installation_info(cluster_name = cluster_name)
	distro = "kubeadm"
	requested_version = installation_info[cluster_name]["requested_version"]
	state = installation_info[cluster_name]["state"]
	phase = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])

	if state is not None and state not in ("<none>", "preparing", "prepared"):
		iktprint([("Error:", "error"), (" Invalid installation state; the system cannot be in a configured or semi-configured state when running prepare; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if phase == "<none>":
		phase = 0

	hostname = socket.gethostname()

	# default options
	installation_info = update_installation_info(cluster_name = cluster_name, distro = distro, requested_version = requested_version, state = "preparing", phase = phase)

	__controlplanes = get_control_planes(fail_on_empty = False)
	controlplanes = [controlplane[0] for controlplane in __controlplanes]
	if len(controlplanes) == 0 and "--control-plane" not in (tmp[0] for tmp in options):
		retval = iktinput([("\nWarning: ", "warning"), ("No control plane defined in the inventory; do you want to add ", "default"), (f"{hostname}", "hostname"), (" as control plane? (No will abort the installation) [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			iktprint([("\nAborting:", "error"), (" No available control plane in inventory.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		else:
			ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [hostname], group = "controlplane", skip_all = False)
			ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [hostname], group = cluster_name, skip_all = True)

	cri = None

	for opt, optarg in options:
		if opt == "--control-plane":
			ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [optarg], group = "controlplane", skip_all = False)
			ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [optarg], group = cluster_name, skip_all = True)
		elif opt == "--no-password":
			no_password = True
		elif opt == "--start-at-task":
			phase = __validate_task_index(prepare_tasks, optarg)
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(prepare_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				iktprint([("Warning: ", "warning"), ("Ignoring request to resume a completed preparation. Exiting.")], stderr = True)
				sys.exit(0)

			else:
				phase = __validate_task_index(prepare_tasks, phase)
		elif opt == "--save-ansible-logs":
			ansible_configuration["save_logs"] = True
		elif opt == "--cri":
			if optarg in ("dockershim", "containerd", "manual"):
				cri = optarg
			else:
				iktprint([("Error:", "error"), (" Unknown CRI “", "default"), (optarg, "argument"), ("“ specified; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)
		elif opt == "-Y":
			confirm = False
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	if len(args) > 1:
		_version = args[1].split(".")
		if len(_version) == 1 or len(_version) >= 2 and int(_version[1]) >= 24:
			if cri == "dockershim":
				iktprint([("Error:", "error"), (" CRI cannot be “", "default"), ("dockershim", "argument"), ("“ for ", "default"), ("Kubernetes ", "programname"), (">= ", "default"), ("1.24", "version"), ("; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)
			elif cri is None:
				cri = "containerd"
		else:
			if cri is None:
				cri = "dockershim"
	else:
		if cri is None:
			cri = "containerd"
		elif cri == "dockershim":
			iktprint([("Error:", "error"), (" CRI cannot be “", "default"), ("dockershim", "argument"), ("“ for ", "default"), ("Kubernetes ", "programname"), (">= ", "default"), ("1.24", "version"), ("; aborting.", "default")], stderr = True)
			sys.exit(errno.EINVAL)

	installation_info = update_installation_info(cri = cri)
	show_configuration()

	if confirm == True:
		retval = iktinput([("\nStart control plane preparation? [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			iktprint([("\nAborting:", "error"), (" User stopped control plane preparation.", "default")], stderr = True)
			os.remove(IKT_INSTALLATION_INFO_FILE)
			sys.exit(errno.EINTR)

	iktprint([("\n[Preparing localhost and control plane(s)]", "phase")])

	run_tasks(tasks = prepare_tasks, phase = phase, phase_skiplist = phase_skiplist, final_state = "prepared")

	iktprint([("\n• ", "separator"), ("Updating installation information", "action")])

	# Adjust the kube* packages for the control plane(s) and localhost to match the requested cluster version if necessary;
	# we couldn't do this before since the apt repository wasn't available then
	if len(args) > 1:
		requested_version = __find_requested_version(distro, args[1])
	else:
		requested_version = __find_requested_version(distro)

	iktprint([("   Requested version: ", "action"), (requested_version, "version")])
	update_installation_info(requested_version = requested_version)

	iktprint([("\nControl plane preparation successful", "success")])
	print("\nNext step:")
	iktprint([("• ", "separator"), (f"{about.ADMIN_PROGRAM_NAME}", "programname"), (" setup-control-plane ", "command"), ("[", "separator"), ("CNI", "argument"), ("]", "separator"), (" [", "separator"), ("POD_NETWORK_CIDR", "argument"), ("]", "separator")])
	iktprint([("\nSee “", "separator"), (f"{about.ADMIN_PROGRAM_NAME}", "programname"), (" help", "command"), ("“ for more information about valid ", "default"), ("CNI", "argument"), (" options.\n", "default")])

def import_cluster(options, args):
	"""
	Import an existing cluster to iKT

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Options to use when executing this action
	"""

	global no_password # pylint: disable=global-statement

	# default options
	confirm = True

	for opt, _optarg in options:
		if opt == "-Y":
			confirm = False
		elif opt == "--no-password":
			no_password = True

	from kubernetes_helper import KubernetesHelper # pylint: disable=import-outside-toplevel
	kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)
	clusters = kh.list_clusters()
	available_clusters = [tmp[0] for tmp in clusters]

	pad = len("Cluster:")
	match = False
	for cluster_name, context in clusters:
		if len(args) > 0 and cluster_name not in args[0].split(","):
			continue
		pad = max(len(cluster_name), pad)
		match = True

	if len(args) > 0:
		for cluster in args[0].split(","):
			if cluster not in available_clusters and match == True:
				iktprint([("Warning: ", "warning"), ("Ignoring non-existing cluster ", "default"), (cluster, "hostname"), ("\n", "default")], stderr = True)

	if match == False:
		iktprint([("Error:", "error"), (" No matching clusters found; available clusters are:", "default")], stderr = True)
		for cluster in available_clusters:
			iktprint([("• ", "separator"), (cluster, "hostname")])
		iktprint([("\nAborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	iktprint([("Cluster:", "header"), ("".ljust(pad + 2 - len("Cluster:")), "default"), ("Context:", "header")])
	for cluster_name, context in clusters:
		if len(args) > 0 and cluster_name not in args[0]:
			continue
		iktprint([(cluster_name, "hostname"), ("".ljust(pad + 2 - len(cluster_name)), "default"), (context, "default")])

	if confirm == True:
		retval = iktinput([("\nImport the following clusters? [y/", "default"), ("N", "emphasis"), ("]: ", "default")])

		if retval.lower() not in ("y", "yes"):
			iktprint([("\nAborting:", "error"), (" User stopped cluster import.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	iktprint([("\n[Importing cluster(s)]", "phase")])

	# Since the clusters might use different versions of Kubernetes
	# we always install the latest kubectl on localhost, so no need to adjust version

	contexts = kh.list_contexts()
	current_context = None
	for context in contexts:
		if context[0] == True:
			current_context = context[1]

	for cluster_name, context in clusters:
		if len(args) > 0 and cluster_name not in args[0]:
			continue

		kh.set_context(context)

		vlist, _status = kh.get_list_by_kind_namespace(("Node", ""), "")

		controlplane = None

		for node in vlist:
			node_name = deep_get(node, "metadata#name")
			node_roles = kh.get_node_roles(node)
			if "control-plane" in node_roles:
				controlplane = node_name
				break

		if controlplane is None:
			iktprint([("Error:", "error"), (" Could not find a control plane for the cluster ", "default"), (cluster_name, "hostname"), ("; aborting.", "default")], stderr = True)
			# Remember to restore current-context
			kh.set_context(current_context)
			sys.exit(errno.ENOENT)

		__task_request_ansible_password(None)

		extra_values = {
			"ansible_become_pass": deep_get(ansible_configuration, "ansible_password"),
			"ansible_ssh_pass": deep_get(ansible_configuration, "ansible_password"),
		}

		install_ansible_posix()

		retval, ansible_results = run_playbook(f"{ANSIBLE_PLAYBOOK_DIR}/prepare_passwordless_ansible.yaml", hosts = [controlplane], extra_values = extra_values, quiet = True)
		if retval != 0:
			break

		cni = kh.identify_cni()
		if len(cni) != 1:
			cni = "<unknown>"
		else:
			cni = cni[0][0]

		retval, ansible_results = run_playbook(f"{ANSIBLE_PLAYBOOK_DIR}/get_versions.yaml", hosts = [controlplane], extra_values = extra_values, quiet = True)
		distro = "<unknown>"
		version = "<unknown>"
		if retval == 0:
			for host in ansible_results: # pylint: disable=consider-using-dict-items
				if str(host) != controlplane:
					continue

				data = ansible_results[host]["TASK: package versions"]["msg"].splitlines()
				for package in data:
					if package.startswith("kubeadm:"):
						distro = "kubeadm"
						version = package.split(" ")[1]
						break
				break

		update_installation_info(cluster_name = cluster_name, distro = distro, version = version, requested_version = "<none>", cni = cni, state = "installed", phase = "<none>", pod_network_cidr = "<FIXME>")

	kh.set_context(current_context)

	iktprint([("\nCluster import successful", "success")])

# pylint: disable-next=unused-argument
def check_for_updates(options, args):
	"""
	Check whether there are newer versions of packages that are related to the cluster

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Options to use when executing this action
	"""

	# default options
	update_cache = True

	for opt, _optarg in options:
		if opt == "--no-cache-update":
			update_cache = False
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	iktprint([("\n[Checking for software updates]", "phase")])

	if update_cache == True:
		iktprint([("\n• ", "separator"), ("Updating APT cache", "action")])
		check_and_print_status(update_apt_cache())

	deb_packages = [
		"ansible",
		"ansible-mitogen",
		"containerd",
		"containerd.io",
		"cri-tools",
		"kubeadm",
		"kubectl",
		"kubelet",
		"kubernetes-cni",
		"kubernetes-client",
		"kubernetes-master",
		"kubernetes-node",
		"docker.io",
		"docker-ce",
		"python3-ansible-runner",
		"python3-natsort",
		"python3-openssl",
		"python3-paramiko",
		"python3-pip",
		"python3-ujson",
		"python3-urllib3",
		"runc",
	]

	version_checks = []

	print()
	check_versions(deb_packages, version_checks)
	print()

def show_configuration():
	"""
	Show cluster configuration
	"""

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	version = installation_info[cluster_name]["version"]
	requested_version = installation_info[cluster_name]["requested_version"]
	cni = installation_info[cluster_name]["cni"]
	pod_network_cidr = installation_info[cluster_name]["pod_network_cidr"]
	cri = installation_info[cluster_name]["cri"]

	controlplanes = get_control_planes()

	http_proxy = deep_get(iktconfig, "Network#http_proxy", "")
	if http_proxy is not None and http_proxy == "":
		http_proxy = None
	http_proxy_env = os.getenv("http_proxy")
	if http_proxy_env is not None and http_proxy_env == "":
		http_proxy_env = None
	https_proxy = deep_get(iktconfig, "Network#https_proxy", "")
	if https_proxy is not None and https_proxy == "":
		https_proxy = None
	https_proxy_env = os.getenv("https_proxy")
	if https_proxy_env is not None and https_proxy_env == "":
		https_proxy_env = None
	no_proxy = deep_get(iktconfig, "Network#no_proxy", "")
	if no_proxy is not None and no_proxy == "":
		no_proxy = None
	no_proxy_env = os.getenv("no_proxy")
	if no_proxy_env is not None and no_proxy_env == "":
		no_proxy_env = None

	iktprint([("\n[Summary]", "phase")])
	iktprint([("\n• ", "separator"), ("Configuration:", "action")])
	iktprint([("        cluster name: ", "action"), (f"{cluster_name}", "hostname")])
	iktprint([("        distribution: ", "action"), (f"{distro}", "programname")])
	iktprint([("   installed version: ", "action"), __format_none(version, "version")])
	if requested_version is not None and requested_version != "<none>":
		iktprint([("   requested version: ", "action"), __format_none(requested_version, "version")])
	if cni is not None and cni != "<none>":
		iktprint([("                 CNI: ", "action"), (f"{cni}", "programname")])
	if pod_network_cidr is not None and pod_network_cidr != "<none>":
		iktprint([("    Pod Network CIDR: ", "action"), (f"{pod_network_cidr}", "emphasis")])
	if cri is not None and cri != "<none>":
		iktprint([("                 CRI: ", "action"), (f"{cri}", "programname")])
	iktprint([("          HTTP Proxy: ", "action"), __format_none(http_proxy, "url"), (" (", "default"), (f"{IKT_CONFIG_FILE}", "path"), (")", "default")])
	iktprint([("          HTTP Proxy: ", "action"), __format_none(http_proxy_env, "url"), (" (Environment)", "default")])
	iktprint([("         HTTPS Proxy: ", "action"), __format_none(https_proxy, "url"), (" (", "default"), (f"{IKT_CONFIG_FILE}", "path"), (")", "default")])
	iktprint([("         HTTPS Proxy: ", "action"), __format_none(https_proxy_env, "url"), (" (Environment)", "default")])
	iktprint([("            No Proxy: ", "action"), __format_none(no_proxy, "url"), (" (", "default"), (f"{IKT_CONFIG_FILE}", "path"), (")", "default")])
	iktprint([("            No Proxy: ", "action"), __format_none(no_proxy_env, "url"), (" (Environment)", "default")])
	if len(controlplanes) > 0:
		iktprint([("\n• ", "separator"), ("Control plane(s):", "action")])
		for controlplane in controlplanes:
			iktprint([("            hostname: ", "action"), (f"{controlplane[0]} ", "emphasis"), ("(", "default"), (f"{controlplane[1]}", "emphasis"), (")", "default")])

def setup_control_plane(options, args):
	"""
	Setup a control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Options to use when executing this action
	"""

	confirm = True

	# We don't need a cluster name for --list-tasks, so check this first of all
	if "--list-tasks" in (tmp[0] for tmp in options):
		__list_phases(setup_control_plane_tasks)
		sys.exit(0)

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	requested_version = installation_info[cluster_name]["requested_version"]
	state = installation_info[cluster_name]["state"]
	phase = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])
	cni = installation_info[cluster_name]["cni"]

	if state is not None and state in ("installed", "upgrading", "tearing_down", "torn_down", "purging"):
		iktprint([("Error:", "error"), (" Invalid installation state; there is a partial or full installation already; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)
	elif state is None or state == "preparing":
		iktprint([("Error:", "error"), (" The system is not prepared for installation yet; run ", "default"), (f"{about.ADMIN_PROGRAM_NAME}", "programname"), (" prepare", "command"), (" before continuing. Aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if state == "prepared":
		phase = 0

	for opt, optarg in options:
		if opt == "--start-at-task":
			phase = __validate_task_index(setup_control_plane_tasks, optarg)
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(setup_control_plane_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				iktprint([("Warning: ", "warning"), ("Ignoring request to resume a completed installation. Exiting.")], stderr = True)
				sys.exit(0)

			phase = __validate_task_index(setup_control_plane_tasks, phase)
		elif opt == "--save-ansible-logs":
			ansible_configuration["save_logs"] = True
		elif opt == "-Y":
			confirm = False
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	if cni is None or cni == "<none>":
		if len(args) == 0:
			iktprint([("Warning: ", "warning"), ("No CNI specified; defaulting to ", "default"), (f"{DEFAULT_CNI}", "programname"), (".", "default")], stderr = True)
			cni = DEFAULT_CNI
		elif cni != args[0]:
			cni = args[0]

	if len(args) > 1:
		pod_network_cidr = args[1]
	else:
		pod_network_cidr = DEFAULT_POD_NETWORK_CIDR

	update_installation_info(cni = cni, pod_network_cidr = pod_network_cidr, state = "installing", phase = phase, phase_skiplist = list(phase_skiplist))

	show_configuration()

	if confirm == True:
		retval = iktinput([("\nStart installation? [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			iktprint([("\nAborting:", "error"), (" User stopped installation.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	iktprint([("\n[Setting up control plane]", "phase")])

	if distro == "kubeadm":
		setup_control_plane_targets["localhost"]["deb_packages"].remove("kubectl")
		setup_control_plane_targets["localhost"]["deb_packages"].append(f"kubectl={requested_version}")
		setup_control_plane_targets["kubeadm"]["deb_packages"].remove("kubectl")
		setup_control_plane_targets["kubeadm"]["deb_packages"].append(f"kubectl={requested_version}")
		setup_control_plane_targets["kubeadm"]["deb_packages"].remove("kubeadm")
		setup_control_plane_targets["kubeadm"]["deb_packages"].append(f"kubeadm={requested_version}")
		setup_control_plane_targets["kubeadm"]["deb_packages"].remove("kubelet")
		setup_control_plane_targets["kubeadm"]["deb_packages"].append(f"kubelet={requested_version}")

	run_tasks(tasks = setup_control_plane_tasks, phase = phase, phase_skiplist = phase_skiplist, final_state = "installed")
	update_installation_info(version = requested_version)

	iktprint([("\nControl plane setup successful", "success")])

def __get_node_info(kh = None):
	if not os.path.isfile(f"{HOMEDIR}/.kube/config"):
		return None, None

	# The reason for importing inside the function is to avoid slow startup
	# when we don't use the Kubernetes helper
	if kh is None:
		from kubernetes_helper import KubernetesHelper # pylint: disable=import-outside-toplevel
		kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

	node_statuses = []

	vlist, status = kh.get_list_by_kind_namespace(("Node", ""), "")
	if status == 504:
		return None, None

	if status != 200:
		iktprint([("Error:", "error"), (" API-server returned ", "default"), (status, "errorvalue"), ("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	for node in vlist:
		node_name = deep_get(node, "metadata#name")
		node_schedulable = not deep_get(node, "spec#unschedulable", False)
		node_roles = kh.get_node_roles(node)
		node_taints = deep_get(node, "spec#taints", [])
		node_statuses.append({
			"name": node_name,
			"schedulable": node_schedulable,
			"roles": node_roles,
			"taints": node_taints,
		})

	return node_statuses, kh

def get_control_planes(fail_on_empty = True):
	"""
	Get a list of control planes defined in the inventory

		Parameters:
			fail_on_empty (bool): If True the action will fail if no control planes are defined in the inventory
		Returns:
			control_planes (list[str]): A list of control planes
	"""

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	inventory = ansible_get_inventory_dict()
	__controlplanes = deep_get(inventory, "controlplane#hosts", {})
	__clusterhosts = deep_get(inventory, f"{cluster_name}#hosts", {})
	controlplanes = []
	if len(__controlplanes) == 0 and fail_on_empty == True:
		iktprint([("Error:", "error"), (" No control plane(s) defined in the inventory; rebuilding the inventory using “", "default"), (f"{about.INVENTORY_PROGRAM_NAME} ", "programname"), ("rebuild-inventory", "command"), ("“ might help. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)
	if len(__clusterhosts) == 0 and fail_on_empty == True:
		iktprint([("Error:", "error"), (" The cluster ", "default"), (f"{cluster_name}", "hostname"), (" has no hosts in the inventory; rebuilding the inventory using “", "default"), (f"{about.INVENTORY_PROGRAM_NAME} ", "programname"), ("rebuild-inventory", "command"), ("“ might help. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	for controlplane in __controlplanes:
		# Only include control planes belonging to this cluster
		if controlplane not in __clusterhosts:
			continue
		ip = socket.gethostbyname(controlplane)
		controlplanes.append((controlplane, ip))
	return controlplanes

# pylint: disable-next=unused-argument
def teardown_control_plane(options, args):
	"""
	Teardown an existing control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Options to use when executing this action
	"""

	confirm = True

	# We don't need a cluster name for --list-tasks, so check this first of all
	if "--list-tasks" in (tmp[0] for tmp in options):
		__list_phases(teardown_control_plane_tasks)
		sys.exit(0)

	if not os.path.exists(IKT_INSTALLATION_INFO_FILE):
		iktprint([("Error:", "error"), (" Could not find reliable installation information. Aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	state = installation_info[cluster_name]["state"]
	phase = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])

	if distro is None or distro == "<none>":
		iktprint([("Error:", "error"), (" Could not find reliable installation information. Aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if state is None:
		iktprint([("Error:", "error"), (" Cannot determine installation state; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)
	elif state in ("preparing", "prepared", "torn_down"):
		iktprint([("Error:", "error"), (" The system has no installed cluster; try ", "default"), (f"{about.ADMIN_PROGRAM_NAME}", "programname"), (" purge-control-plane", "command"), ("; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	for opt, optarg in options:
		if opt == "--start-at-task":
			phase = __validate_task_index(teardown_control_plane_tasks, optarg)
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(teardown_control_plane_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				iktprint([("Warning: ", "warning"), ("Ignoring request to resume a completed teardown. Exiting.")], stderr = True)
				sys.exit(0)

			phase = __validate_task_index(setup_control_plane_tasks, phase)
		elif opt == "--save-ansible-logs":
			ansible_configuration["save_logs"] = True
		elif opt == "-Y":
			confirm = False
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	show_configuration()

	if confirm == True:
		retval = iktinput([("\nStart teardown? [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			iktprint([("\nAborting:", "error"), (" User stopped teardown.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	iktprint([("\n[Tearing down cluster]", "phase")])

	installation_info = update_installation_info(state = "tearing_down", phase = 0)

	run_tasks(tasks = teardown_control_plane_tasks, phase = phase, phase_skiplist = phase_skiplist, final_state = "torn_down")
	iktprint([("\nCluster teardown successful", "success")])

def purge_control_plane(options, args):
	"""
	Purge an existing control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Options to use when executing this action
	"""

	confirm = True

	# We don't need a cluster name for --list-tasks, so check this first of all
	if "--list-tasks" in (tmp[0] for tmp in options):
		__list_phases(purge_control_plane_tasks)
		sys.exit(0)

	if not os.path.exists(IKT_INSTALLATION_INFO_FILE):
		iktprint([("Error:", "error"), (" Could not find reliable installation information. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	state = installation_info[cluster_name]["state"]
	phase = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])

	if state is None or state in ("preparing", "installing", "upgrading"):
		iktprint([("Error:", "error"), (" Invalid installation state; there's no fully installed cluster; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if len(options) == 0:
		phase = 0

	for opt, optarg in options:
		if opt == "--start-at-task":
			phase = __validate_task_index(teardown_control_plane_tasks, optarg)
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(teardown_control_plane_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				iktprint([("Warning: ", "warning"), ("Ignoring request to resume a completed teardown. Exiting.")], stderr = True)
				sys.exit(0)

			phase = __validate_task_index(setup_control_plane_tasks, phase)
		elif opt == "--save-ansible-logs":
			ansible_configuration["save_logs"] = True
		elif opt == "-Y":
			confirm = False
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	# If there's still an installed cluster or if the teardown hasn't finished, teardown the cluster before purging
	if state in ("installed", "upgraded", "tearing_down"):
		teardown_control_plane(options, args)
		state = "torn_down"
	else:
		show_configuration()

		if confirm == True:
			retval = iktinput([("\nStart purge? [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
			if retval.lower() not in ("y", "yes"):
				iktprint([("\nAborting:", "error"), (" User stopped purge.", "default")], stderr = True)
				sys.exit(errno.EINTR)

	iktprint([("\n\n[Purging cluster configuration and software]", "phase")])

	# If we're purging the control plane we want to leave kubectl behind; if we have a setup with multiple
	# control planes and we run this from one of them, then kubectl will remain on the other two. Just don't do it.
	if __selection_localhost() == __selection_control_planes():
		purge_control_plane_targets["kubeadm"]["deb_packages"].remove("kubectl")
		purge_control_plane_targets["kubeadm"]["deb_packages_held"].remove("kubectl")

	installation_info = update_installation_info(state = "purging", phase = 0)

	run_tasks(tasks = purge_control_plane_tasks, phase = phase, phase_skiplist = phase_skiplist, final_state = "purged")
	os.remove(IKT_INSTALLATION_INFO_FILE)

	iktprint([("\nCluster purge successful", "success")])

	iktprint([("\nNote: ", "note"), ("It's recommended to reboot the control plane(s) after purging the cluster\n", "default")])

def upgrade_control_plane(options, args):
	"""
	Upgrade a control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Options to use when executing this action
	"""

	confirm = True

	# default options
	update_cache = True
	allow_reinstall = False
	requested_version = None

	# We don't need a cluster name for --list-tasks or --override, so check this first of all
	if "--list-tasks" in (tmp[0] for tmp in options):
		__list_phases(upgrade_control_plane_tasks)
		sys.exit(0)
	elif "--override" in (tmp[0] for tmp in options):
		if os.path.isfile(IKT_INSTALLATION_INFO_FILE) == True:
			iktprint([("Warning: ", "warning"), ("Overriding ", "default"), (f"{IKT_INSTALLATION_INFO_FILE}", "path"), ("; this may cause issues.", "default")], stderr = True)
		else:
			iktprint([("Note: ", "note"), (f"{IKT_INSTALLATION_INFO_FILE}", "path"), (" does not exist; rebuilding.", "default")])
		rebuild_installation_info(state = "upgrading")

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	version = installation_info[cluster_name]["version"]
	requested_version = installation_info[cluster_name]["requested_version"]
	state = installation_info[cluster_name]["state"]
	phase = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])

	if state is None or state == "<none>":
		iktprint([("Error:", "error"), (" Unknown installation state; if you believe this is OK (such as when upgrading a cluster not installed using ", "default"), (f"{about.ADMIN_PROGRAM_NAME}", "programname"), (" you can try using the “", "default"), ("--override", "option"), ("“ option; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if state is None or state in ("<none>", "preparing", "prepared", "installing", "tearing_down", "torn_down", "purging"):
		iktprint([("Error:", "error"), (" Invalid installation state; Kubernetes does not seems to be fully installed; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if state in ("installed", "upgraded"):
		phase = 0

	if len(args) > 0:
		requested_version = __find_requested_version(distro, args[0])
	else:
		requested_version = __find_requested_version(distro)

	for opt, optarg in options:
		if opt == "--start-at-task":
			phase = __validate_task_index(upgrade_control_plane_tasks, optarg)
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(upgrade_control_plane_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				iktprint([("Warning: ", "warning"), ("Ignoring request to resume a completed upgrade. Exiting.")], stderr = True)
				sys.exit(0)

			phase = __validate_task_index(upgrade_control_plane_tasks, phase)
		elif opt == "--no-cache-update":
			update_cache = False
		elif opt == "--reinstall":
			allow_reinstall = True
		elif opt in ("--override", "--list-tasks"):
			continue
		elif opt == "--save-ansible-logs":
			ansible_configuration["save_logs"] = True
		elif opt == "-Y":
			confirm = False
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	# XXX: How do we check that nodes are drained? We can check whether they are cordoned
	node_status, _kh = __get_node_info()

	if node_status is None:
		iktprint([("Error:", "error"), (" No ", "default"), (f"{HOMEDIR}/.kube/config", "path"), (" available; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	if update_cache == True:
		iktprint([("\n• ", "separator"), ("Updating APT cache", "action")])
		check_and_print_status(update_apt_cache())

	iktprint([("\n• ", "separator"), ("Running sanity checks", "action")])

	deb_versions = check_deb_versions(["kubeadm"])

	if len(deb_versions) == 0:
		iktprint([("Critical:", "critical"), (" No candidate version for ", "default"), ("kubeadm", "programname"), (" available; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	if requested_version is not None:
		if requested_version not in deb_versions[0][3]:
			iktprint([("Error:", "error"), (" The requested version ", "default"), (f"{requested_version}", "version"), (" is not available; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		elif requested_version == version:
			if allow_reinstall == False:
				iktprint([("Warning:", "warning"), (" The requested version ", "default"), (f"{requested_version}", "version"), (" is already installed; to reinstall use the option “", "default"), ("--reinstall", "option"), ("“.", "default")], stderr = True)
				sys.exit(errno.EINVAL)
		elif deb_compare_versions(version, requested_version) == True:
			iktprint([("Error:", "error"), (" The requested version ", "default"), (f"{requested_version}", "version"), (" is older than than the installed version ", "default"), (f"{deb_versions[0][1]}", "version"), (". Downgrades are not supported; aborting.", "default")], stderr = True)
			sys.exit(errno.EINVAL)
	else:
		requested_version = deb_versions[0][2]
		if len(requested_version) == 0 or requested_version == "<none>":
			iktprint([("Note: ", "ok"), ("The latest version ", "default"), (f"{deb_versions[0][1]}", "version"), (" is already installed.", "default")])
			sys.exit(0)

	# Is this an major, minor, or patchrev upgrade?
	installed_version_tuple = version.split(".")
	requested_version_tuple = requested_version.split(".")

	upgrade_type = None

	if installed_version_tuple[0] != requested_version_tuple[0]:
		iktprint([("Error:", "error"), (" Upgrades between ", "default"), ("MAJOR", "emphasis"), (" versions is currently not supported (installed version: ", "default"), (f"{deb_versions[0][1]}", "version"), (", requested version: ", "default"), (f"{requested_version}", "version"), ("; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOTSUP)
	elif installed_version_tuple[1] != requested_version_tuple[1]:
		if int(requested_version_tuple[1]) - int(installed_version_tuple[1]) > 1:
			iktprint([("Error:", "error"), (" Skipping ", "default"), ("MINOR", "emphasis"), (" versions is not supported, please perform the following upgrades sequentially:", "default")], stderr = True)
			minor_versions = {}
			for version in reversed(deb_versions[0][3]):
				version_tuple = version.split(".")
				major_minor = f"{version_tuple[0]}.{version_tuple[1]}"
				if int(version_tuple[1]) > int(installed_version_tuple[1]) and int(version_tuple[1]) <= int(requested_version_tuple[1]) and (major_minor not in minor_versions or minor_versions[major_minor] < version_tuple[2]):
					minor_versions[major_minor] = version_tuple[2]
			for version, minor_version in minor_versions.items():
				iktprint([("• ", "separator"), (f"{about.ADMIN_PROGRAM_NAME}", "programname"), (" upgrade-control-plane", "command"), (f" {version}.{minor_version}", "version")])
			sys.exit(errno.EINVAL)
		else:
			upgrade_type = "minor"
	else:
		upgrade_type = "patchrev"

	# If this is an upgrade to a new patchrev the cluster doesn't have to be drained
	if upgrade_type == "minor":
		schedulable_count = 0
		nodes_to_drain = ""
		for node in node_status:
			if node["schedulable"] == False:
				continue

			if "control-plane" in node["roles"]:
				continue

			if schedulable_count == 0:
				iktprint([("\nError:", "error"), (" The following nodes need to be drained; aborting.", "default")])
			schedulable_count += 1
			iktprint([("• ", "separator"), (f"{node['name']}", "emphasis")])
			nodes_to_drain += node['name']

		if schedulable_count > 0:
			iktprint([("\nThis can be achieved with: “", "default"), ("kubectl ", "programname"), ("drain ", "command"), ("--ignore-daemonsets --delete-emptydir-data ", "option"), (f"{nodes_to_drain}", "url"), ("“", "default")])
			sys.exit(errno.EBUSY)

	installation_info = update_installation_info(state = "upgrading", requested_version = requested_version, phase = 0)

	# If we got here all the sanity checks were successful
	iktprint([("OK", "ok")])

	# Adjust package version for localhost
	upgrade_control_plane_targets["localhost"]["deb_packages"].remove("kubectl")
	upgrade_control_plane_targets["localhost"]["deb_packages"].append(f"kubectl={requested_version}")

	show_configuration()

	if confirm == True:
		retval = iktinput([("\nStart upgrade? [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			iktprint([("\nAborting:", "error"), (" User stopped upgrade.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	iktprint([("\n[Upgrading control plane]", "phase")])

	run_tasks(tasks = upgrade_control_plane_tasks, phase = phase, phase_skiplist = phase_skiplist, final_state = "upgraded")
	values = {
		"control_plane_k8s_version": requested_version,
	}
	ansible_set_vars(ANSIBLE_INVENTORY, "all", values)
	update_installation_info(version = requested_version)

	iktprint([("\nControl plane upgrade successful", "success")])

# pylint: disable-next=unused-argument
def taint_control_plane(options, args):
	"""
	Taint a control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Options to use when executing this action
	"""

	node_statuses, kh = __get_node_info()

	if node_statuses is None:
		iktprint([("Critical: ", "critical"), ("Failed to get node information; do you have a running cluster? Aborting.", "default")], stderr = True)
		sys.exit(errno.ENXIO)

	first = True

	for node in node_statuses:
		if "control-plane" in node["roles"] and (len(args) == 0 or node["name"] in args):
			if first == True:
				iktprint([("Tainting control plane(s):", "header")])
				first = False
			iktprint([(node["name"], "hostname")])
			_message, status = kh.taint_node(node["name"], node["taints"], ("node-role.kubernetes.io/control-plane", None, None, "NoSchedule"))
			if status == 304:
				iktprint([("  Not modified", "none")])
			elif status == 200:
				iktprint([("  Tainted", "success")])
			else:
				iktprint([("  Failed to modify taint", "error"), (f"; HTTP error {status}; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)

		if "master" in node["roles"] and (len(args) == 0 or node["name"] in args):
			if first == True:
				iktprint([("Tainting control plane(s):", "header")])
				first = False
			iktprint([(node["name"], "hostname")])
			_message, status = kh.taint_node(node["name"], node["taints"], ("node-role.kubernetes.io/master", None,  None, "NoSchedule"))
			if status == 304:
				iktprint([("  Not modified", "none")])
			elif status == 200:
				iktprint([("  Tainted", "success")])
			else:
				iktprint([("  Failed to modify taint", "error"), (f"; HTTP error {status}; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)

	if first == True:
		iktprint([("Warning:", "warning"), (" No matching control planes found. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

# pylint: disable-next=unused-argument
def untaint_control_plane(options, args):
	"""
	Untaint a control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Options to use when executing this action
	"""

	node_statuses, kh = __get_node_info()

	if node_statuses is None:
		iktprint([("Critical:", "critical"), (" Failed to get node information; do you have a running cluster? Aborting.", "default")], stderr = True)
		sys.exit(errno.ENXIO)

	first = True

	for node in node_statuses:
		if "control-plane" in node["roles"] and (len(args) == 0 or node["name"] in args):
			if first == True:
				iktprint([("Untainting control plane(s):", "header")])
				first = False
			iktprint([(node["name"], "hostname")])
			_message, status = kh.taint_node(node["name"], node["taints"], ("node-role.kubernetes.io/control-plane", None,  None, None))
			if status == 304:
				iktprint([("  Not modified", "none")])
			elif status == 200:
				iktprint([("  Untainted", "success")])
			else:
				iktprint([("  Failed to modify taint", "error"), (f"; HTTP error {status}; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)

		if "master" in node["roles"] and (len(args) == 0 or node["name"] in args):
			if first == True:
				iktprint([("Untainting control plane(s):", "header")])
				first = False
			iktprint([(node["name"], "hostname")])
			_message, status = kh.taint_node(node["name"], node["taints"], ("node-role.kubernetes.io/master", None, None, None))
			if status == 304:
				iktprint([("  Not modified", "none")])
			elif status == 200:
				iktprint([("  Untainted", "success")])
			else:
				iktprint([("  Failed to modify taint", "error"), (f"; HTTP error {status}; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)

	if first == True:
		iktprint([("Warning: ", "warning"), ("No matching control planes found. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

# pylint: disable=unused-argument,redefined-outer-name
def run_checks(checks, **kwargs) -> None:
	"""
	Run a batch of checks, and output the result.
	The checks can return 4 different severities; critical, error, warning, and note.

		Parameters:
			checks (list[dict]): A list with all checks to run
	"""

	critical: int = 0
	error: int = 0
	warning: int = 0
	note: int = 0

	user = getuser()
	cluster_name = get_cluster_name()
	with open(f"{KUBE_CONFIG_FILE}", "r", encoding = "utf-8") as f:
		kubeconfig = yaml.safe_load(f)

	for check in checks:
		call = deep_get(check, DictPath("call"))
		if call is not None:
			critical, error, warning, note = call(cluster_name, kubeconfig, iktconfig, user, critical, error, warning, note, **kwargs)

	iktprint([("Summary:", "header")])
	iktprint([ ("Critical:", "critical"), (f" {critical}", "error")])
	iktprint([(f"  Errors: {error}", "error")])
	iktprint([(f"Warnings: {warning}", "warning")])
	iktprint([(f"   Notes: {note}", "note")])

security_audit_checks = [
	{
		"description": "Check whether strict host key checking has been disabled",
		"call": checks.check_security_disable_strict_host_key_checking,
	},
	{
		"description": "Check for insecure kube config options",
		"call": checks.check_insecure_kube_config_options,
	}, {
		"description": "Check for insecure file permissions",
		"call": checks.check_file_permissions,
	},
]

# pylint: disable-next=unused-argument
def audit(options, args):
	"""
	Run security audit checks

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Options to use when executing this action
	"""

	usergroup = ""

	for opt, optarg in options:
		if opt == "--usergroup":
			usergroup = optarg
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	kwargs = {
		"usergroup": usergroup
	}

	run_checks(security_audit_checks, **kwargs)

	iktprint([("\nImportant:", "emphasis"),
		  (" iktadm", "programname"), (" audit", "command"),
		  (" currently only checks for a very limited set of issues;", "default")])
	iktprint([("a perfect score is not a guarantee that your installation is secure.", "default")])

preflight_checks = [
	{
		"description": "Check whether the user can sudo without a password",
		"call": checks.check_sudo_configuration,
	}, {
		"description": "Check whether SSH known_hosts hashing is enabled",
		"call": checks.check_known_hosts_hashing,
	}, {
		"description": "Check whether docker-ce / containerd.io is installed instead of docker.io / containerd",
		"call": checks.check_containerd_and_docker,
	},
]

# pylint: disable-next=unused-argument
def preflight_check(options, args):
	"""
	Run preflight checks before creating a new cluster

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Options to use when executing this action
	"""

	run_checks(preflight_checks)

	iktprint([("\nImportant:", "emphasis"),
		  (" iktadm", "programname"), (" preflight-check", "command"),
		  (" currently only checks for a very limited set of issues;", "default")])
	iktprint([("a perfect score is not a guarantee that installation will succeed.", "default")])

troubleshoot_checks = [
	# First start with the really basic: does the cluster respond?
	# Check no_proxy, perhaps?
	{
		"description": "Check whether client / server versions match",
		"call": checks.check_client_server_version_match,
	}, {
		"description": "Check kubelet and kube-proxy versions",
		"call": checks.check_kubelet_and_kube_proxy_versions,
	},
	# Check kube-controller-manager, kube-scheduler, and cloud-controller-manager;
	# they should match, but can be up to one version older,
	# but must not be newer

	# check whether role bindings and cluster role bindings refer to non-existing roles/cluster roles
]

# pylint: disable-next=unused-argument
def troubleshoot(options, args):
	"""
	Troubleshoot issues in the cluster

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Options to use when executing this action
	"""

	run_checks(troubleshoot_checks)

	iktprint([("\nImportant:", "emphasis"),
		  (" iktadm", "programname"), (" troubleshoot", "command"),
		  (" currently only checks for a very limited set of issues;", "default")])
	iktprint([("a perfect score is not a guarantee that your cluster is problem free.", "default")])

commandline = {
	"Check Versions": {
		"command": ["check-versions", "cv"],
		"description": [("Update the package cache and show software versions", "description")],
		"extended_description": [
			[("Note: ", "note"), ("some of the listed software might not be relevant", "description")],
			[("to the configuration in use", "description")],
		],
		"options": {
			"--no-cache-update": {
				"description": [("Do not update the APT cache", "description")],
			},
		},
		"min_args": 0,
		"max_args": 0,
		"callback": check_for_updates,
	},
	"Import Cluster": {
		"command": ["import-cluster"],
		"values": [("[", "separator"), ("CLUSTER_NAME", "argument"), (",", "separator"), ("...", "argument"), ("]", "separator")],
		"description": [(f"Import existing cluster(s) and prepare them for use with {about.PROGRAM_SUITE_NAME}", "description")],
		"extended_description": [
			[("If ", "description"), ("CLUSTER_NAME", "argument"), (",", "separator"), ("...", "argument"), (" is not specified all clusters in ", "description"), (f"{HOMEDIR}/.kube/config", "path")],
			[(" will be imported", "description")],
		],
		"options": {
			"-Y": {
				"description": [("Do not ask for confirmation before performing actions", "description")],
			},
			"--no-password": {
				"description": [("Do not prompt for a password; use this if the hosts you're preparing are already configured for login using an SSH key", "description")],
			},
		},
		"min_args": 0,
		"max_args": 1,
		"callback": import_cluster,
	},
	"Prepare Installation": {
		"command": ["prepare"],
		"values": [("CLUSTER_NAME", "argument"), (" [", "separator"), ("KUBERNETES_VERSION", "argument"), ("]", "separator")],
		"description": [("Install and configure pre-requisites; run this before ", "description"), ("setup-control-plane", "command")],
		"extended_description": [
			[("If no version is specified the newest available version will be used", "description")],
		],
		"options": {
			"--control-plane": {
				"values": [("HOST", "argument")],
				"extended_description": [
					[("Note: ", "note"), ("HOST", "argument"), (" should be a resolvable hostname; using IP-addresses may cause issues.", "description")],
					[("If the host intend for use as control plane in the cluster does not have a resolvable", "description")],
					[("hostname it's recommended to use ", "description"), ("/etc/hosts", "path"), (" for this purpose.", "description")],
				],
				"description": [("Use ", "description"), ("HOST", "argument"), (" as control plane ", "description")],
				"requires_arg": True,
			},
			"--resume": {
				"description": [("Resume preparation; can be used if preparation was aborted", "description")],
			},
			"--start-at-task": {
				"values": [("TASK", "argument")],
				"description": [("Start at ", "description"), ("TASK", "argument"), (" instead of running all tasks", "description")],
				"requires_arg": True,
			},
			"--skip-tasks": {
				"values": [("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"description": [("Skip ", "description"), ("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"requires_arg": True,
			},
			"--list-tasks": {
				"description": [("List valid values for ", "description"), ("TASK", "argument"), (" to use with ", "description"), ("--start-at-task", "option"), (" and ", "description"), ("--skip-tasks", "option")],
			},
			"--no-password": {
				"description": [("Do not prompt for a password; use this if the hosts you're preparing are already configured for login using an SSH key", "description")],
			},
			"--save-ansible-logs": {
				"description": [("Save logs from Ansible runs; the logs can be viewed using “", "description"), ("iku", "programname"), (" logs", "command"), ("“", "description")]
			},
			"--cri": {
				"values": [("CRI", "argument")],
				"description": [("Use ", "description"), ("CRI", "argument"), (" instead of the default CRI", "description")],
				"extended_description": [
					[("Valid options for CRI (Container Runtime Interface) are:", "description")],
					[
						("dockershim", "argument"), (" (", "description"), ("Kubernetes", "programname"), (" < ", "description"), ("1.24", "version"), (")", "description"), (", ", "separator"),
						("containerd", "argument"), (", ", "separator"),
					],
					[
						("manual", "argument"), (" (do not install a CRI; this requires you to manually install and configure the CRI)", "description"),
					],
					[("The default CRI is ", "description"), ("dockershim", "argument"), (" for ", "description"), ("Kubernetes", "programname"), (" < ", "description"), ("1.24", "version")],
					[("and ", "description"), ("containerd", "argument"), (" for ", "description"), ("Kubernetes", "programname"), (" >= ", "description"), ("1.24", "version")],
				],
				"requires_arg": True,
			},
			"-Y": {
				"description": [("Do not ask for confirmation before performing actions", "description")],
			},
		},
		"min_args": 0,
		"max_args": 2,
		"callback": prepare_installation,
	},
	"Setup Control Plane": {
		"command": ["setup-control-plane"],
		"values": [
			("[", "separator"), ("CNI", "argument"), ("]", "separator"),
			(" [", "separator"), ("POD_NETWORK_CIDR", "argument"), ("]", "separator"),
		],
		"description": [("Setup and launch the control plane", "description")],
		"extended_description": [
			[("Valid options for CNI (Container Network Interface, aka Pod Network): ", "description")],
			[
				("antrea", "argument"), (", ", "separator"),
				("calico", "argument"), (", ", "separator"),
				("canal", "argument"), (", ", "separator"),
				("cilium", "argument"), (", ", "separator"),
				("flannel", "argument"), (", ", "separator"),
				("kube-router", "argument"), (", ", "separator"),
				("weave", "argument"),
			],
			[("By default ", "description"), ("cilium", "argument"), (" will be used as CNI", "description")],
			[("and ", "description"), ("10.244.0.0/16", "argument"), (" will be used as pod network CIDR", "description")],
		],
		"options": {
			"--resume": {
				"description": [("Resume installation; can be used if installation was aborted", "description")],
			},
			"--start-at-task": {
				"values": [("TASK", "argument")],
				"description": [("Start at ", "description"), ("TASK", "argument"), (" instead of running all tasks", "description")],
				"requires_arg": True,
			},
			"--skip-tasks": {
				"values": [("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"description": [("Skip ", "description"), ("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"requires_arg": True,
			},
			"--list-tasks": {
				"description": [("List valid values for ", "description"), ("TASK", "argument"), (" to use with ", "description"), ("--start-at-task", "option"), (" and ", "description"), ("--skip-tasks", "option")],
			},
			"--save-ansible-logs": {
				"description": [("Save logs from Ansible runs; the logs can be viewed using “", "description"), ("iku", "programname"), (" logs", "command"), ("“", "description")]
			},
			"-Y": {
				"description": [("Do not ask for confirmation before performing actions", "description")],
			},
		},
		"min_args": 0,
		"max_args": 2,
		"callback": setup_control_plane,
	},
	"Upgrade CNI": {
		"command": ["upgrade-cni"],
		"values": [("[", "separator"), ("CNI", "argument"), ("]", "separator")],
		"description": [("Upgrade the CNI", "description")],
		"extended_description": [
			[("Upgrades the CNI (currently only Cilium is supported)", "description")],
		],
		"min_args": 0,
		"max_args": 1,
		"callback": upgrade_cni,
	},
	"Upgrade Control Plane": {
		"command": ["upgrade-control-plane"],
		"values": [("[", "separator"), ("KUBERNETES_VERSION", "argument"), ("]", "separator")],
		"description": [("Upgrade the control plane", "description")],
		"extended_description": [
			[("Upgrades the control plane to ", "description"), ("KUBERNETES_VERSION", "argument"), (" if specified;", "description")],
			[("if no version is specified the newest available version will be used", "description")],
			[("Upgrading requires all nodes to be drained first. Once the control plane", "description")],
			[("has been upgraded you must upgrade all nodes to the same version.", "description")],
			[("Important", "emphasis"), (": skipping PATCH REVISIONS is acceptable,", "description")],
			[("but when upgrading to a newer MINOR version all intermediate MINOR versions", "description")],
			[("must be installed first; this applies to nodes too", "description")],
		],
		"options": {
			"--no-cache-update": {
				"description": [("Do not update the APT cache", "description")],
			},
			"--resume": {
				"description": [("Resume upgrade; can be used if upgrade was aborted", "description")],
			},
			"--start-at-task": {
				"values": [("TASK", "argument")],
				"description": [("Start at ", "description"), ("TASK", "argument"), (" instead of running all tasks", "description")],
				"requires_arg": True,
			},
			"--skip-tasks": {
				"values": [("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"description": [("Skip ", "description"), ("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"requires_arg": True,
			},
			"--list-tasks": {
				"description": [("List valid values for ", "description"), ("TASK", "argument"), (" to use with ", "description"), ("--start-at-task", "option"), (" and ", "description"), ("--skip-tasks", "option")],
			},
			"--reinstall": {
				"description": [("Allow installing an already installed Kubernetes version", "description")],
			},
			"--override": {
				"description": [("Override/rebuild installation info", "description")],
			},
			"--save-ansible-logs": {
				"description": [("Save logs from Ansible runs; the logs can be viewed using “", "description"), ("iku", "programname"), (" logs", "command"), ("“", "description")]
			},
			"-Y": {
				"description": [("Do not ask for confirmation before performing actions", "description")],
			},
		},
		"min_args": 0,
		"max_args": 1,
		"callback": upgrade_control_plane,
	},
	"Teardown Control Plane": {
		"command": ["teardown-control-plane"],
		"description": [("Tear down the control plane", "description")],
		"extended_description": [
			[("Note", "emphasis"), (": Before running this command all nodes must have been removed first", "description")],
			[("The configuration for the control plane and any software installed", "description")],
			[("during installation will NOT be removed", "description")],

		],
		"options": {
			"--resume": {
				"description": [("Resume teardown; can be used if teardown was aborted", "description")],
			},
			"--start-at-task": {
				"values": [("TASK", "argument")],
				"description": [("Start at ", "description"), ("TASK", "argument"), (" instead of running all tasks", "description")],
				"requires_arg": True,
			},
			"--skip-tasks": {
				"values": [("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"description": [("Skip ", "description"), ("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"requires_arg": True,
			},
			"--list-tasks": {
				"description": [("List valid values for ", "description"), ("TASK", "argument"), (" to use with ", "description"), ("--start-at-task", "option"), (" and ", "description"), ("--skip-tasks", "option")],
			},
			"--save-ansible-logs": {
				"description": [("Save logs from Ansible runs; the logs can be viewed using “", "description"), ("iku", "programname"), (" logs", "command"), ("“", "description")]
			},
			"-Y": {
				"description": [("Do not ask for confirmation before performing actions", "description")],
			},
		},
		"min_args": 0,
		"max_args": 0,
		"callback": teardown_control_plane,
	},
	"Purge Control Plane": {
		"command": ["purge-control-plane"],
		"description": [("Purge configuration and installed software", "description")],
		"extended_description": [
			[("purge-control-plane", "command"), (" will run ", "description"), ("teardown-control-plane", "command"), (" first if necessary", "description")],
			[("Software and configuration needed for ", "description"), (f"{about.PROGRAM_SUITE_NAME}", "programname"), (" will not be purged", "description")],

		],
		"options": {
			"--resume": {
				"description": [("Resume purge; can be used if purge was aborted", "description")],
			},
			"--start-at-task": {
				"values": [("TASK", "argument")],
				"description": [("Start at ", "description"), ("TASK", "argument"), (" instead of running all tasks", "description")],
				"requires_arg": True,
			},
			"--skip-tasks": {
				"values": [("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"description": [("Skip ", "description"), ("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"requires_arg": True,
			},
			"--list-tasks": {
				"description": [("List valid values for ", "description"), ("TASK", "argument"), (" to use with ", "description"), ("--start-at-task", "option"), (" and ", "description"), ("--skip-tasks", "option")],
			},
			"--save-ansible-logs": {
				"description": [("Save logs from Ansible runs; the logs can be viewed using “", "description"), ("iku", "programname"), (" logs", "command"), ("“", "description")]
			},
			"-Y": {
				"description": [("Do not ask for confirmation before performing actions", "description")],
			},
		},
		"min_args": 0,
		"max_args": 0,
		"callback": purge_control_plane,
	},
	"Taint Control Plane": {
		"command": ["taint-control-plane"],
		"values": [("[", "separator"), ("CONTROLPLANE", "argument"), (",", "separator"), ("...", "argument"), ("]", "separator")],
		"description": [("Mark control plane(s) as tainted", "description")],
		"extended_description": [
			[("If you have previously marked your control plane(s) as untainted", "description")],
			[("you can mark them as tainted again using this command", "description")],
			[("If ", "description"), ("CONTROLPLANE", "argument"), (",", "separator"), ("...", "argument"), (" is not specified all control planes will be tainted", "description")],
		],
		"min_args": 0,
		"max_args": 1,
		"callback": taint_control_plane,
	},
	"Untaint Control Plane": {
		"command": ["untaint-control-plane"],
		"values": [("[", "separator"), ("CONTROLPLANE", "argument"), (",", "separator"), ("...", "argument"), ("]", "separator")],
		"description": [("Mark control plane(s) as untainted", "description")],
		"extended_description": [
			[("Per default control planes are marked as tainted; workloads that lack ", "description")],
			[("tolerations will not be scheduled to them", "description")],
			[("If you're running a single-node cluster, or if the control plane is very", "description")],
			[("powerful it might be useful to permit workloads on control plane(s) too", "description")],
			[("If ", "description"), ("CONTROLPLANE", "argument"), (",", "separator"), ("...", "argument"), (" is not specified all control planes will be untainted", "description")],

		],
		"min_args": 0,
		"max_args": 1,
		"callback": untaint_control_plane,
	},
	"Audit": {
		"command": ["audit"],
		"description": [("Search for potential security issues in the cluster", "description")],
		"extended_description": [
			[("Note: ", "emphasis"), ("If the system is configured to use ", "description"), ("usergroups", "emphasis")],
			[("(every user have their own group that only they belong to) ", "description")],
			[("be sure to specify that group using the ", "description"), ("--usergroup ", "option"), ("USERGROUP", "argument"), (" option,", "description")],
			[("to prevent the permission checker from complain about insecure permissions",  "description")],
		],
		"options": {
			"--usergroup": {
				"values": [("USERGROUP", "argument")],
				"description": [("If your system uses usergroups, specify your usergroup here", "description")],
				"requires_arg": True,
			},
		},
		"min_args": 0,
		"max_args": 0,
		"callback": audit,
	},
	"Preflight Check": {
		"command": ["preflight-check"],
		"description": [("Check for potential pitfalls that may prevent installation from succeeding", "description")],
		"min_args": 0,
		"max_args": 0,
		"callback": preflight_check,
	},
	"Troubleshoot": {
		"command": ["troubleshoot"],
		"description": [("Search for potential problems in the cluster", "description")],
		"min_args": 0,
		"max_args": 0,
		"callback": troubleshoot,
	},
	"spacer1": {
		"command": [""],
		"description": [("", "default")],
	},
}

def main():
	"""
	Main function for the program
	"""

	# Before doing anything else, make sure that the user isn't running as root
	if os.geteuid() == 0:
		sys.exit("CRITICAL: This program should not be run as the root user; aborting.")

	init_iktprint(DEFAULT_THEME_FILE)

	command, options, args = parse_commandline(about.ADMIN_PROGRAM_NAME, about.ADMIN_PROGRAM_VERSION, PROGRAMDESCRIPTION, PROGRAMAUTHORS, sys.argv, commandline)

	# Used by the ansible module
	ansible_configuration["ansible_forks"] = deep_get(iktconfig, "Ansible#forks", 5)
	ansible_user = deep_get(iktconfig, "Ansible#ansible_user")
	if ansible_user is None or len(ansible_user) == 0:
		ansible_user = getuser()
	ansible_configuration["ansible_user"] = ansible_user
	ansible_password = deep_get(iktconfig, "Ansible#ansible_password")
	if ansible_password is not None and len(ansible_password) > 0:
		ansible_configuration["ansible_password"] = ansible_password
	ansible_configuration["disable_strict_host_key_checking"] = deep_get(iktconfig, "Nodes#disablestricthostkeychecking", False)
	ansible_configuration["save_logs"] = deep_get(iktconfig, "Ansible#save_logs", False)
	return command(options, args)

if __name__ == "__main__":
	main()
