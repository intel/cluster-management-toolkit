#! /usr/bin/env python3
# Requires: python3 (>= 3.6)
# Requires: python3-natsort
# Requires: python3-openssl
# Requires: python3-paramiko

import base64
import errno
from functools import partial
from getpass import getuser
from glob import glob
import os
from pathlib import Path
import re
import shutil
from shutil import which
import socket
import subprocess
import sys
import tempfile
import time
import yaml

import paramiko

try:
	from natsort import natsorted
except ModuleNotFoundError:
	sys.exit("ModuleNotFoundError: You probably need to install python3-natsort; did you forget to run ikt-install?")

from commandparser import parse_commandline

from ansible_helper import ansible_configuration, ansible_get_inventory_dict, ansible_set_vars, ansible_run_playbook_on_selection, ansible_add_hosts, ansible_print_play_results
from ansible_helper import ANSIBLE_PLAYBOOK_DIR, ANSIBLE_INVENTORY

from iktio import download_files
import iktlib
from iktlib import deep_get, execute_command, execute_command_with_response

from kubernetes_helper import kubectl_get_version

HOMEDIR = str(Path.home())
BINDIR = f"{HOMEDIR}/bin"
IKTDIR = f"{HOMEDIR}/.ikt"
IKT_HOOKS_DIR = f"{IKTDIR}/hooks"
DEPLOYMENTDIR = f"{IKTDIR}/deployments"
ANSIBLE_PLAYBOOK_DIRNAME = "playbooks"
PLAYBOOKDIR = f"{IKTDIR}/{ANSIBLE_PLAYBOOK_DIRNAME}"
IKT_CONFIG_FILENAME = "ikt.yaml"
IKT_CONFIG_FILE = f"{IKTDIR}/{IKT_CONFIG_FILENAME}"
IKT_CONFIG_FILE_DIR = f"{IKTDIR}/{IKT_CONFIG_FILENAME}.d"
IKT_INSTALLATION_INFO = f"{IKTDIR}/installation_info.yaml"

from iktprint import iktinput, iktinput_password, iktprint, init_iktprint

import about
PROGRAMDESCRIPTION = "Setup or teardown a Kubernetes cluster"
PROGRAMAUTHORS = "Written by David Weinehall."

THEME_DIRNAME = "themes"
THEMEDIR = f"{IKTDIR}/{THEME_DIRNAME}"
THEME_PATH = f"{THEMEDIR}/default.yaml"

iktconfig = None

DEFAULT_CNI = "cilium"

no_password = False

prepare_targets = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/prepare_passwordless_ansible.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/install_packages.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/prepare_control_plane.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/add_kubernetes_repo.yaml",
		],
		"deb_packages": [
			"docker.io",
		],
	},
	"localhost": {
		"pretty_name": [("host system", "programname")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/prepare_passwordless_ansible.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/add_kubernetes_repo.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/install_packages.yaml",
		],
		"deb_packages": [
			"ansible",
			# If available
			# "ansible-mitogen",
		],
	},
}

setup_control_plane_targets = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/install_packages.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/kubeadm_setup_control_plane.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/fetch_kube_config.yaml",
		],
		"deb_packages": [
			"kubeadm",
			"kubectl",
			"kubelet",
			"kubernetes-cni",
		],
		"deb_packages_held": [
			"kubeadm",
			"kubectl",
			"kubelet",
		],
	},
	"localhost": {
		"pretty_name": [("host system", "programname")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/install_packages.yaml",
		],
		"deb_packages": [
			"kubectl",
		],
		"deb_packages_held": [
			"kubectl",
		],
	},
}

upgrade_control_plane_targets = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/kubeadm_upgrade_control_plane.yaml",
		],
	},
	"localhost": {
		"pretty_name": [("host system", "programname")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/install_packages.yaml",
		],
		"deb_packages": [
			"kubectl",
		],
		"deb_packages_held": [
			"kubectl",
		],
        },
}

teardown_control_plane_targets = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/teardown_cni.yaml",
			f"{ANSIBLE_PLAYBOOK_DIR}/kubeadm_teardown_control_plane.yaml",
		],
	},
}

purge_control_plane_targets = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			f"{ANSIBLE_PLAYBOOK_DIR}/kubeadm_purge.yaml",
		],
		"deb_packages": [
			"kubeadm",
			"kubectl",
			"kubelet",
			"kubernetes-cni",
		],
		"deb_packages_held": [
			"kubeadm",
			"kubectl",
			"kubelet",
		],
	},
}

def mkdir_if_not_exists(directory):
	if not os.path.exists(directory):
		iktprint([("mkdir ", "programname"), (f"{directory}", "path")])
		os.mkdir(directory)

def set_file_permissions(path, permissions):
	iktprint([("chmod ", "programname"), (f"{permissions} ", "argument"), (f"{path}", "path")])
	args = ["/usr/bin/chmod", permissions, path]
	execute_command_with_response(args)

def rmdir_recursive(directory):
	permitted = [
		"/etc/cni",
		"/etc/kubernetes",
		"/etc/systemd/system/kubelet.service.d",
		"/opt/cni",
		"/var/lib/cni",
		"/var/lib/etcd",
		"/var/lib/kubelet",
		f"{DEPLOYMENTDIR}",
		f"{HOMEDIR}/.kube",
	]

	if directory == "/" or directory not in permitted:
		raise Exception(f"Error: There's something seriously wrong; an attempt to remove the directory “{directory}“ was just made. Aborting.")

	if os.path.isdir(directory):
		iktprint([(f"  {directory}", "path")])
		args = ["/usr/bin/sudo", "/usr/bin/rm", "-r", directory]
		execute_command_with_response(args)

def rebuild_installation_info(state = None):
	cluster_name = None
	distro = None
	version = None

	controlplanes = __selection_control_planes()
	if controlplanes is None or len(controlplanes) == 0:
		iktprint([("", "default")])
		iktprint([("Critical:", "critical"), (" No control plane defined in inventory; cannot rebuild installation info. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	deb_versions = check_deb_versions(["kubeadm"])
	if len(deb_versions) == 0 or deb_versions[0][1] == "<none>":
		iktprint([("", "default")])
		iktprint([("Critical:", "critical"), (" Failed to get kubeadm version; are you sure there's a kubeadm-based cluster installed? Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)
	else:
		version = deb_versions[0][1]
		distro = "kubeadm"

	cluster_name = get_cluster_name()
	update_installation_info(cluster_name = cluster_name, distro = distro, version = version, requested_version = "<none>", state = state, phase = "<none>", phase_skiplist = [], cni = "<FIXME>", pod_network_cidr = "<FIXME>")

def get_installation_info(cluster_name = None):
	info = None

	try:
		with open(IKT_INSTALLATION_INFO, "r") as f:
			info = yaml.safe_load(f)
	except FileNotFoundError:
		pass

	if info is None and cluster_name is None:
		raise Exception("cluster_name cannot be None when the installation_info file is empty")

	if info is None or info.get("installation_target") is None or (info.get("installation_target") is not None and cluster_name is not None and cluster_name not in info) :
		info = {
			"installation_target": cluster_name,
			cluster_name: {
				"distro": "<none>",
				"version": "<none>",
				"requested_version": "<none>",
				"state": "<none>",
				"phase": "<none>",
				"phase_skiplist": [],
				"cni": "<none>",
				"pod_network_cidr": "<none>",
				"cri": "<none>",
			}
		}
	elif info.get("installation_target") is None and cluster_name is not None:
		# Old format file; transition it
		tmpinfo = info.copy()
		tmpinfo.pop("cluster_name")
		info = {}
		info["installation_target"] = cluster_name
		info[cluster_name] = tmpinfo

	return info

def update_installation_info(cluster_name = None, distro = None, version = None, requested_version = None, state = None, phase = None, phase_skiplist = None, cni = None, pod_network_cidr = None, cri = None):
	info = get_installation_info(cluster_name = cluster_name)

	if cluster_name is None:
		cluster_name = info.get("installation_target")

	if info.get("installation_target") is None:
		info["installation_target"] = cluster_name

	if distro is not None:
		info[cluster_name]["distro"] = distro
	if version is not None:
		info[cluster_name]["version"] = version
	if requested_version is not None:
		info[cluster_name]["requested_version"] = requested_version
	if state is not None:
		info[cluster_name]["state"] = state
	if phase is not None:
		info[cluster_name]["phase"] = phase
	if phase_skiplist is not None:
		info[cluster_name]["phase_skiplist"] = phase_skiplist
	if cni is not None:
		info[cluster_name]["cni"] = cni
	if pod_network_cidr is not None:
		info[cluster_name]["pod_network_cidr"] = pod_network_cidr
	if cri is not None:
		info[cluster_name]["cri"] = cri

	with open(IKT_INSTALLATION_INFO, "w") as f:
		f.write(yaml.dump(info, default_flow_style = False, sort_keys = False))

	return info

def check_and_print_status(retval):
	if retval == True:
		iktprint([("OK", "ok")])
	else:
		iktprint([("NOT OK", "notok"), ("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

def weave_urlgetter(pod_network_cidr):
	args = ["/usr/bin/kubectl", "version"]
	kubectl_version = execute_command_with_response(args).encode("ascii")
	version_base64 = base64.urlsafe_b64encode(kubectl_version).decode("ascii")
	url = f"https://cloud.weave.works/k8s/net?k8s-version=\"{version_base64}\"&env.IPALLOC_RANGE={pod_network_cidr}"
	return url

DEFAULT_POD_NETWORK_CIDR = "10.244.0.0/16"

def str_presenter(dumper, data):
	if "\n" in data:
		return dumper.represent_scalar("tag:yaml.org,2002:str", data, style="|")
	return dumper.represent_scalar("tag:yaml.org,2002:str", data)

def patch_cni_flannel(cni_path, pod_network_cidr):
	# Ideally we should patch this using a round-trip capable YAML parser,
	# such as ruamel
	sedstr = f's#^\(.*"\)Network": "10.244.0.0/16",$#\\1Network:": "{pod_network_cidr}",#'
	args = ["/usr/bin/sed", "-i", "-e", sedstr, cni_path]
	check_and_print_status(execute_command(args))

# XXX: We should convert all of cni_data to use this format instead,
#      and move all of this code to a separate file to allow it to be used both from iku and iktadm
cni_upgrade_data = {
	"cilium": {
		"executable": {
			"version_command": ["cilium", "--context", "<<<context>>>", "version"],
			"version_regex": r"^cilium-cli: (v)(\d+)(\.)(\d+)(\.)(\d+) .*$",
			"candidate_version_url": "https://raw.githubusercontent.com/cilium/cilium-cli/master/stable.txt",
			"candidate_version_regex": r"(v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"url": "https://github.com/cilium/cilium-cli/releases/download/<<<version>>>/cilium-linux-<<<arch>>>.tar.gz",
			"filename": "cilium",
		},
		"CNI": {
			"version_command": ["cilium", "--context", "<<<context>>>", "version"],
			"version_regex": r"^cilium image \(running\): (v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"candidate_version_command": ["cilium", "--context", "<<<context>>>", "version"],
			"candidate_version_regex": r"^cilium image \(default\): (v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"upgrade": ["cilium", "--context", "<<<context>>>", "upgrade"],
			"install": ["cilium", "--context", "<<<context>>>", "install"],
		}
	}
}

cni_data = {
	"antrea": {
		"url": "https://raw.githubusercontent.com/antrea-io/antrea/main/build/yamls/antrea.yml",
		"type": "yaml",
		"filename": "antrea.yaml",
	},
	"calico": {
		"url": "https://docs.projectcalico.org/manifests/calico.yaml",
		"type": "yaml",
		"filename": "calico.yaml",
	},
	"canal": {
		"url": "https://docs.projectcalico.org/manifests/canal.yaml",
		"type": "yaml",
		"filename": "canal.yaml",
	},
	"cilium": {
		"version_url": "https://raw.githubusercontent.com/cilium/cilium-cli/master/stable.txt",
		"url": "https://github.com/cilium/cilium-cli/releases/download/<<<version>>>/cilium-linux-<<<arch>>>.tar.gz",
		"type": "installer",
		"filename": "cilium",
		"command": ["cilium", "--context", "<<<context>>>", "install"]
	},
	"flannel": {
		"url": "https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml",
		"type": "yaml",
		"filename": "flannel.yaml",
		"patch_cni": patch_cni_flannel,
	},
	"kube-router": {
		"url": "https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter.yaml",
		"type": "yaml",
		"filename": "kube-router.yaml",
	},
	"weave": {
		"urlgetter": weave_urlgetter,
		"type": "yaml",
		"filename": "weave.yaml",
	},
}

def substitute_string(string, substitutions):
	for key, value in substitutions.items():
		string = string.replace(key, value)
	return string

def substitute_list(strlist, substitutions):
	subst = substitutions.get
	return [subst(s, s) for s in strlist]

def check_version_from_url(url, version_regex):
	version = None
	if url is not None:
		with tempfile.TemporaryDirectory() as td:
			check_and_print_status(download_files(td, [(url, "version.txt")], permissions = 0o600))
			with open(f"{td}/version.txt") as f:
				versionoutput = f.read().splitlines()
				for line in versionoutput:
					tmp = re.match(version_regex, line)
					if tmp is not None:
						version = tmp.groups()
						break
	return version

def check_version_from_executable(command, args, version_regex):
	version = None
	# If command is just a command try to find it in path
	if "/" not in command:
		cpath = which(command)
	else:
		cpath = command

	if cpath is not None and len(cpath) > 0:
		result = execute_command_with_response([cpath] + args)

		if result is not None:
			versionoutput = result.splitlines()
			for line in versionoutput:
				tmp = re.match(version_regex, line)
				if tmp is not None:
					version = tmp.groups()
					break
	return version

def __upgrade_cni(cni, upgradetype, context):
	if upgradetype not in ["CNI", "executable"]:
		raise Exception(f"Unknown upgradetype {upgradetype}; this is a programming error.")

	# FIXME: for now we hardcode this
	arch = "amd64"
	version_command = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#version_command")
	version_command_regex = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#version_regex")
	candidate_version_url = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#candidate_version_url")
	candidate_version_command = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#candidate_version_command")
	candidate_version_regex = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#candidate_version_regex")
	download_url = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#url")
	command_filename = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#filename")
	install_command = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#install")
	upgrade_command = deep_get(cni_upgrade_data, f"{cni}#{upgradetype}#upgrade")

	version_substitutions = {
		"<<<arch>>>": arch,
		"<<<context>>>": context,
	}

	version = None
	if version_command is not None:
		iktprint([("\n• ", "separator"), (f"Checking {upgradetype} version", "action")])
		version = check_version_from_executable(version_command[0], substitute_list(version_command[1:], version_substitutions), version_command_regex)

	candidate_version = ""
	if candidate_version_url is not None:
		iktprint([("\n• ", "separator"), (f"Checking {upgradetype} candidate version", "action")])
		candidate_version = check_version_from_url(substitute_string(candidate_version_url, version_substitutions), candidate_version_regex)
	elif candidate_version_command is not None:
		iktprint([("\n• ", "separator"), (f"Checking {upgradetype} candidate version", "action")])
		candidate_version = check_version_from_executable(candidate_version_command[0], substitute_list(candidate_version_command[1:], version_substitutions), candidate_version_regex)

	if download_url is not None and command_filename is not None and (version is None or version < candidate_version):
		version = "".join(candidate_version)

		iktprint([("\n• ", "separator"), (f"Downloading {upgradetype} ", "action"), (f"{version}", "version")])

		substitutions = {
			"<<<version>>>": version,
			"<<<arch>>>": arch,
			"<<<context>>>": context,
		}

		download_url = substitute_string(download_url, substitutions)

		if upgradetype == "CNI":
			mkdir_if_not_exists(f"{DEPLOYMENTDIR}")
			directory = f"{DEPLOYMENTDIR}/cni"
			permissions = 0o644
		elif upgradetype == "executable":
			directory = f"{BINDIR}"
			permissions = 0o755
		mkdir_if_not_exists(directory)
		check_and_print_status(download_files(directory, [(download_url, command_filename)], permissions = permissions))
	elif install_command is not None and version is None:
		version = "".join(candidate_version)

		iktprint([("\n• ", "separator"), (f"Installing {upgradetype} ", "action"), (f"{version}", "version")])

		substitutions = {
			"<<<version>>>": version,
			"<<<arch>>>": arch,
			"<<<context>>>": context,
		}
		check_and_print_status(execute_command(substitute_list(install_command, substitutions)))
	elif upgrade_command is not None and version is None or version < candidate_version:
		version = "".join(candidate_version)

		iktprint([("\n• ", "separator"), (f"Upgrading {upgradetype} to ", "action"), (f"{version}", "version")])

		substitutions = {
			"<<<version>>>": version,
			"<<<arch>>>": arch,
			"<<<context>>>": context,
		}
		check_and_print_status(execute_command(substitute_list(upgrade_command, substitutions)))

def upgrade_cni(options = [], args = None):
	retval = True

	if len(args) > 0:
		cni = args[0]
	else:
		installation_info = get_installation_info()
		cluster_name = installation_info["installation_target"]
		cni = installation_info[cluster_name]["cni"]
	if cni not in cni_upgrade_data.keys():
		iktprint([("Upgrading ", "default"), (f"{cni}", "command"), (" is currently not supported; exiting.", "default")])
		sys.exit(errno.ENOTSUP)

	context_name = execute_command_with_response(["kubectl", "config", "current-context"]).splitlines()[0]

	iktprint([("\n[Upgrading CNI]", "phase")])

	__upgrade_cni(cni, "executable", context_name)
	__upgrade_cni(cni, "CNI", context_name)

	iktprint([("\nCNI upgrade successful", "success")])

def setup_cni(cni, pod_network_cidr, context_name, cluster_name):
	if cni not in cni_data:
		iktprint([("Error:", "error"), (f" {cni}", "argument"), (" is not a valid/supported CNI; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	version_url = deep_get(cni_data, f"{cni}#version_url")
	version_regex = deep_get(cni_data, f"{cni}#version_regex")

	version = check_version_from_url(version_url, version_regex)

	url = deep_get(cni_data, f"{cni}#url")
	if url is None:
		urlgetter = deep_get(cni_data, f"{cni}#urlgetter")
		if urlgetter is None:
			raise Exception(f"Both URL and URL getter for {cni} are empty; this is a programming error.")
		url = urlgetter(pod_network_cidr)

	# FIXME: for now we hardcode this
	arch = "amd64"
	substitutions = {
		"<<<version>>>": version,
		"<<<arch>>>": arch,
	}

	url = substitute_string(url, substitutions)

	filename = deep_get(cni_data, f"{cni}#filename")
	patch_cni = deep_get(cni_data, f"{cni}#patch_cni", None)
	filetype = deep_get(cni_data, f"{cni}#type")
	if filetype is None:
		raise Exception(f"type for {cni} is missing; this is a programming error.")
	if filetype == "yaml":
		mkdir_if_not_exists(f"{DEPLOYMENTDIR}")
		directory = f"{DEPLOYMENTDIR}/cni"
		permissions = 0o644
	elif filetype == "installer":
		directory = f"{BINDIR}"
		permissions = 0o755
	mkdir_if_not_exists(directory)

	check_and_print_status(download_files(directory, [(url, filename)], permissions = permissions))

	if patch_cni is not None:
		iktprint([("\n• ", "separator"), ("Patching “", "action"), (f"{cni}", "argument"), ("“ configuration", "action")])
		patch_cni(f"{directory}/{filename}", pod_network_cidr)

	if filetype == "yaml":
		args = ["/usr/bin/kubectl", "apply", f"--context=<<<context>>>", "-f", cni_path]
	elif filetype == "installer":
		args = deep_get(cni_data, f"{cni}#command")

	substitutions = {
		"<<<cluster>>>": cluster_name,
		"<<<context>>>": context_name,
	}

	check_and_print_status(execute_command(substitute_list(args, substitutions)))

def check_for_ssh_key():
	retval = False
	files = [file for file in glob(f"{HOMEDIR}/.ssh/*.pub") if os.path.isfile(file)]
	for file in files:
		if os.path.isfile(file) and os.path.isfile(file[:-len(".pub")]):
			retval = True
			break
	return retval

def scan_and_add_ssh_keys():
	controlplanes = get_control_planes()
	hosts = [controlplane[0] for controlplane in controlplanes]
	hosts += [f"{controlplane[0]}.local" for controlplane in controlplanes]
	hosts += [
		"localhost",
	]

	for host in hosts:
		try:
			transport = paramiko.Transport(host)
		except socket.gaierror as e:
			if str(e) in ["[Errno -3] Temporary failure in name resolution", "[Errno -2] Name or service not known"]:
				continue
			else:
				raise socket.gaierror(f"{str(e)}\nhost: {host}")
		transport.connect()
		key = transport.get_remote_server_key()
		transport.close()
		known_hosts = f"{HOMEDIR}/.ssh/known_hosts"

		# Note: Paramiko seems to have issues if .ssh/known_hosts doesn't exist,
		# so "touch" the file just in case.
		open(known_hosts, 'a').close()

		hostfile = paramiko.HostKeys(filename = known_hosts)
		hostfile.add(hostname = host, key = key, keytype = key.get_name())
		hostfile.save(filename = known_hosts)

def create_ssh_key():
	if not os.path.exists(f"{HOMEDIR}/.ssh/id_ed25519"):
		args = ["/usr/bin/ssh-keygen", "-t", "ed25519", "-f", f"{HOMEDIR}/.ssh/id_ed25519"]
		retval = execute_command(args)
	else:
		retval = True
	return retval

def add_ssh_keys_to_authorized_keys():
	pubkey = None
	retval = False

	# Since we run create_ssh_key() before this task we can safely
	# assume that .ssh/ exists
	for item in os.listdir(f"{HOMEDIR}/.ssh"):
		if not item.endswith(".pub"):
			continue

		with open(f"{HOMEDIR}/.ssh/{item}", "r") as f:
			tmp = f.readlines()
			if tmp is not None and len(tmp) > 0:
				pubkey = tmp

		if pubkey is None or len(pubkey) == 0:
			continue

		exists = False

		try:
			with open(f"{HOMEDIR}/.ssh/authorized_keys", "r") as f:
				tmp = f.readlines()

				if tmp is not None and len(tmp) > 0:
					for line in tmp:
						if line == pubkey[0]:
							exists = True
							break
		except FileNotFoundError:
			pass

		# This either means that the key doesn't exist in the file,
		# or that authorized_keys doesn't exist at all.  Hence we open
		# with a+ to ensure that it's created if it doesn't exist.
		# While we technically only need to worry about authorized_keys
		# not existing for the first key we add, it's better not to
		# special case things
		if exists == False:
			with open(f"{HOMEDIR}/.ssh/authorized_keys", "a+") as f:
				f.writelines(pubkey)

		# We've added at least one public key
		retval = True

	return retval

def __task_check_and_create_ssh_key(installation_info):
	if check_for_ssh_key() == False:
		retval = iktinput([("Warning:", "warning"), (" No ssh key found in ", "default"), (f"{HOMEDIR}/.ssh", "path"), ("; create one now? (No will abort the installation) [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
		if retval.lower() not in ["y", "yes"]:
			iktprint([("\nAborting:", "error"), (" No ssh key available.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		else:
			check_and_print_status(create_ssh_key())

def __task_scan_and_add_ssh_keys(installation_info):
	scan_and_add_ssh_keys()

def __task_add_ssh_keys_to_inventory(installation_info):
	pubkey = None
	d = ansible_get_inventory_dict()
	__vars = deep_get(d, "all#vars", {})
	__authorized_keys = __vars.get("authorized_keys", [])
	found_key = False

	for item in os.listdir(f"{HOMEDIR}/.ssh"):
		if not item.endswith(".pub"):
			continue

		with open(f"{HOMEDIR}/.ssh/{item}", "r") as f:
			tmp = f.readlines()
			if tmp is not None and len(tmp) > 0:
				pubkey = tmp[0]

		if pubkey == None:
			iktprint([("Warning:", "warning"), (" Failed to read ", "default"), (f"{HOMEDIR}/.ssh/{item}", "path"), ("; skipping.", "default")], stderr = True)
			continue

		if pubkey not in __authorized_keys:
			__authorized_keys.append(pubkey)

		found_key = True

	if found_key == False:
		iktprint([("Error:", "error"), (" Could not find a valid public key in ", "default"), (f"{HOMEDIR}/.ssh", "path"), ("; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	__vars["authorized_keys"] = __authorized_keys
	ansible_set_vars(ANSIBLE_INVENTORY, "all", __vars)

def __task_check_and_add_ssh_keys_to_authorized_keys(installation_info):
	add_ssh_keys_to_authorized_keys()

def install_ansible_posix():
	# Old versions of ansible-galaxy doesn't have the list command;
	# if it doesn't work we just assume that ansible.posix is missing
	args = ["/usr/bin/ansible-galaxy", "collection", "list"]
	result = execute_command_with_response(args)
	if "COLLECTION_ACTION: invalid choice" in result or "ansible.posix" not in result:
		http_proxy = deep_get(iktconfig, "Network#http_proxy", "")
		https_proxy = deep_get(iktconfig, "Network#https_proxy", "")
		no_proxy = deep_get(iktconfig, "Network#no_proxy", "")
		env = {
			"http_proxy": http_proxy,
			"https_proxy": https_proxy,
			"no_proxy": no_proxy,
		}
		args = ["/usr/bin/ansible-galaxy", "collection", "install", "ansible.posix"]
		return execute_command(args, env = env)
	else:
		return True

def __task_check_and_install_ansible_posix(installation_info):
	check_and_print_status(install_ansible_posix())

def update_apt_cache():
	args = ["/usr/bin/sudo", "/usr/bin/apt-get", "update"]
	return execute_command(args)

def deb_compare_versions(current_version, candidate_version):
	args = ["/usr/bin/dpkg", "--compare-versions", current_version, "lt", candidate_version]
	return execute_command(args, comparison = 1)

def __get_theme(string, default):
	translation = {
		"<none>": "none",
		"<unknown>": "unknown",
	}
	return translation.get(string, default)

extract_version_re = re.compile(r"^\s*.*?\s\|\s*(.*?)\s\|\s.*")

def extract_version(line):
	tmp = extract_version_re.match(line)
	if tmp is None:
		raise Exception("Error: Failed to extract a version; this is (most likely) a programming error.")
	return tmp[1]

def check_deb_versions(deb_packages):
	deb_versions = []

	args = ["/usr/bin/apt-cache", "policy"] + deb_packages
	response = execute_command_with_response(args)
	split_response = response.splitlines()
	for line in split_response:
		if line.endswith(":"):
			package = line[:-1]
		elif line.startswith("  Installed: "):
			tmp = re.match(r"\s*Installed: (.*)", line)
			if tmp is not None:
				if tmp[1] == "(none)":
					installed_version = "<none>"
				else:
					installed_version = tmp[1]
			else:
				installed_version = "<none>"
		elif line.startswith("  Candidate: "):
			tmp = re.match(r"\s*Candidate: (.*)", line)
			if tmp is not None and tmp[1] != installed_version:
				if tmp[1] == "(none)":
					if installed_version == "<none>":
						continue
					else:
						candidate_version = "<none>"
				else:
					candidate_version = tmp[1]
			else:
				candidate_version = ""
			# We have the current and candidate version now; get all the other versions of the same package
			_args = ["/usr/bin/apt-cache", "madison", package]
			_response = execute_command_with_response(_args)
			_split_response = _response.splitlines()
			all_versions = natsorted([extract_version(line) for line in _split_response], reverse = True)
			deb_versions.append((package, installed_version, candidate_version, all_versions))

	return deb_versions

def check_versions(deb_packages, version_checks):
	other_versions = []

	# First check all Debian versions
	deb_versions = check_deb_versions(deb_packages)

	# Now check versions that need special checks
	for version_check in version_checks:
		software = version_check[0]
		args = version_check[1]
		regex = version_check[2]

		try:
			response = execute_command_with_response(args)
		except FileNotFoundError:
			other_versions.append((software, "<none>", ""))
			continue
		except subprocess.CalledProcessError:
			other_versions.append((software, "<unknown>", ""))
			continue

		if regex is None:
			installed_version = response
		else:
			tmp = re.match(regex, response)
			if tmp is not None:
				installed_version = tmp[1]
			else:
				installed_version = "<none>"
		other_versions.append((software, installed_version, ""))

	# Finally, display the gathered version information; find the longest string of each type
	# Create lists of header + all values belonging to that header, and get the length of the longest element
	slen = len(max(["Software:"] + [tmp[0] for tmp in deb_versions + other_versions], key = len))
	ilen = len(max(["Installed Version:"] + [tmp[1] for tmp in deb_versions + other_versions], key = len))
	clen = len(max(["Candidate Version:"] + [tmp[2] for tmp in deb_versions + other_versions], key = len))

	# Print a header
	iktprint([("Software:", "header"), (f"{''.ljust(slen - len('Software:') + 2)}", "default"), ("Installed Version:", "header"), (f"{''.ljust(ilen - len('Installed Version:') + 2)}", "default"), ("Candidate Version:", "header")])
	for software, installed_version, candidate_version, _ in natsorted(deb_versions):
		iformat = __get_theme(installed_version, "version")
		cformat = __get_theme(candidate_version, "version")
		iktprint([(f"{software.ljust(slen + 2)}", "default"), (f"{installed_version.ljust(ilen + 2)}", iformat), (f"{candidate_version}", cformat)])
	print()
	for software, installed_version, candidate_version in natsorted(other_versions):
		iformat = __get_theme(installed_version, "version")
		cformat = __get_theme(candidate_version, "version")
		iktprint([(f"{software.ljust(slen + 2)}", "default"), (f"{installed_version.ljust(ilen + 2)}", iformat), (f"{candidate_version}", cformat)])

	return deb_versions, other_versions

def configure_system(configure_commands):
	for string, cmd in configure_commands:
		print(string)
		check_and_print_status(cmd())

def run_playbook(playbookpath, hosts = None, extra_values = {}, quiet = False):
	# Set necessary Ansible keys before running playbooks
	http_proxy = deep_get(iktconfig, "Network#http_proxy", "")
	if http_proxy is None:
		http_proxy = ""
	https_proxy = deep_get(iktconfig, "Network#https_proxy", "")
	if https_proxy is None:
		https_proxy = ""
	no_proxy = deep_get(iktconfig, "Network#no_proxy", "")
	if no_proxy is None:
		no_proxy = ""
	insecure_registries = deep_get(iktconfig, "Docker#insecure_registries", [])
	registry_mirrors = deep_get(iktconfig, "Containerd#registry_mirrors", [])
	retval = 0

	use_proxy = "no"
	if len(http_proxy) > 0 or len(https_proxy) > 0:
		use_proxy = "yes"

	values = {
		"http_proxy": http_proxy,
		"https_proxy": https_proxy,
		"no_proxy": no_proxy,
		"insecure_registries": insecure_registries,
		"registry_mirrors": registry_mirrors,
		"use_proxy": use_proxy,
	}
	merged_values = { **values, **extra_values }

	if hosts is None:
		retval, ansible_results = ansible_run_playbook(playbookpath, values = merged_values)
	else:
		retval, ansible_results = ansible_run_playbook_on_selection(playbookpath, selection = hosts, values = merged_values)

	ansible_print_play_results(retval, ansible_results)

	return retval, ansible_results

def run_playbooks(playbooks, hosts = None, extra_values = {}):
	if len(playbooks) == 0 or hosts == None:
		return True

	for string, playbookpath in playbooks:
		iktprint(string)
		retval, ansible_results = run_playbook(playbookpath, hosts = hosts, extra_values = extra_values)

		# We don't want to continue executing playbooks if the first one failed
		if retval != 0:
			break

	return retval == 0

# Scan a directory and return an array of playbook paths
def __playbook_paths_from_path(path):
	if path is None:
		raise Exception("No path passed to __playbook_paths_from_path; this is a programming error.")

	playbook_paths = []

	# Populate list of playbooks
	for filename in os.listdir(path):
		# Don't process backups, etc.
		if filename.startswith(("~", ".")):
			continue

		# Only process playbooks
		tmp = re.match(r"(.*)\.ya?ml$", filename)
		if tmp is None:
			continue

		playbook_paths.append(os.path.join(path, filename))

	return playbook_paths

# Add all playbooks in the array
def populate_playbooks_from_paths(paths):
	playbooks = []

	for playbookpath in paths:
		# Only process playbooks
		tmp = re.match(r"(.*)\.ya?ml$", os.path.basename(playbookpath))
		if tmp is None:
			raise Exception(f"The playbook filename “{os.path.basename(playbookpath)}“ does not end with .yaml or .yml; this is most likely a programming error.")

		playbookname = tmp[1]
		description = None
		with open(playbookpath) as f:
			d = yaml.safe_load(f)
			description = [(deep_get(d[0], "vars#metadata#description"), "play")]

		if description is None or len(description) == 0:
			description = [("Running “", "play"), (playbookname, "programname"), ("“", "play")]

		# If there's no description we fallback to just using the filename
		playbooks.append(([("  • ", "separator")] + description, playbookpath))

	return playbooks

# Add all playbooks in the directory
def populate_playbooks_from_dir(path):
	playbook_paths = []

	# Populate list of playbooks
	for filename in os.listdir(path):
		# Don't process backups, etc.
		if filename.startswith(("~", ".")):
			continue

		# Only process playbooks
		tmp = re.match(r"(.*)\.ya?ml$", filename)
		if tmp is None:
			continue

		playbookname = tmp[1]

		playbook_paths.append(f"{path}/{filename}")
	return populate_playbooks_from_paths(playbook_paths)

def __task_request_ansible_password(installation_info):
	global no_password

	# Check whether ansible_password is defined or not
	if ansible_configuration.ansible_password == None and no_password == False:
		iktprint([("Attention: ", "warning"), ("To be able to run playbooks you need to provide the ansible/ssh password.", "default")])
		iktprint([("Since the systems will be reconfigured to use passwordless sudo and ssh keys this is a one-time thing.", "default")])
		ansible_password = iktinput_password([("\nPassword: ", "default")])
		if len(ansible_password) == 0:
			iktprint([("\nError: ", "Error"), ("Empty password; aborting.")], stderr = True)
			sys.exit(errno.EINVAL)
		else:
			ansible_configuration.ansible_password = ansible_password

def __run_playbooks_on_selection(playbooks, selection, extra_values = {}):
	check_and_print_status(run_playbooks(playbooks, hosts = selection, extra_values = extra_values))

def __selection_control_planes():
	__controlplanes = get_control_planes(fail_on_empty = False)
	return [controlplane[0] for controlplane in __controlplanes]

def __selection_localhost():
	if os.path.exists("/etc/hostname"):
		f = open("/etc/hostname", "r")
		hostname = f.readline().strip()
	else:
		raise Exception("Error: /etc/hostname not found; Aborting.")

	return [hostname]

# Run preparation playbooks on localhost
def __task_run_preparation_playbooks_on_localhost(installation_info):
	selection = __selection_localhost()
	playbooks = populate_playbooks_from_paths(prepare_targets["localhost"]["playbooks"])
	extra_values = {
		"packages": prepare_targets["localhost"].get("deb_packages", []),
		"held_packages": prepare_targets["localhost"].get("deb_packages_held", []),
		"ansible_become_pass": ansible_configuration.ansible_password,
		"ansible_ssh_pass": ansible_configuration.ansible_password,
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

def __task_run_preparation_playbooks_on_control_planes(installation_info):
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	requested_version = installation_info[cluster_name]["requested_version"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(prepare_targets[distro]["playbooks"])
	cri = installation_info[cluster_name]["cri"]
	extra_values = {
		"packages": prepare_targets[distro].get("deb_packages", []),
		"held_packages": prepare_targets[distro].get("deb_packages_held", []),
		"ansible_become_pass": ansible_configuration.ansible_password,
		"ansible_ssh_pass": ansible_configuration.ansible_password,
		"cri": cri,
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

def __task_setup_bash_completion(installation_info):
	args = ["/usr/bin/kubectl", "completion", "bash"]
	result = execute_command_with_response(args)
	with tempfile.TemporaryDirectory() as td:
		with open(f"{td}/kubectl", "w") as f:
			f.write(result)
		args = ["/usr/bin/sudo", "/usr/bin/mv", f"{td}/kubectl", "/etc/bash_completion.d/kubectl"]
		check_and_print_status(execute_command(args))

def get_cluster_name():
	if os.path.exists(f"{HOMEDIR}/.kube/config"):
		with open(f"{HOMEDIR}/.kube/config", "r") as f:
			d1 = yaml.safe_load(f)
	else:
		return None

	current_context = d1.get("current-context", None)
	if current_context is None:
		return None

	cluster_name = None

	for context in d1.get("contexts", []):
		if context.get("name", "") == current_context:
			cluster_name = context["context"].get("cluster", None)
			break

	return cluster_name

def __task_run_setup_playbooks_on_localhost(installation_info):
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	requested_version = installation_info[cluster_name]["requested_version"]
	pod_network_cidr = installation_info[cluster_name]["pod_network_cidr"]
	selection = __selection_localhost()
	playbooks = populate_playbooks_from_paths(setup_control_plane_targets["localhost"]["playbooks"])
	extra_values = {
		"cluster_name": cluster_name,
		"pod_network_cidr": pod_network_cidr,
		"packages": setup_control_plane_targets["localhost"].get("deb_packages", []),
		"held_packages": setup_control_plane_targets["localhost"].get("deb_packages_held", []),
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

def __task_run_setup_playbooks_on_control_planes(installation_info):
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	requested_version = installation_info[cluster_name]["requested_version"]
	pod_network_cidr = installation_info[cluster_name]["pod_network_cidr"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(setup_control_plane_targets[distro]["playbooks"])
	extra_values = {
		"cluster_name": cluster_name,
		"pod_network_cidr": pod_network_cidr,
		"packages": setup_control_plane_targets[distro].get("deb_packages", []),
		"held_packages": setup_control_plane_targets[distro].get("deb_packages_held", []),
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

def __task_import_kube_config(installation_info):
	cluster_name = installation_info["installation_target"]
	config_file_name = f"{HOMEDIR}/.kube/config.{cluster_name}"
	admin_name = f"kubernetes-admin+{cluster_name}"
	context_name = f"{admin_name}@{cluster_name}"

	with open(config_file_name, "r") as f:
		d2 = yaml.safe_load(f)

	if os.path.exists(f"{HOMEDIR}/.kube/config"):
		with open(f"{HOMEDIR}/.kube/config", "r") as f:
			d1 = yaml.safe_load(f)
	else:
		d1 = dict(d2)
		# We'll be renaming things anyway, so instead of using a lot of special casing below we just empty
		# these fields
		d1["clusters"] = []
		d1["contexts"] = []
		d1["current-context"] = context_name
		d1["users"] = []

	for cluster in d1["clusters"]:
		if cluster_name == cluster["name"]:
			iktprint([("Error:", "error"), (" A cluster named ", "default"), (cluster_name, "hostname"), (" already exists in ", "default"), (f"{HOMEDIR}/.kube/config", "path"), ("; manual merge is necessary.")], stderr = True)
			return

	for user in d1["users"]:
		if admin_name == user["name"]:
			iktprint([("Error:", "error"), (" A user named ", "default"), (admin_name, "hostname"), (" already exists in ", "default"), (f"{HOMEDIR}/.kube/config", "path"), ("; manual merge is necessary.")], stderr = True)
			return

	for context in d1["contexts"]:
		if context_name == context["name"]:
			iktprint([("Error:", "error"), (" A context named ", "default"), (context_name, "hostname"), (" already exists in ", "default"), (f"{HOMEDIR}/.kube/config", "path"), ("; manual merge is necessary.")], stderr = True)
			return

	cad = d2["clusters"][0]["cluster"].get("certificate-authority-data")
	server = d2["clusters"][0]["cluster"]["server"]
	insecure_skip_tls_verify = d2["clusters"][0]["cluster"].get("insecure-skip-tls-verify")
	cluster = {
		"cluster": {
			"server": server,
		},
		"name": cluster_name,
	}
	if cad is not None:
		cluster["cluster"]["certificate-authority-data"] = cad
	if insecure_skip_tls_verify is not None:
		cluster["cluster"]["insecure-skip-tls-verify"] = insecure_skip_tls_verify

	d1["clusters"].append(cluster)

	context = {
		"context": {
			"cluster": cluster_name,
			"user": admin_name,
		},
		"name": context_name,
	}
	d1["contexts"].append(context)

	ccd = d2["users"][0]["user"].get("client-certificate-data")
	ckd = d2["users"][0]["user"].get("client-key-data")
	token = d2["users"][0]["user"].get("token")
	user = {
		"user": {
		},
		"name": admin_name,
	}
	if ccd is not None:
		user["user"]["client-certificate-data"] = ccd
	if ckd is not None:
		user["user"]["client-key-data"] = ckd
	if token is not None:
		user["user"]["token"] = token

	d1["users"].append(user)

	with open(f"{HOMEDIR}/.kube/config", "w") as f:
		f.write(yaml.dump(d1, default_flow_style = False, sort_keys = False))

	check_and_print_status(True)

def __task_setup_kubeadm_cni(installation_info):
	cluster_name = installation_info["installation_target"]
	cni = installation_info[cluster_name]["cni"]
	pod_network_cidr = installation_info[cluster_name]["pod_network_cidr"]
	admin_name = f"kubernetes-admin+{cluster_name}"
	context_name = f"{admin_name}@{cluster_name}"

	# If everything is successful so far we deploy the pod network
	cni_path = setup_cni(cni, pod_network_cidr, context_name)

def __task_drain_control_planes(installation_info):
	controlplanes = __selection_control_planes()

	# Check if there's an API-server running that will listen to our request;
	# drain is issued during teardown--so if we're resuming a teardown the cluster
	# might already be partially deconfigured
	# XXX: This should be done on the control plane(s), not on localhost
	args = ["/usr/bin/sudo", "/usr/bin/lsof", "-i", "-P", "-n"]
	response = execute_command_with_response(args)
	running = False
	for line in response.splitlines():
		if "6443 (LISTEN)" in line:
			running = True
			break
	if running == False:
		check_and_print_status(True)
		return

	kubectl_major_version, kubectl_minor_version, _kubectl_git_version, _server_major_version, _server_minor_version, _server_git_version = kubectl_get_version()

	# Build the drain command line based on what version of kubectl is installed
	args = ["/usr/bin/kubectl", "drain", "--ignore-daemonsets"]
	if kubectl_major_version >= 1 and kubectl_minor_version >= 20:
		args.append("--delete-emptydir-data")
	else:
		args.append("--delete-local-data")
	if kubectl_major_version >= 1 and kubectl_minor_version >= 18:
		args.append("--disable-eviction")

	for controlplane in controlplanes:
		check_and_print_status(execute_command(args + [controlplane]))

def __task_uncordon_control_planes(installation_info):
	controlplanes = __selection_control_planes()

	from kubernetes_helper import KubernetesHelper
	kh = KubernetesHelper(about.program_suite_name, about.program_suite_version, None)

	for controlplane in controlplanes:
		iktprint([(f"  {controlplane}:", "hostname")])
		message, status = kh.uncordon_node(controlplane)
		if status in [200, 204]:
			iktprint([("    Uncordoned", "success")])
			print(message)
		elif status == 42503:
			iktprint([("\n  Critical: ", "critical"), ("Cluster not available; aborting", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		else:
			iktprint([("\n  API call returned error:", "error")], stderr = True)
			iktprint([(f"    {message}", "error")], stderr = True)
			sys.exit(errno.EINVAL)

# Run pre-upgrade playbooks on localhost
def __task_run_preupgrade_playbooks_on_localhost(installation_info):
	selection = __selection_localhost()
	playbooks = populate_playbooks_from_paths(upgrade_control_plane_targets["localhost"]["playbooks"])
	extra_values = {
		"packages": prepare_targets["localhost"].get("deb_packages", []),
		"held_packages": upgrade_control_plane_targets["localhost"].get("deb_packages_held", []),
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

# Run pre-upgrade playbooks on control planes
def __task_run_preupgrade_playbooks_on_control_planes(installation_info):
	selection = __selection_control_planes()
	paths = __playbook_paths_from_path(os.path.join(IKT_HOOKS_DIR, "pre-upgrade.d"))
	playbooks = populate_playbooks_from_paths(paths)
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = {})

# Run upgrade playbooks on control planes
def __task_run_upgrade_playbooks_on_control_planes(installation_info):
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	requested_version = installation_info[cluster_name]["requested_version"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(upgrade_control_plane_targets[distro]["playbooks"])
	extra_values = {
		"packages": prepare_targets[distro].get("deb_packages", []),
		"held_packages": upgrade_control_plane_targets[distro].get("deb_packages_held", []),
		"requested_control_plane_k8s_version": requested_version,
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

# Run post-upgrade playbooks on control planes
def __task_run_postupgrade_playbooks_on_control_planes(installation_info):
	selection = __selection_control_planes()
	paths = __playbook_paths_from_path(os.path.join(IKT_HOOKS_DIR, "post-upgrade.d"))
	playbooks = populate_playbooks_from_paths(paths)
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = {})

# Verify that the cluster has no nodes
def __task_verify_that_cluster_has_no_nodes(installation_info):
	node_statuses, kh = __get_node_info()

	if node_statuses is not None:
		for node in node_statuses:
			if "control-plane" not in node["roles"]:
				iktprint([("\nPlease delete all nodes (except the ", "warning"), ("control plane", "emphasis"), (") from the cluster before attempting a teardown.", "warning")])
				sys.exit(errno.EAGAIN)

	iktprint([("OK", "ok")])

# Run teardown playbooks on control planes
def __task_run_teardown_playbooks_on_control_planes(installation_info):
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(teardown_control_plane_targets[distro]["playbooks"])
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = {})

def __task_remove_kube_config(installation_info):
	cluster_name = installation_info["installation_target"]
	admin_name = f"kubernetes-admin+{cluster_name}"
	context_name = f"{admin_name}@{cluster_name}"
	d1 = None

	if not os.path.exists(f"{HOMEDIR}/.kube"):
		check_and_print_status(True)

	if os.path.exists(f"{HOMEDIR}/.kube/config.{cluster_name}"):
		os.remove(f"{HOMEDIR}/.kube/config.{cluster_name}")

	if os.path.isfile(f"{HOMEDIR}/.kube/config"):
		with open(f"{HOMEDIR}/.kube/config", "r") as f:
			d1 = yaml.safe_load(f)

		# This isn't perfect--there might be leftover users and contexts belonging to this cluster;
		# but we better not go on a killing spree--better leave cruft behind than remove everything.
		for i in range(0, len(d1["clusters"])):
			if d1["clusters"][i].get("name") == cluster_name:
				d1["clusters"].pop(i)
				break
		for i in range(0, len(d1["users"])):
			if d1["users"][i].get("name") == admin_name:
				d1["users"].pop(i)
				break
		for i in range(0, len(d1["contexts"])):
			if d1["contexts"][i].get("name") == context_name:
				d1["contexts"].pop(i)
				break

	# If there's no cluster left, remove the config completely
	if d1 is None or len(d1["clusters"]) == 0:
		os.remove(f"{HOMEDIR}/.kube/config")
		_dir = os.listdir(f"{HOMEDIR}/.kube")
		try:
			_dir.remove(f"cache")
		except ValueError:
			pass
		try:
			_dir.remove(f"http-cache")
		except ValueError:
			pass

		# If there's nothing else than the cache subdirectories in .kube, remove .kube too
		if len(_dir) == 0:
			shutil.rmtree(f"{HOMEDIR}/.kube")
	else:
		# Set the context to the first remaining context, if any
		if len(d1["contexts"]) > 0:
			d1["current-context"] = d1["contexts"][0]["name"]

		with open(f"{HOMEDIR}/.kube/config", "w") as f:
			f.write(yaml.dump(d1, default_flow_style = False, sort_keys = False))

	check_and_print_status(True)

# Run purge playbooks on control planes
def __task_run_purge_playbooks_on_control_planes(installation_info):
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(purge_control_plane_targets[distro]["playbooks"])
	extra_values = {
		"packages": purge_control_plane_targets[distro].get("deb_packages", []),
		"held_packages": purge_control_plane_targets[distro].get("deb_packages_held", []),
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values)

def __validate_task_index(tasks, task):
	try:
		task = int(task)
	except Exception as e:
		iktprint([("Error:", "error"), (" TASK", "argument"), (f" needs to be an integer index in the range [0, {len(tasks) - 1}]. Aborting.", "default")], stderr = True)
		sys.exit(f"Exception: {e}")

	if task >= len(tasks):
		iktprint([("Error:", "error"), (" TASK", "argument"), (f" needs to be in the range [0, {len(tasks)}]. Aborting.", "default")], stderr = True)
		sys.exit(errno.ERANGE)
	return task

def __list_phases(phases):
	for i in range(0, len(phases)):
		tmp = [(f"{str(i).rjust(2)}: ", "emphasis")]
		tmp += phases[i][0]
		iktprint(tmp)

def __expand_index_list(index_list):
	indexes = set()

	for index in index_list.split(","):
		try:
			if "-" in index:
				first, last = index.split("-")
				first = int(first)
				last = int(last)
			else:
				first = int(index)
				last = first
		except Exception as e:
			iktprint([("Error:", "error"), (f" {index}", "argument"), (" is not an integer or range of integers. Aborting.", "default")], stderr = True)
			sys.exit(f"Exception: {e}")
		for i in range(first, last + 1):
			indexes.add(i)
	return indexes

def __format_none(string, fmt):
	if string is None or string == "<none>":
		__string = ("<none>", "none")
	else:
		__string = (string, fmt)
	return __string

prepare_tasks = [
	([("Check for ssh host key and create if needed", "action")], __task_check_and_create_ssh_key),
	([("Add ssh keys for localhost and the control plane(s) to ", "action"), (f"{HOMEDIR}/.ssh/known_hosts", "path")], __task_scan_and_add_ssh_keys),
	([("Add public ssh keys to ", "action"), (f"{HOMEDIR}/.ssh/authorized_keys", "path")], __task_check_and_add_ssh_keys_to_authorized_keys),
	([("Add public ssh keys to inventory", "action")], __task_add_ssh_keys_to_inventory),
	([("Request the ansible password if necessary", "action")], __task_request_ansible_password),
	([("Install ", "action"), ("ansible.posix", "programname"), (" if necessary", "action")], __task_check_and_install_ansible_posix),
	([("Run playbooks on ", "action"), ("localhost", "hostname")], __task_run_preparation_playbooks_on_localhost),
	([("Run playbooks on ", "action"), ("control planes", "hostname")], __task_run_preparation_playbooks_on_control_planes),
]

__setup_kubeadm_control_plane_tasks = [
	([("Run playbooks on ", "action"), ("localhost", "hostname")], __task_run_setup_playbooks_on_localhost),
	([("Setup ", "action"), ("bash completion", "emphasis"), (" for ", "action"), ("kubectl", "programname")], __task_setup_bash_completion),
	([("Run playbooks on ", "action"), ("control planes", "hostname")], __task_run_setup_playbooks_on_control_planes),
	([("Import kube config", "action")], __task_import_kube_config),
	([("Setup ", "action"), ("kubeadm", "programname"), (" Container Network Interface (CNI)", "action")], __task_setup_kubeadm_cni),
]

setup_control_plane_tasks = __setup_kubeadm_control_plane_tasks

upgrade_control_plane_tasks = [
	([("Drain the ", "action"), ("control planes", "hostname")], __task_drain_control_planes),
	([("Run pre-upgrade playbooks on ", "action"), ("localhost", "hostname")], __task_run_preupgrade_playbooks_on_localhost),
	([("Run pre-upgrade playbooks on ", "action"), ("control planes", "hostname")], __task_run_preupgrade_playbooks_on_control_planes),
	([("Run upgrade playbooks on ", "action"), ("control planes", "hostname")], __task_run_upgrade_playbooks_on_control_planes),
	([("Run post-upgrade playbooks on ", "action"), ("control planes", "hostname")], __task_run_postupgrade_playbooks_on_control_planes),
	([("Uncordon the ", "action"), ("control planes", "hostname")], __task_uncordon_control_planes),
]

teardown_control_plane_tasks = [
	([("Verify that only ", "action"), ("control planes", "hostname"), (" remain in the cluster", "action")], __task_verify_that_cluster_has_no_nodes),
	([("Drain the ", "action"), ("control planes", "hostname")], __task_drain_control_planes),
	([("Run teardown playbooks on ", "action"), ("control planes", "hostname")], __task_run_teardown_playbooks_on_control_planes),
	([("Remove kube config", "action")], __task_remove_kube_config),
]

purge_control_plane_tasks = [
	([("Run purge playbooks on ", "action"), ("control planes", "hostname")], __task_run_purge_playbooks_on_control_planes),
]

def run_tasks(tasks, phase, phase_skiplist, final_state):
	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]

	if type(phase) is not int:
		phase = 0

	for i in range(phase, len(tasks)):
		iktprint([("\n• ", "separator")] + tasks[i][0])
		if i not in set(phase_skiplist):
			tasks[i][1](installation_info)
		if i < len(tasks) - 1:
			installation_info = update_installation_info(phase = i)
		else:
			update_installation_info(state = final_state, phase = "<done>")

def __find_requested_version(distro, version = None):
	requested_version = None

	if distro == "kubeadm":
		# If version is an exact match for a package version, use it.
		# If version is a match for a package version with the package revision ("-nn") removed, use the latest matching package revision.
		# If no version is specified, use the latest package revision.
		versions = check_deb_versions(["kubeadm"])

		if len(versions) == 0:
			iktprint([("Critical: ", "critical"), ("No candidate version for ", "default"), ("kubeadm", "programname"), (" available; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		elif version is not None:
			# The list is sorted in falling order, so the first match is the one we want, since that's the newest package revision.
			for package_version in versions[0][3]:
				if package_version.split("-")[0] == version:
					requested_version = package_version
					break
				elif package_version.split(".")[0] + "." + package_version.split(".")[1] == version:
					requested_version = package_version
					break
				elif version.split(".")[0] == version:
					if package_version.split(".")[0] == version:
						requested_version = package_version
						break
		else:
			requested_version = versions[0][2]

		if requested_version is None:
			iktprint([("Error:", "error"), (" Could not find a matching kubeadm package for version ", "default"), (version, "version"), ("; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
	else:
		raise Exception("No support for other distros implemented")

	major, minor, patchrev = requested_version.split(".")
	if int(minor) < 11:
		iktprint([("Error:", "error"), (" Kubernetes versions older than ", "default"), ("1.11", "version"), (" are not supported by ", "default"), (f"{about.program_suite_name}", "programname"), ("; aborting.", "default")], stderr = True)
		sys.exit(erro.EINVAL)
	elif int(minor) < 18:
		iktprint([("Warning:", "warning"), (" Kubernetes versions older than ", "default"), ("1.18", "version"), (" are not fully supported by ", "default"), (f"{about.program_suite_name}", "programname"), (". Some features may be missing or completely broken.", "default")], stderr = True)

	return requested_version

def prepare_installation(options = [], args = None):
	global no_password
	confirm = True

	# We don't need a cluster name for --list-tasks, so check this first of all
	if "--list-tasks" in [tmp[0] for tmp in options]:
		__list_phases(prepare_tasks)
		sys.exit(0)
	elif len(args) == 0:
		iktprint([(f"{about.admin_program_name}", "programname"), (": “", "default"), ("prepare", "command"), ("“ requires at least 1 arguments.", "default")], stderr = True)
		iktprint([("Try “", "default"), (f"{about.admin_program_name} ", "programname"), ("help", "command"), ("“ for more information.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	# Always require the user to specify the name of the cluster to operate against, even when resuming prepare;
	# this avoids a lot of hairy corner-cases and attempts to figure out what cluster the user intended to operate against
	cluster_name = args[0]

	installation_info = get_installation_info(cluster_name = cluster_name)
	distro = "kubeadm"
	version = None
	requested_version = installation_info[cluster_name]["requested_version"]
	state = installation_info[cluster_name]["state"]
	phase = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])

	if state is not None and state not in ["<none>", "preparing", "prepared"]:
		iktprint([("Error:", "error"), (" Invalid installation state; the system cannot be in a configured or semi-configured state when running prepare; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if phase == "<none>":
		phase = 0

	if os.path.exists("/etc/hostname"):
		f = open("/etc/hostname", "r")
		hostname = f.readline().strip()
	else:
		raise Exception("Error: /etc/hostname not found; Aborting.")

	# default options
	installation_info = update_installation_info(cluster_name = cluster_name, distro = distro, requested_version = requested_version, state = "preparing", phase = phase)

	__controlplanes = get_control_planes(fail_on_empty = False)
	controlplanes = [controlplane[0] for controlplane in __controlplanes]
	if len(controlplanes) == 0 and "--control-plane" not in [tmp[0] for tmp in options]:
		retval = iktinput([("\nWarning: ", "warning"), ("No control plane defined in the inventory; do you want to add ", "default"), (f"{hostname}", "hostname"), (" as control plane? (No will abort the installation) [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
		if retval.lower() not in ["y", "yes"]:
			iktprint([("\nAborting:", "error"), (" No available control plane in inventory.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		else:
			ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [hostname], group = "controlplane", skip_all = False)
			ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [hostname], group = cluster_name, skip_all = True)

	cri = None

	for opt, optarg in options:
		if opt == "--control-plane":
			ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [optarg], group = "controlplane", skip_all = False)
			ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [optarg], group = cluster_name, skip_all = True)
		elif opt == "--no-password":
			no_password = True
		elif opt == "--start-at-task":
			phase = __validate_task_index(prepare_tasks, optarg)
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(prepare_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				iktprint([("Warning: ", "warning"), ("Ignoring request to resume a completed preparation. Exiting.")], stderr = True)
				sys.exit(0)

			else:
				phase = __validate_task_index(prepare_tasks, phase)
		elif opt == "--save-ansible-logs":
			ansible_configuration.save_logs = True
		elif opt == "--cri":
			if optarg in ["dockershim", "containerd", "manual"]:
				cri = optarg
			else:
				iktprint([("Error:", "error"), (" Unknown CRI “", "default"), (optarg, "argument"), ("“ specified; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)
		elif opt == "-Y":
			confirm = False
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	if len(args) > 1:
		_version = args[1].split(".")
		if len(_version) == 1 or len(_version) >= 2 and int(_version[1]) >= 24:
			if cri == "dockershim":
				iktprint([("Error:", "error"), (" CRI cannot be “", "default"), ("dockershim", "argument"), ("“ for ", "default"), ("Kubernetes ", "programname"), (">= ", "default"), ("1.24", "version"), ("; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)
			elif cri is None:
				cri = "containerd"
		else:
			if cri is None:
				cri = "dockershim"
	else:
		if cri is None:
			cri = "containerd"
		elif cri == "dockershim":
			iktprint([("Error:", "error"), (" CRI cannot be “", "default"), ("dockershim", "argument"), ("“ for ", "default"), ("Kubernetes ", "programname"), (">= ", "default"), ("1.24", "version"), ("; aborting.", "default")], stderr = True)
			sys.exit(errno.EINVAL)

	installation_info = update_installation_info(cri = cri)
	show_configuration()

	if confirm == True:
		retval = iktinput([("\nStart control plane preparation? [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
		if retval.lower() not in ["y", "yes"]:
			iktprint([("\nAborting:", "error"), (" User stopped control plane preparation.", "default")], stderr = True)
			os.remove(IKT_INSTALLATION_INFO)
			sys.exit(errno.EINTR)

	iktprint([(f"\n[Preparing localhost and control plane(s)]", "phase")])

	run_tasks(tasks = prepare_tasks, phase = phase, phase_skiplist = phase_skiplist, final_state = "prepared")

	iktprint([("\n• ", "separator"), ("Updating installation information", "action")])

	# Adjust the kube* packages for the control plane(s) and localhost to match the requested cluster version if necessary;
	# we couldn't do this before since the apt repository wasn't available then
	if len(args) > 1:
		requested_version = __find_requested_version(distro, args[1])
	else:
		requested_version = __find_requested_version(distro)

	iktprint([("   Requested version: ", "action"), (requested_version, "version")])
	update_installation_info(requested_version = requested_version)

	iktprint([("\nControl plane preparation successful", "success")])
	print("\nNext step:")
	iktprint([("• ", "separator"), (f"{about.admin_program_name}", "programname"), (" setup-control-plane ", "command"), ("[", "separator"), ("CNI", "argument"), ("]", "separator"), (" [", "separator"), ("POD_NETWORK_CIDR", "argument"), ("]", "separator")])
	iktprint([("\nSee “", "separator"), (f"{about.admin_program_name}", "programname"), (" help", "command"), ("“ for more information about valid ", "default"), ("CNI", "argument"), (" options.\n", "default")])

def import_cluster(options = [], args = None):
	global no_password

	if os.path.exists("/etc/hostname"):
		f = open("/etc/hostname", "r")
		hostname = f.readline().strip()
	else:
		raise Exception("Error: /etc/hostname not found; Aborting.")

	# default options
	confirm = True

	for opt, optarg in options:
		if opt == "-Y":
			confirm = False
		elif opt == "--no-password":
			no_password = True

	from kubernetes_helper import KubernetesHelper
	kh = KubernetesHelper(about.program_suite_name, about.program_suite_version, None)
	clusters = kh.list_clusters()
	available_clusters = [tmp[0] for tmp in clusters]

	pad = len("Cluster:")
	match = False
	for cluster_name, context in clusters:
		if len(args) > 0 and cluster_name not in args[0].split(","):
			continue
		pad = max(len(cluster_name), pad)
		match = True

	if len(args) > 0:
		for cluster in args[0].split(","):
			if cluster not in available_clusters and match == True:
				iktprint([("Warning: ", "warning"), ("Ignoring non-existing cluster ", "default"), (cluster, "hostname"), ("\n", "default")], stderr = True)

	if match == False:
		iktprint([("Error:", "error"), (" No matching clusters found; available clusters are:", "default")], stderr = True)
		for cluster in available_clusters:
			iktprint([("• ", "separator"), (cluster, "hostname")])
		iktprint([("\nAborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	iktprint([("Cluster:", "header"), ("".ljust(pad + 2 - len("Cluster:")), "default"), ("Context:", "header")])
	for cluster_name, context in clusters:
		if len(args) > 0 and cluster_name not in args[0]:
			continue
		iktprint([(cluster_name, "hostname"), ("".ljust(pad + 2 - len(cluster_name)), "default"), (context, "default")])

	if confirm == True:
		retval = iktinput([("\nImport the following clusters? [y/", "default"), ("N", "emphasis"), ("]: ", "default")])

		if retval.lower() not in ["y", "yes"]:
			iktprint([("\nAborting:", "error"), (" User stopped cluster import.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	iktprint([(f"\n[Importing cluster(s)]", "phase")])

	# Since the clusters might use different versions of Kubernetes
	# we always install the latest kubectl on localhost, so no need to adjust version

	contexts = kh.list_contexts()
	current_context = None
	for context in contexts:
		if context[0] == True:
			current_context = context[1]

	for cluster_name, context in clusters:
		if len(args) > 0 and cluster_name not in args[0]:
			continue

		kh.set_context(context)

		vlist, status = kh.get_list_by_kind_namespace(("Node", ""), "")

		controlplane = None

		for node in vlist:
			node_name = deep_get(node, "metadata#name")
			node_roles = kh.get_node_roles(node)
			if "control-plane" in node_roles:
				controlplane = node_name
				break

		if controlplane is None:
			iktprint([("Error:", "error"), (" Could not find a control plane for the cluster ", "default"), (cluster_name, "hostname"), ("; aborting.", "default")], stderr = True)
			# Remember to restore current-context
			kh.set_context(current_context)
			sys.exit(errno.ENOENT)

		__task_request_ansible_password(None)

		extra_values = {
			"ansible_become_pass": ansible_configuration.ansible_password,
			"ansible_ssh_pass": ansible_configuration.ansible_password,
		}

		install_ansible_posix()

		retval, ansible_results = run_playbook(f"{ANSIBLE_PLAYBOOK_DIR}/prepare_passwordless_ansible.yaml", hosts = [controlplane], extra_values = extra_values, quiet = True)
		if retval != 0:
			break

		cni = kh.identify_cni()
		if len(cni) != 1:
			cni = "<unknown>"
		else:
			cni = cni[0][0]

		retval, ansible_results = run_playbook(f"{ANSIBLE_PLAYBOOK_DIR}/get_versions.yaml", hosts = [controlplane], extra_values = extra_values, quiet = True)
		distro = "<unknown>"
		version = "<unknown>"
		if retval == 0:
			for host in ansible_results:
				if str(host) != controlplane:
					continue

				data = ansible_results[host]["TASK: package versions"]["msg"].splitlines()
				for package in data:
					if package.startswith("kubeadm:"):
						distro = "kubeadm"
						version = package.split(" ")[1]
						break
				break

		update_installation_info(cluster_name = cluster_name, distro = distro, version = version, requested_version = "<none>", cni = cni, state = "installed", phase = "<none>", pod_network_cidr = "<FIXME>")

	kh.set_context(current_context)

	iktprint([("\nCluster import successful", "success")])

def check_for_updates(options = [], args = None):
	# default options
	update_cache = True

	for opt, optarg in options:
		if opt == "--no-cache-update":
			update_cache = False
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	iktprint([("\n[Checking for software updates]", "phase")])

	if update_cache == True:
		iktprint([("\n• ", "separator"), ("Updating APT cache", "action")])
		check_and_print_status(update_apt_cache())

	deb_packages = [
		"ansible",
		"ansible-mitogen",
		"containerd",
		"containerd.io",
		"cri-tools",
		"kubeadm",
		"kubectl",
		"kubelet",
		"kubernetes-cni",
		"kubernetes-client",
		"kubernetes-master",
		"kubernetes-node",
		"docker.io",
		"docker-ce",
		"python3-ansible-runner",
		"python3-natsort",
		"python3-openssl",
		"python3-paramiko",
		"python3-pip",
		"python3-ujson",
		"python3-urllib3",
		"runc",
	]

	version_checks = []

	print()
	check_versions(deb_packages, version_checks)
	print()

def show_configuration():
	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	version = installation_info[cluster_name]["version"]
	requested_version = installation_info[cluster_name]["requested_version"]
	cni = installation_info[cluster_name]["cni"]
	pod_network_cidr = installation_info[cluster_name]["pod_network_cidr"]
	cri = installation_info[cluster_name]["cri"]

	controlplanes = get_control_planes()

	http_proxy = deep_get(iktconfig, "Network#http_proxy", "")
	if http_proxy is not None and http_proxy == "":
		http_proxy = None
	http_proxy_env = os.getenv("http_proxy")
	if http_proxy_env is not None and http_proxy_env == "":
		http_proxy_env = None
	https_proxy = deep_get(iktconfig, "Network#https_proxy", "")
	if https_proxy is not None and https_proxy == "":
		https_proxy = None
	https_proxy_env = os.getenv("https_proxy")
	if https_proxy_env is not None and https_proxy_env == "":
		https_proxy_env = None
	no_proxy = deep_get(iktconfig, "Network#no_proxy", "")
	if no_proxy is not None and no_proxy == "":
		no_proxy = None
	no_proxy_env = os.getenv("no_proxy")
	if no_proxy_env is not None and no_proxy_env == "":
		no_proxy_env = None

	iktprint([("\n[Summary]", "phase")])
	iktprint([("\n• ", "separator"), ("Configuration:", "action")])
	iktprint([("        cluster name: ", "action"), (f"{cluster_name}", "hostname")])
	iktprint([("        distribution: ", "action"), (f"{distro}", "programname")])
	iktprint([("   installed version: ", "action"), __format_none(version, "version")])
	if requested_version is not None and requested_version != "<none>":
		iktprint([("   requested version: ", "action"), __format_none(requested_version, "version")])
	if cni is not None and cni != "<none>":
		iktprint([("                 CNI: ", "action"), (f"{cni}", "programname")])
	if pod_network_cidr is not None and pod_network_cidr != "<none>":
		iktprint([("    Pod Network CIDR: ", "action"), (f"{pod_network_cidr}", "emphasis")])
	if cri is not None and cri != "<none>":
		iktprint([("                 CRI: ", "action"), (f"{cri}", "programname")])
	iktprint([("          HTTP Proxy: ", "action"), __format_none(http_proxy, "url"), (" (", "default"), (f"{IKT_CONFIG_FILE}", "path"), (")", "default")])
	iktprint([("          HTTP Proxy: ", "action"), __format_none(http_proxy_env, "url"), (" (Environment)", "default")])
	iktprint([("         HTTPS Proxy: ", "action"), __format_none(https_proxy, "url"), (" (", "default"), (f"{IKT_CONFIG_FILE}", "path"), (")", "default")])
	iktprint([("         HTTPS Proxy: ", "action"), __format_none(https_proxy_env, "url"), (" (Environment)", "default")])
	iktprint([("            No Proxy: ", "action"), __format_none(no_proxy, "url"), (" (", "default"), (f"{IKT_CONFIG_FILE}", "path"), (")", "default")])
	iktprint([("            No Proxy: ", "action"), __format_none(no_proxy_env, "url"), (" (Environment)", "default")])
	if len(controlplanes) > 0:
		iktprint([("\n• ", "separator"), ("Control plane(s):", "action")])
		for controlplane in controlplanes:
			iktprint([("            hostname: ", "action"), (f"{controlplane[0]} ", "emphasis"), ("(", "default"), (f"{controlplane[1]}", "emphasis"), (")", "default")])

def setup_control_plane(options = [], args = None):
	confirm = True

	# We don't need a cluster name for --list-tasks, so check this first of all
	if "--list-tasks" in [tmp[0] for tmp in options]:
		__list_phases(setup_control_plane_tasks)
		sys.exit(0)

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	version = None
	requested_version = installation_info[cluster_name]["requested_version"]
	state = installation_info[cluster_name]["state"]
	phase = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])
	cni = installation_info[cluster_name]["cni"]
	cri = installation_info[cluster_name]["cri"]

	if state is not None and state in ["installed", "upgrading", "tearing_down", "torn_down", "purging"]:
		iktprint([("Error:", "error"), (" Invalid installation state; there is a partial or full installation already; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)
	elif state is None or state == "preparing":
		iktprint([("Error:", "error"), (" The system is not prepared for installation yet; run ", "default"), (f"{about.admin_program_name}", "programname"), (" prepare", "command"), (" before continuing. Aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if state == "prepared":
		phase = 0

	for opt, optarg in options:
		if opt == "--start-at-task":
			phase = __validate_task_index(setup_control_plane_tasks, optarg)
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(setup_control_plane_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				iktprint([("Warning: ", "warning"), ("Ignoring request to resume a completed installation. Exiting.")], stderr = True)
				sys.exit(0)

			phase = __validate_task_index(setup_control_plane_tasks, phase)
		elif opt == "--save-ansible-logs":
			ansible_configuration.save_logs = True
		elif opt == "-Y":
			confirm = False
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	if cni is None or cni == "<none>":
		if len(args) == 0:
			iktprint([("Warning: ", "warning"), ("No CNI specified; defaulting to ", "default"), (f"{DEFAULT_CNI}", "programname"), (".", "default")], stderr = True)
			cni = DEFAULT_CNI
		elif cni != args[0]:
			cni = args[0]

	if len(args) > 1:
		pod_network_cidr = args[1]
	else:
		pod_network_cidr = DEFAULT_POD_NETWORK_CIDR

	update_installation_info(cni = cni, pod_network_cidr = pod_network_cidr, state = "installing", phase = phase, phase_skiplist = list(phase_skiplist))

	show_configuration()

	if confirm == True:
		retval = iktinput([("\nStart installation? [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
		if retval.lower() not in ["y", "yes"]:
			iktprint([("\nAborting:", "error"), (" User stopped installation.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	iktprint([("\n[Setting up control plane]", "phase")])

	if distro == "kubeadm":
		setup_control_plane_targets["localhost"]["deb_packages"].remove("kubectl")
		setup_control_plane_targets["localhost"]["deb_packages"].append(f"kubectl={requested_version}")
		setup_control_plane_targets["kubeadm"]["deb_packages"].remove("kubectl")
		setup_control_plane_targets["kubeadm"]["deb_packages"].append(f"kubectl={requested_version}")
		setup_control_plane_targets["kubeadm"]["deb_packages"].remove("kubeadm")
		setup_control_plane_targets["kubeadm"]["deb_packages"].append(f"kubeadm={requested_version}")
		setup_control_plane_targets["kubeadm"]["deb_packages"].remove("kubelet")
		setup_control_plane_targets["kubeadm"]["deb_packages"].append(f"kubelet={requested_version}")

	run_tasks(tasks = setup_control_plane_tasks, phase = phase, phase_skiplist = phase_skiplist, final_state = "installed")
	update_installation_info(version = requested_version)

	iktprint([("\nControl plane setup successful", "success")])

def __check_path(args):
	return os.path.exists(args[0])

def __which(args):
	return which(args[0]) is not None

def __get_node_info(kh = None):
	if not os.path.isfile(f"{HOMEDIR}/.kube/config"):
		return None, None

	# The reason for importing inside the function is to avoid slow startup
	# when we don't use the Kubernetes helper
	if kh is None:
		from kubernetes_helper import KubernetesHelper
		kh = KubernetesHelper(about.program_suite_name, about.program_suite_version, None)

	node_statuses = []

	vlist, status = kh.get_list_by_kind_namespace(("Node", ""), "")
	if status == 504:
		return None, None
	elif status != 200:
		iktprint([("Error:", "error"), (" API-server returned ", "default"), (status, "errorvalue"), ("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	retval = False

	for node in vlist:
		node_name = deep_get(node, "metadata#name")
		node_schedulable = not deep_get(node, "spec#unschedulable", False)
		node_roles = kh.get_node_roles(node)
		node_taints = deep_get(node, "spec#taints", [])
		node_statuses.append({
			"name": node_name,
			"schedulable": node_schedulable,
			"roles": node_roles,
			"taints": node_taints,
		})

	return node_statuses, kh

def get_control_planes(fail_on_empty = True):
	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	inventory = ansible_get_inventory_dict()
	__controlplanes = deep_get(inventory, "controlplane#hosts", {})
	__clusterhosts = deep_get(inventory, f"{cluster_name}#hosts", {})
	controlplanes = []
	if len(__controlplanes) == 0 and fail_on_empty == True:
		iktprint([("Error:", "error"), (" No control plane(s) defined in the inventory; rebuilding the inventory using “", "default"), (f"{about.inventory_program_name} ", "programname"), ("rebuild-inventory", "command"), ("“ might help. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)
	if len(__clusterhosts) == 0 and fail_on_empty == True:
		iktprint([("Error:", "error"), (" The cluster ", "default"), (f"{cluster_name}", "hostname"), (" has no hosts in the inventory; rebuilding the inventory using “", "default"), (f"{about.inventory_program_name} ", "programname"), ("rebuild-inventory", "command"), ("“ might help. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	for controlplane in __controlplanes:
		# Only include control planes belonging to this cluster
		if controlplane not in __clusterhosts:
			continue
		ip = socket.gethostbyname(controlplane)
		controlplanes.append((controlplane, ip))
	return controlplanes

def teardown_control_plane(options = [], args = None):
	confirm = True

	# We don't need a cluster name for --list-tasks, so check this first of all
	if "--list-tasks" in [tmp[0] for tmp in options]:
		__list_phases(teardown_control_plane_tasks)
		sys.exit(0)

	if not os.path.exists(IKT_INSTALLATION_INFO):
		iktprint([("Error:", "error"), (" Could not find reliable installation information. Aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	state = installation_info[cluster_name]["state"]
	phase = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])

	if distro is None or distro == "<none>":
		iktprint([("Error:", "error"), (" Could not find reliable installation information. Aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if state is None:
		iktprint([("Error:", "error"), (" Cannot determine installation state; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)
	elif state in ["preparing", "prepared", "torn_down"]:
		iktprint([("Error:", "error"), (" The system has no installed cluster; try ", "default"), (f"{about.admin_program_name}", "programname"), (" purge-control-plane", "command"), ("; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	for opt, optarg in options:
		if opt == "--start-at-task":
			phase = __validate_task_index(teardown_control_plane_tasks, optarg)
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(teardown_control_plane_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				iktprint([("Warning: ", "warning"), ("Ignoring request to resume a completed teardown. Exiting.")], stderr = True)
				sys.exit(0)

			phase = __validate_task_index(setup_control_plane_tasks, phase)
		elif opt == "--save-ansible-logs":
			ansible_configuration.save_logs = True
		elif opt == "-Y":
			confirm = False
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	show_configuration()

	if confirm == True:
		retval = iktinput([("\nStart teardown? [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
		if retval.lower() not in ["y", "yes"]:
			iktprint([("\nAborting:", "error"), (" User stopped teardown.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	iktprint([("\n[Tearing down cluster]", "phase")])

	installation_info = update_installation_info(state = "tearing_down", phase = 0)

	run_tasks(tasks = teardown_control_plane_tasks, phase = phase, phase_skiplist = phase_skiplist, final_state = "torn_down")
	iktprint([("\nCluster teardown successful", "success")])

def purge_control_plane(options = [], args = None):
	confirm = True

	# We don't need a cluster name for --list-tasks, so check this first of all
	if "--list-tasks" in [tmp[0] for tmp in options]:
		__list_phases(purge_control_plane_tasks)
		sys.exit(0)

	if not os.path.exists(IKT_INSTALLATION_INFO):
		iktprint([("Error:", "error"), (" Could not find reliable installation information. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	state = installation_info[cluster_name]["state"]
	phase = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])

	if state is None or state in ["preparing", "installing", "upgrading"]:
		iktprint([("Error:", "error"), (" Invalid installation state; there's no fully installed cluster; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if len(options) == 0:
		phase = 0

	for opt, optarg in options:
		if opt == "--start-at-task":
			phase = __validate_task_index(teardown_control_plane_tasks, optarg)
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(teardown_control_plane_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				iktprint([("Warning: ", "warning"), ("Ignoring request to resume a completed teardown. Exiting.")], stderr = True)
				sys.exit(0)

			phase = __validate_task_index(setup_control_plane_tasks, phase)
		elif opt == "--save-ansible-logs":
			ansible_configuration.save_logs = True
		elif opt == "-Y":
			confirm = False
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	# If there's still an installed cluster or if the teardown hasn't finished, teardown the cluster before purging
	if state in ["installed", "upgraded", "tearing_down"]:
		teardown_control_plane(options, args)
		state = "torn_down"
	else:
		show_configuration()

		if confirm == True:
			retval = iktinput([("\nStart purge? [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
			if retval.lower() not in ["y", "yes"]:
				iktprint([("\nAborting:", "error"), (" User stopped purge.", "default")], stderr = True)
				sys.exit(errno.EINTR)

	iktprint([("\n\n[Purging cluster configuration and software]", "phase")])

	# If we're purging the control plane we want to leave kubectl behind; if we have a setup with multiple
	# control planes and we run this from one of them, then kubectl will remain on the other two. Just don't do it.
	if __selection_localhost() == __selection_control_planes():
		purge_control_plane_targets["kubeadm"]["deb_packages"].remove("kubectl")
		purge_control_plane_targets["kubeadm"]["deb_packages_held"].remove("kubectl")

	installation_info = update_installation_info(state = "purging", phase = 0)

	run_tasks(tasks = purge_control_plane_tasks, phase = phase, phase_skiplist = phase_skiplist, final_state = "purged")
	os.remove(IKT_INSTALLATION_INFO)

	iktprint([("\nCluster purge successful", "success")])

	iktprint([("\nNote: ", "note"), ("It's recommended to reboot the control plane(s) after purging the cluster\n", "default")])

def upgrade_control_plane(options = [], args = None):
	confirm = True

	# default options
	update_cache = True
	allow_reinstall = False
	requested_version = None

	# We don't need a cluster name for --list-tasks or --override, so check this first of all
	if "--list-tasks" in [tmp[0] for tmp in options]:
		__list_phases(upgrade_control_plane_tasks)
		sys.exit(0)
	elif "--override" in [tmp[0] for tmp in options]:
		if os.path.isfile(IKT_INSTALLATION_INFO) == True:
			iktprint([("Warning: ", "warning"), ("Overriding ", "default"), (f"{IKT_INSTALLATION_INFO}", "path"), ("; this may cause issues.", "default")], stderr = True)
		else:
			iktprint([("Note: ", "note"), (f"{IKT_INSTALLATION_INFO}", "path"), (" does not exist; rebuilding.", "default")])
		rebuild_installation_info(state = "upgrading")

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	distro = installation_info[cluster_name]["distro"]
	version = installation_info[cluster_name]["version"]
	requested_version = installation_info[cluster_name]["requested_version"]
	state = installation_info[cluster_name]["state"]
	phase = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])

	if state is None or state in ["<none>"]:
		iktprint([("Error:", "error"), (" Unknown installation state; if you believe this is OK (such as when upgrading a cluster not installed using ", "default"), (f"{about.admin_program_name}", "programname"), (" you can try using the “", "default"), ("--override", "argument"), ("“ argument; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if state is None or state in ["<none>", "preparing", "prepared", "installing", "tearing_down", "torn_down", "purging"]:
		iktprint([("Error:", "error"), (" Invalid installation state; Kubernetes does not seems to be fully installed; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if state in ["installed", "upgraded"]:
		phase = 0

	if len(args) > 0:
		requested_version = __find_requested_version(distro, args[0])
	else:
		requested_version = __find_requested_version(distro)

	for opt, optarg in options:
		if opt == "--start-at-task":
			phase = __validate_task_index(upgrade_control_plane_tasks, optarg)
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(upgrade_control_plane_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				iktprint([("Warning: ", "warning"), ("Ignoring request to resume a completed upgrade. Exiting.")], stderr = True)
				sys.exit(0)

			phase = __validate_task_index(upgrade_control_plane_tasks, phase)
		elif opt == "--no-cache-update":
			update_cache = False
		elif opt == "--reinstall":
			allow_reinstall = True
		elif opt in ["--override", "--list-tasks"]:
			continue
		elif opt == "--save-ansible-logs":
			ansible_configuration.save_logs = True
		elif opt == "-Y":
			confirm = False
		else:
			raise Exception(f"Programming error; invalid option {opt}")

	# XXX: How do we check that nodes are drained? We can check whether they are cordoned
	node_status, kh = __get_node_info()

	if node_status is None:
		iktprint([("Error:", "error"), (" No ", "default"), (f"{HOMEDIR}/.kube/config", "path"), (" available; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	if update_cache == True:
		iktprint([("\n• ", "separator"), ("Updating APT cache", "action")])
		check_and_print_status(update_apt_cache())

	iktprint([("\n• ", "separator"), ("Running sanity checks", "action")])

	deb_versions = check_deb_versions(["kubeadm"])

	if len(deb_versions) == 0:
		iktprint([("Critical:", "critical"), (" No candidate version for ", "default"), ("kubeadm", "programname"), (" available; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	if requested_version is not None:
		if requested_version not in deb_versions[0][3]:
			iktprint([("Error:", "error"), (" The requested version ", "default"), (f"{requested_version}", "version"), (" is not available; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		elif requested_version == version:
			if allow_reinstall == False:
				iktprint([("Warning:", "warning"), (" The requested version ", "default"), (f"{requested_version}", "version"), (" is already installed; to reinstall use the option “", "default"), ("--reinstall", "option"), ("“.", "default")], stderr = True)
				sys.exit(errno.EINVAL)
		elif deb_compare_versions(version, requested_version) == True:
			iktprint([("Error:", "error"), (" The requested version ", "default"), (f"{requested_version}", "version"), (" is older than than the installed version ", "default"), (f"{deb_versions[0][1]}", "version"), (". Downgrades are not supported; aborting.", "default")], stderr = True)
			sys.exit(errno.EINVAL)
	else:
		requested_version = deb_versions[0][2]
		if len(requested_version) == 0 or requested_version == "<none>":
			iktprint([("Note: ", "ok"), ("The latest version ", "default"), (f"{deb_versions[0][1]}", "version"), (" is already installed.", "default")])
			sys.exit(0)

	# Is this an major, minor, or patchrev upgrade?
	installed_version_tuple = version.split(".")
	requested_version_tuple = requested_version.split(".")

	upgrade_type = None

	if installed_version_tuple[0] != requested_version_tuple[0]:
		iktprint([("Error:", "error"), (" Upgrades between ", "default"), ("MAJOR", "emphasis"), (" versions is currently not supported (installed version: ", "default"), (f"{deb_versions[0][1]}", "version"), (", requested version: ", "default"), (f"{requested_version}", "version"), ("; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOTSUP)
	elif installed_version_tuple[1] != requested_version_tuple[1]:
		installed_major_minor = f"{installed_version_tuple[0]}.{installed_version_tuple[1]}"
		if int(requested_version_tuple[1]) - int(installed_version_tuple[1]) > 1:
			iktprint([("Error:", "error"), (" Skipping ", "default"), ("MINOR", "emphasis"), (" versions is not supported, please perform the following upgrades sequentially:", "default")], stderr = True)
			minor_versions = {}
			for version in reversed(deb_versions[0][3]):
				version_tuple = version.split(".")
				major_minor = f"{version_tuple[0]}.{version_tuple[1]}"
				if int(version_tuple[1]) > int(installed_version_tuple[1]) and int(version_tuple[1]) <= int(requested_version_tuple[1]) and (major_minor not in minor_versions or minor_versions[major_minor] < version_tuple[2]):
					minor_versions[major_minor] = version_tuple[2]
			for version in minor_versions:
				iktprint([("• ", "separator"), (f"{about.admin_program_name}", "programname"), (" upgrade-control-plane", "command"), (f" {version}.{minor_versions[version]}", "version")])
			sys.exit(errno.EINVAL)
		else:
			upgrade_type = "minor"
	else:
		upgrade_type = "patchrev"

	# If this is an upgrade to a new patchrev the cluster doesn't have to be drained
	if upgrade_type == "minor":
		schedulable_count = 0
		nodes_to_drain = ""
		for node in node_status:
			if node["schedulable"] == False:
				continue

			if "control-plane" in node["roles"]:
				continue

			if schedulable_count == 0:
				iktprint([("\nError:", "error"), (" The following nodes need to be drained; aborting.", "default")])
			schedulable_count += 1
			iktprint([("• ", "separator"), (f"{node['name']}", "emphasis")])
			nodes_to_drain += node['name']

		if schedulable_count > 0:
			iktprint([("\nThis can be achieved with: “", "default"), ("kubectl ", "programname"), ("drain ", "command"), ("--ignore-daemonsets --delete-emptydir-data ", "option"), (f"{nodes_to_drain}", "url"), ("“", "default")])
			sys.exit(errno.EBUSY)

	installation_info = update_installation_info(state = "upgrading", requested_version = requested_version, phase = 0)

	# If we got here all the sanity checks were successful
	iktprint([("OK", "ok")])

	# Adjust package version for localhost
	upgrade_control_plane_targets["localhost"]["deb_packages"].remove("kubectl")
	upgrade_control_plane_targets["localhost"]["deb_packages"].append(f"kubectl={requested_version}")

	show_configuration()

	if confirm == True:
		retval = iktinput([("\nStart upgrade? [y/", "default"), ("N", "emphasis"), ("]: ", "default")])
		if retval.lower() not in ["y", "yes"]:
			iktprint([("\nAborting:", "error"), (" User stopped upgrade.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	iktprint([("\n[Upgrading control plane]", "phase")])

	run_tasks(tasks = upgrade_control_plane_tasks, phase = phase, phase_skiplist = phase_skiplist, final_state = "upgraded")
	values = {
		"control_plane_k8s_version": requested_version,
	}
	ansible_set_vars(ANSIBLE_INVENTORY, "all", values)
	update_installation_info(version = requested_version)

	iktprint([("\nControl plane upgrade successful", "success")])

# This basically just checks downloads the latest CNI yaml and applies it
def update_cni(options = [], args = None):
	iktprint([("update-cni is not yet implemented", "notok")])

def taint_control_plane(options = [], args = None):
	node_statuses, kh = __get_node_info()

	if node_statuses is None:
		iktprint([("Critical: ", "critical"), ("Failed to get node information; do you have a running cluster? Aborting.", "default")], stderr = True)
		sys.exit(errno.ENXIO)

	first = True

	for node in node_statuses:
		if "control-plane" in node["roles"] and (len(args) == 0 or node["name"] in args):
			if first == True:
				iktprint([("Tainting control plane(s):", "header")])
				first = False
			iktprint([(node["name"], "hostname")])
			message, status = kh.taint_node(node["name"], node["taints"], ("node-role.kubernetes.io/control-plane", "NoSchedule"))
			iktprint([("  Tainted", "success")])

		if "master" in node["roles"] and (len(args) == 0 or node["name"] in args):
			if first == True:
				iktprint([("Tainting control plane(s):", "header")])
				first = False
			iktprint([(node["name"], "hostname")])
			message, status = kh.taint_node(node["name"], node["taints"], ("node-role.kubernetes.io/master", "NoSchedule"))
			iktprint([("  Tainted", "success")])

	if first == True:
		iktprint([("Warning:", "warning"), (" No matching control planes found. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

def untaint_control_plane(options = [], args = None):
	node_statuses, kh = __get_node_info()

	if node_statuses is None:
		iktprint([("Critical:", "critical"), (" Failed to get node information; do you have a running cluster? Aborting.", "default")], stderr = True)
		sys.exit(errno.ENXIO)

	first = True

	for node in node_statuses:
		if "control-plane" in node["roles"] and (len(args) == 0 or node["name"] in args):
			if first == True:
				iktprint([("Untainting control plane(s):", "header")])
				first = False
			iktprint([(node["name"], "hostname")])
			message, status = kh.taint_node(node["name"], node["taints"], ("node-role.kubernetes.io/control-plane", None))
			iktprint([("  Untainted", "success")])

		if "master" in node["roles"] and (len(args) == 0 or node["name"] in args):
			if first == True:
				iktprint([("Untainting control plane(s):", "header")])
				first = False
			iktprint([(node["name"], "hostname")])
			message, status = kh.taint_node(node["name"], node["taints"], ("node-role.kubernetes.io/master", None))
			iktprint([("  Untainted", "success")])

	if first == True:
		iktprint([("Warning: ", "warning"), ("No matching control planes found. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

def preflight_check(options = [], args = None):
	error = 0
	warning = 0
	note = 0

	user = getuser()

	iktprint([("[Checking whether ", "phase"), (f"{user}", "path"), (" is in ", "phase"), ("/etc/sudoers", "path"), (" or ", "default"), ("/etc/sudoers.d", "path"), ("]", "phase")])
	args = ["/usr/bin/sudo", "-l"]
	result = execute_command_with_response(args)

	sudoer = True

	for line in result.splitlines():
		tmp = re.match(r"^User ([^\s]+) is not allowed to run sudo on.*", line)
		if tmp is not None:
			iktprint([("  Error:", "error"), (f" {user} ", "path"), ("is not in ", "default"), ("/etc/sudoers", "path"), (" or ", "default"), ("/etc/sudoers.d\n", "path")], stderr = True)
			error += 1
			sudoer = False
			break

	if sudoer == True:
		iktprint([("  OK\n", "emphasis")])

		iktprint([("[Checking whether", "phase") ,(f" {user} ", "path"), ("can perform passwordless sudo]", "phase")])
		args = ["/usr/bin/sudo", "-l"]
		result = execute_command_with_response(args)
		passwordless_sudo = False

		for line in result.splitlines():
			tmp = re.match(r"^\s*\(ALL\s*:\s*ALL\)\s*NOPASSWD:\s*ALL\s*$", line)
			if tmp is not None:
				iktprint([("  OK\n", "emphasis")])
				passwordless_sudo = True
				break

		if passwordless_sudo == False:
			iktprint([("  Error:", "error"), (f" {user} ", "path"), ("cannot perform passwordless sudo\n", "default")], stderr = True)

	iktprint([("[Checking whether ", "phase"), ("ssh", "command"), (" known_hosts hashing is enabled]", "phase")])
	iktprint([("  Note:", "emphasis"), (" this test is not 100% reliable since ssh settings can vary based on target host\n", "default")])
	args = ["/usr/bin/ssh", "-G", "localhost"]
	result = execute_command_with_response(args)

	for line in result.splitlines():
		tmp = re.match(r"^hashknownhosts\s+yes$", line)
		if tmp is not None:
			iktprint([("  Warning:", "warning"), (" ssh", "command"), (" known_hosts hashing is enabled; this may cause issues with ", "default"), ("paramiko\n", "command")], stderr = True)
			warning += 1
			break

	iktprint([("Summary:", "header")])
	iktprint([(f"  Errors: {error}", "error")])
	iktprint([(f"Warnings: {warning}", "warning")])
	iktprint([(f"   Notes: {note}", "note")])

def troubleshoot(options = [], args = None):
	error = 0
	warning = 0
	note = 0
	total = 0

	# First start with the really basic: does the cluster respond?
	# Check no_proxy, perhaps?

	# Is the version of kubectl within one version of the cluster version?
	iktprint([("[Checking client/server version match]\n", "phase")])

	kubectl_major_version, kubectl_minor_version, kubectl_git_version, server_major_version, server_minor_version, server_git_version = kubectl_get_version()

	iktprint([("       kubectl ", "programname"), ("version: ", "default"), (f"{kubectl_git_version}", "version")])
	iktprint([("kube-apiserver ", "programname"), ("version: ", "default"), (f"{server_git_version}", "version")])

	print()

	if server_major_version != 1:
		iktprint([("Critical:", "critical"), (f" {about.program_suite_name}", "programname"), (" has not been tested for any other major version of Kubernetes than v1; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOTSUP)

	if kubectl_minor_version > server_minor_version and kubectl_minor_version == server_minor_version + 1:
		iktprint([("Note: ", "note"), ("The ", "default"), ("kubectl", "programname"), (f" version is one minor version newer than that of ", "default"), ("kube-apiserver", "programname"), (";", "default")])
		iktprint([("      this is a supported configuration, but it's generally recommended to keep the versions in sync.", "default")])
		note += 1
	elif kubectl_minor_version > server_minor_version:
		iktprint([("Warning: ", "warning"), ("The ", "default"), ("kubectl", "programname"), (f" version is more than one minor versions newer than that of ", "default"), ("kube-apiserver", "programname"), (";", "default")], stderr = True)
		iktprint([("         this might work, but it's generally recommended to keep the versions in sync.", "default")], stderr = True)
		warning += 1
	elif kubectl_minor_version < server_minor_version and kubectl_minor_version + 1 == server_minor_version:
		iktprint([("Note: ", "note"), ("The ", "default"), ("kubectl", "programname"), (f" version is one minor version older than that of ", "default"), ("kube-apiserver", "programname"), (";", "default")])
		iktprint([("      this is a supported configuration, but it's generally recommended to keep the versions in sync.", "default")])
		warning += 1
	elif kubectl_minor_version < server_minor_version:
		iktprint([("Error:", "error"), (" The ", "default"), ("kubectl", "programname"), (f" version is much older than that of ", "default"), ("kube-apiserver", "programname"), (";", "default")], stderr = True)
		iktprint([("       this is NOT supported and is likely to cause issues.", "default")], stderr = True)
		error += 1

	total = error + warning + note

	if total == 0:
		iktprint([("OK", "ok")])

	# Kubernetes API based checks
	iktprint([("\n[Checking kubelet & kube-proxy versions]", "phase")])

	from kubernetes_helper import KubernetesHelper
	kh = KubernetesHelper(about.program_suite_name, about.program_suite_version, None)

	vlist, status = kh.get_list_by_kind_namespace(("Node", ""), "")

	# Check kubelet and kube-proxy versions;
	# they can be up to two minor versions older than kube-apiserver,
	# but most not be newer
	critical = False

	for node in vlist:
		node_name = deep_get(node, "metadata#name")
		kubelet_version = deep_get(node, "status#nodeInfo#kubeletVersion")
		kubeproxy_version = deep_get(node, "status#nodeInfo#kubeProxyVersion")
		tmp = re.match(r"^v(\d+)\.(\d+)\..*", kubelet_version)

		kubelet_major_version = None
		kubelet_minor_version = None
		kubeproxy_major_version = None
		kubeproxy_minor_version = None
		if tmp is not None:
			kubelet_major_version = int(tmp[1])
			kubelet_minor_version = int(tmp[2])
		else:
			iktprint([("Error:", "error"), (" Failed to extract ", "default"), ("kubelet", "programname"), (" version on node ", "default"), (f"{node_name}", "hostname")], stderr = True)
			critical = True

		tmp = re.match(r"^v(\d+)\.(\d+)\..*", kubeproxy_version)
		if tmp is not None:
			kubeproxy_major_version = int(tmp[1])
			kubeproxy_minor_version = int(tmp[2])
		else:
			iktprint([("Error:", "error"), (" Failed to extract ", "default"), ("kube-proxy", "programname"), (" version on node ", "default"), (f"{node_name}", "hostname")], stderr = True)
			critical = True

		if kubelet_major_version is not None and kubelet_major_version != 1:
			iktprint([(f"Critical:", "critical"), (f" {about.program_suite_name}", "programname"), (" has not been tested for any other major version of Kubernetes than v1; node ", "default"), (f"{node_name}", "hostname"), (" runs ", "default"), ("kubelet ", "programname"), ("version ", "default"), (f"{kubelet_version}", "version")], stderr = True)
			critical = True

		if kubeproxy_major_version is not None and kubeproxy_major_version != 1:
			iktprint([(f"Critical:", "critical"), (f" {about.program_suite_name}", "programname"), (" has not been tested for any other major version of Kubernetes than v1; node ", "default"), (f"{node_name}", "hostname"), (" runs ", "default"), ("kube-proxy ", "programname"), ("version ", "default"), (f"{kubeproxy_version}", "version")], stderr = True)
			critical = True

		if kubelet_minor_version is not None and kubelet_minor_version > server_minor_version:
			iktprint([(f"Error:", "error"), (" The version of ", "default"), ("kubelet", "programname"), (" (", "default"), (f"{kubelet_major_version}.{kubelet_minor_version}", "version"), (") on node ", "default"), (f"{node_name}", "hostname"), (" is newer than that of ", "default"), ("kube-apiserver", "programname"), (" (", "default"), (f"{server_major_version}.{server_minor_version}", "version"), (");", "default")], stderr = True)
			iktprint([(f"       this is not supported.", "default")], stderr = True)
			error += 1
		elif kubelet_minor_version is not None and kubelet_minor_version < server_minor_version and kubelet_minor_version + 2 >= server_minor_version:
			iktprint([(f"Warning: ", "warning"), ("The version of ", "default"), ("kubelet", "programname"), (" (", "default"), (f"{kubelet_major_version}.{kubelet_minor_version}", "version"), (") on node ", "default"), (f"{node_name}", "hostname"), (" is a bit older than that of ", "default"), ("kube-apiserver", "programname"), (" (", "default"), (f"{server_major_version}.{server_minor_version}", "version"), (");", "default")], stderr = True)
			iktprint([(f"         this is supported, but not recommended.", "default")], stderr = True)
			warning += 1
		elif kubelet_minor_version is not None and kubelet_minor_version < server_minor_version:
			iktprint([(f"Error:", "error"), (" The version of ", "default"), ("kubelet", "programname"), (" (", "default"), (f"{kubelet_major_version}.{kubelet_minor_version}", "version"), (") on node ", "default"), (f"{node_name}", "hostname"), (" is a much older than that of ", "default"), ("kube-apiserver", "programname"), (" (", "default"), (f"{server_major_version}.{server_minor_version}", "version"), (");", "default")], stderr = True)
			iktprint([(f"       this is not supported.", "default")], stderr = True)
			error += 1

		if kubelet_minor_version is not None and kubeproxy_minor_version is not None and kubelet_minor_version != kubeproxy_minor_version:
			iktprint([(f"Error:", "error"), (" The version of ", "default"), ("kubelet", "programname"), (" (", "default"), (f"{kubelet_major_version}.{kubelet_minor_version}", "version"), (") on node ", "default"), (f"{node_name}", "hostname"), (" is not the same as that of ", "default"), ("kube-proxy", "programname"), (" (", "default"), (f"{kubeproxy_major_version}.{kubeproxy_minor_version}", "version"), (");", "default")], stderr = True)
			iktprint([(f"       this is not supported.", "default")], stderr = True)
			error += 1

	if critical == True:
		print()
		iktprint([("Critical errors detected; aborting.", "emphasis")], stderr = True)
		sys.exit(errno.EINVAL)

	print()

	if error + warning + note == total:
		iktprint([("OK", "ok")])

	total += error + warning + note

	# Check kube-controller-manager, kube-scheduler, and cloud-controller-manager;
	# they should match, but can be up to one version older,
	# but most not be newer

	# check whether role bindings and cluster role bindings refer to non-existing roles/cluster roles

	print()

	iktprint([("Summary:", "header")])
	iktprint([(f"  Errors: {error}", "error")])
	iktprint([(f"Warnings: {warning}", "warning")])
	iktprint([(f"   Notes: {note}", "note")])

commandline = {
	"Check Versions": {
		"command": ["check-versions", "cv"],
		"description": [("Update the package cache and show software versions", "description")],
		"extended_description": [
			[("Note: ", "note"), ("some of the listed software might not be relevant", "description")],
			[("to the configuration in use", "description")],
		],
		"options": {
			"--no-cache-update": {
				"description": [("Do not update the APT cache", "description")],
			},
		},
		"min_args": 0,
		"max_args": 0,
		"callback": check_for_updates,
	},
	"Import Cluster": {
		"command": ["import-cluster"],
		"values": [("[", "separator"), ("CLUSTER_NAME", "argument"), (",", "separator"), ("...", "argument"), ("]", "separator")],
		"description": [(f"Import existing cluster(s) and prepare them for use with {about.program_suite_name}", "description")],
		"extended_description": [
			[("If ", "description"), ("CLUSTER_NAME", "argument"), (",", "separator"), ("...", "argument"), (" is not specified all clusters in ", "description"), (f"{HOMEDIR}/.kube/config", "path")],
			[(" will be imported", "description")],
		],
		"min_args": 0,
		"max_args": 1,
		"callback": import_cluster,
		"options": {
			"-Y": {
				"description": [("Do not ask for confirmation before performing actions", "description")],
			},
			"--no-password": {
				"description": [("Do not prompt for a password; use this if the hosts you're preparing are already configured for login using an SSH key", "description")],
			},
		},
	},
	"Prepare Installation": {
		"command": ["prepare"],
		"values": [("CLUSTER_NAME", "argument"), (" [", "separator"), ("KUBERNETES_VERSION", "argument"), ("]", "separator")],
		"description": [("Install and configure pre-requisites; run this before ", "description"), ("setup-control-plane", "command")],
		"extended_description": [
			[("If no version is specified the newest available version will be used", "description")],
		],
		"options": {
			"--control-plane": {
				"values": [("HOST", "argument")],
				"extended_description": [
					[("Note: ", "note"), ("HOST", "argument"), (" should be a resolvable hostname; using IP-addresses may cause issues.", "description")],
					[("If the host intend for use as control plane in the cluster does not have a resolvable", "description")],
					[("hostname it's recommended to use ", "description"), ("/etc/hosts", "path"), (" for this purpose.", "description")],
				],
				"description": [("Use ", "description"), ("HOST", "argument"), (" as control plane ", "description")],
				"requires_arg": True,
			},
			"--resume": {
				"description": [("Resume preparation; can be used if preparation was aborted", "description")],
			},
			"--start-at-task": {
				"values": [("TASK", "argument")],
				"description": [("Start at ", "description"), ("TASK", "argument"), (" instead of running all tasks", "description")],
				"requires_arg": True,
			},
			"--skip-tasks": {
				"values": [("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"description": [("Skip ", "description"), ("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"requires_arg": True,
			},
			"--list-tasks": {
				"description": [("List valid values for ", "description"), ("TASK", "argument"), (" to use with ", "description"), ("--start-at-task", "option"), (" and ", "description"), ("--skip-tasks", "option")],
			},
			"--no-password": {
				"description": [("Do not prompt for a password; use this if the hosts you're preparing are already configured for login using an SSH key", "description")],
			},
			"--save-ansible-logs": {
				"description": [("Save logs from Ansible runs; the logs can be viewed using “", "description"), ("iku", "programname"), (" logs", "command"), ("“", "description")]
			},
			"--cri": {
				"values": [("CRI", "argument")],
				"description": [("Use ", "description"), ("CRI", "argument"), (" instead of the default CRI", "description")],
				"extended_description": [
					[("Valid options for CRI (Container Runtime Interface) are:", "description")],
					[
						("dockershim", "argument"), (" (", "description"), ("Kubernetes", "programname"), (" < ", "description"), ("1.24", "version"), (")", "description"), (", ", "separator"),
						("containerd", "argument"), (", ", "separator"),
					],
					[
						("manual", "argument"), (" (do not install a CRI; this requires you to manually install and configure the CRI)", "description"),
					],
					[("The default CRI is ", "description"), ("dockershim", "argument"), (" for ", "description"), ("Kubernetes", "programname"), (" < ", "description"), ("1.24", "version")],
					[("and ", "description"), ("containerd", "argument"), (" for ", "description"), ("Kubernetes", "programname"), (" >= ", "description"), ("1.24", "version")],
				],
				"requires_arg": True,
			},
			"-Y": {
				"description": [("Do not ask for confirmation before performing actions", "description")],
			},
		},
		"min_args": 0,
		"max_args": 2,
		"callback": prepare_installation,
	},
	"Setup Control Plane": {
		"command": ["setup-control-plane"],
		"values": [
			("[", "separator"), ("CNI", "argument"), ("]", "separator"),
			(" [", "separator"), ("POD_NETWORK_CIDR", "argument"), ("]", "separator"),
		],
		"description": [("Setup and launch the control plane", "description")],
		"extended_description": [
			[("Valid options for CNI (Container Network Interface, aka Pod Network): ", "description")],
			[
				("antrea", "argument"), (", ", "separator"),
				("calico", "argument"), (", ", "separator"),
				("canal", "argument"), (", ", "separator"),
				("cilium", "argument"), (", ", "separator"),
				("flannel", "argument"), (", ", "separator"),
				("kube-router", "argument"), (", ", "separator"),
				("weave", "argument"),
			],
			[("By default ", "description"), ("cilium", "argument"), (" will be used as CNI", "description")],
			[("and ", "description"), ("10.244.0.0/16", "argument"), (" will be used as pod network CIDR", "description")],
		],
		"options": {
			"--resume": {
				"description": [("Resume installation; can be used if installation was aborted", "description")],
			},
			"--start-at-task": {
				"values": [("TASK", "argument")],
				"description": [("Start at ", "description"), ("TASK", "argument"), (" instead of running all tasks", "description")],
				"requires_arg": True,
			},
			"--skip-tasks": {
				"values": [("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"description": [("Skip ", "description"), ("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"requires_arg": True,
			},
			"--list-tasks": {
				"description": [("List valid values for ", "description"), ("TASK", "argument"), (" to use with ", "description"), ("--start-at-task", "option"), (" and ", "description"), ("--skip-tasks", "option")],
			},
			"--save-ansible-logs": {
				"description": [("Save logs from Ansible runs; the logs can be viewed using “", "description"), ("iku", "programname"), (" logs", "command"), ("“", "description")]
			},
			"-Y": {
				"description": [("Do not ask for confirmation before performing actions", "description")],
			},
		},
		"min_args": 0,
		"max_args": 2,
		"callback": setup_control_plane,
	},
	"Upgrade CNI": {
		"command": ["upgrade-cni"],
		"values": [("[", "separator"), ("CNI", "argument"), ("]", "separator")],
		"description": [("Upgrade the CNI", "description")],
		"extended_description": [
			[("Upgrades the CNI (currently only Cilium is supported)", "description")],
		],
		"min_args": 0,
		"max_args": 1,
		"callback": upgrade_cni,
	},
	"Upgrade Control Plane": {
		"command": ["upgrade-control-plane"],
		"values": [("[", "separator"), ("KUBERNETES_VERSION", "argument"), ("]", "separator")],
		"description": [("Upgrade the control plane", "description")],
		"extended_description": [
			[("Upgrades the control plane to ", "description"), ("KUBERNETES_VERSION", "argument"), (" if specified;", "description")],
			[("if no version is specified the newest available version will be used", "description")],
			[("Upgrading requires all nodes to be drained first. Once the control plane", "description")],
			[("has been upgraded you must upgrade all nodes to the same version.", "description")],
			[("Important", "emphasis"), (": skipping PATCH REVISIONS is acceptable,", "description")],
			[("but when upgrading to a newer MINOR version all intermediate MINOR versions", "description")],
			[("must be installed first; this applies to nodes too", "description")],
		],
		"options": {
			"--no-cache-update": {
				"description": [("Do not update the APT cache", "description")],
			},
			"--resume": {
				"description": [("Resume upgrade; can be used if upgrade was aborted", "description")],
			},
			"--start-at-task": {
				"values": [("TASK", "argument")],
				"description": [("Start at ", "description"), ("TASK", "argument"), (" instead of running all tasks", "description")],
				"requires_arg": True,
			},
			"--skip-tasks": {
				"values": [("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"description": [("Skip ", "description"), ("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"requires_arg": True,
			},
			"--list-tasks": {
				"description": [("List valid values for ", "description"), ("TASK", "argument"), (" to use with ", "description"), ("--start-at-task", "option"), (" and ", "description"), ("--skip-tasks", "option")],
			},
			"--reinstall": {
				"description": [("Allow installing an already installed Kubernetes version", "description")],
			},
			"--override": {
				"description": [("Override/rebuild installation info", "description")],
			},
			"--save-ansible-logs": {
				"description": [("Save logs from Ansible runs; the logs can be viewed using “", "description"), ("iku", "programname"), (" logs", "command"), ("“", "description")]
			},
			"-Y": {
				"description": [("Do not ask for confirmation before performing actions", "description")],
			},
		},
		"min_args": 0,
		"max_args": 1,
		"callback": upgrade_control_plane,
	},
	"Teardown Control Plane": {
		"command": ["teardown-control-plane"],
		"description": [("Tear down the control plane", "description")],
		"extended_description": [
			[("Note", "emphasis"), (": Before running this command all nodes must have been removed first", "description")],
			[("The configuration for the control plane and any software installed", "description")],
			[("during installation will NOT be removed", "description")],

		],
		"options": {
			"--resume": {
				"description": [("Resume teardown; can be used if teardown was aborted", "description")],
			},
			"--start-at-task": {
				"values": [("TASK", "argument")],
				"description": [("Start at ", "description"), ("TASK", "argument"), (" instead of running all tasks", "description")],
				"requires_arg": True,
			},
			"--skip-tasks": {
				"values": [("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"description": [("Skip ", "description"), ("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"requires_arg": True,
			},
			"--list-tasks": {
				"description": [("List valid values for ", "description"), ("TASK", "argument"), (" to use with ", "description"), ("--start-at-task", "option"), (" and ", "description"), ("--skip-tasks", "option")],
			},
			"--save-ansible-logs": {
				"description": [("Save logs from Ansible runs; the logs can be viewed using “", "description"), ("iku", "programname"), (" logs", "command"), ("“", "description")]
			},
			"-Y": {
				"description": [("Do not ask for confirmation before performing actions", "description")],
			},
		},
		"min_args": 0,
		"max_args": 0,
		"callback": teardown_control_plane,
	},
	"Purge Control Plane": {
		"command": ["purge-control-plane"],
		"description": [("Purge configuration and installed software", "description")],
		"extended_description": [
			[("purge-control-plane", "command"), (" will run ", "description"), ("teardown-control-plane", "command"), (" first if necessary", "description")],
			[("Software and configuration needed for ", "description"), (f"{about.program_suite_name}", "programname"), (" will not be purged", "description")],

		],
		"options": {
			"--resume": {
				"description": [("Resume purge; can be used if purge was aborted", "description")],
			},
			"--start-at-task": {
				"values": [("TASK", "argument")],
				"description": [("Start at ", "description"), ("TASK", "argument"), (" instead of running all tasks", "description")],
				"requires_arg": True,
			},
			"--skip-tasks": {
				"values": [("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"description": [("Skip ", "description"), ("TASK", "argument"), (",", "separator"), ("...", "argument")],
				"requires_arg": True,
			},
			"--list-tasks": {
				"description": [("List valid values for ", "description"), ("TASK", "argument"), (" to use with ", "description"), ("--start-at-task", "option"), (" and ", "description"), ("--skip-tasks", "option")],
			},
			"--save-ansible-logs": {
				"description": [("Save logs from Ansible runs; the logs can be viewed using “", "description"), ("iku", "programname"), (" logs", "command"), ("“", "description")]
			},
			"-Y": {
				"description": [("Do not ask for confirmation before performing actions", "description")],
			},
		},
		"min_args": 0,
		"max_args": 0,
		"callback": purge_control_plane,
	},
	"Taint Control Plane": {
		"command": ["taint-control-plane"],
		"values": [("[", "separator"), ("CONTROLPLANE", "argument"), (",", "separator"), ("...", "argument"), ("]", "separator")],
		"description": [("Mark control plane(s) as tainted", "description")],
		"extended_description": [
			[("If you have previously marked your control plane(s) as untainted", "description")],
			[("you can mark them as tainted again using this command", "description")],
			[("If ", "description"), ("CONTROLPLANE", "argument"), (",", "separator"), ("...", "argument"), (" is not specified all control planes will be tainted", "description")],
		],
		"min_args": 0,
		"max_args": 1,
		"callback": taint_control_plane,
	},
	"Untaint Control Plane": {
		"command": ["untaint-control-plane"],
		"values": [("[", "separator"), ("CONTROLPLANE", "argument"), (",", "separator"), ("...", "argument"), ("]", "separator")],
		"description": [("Mark control plane(s) as untainted", "description")],
		"extended_description": [
			[("Per default control planes are marked as tainted; workloads that lack ", "description")],
			[("tolerations will not be scheduled to them", "description")],
			[("If you're running a single-node cluster, or if the control plane is very", "description")],
			[("powerful it might be useful to permit workloads on control plane(s) too", "description")],
			[("If ", "description"), ("CONTROLPLANE", "argument"), (",", "separator"), ("...", "argument"), (" is not specified all control planes will be untainted", "description")],

		],
		"min_args": 0,
		"max_args": 1,
		"callback": untaint_control_plane,
	},
	"Preflight Check": {
		"command": ["preflight-check"],
		"description": [("Check for potential pitfalls that may prevent installation from succeeding", "description")],
		"min_args": 0,
		"max_args": 0,
		"callback": preflight_check,
	},
	"Troubleshoot": {
		"command": ["troubleshoot"],
		"description": [("Search for potential issues in a cluster", "description")],
		"min_args": 0,
		"max_args": 0,
		"callback": troubleshoot,
	},
	"spacer1": {
		"command": [""],
		"description": [("", "default")],
	},
}

def main():
	init_iktprint(THEME_PATH)
	command, options, args = parse_commandline(about.admin_program_name, about.admin_program_version, PROGRAMDESCRIPTION, PROGRAMAUTHORS, sys.argv, commandline)
	iktconfig = iktlib.read_iktconfig()

	# Used by the ansible module
	ansible_configuration.ansible_forks = deep_get(iktconfig, "Ansible#forks", 5)
	ansible_user = deep_get(iktconfig, "Ansible#ansible_user")
	if ansible_user is None or len(ansible_user) == 0:
		ansible_user = getuser()
	ansible_configuration.ansible_user = ansible_user
	ansible_password = deep_get(iktconfig, "Ansible#ansible_password")
	if ansible_password is not None and len(ansible_password) > 0:
		ansible_configuration.ansible_password = ansible_password
	ansible_configuration.disable_strict_host_key_checking = deep_get(iktconfig, "Nodes#disablestricthostkeychecking", False)
	ansible_configuration.save_logs = deep_get(iktconfig, "Ansible#save_logs", False)
	return command(options, args)

if __name__ == "__main__":
	main()
