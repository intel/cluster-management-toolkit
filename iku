#! /usr/bin/env python3
# Requires: ansible
# Requires: python3 (>= 3.6)
# Requires: python3-natsort
# Requires: python3-openssl
# Recommends: python3-ujson

from collections import OrderedDict
import base64
import copy
import csv
import curses
from curses import wrapper
import curses.textpad
from datetime import datetime, timezone
import errno
from functools import reduce
from getpass import getuser
import http.client
# ujson is much faster than json,
# but it might not be available
try:
	import ujson as json
except ModuleNotFoundError:
	import json
from operator import itemgetter
import os
from pathlib import Path
import re
import socket
import subprocess
from subprocess import PIPE, STDOUT
import sys
import tempfile
import time
import yaml

try:
	from natsort import natsorted
except ModuleNotFoundError:
	sys.exit("ModuleNotFoundError: you probably need to install python3-natsort")

try:
	import urllib3
except ModuleNotFoundError:
	sys.exit("ModuleNotFoundError: You probably need to install python3-urllib3; did you forget to run ikt-install?")

from logparser import logparser, logparser_initialised, loglevel, lvl_to_letter_severity, lvl_to_4letter_severity, lvl_to_word_severity, loglevel_to_name, get_loglevel_names, name_to_loglevel, get_parser_list
import curses_helper
import iktlib
from iktlib import split_msg, deep_get, deep_get_list, deep_get_with_fallback, deep_set, stgroup, versiontuple, timestamp_to_datetime, datetime_to_timestamp, get_since, none_timestamp
from curses_helper import curses_configuration, color_log_severity, get_mousemask, color_status_group, color, UIProps, widgetlineattrs, get_theme_ref, read_theme, strarray_wrap_line, attr_to_curses_merged, themearray_to_string, themearray_len

from ansible_helper import ansible_clean_results, ansible_configuration, ansible_support, ansible_get_inventory_dict, ansible_get_groups, ansible_get_groups_by_host, ansible_add_hosts, ansible_remove_hosts, ansible_set_vars, ansible_ping, ansible_run_playbook_on_selection, ansible_get_logs, ansible_delete_log
from ansible_helper import ANSIBLE_PLAYBOOK_DIR, ANSIBLE_INVENTORY
import helptexts

from kubernetes_helper import KubernetesHelper

HOMEDIR = str(Path.home())
IKTDIR = os.path.join(HOMEDIR, ".ikt")
DEPLOYMENTDIR = f"{IKTDIR}/deployments"
IKT_CONFIG_FILENAME = "ikt.yaml"
IKT_CONFIG_FILE = os.path.join(IKTDIR, IKT_CONFIG_FILENAME)
IKT_CONFIG_FILE_DIR = os.path.join(IKTDIR, f"{IKT_CONFIG_FILENAME}.d")
THEME_DIRNAME = "themes"
VIEW_DIRNAME = "views"
THEMEDIR = os.path.join(IKTDIR, THEME_DIRNAME)
DEFAULT_THEME = "default.yaml"

from iktprint import iktprint, init_iktprint

import about

PROGRAMDESCRIPTION = "UI for managing Kubernetes clusters"
PROGRAMAUTHORS = "Written by David Weinehall."

iktconfig = None

# If the user passes an object (and optionally namespace for that object)
# on the command line, they're stored here
# For pods a container can be appended too
initial_name = None
initial_namespace = None
initial_container = None

# Is iku running in read only-mode?
read_only_mode = False

# Namespace
namespace = ""

# defaults
defaultview = ""

kh = None

# Behaves roughly as which(1)
def which(commandname):
	cpath = None

	# Did we get a full path, or just a command name?
	fpath, fname = os.path.split(commandname)

	# If we got a path we just verify whether commandname
	# exists and is executable
	if fpath:
		if os.path.isfile(commandname) and os.access(commandname, os.X_OK):
			cpath = commandname
		return cpath

	# If we just got a command name we check if it's in the path
	for path in os.environ["PATH"].split(os.pathsep):
		tmp = os.path.join(path, commandname)
		if os.path.isfile(tmp) and os.access(tmp, os.X_OK):
			cpath = tmp
			break

	return cpath

def init_kubernetes_client():
	global kh
	kh = KubernetesHelper(about.program_suite_name, about.program_suite_version, None)

override_tail_lines = None
default_tail_lines = 4000

# Pass in the name of a playbook that exists in {ANSIBLE_PLAYBOOK_DIR};
# returns the path to the drop-in playbook with the highest priority
# (or the same playbook in case there is no override)
def get_playbook_path(playbook):
	path = ""

	# Check if there's a local playbook overriding this one
	local_playbooks = deep_get(iktconfig, "Ansible#local_playbooks", [])
	for playbook_path in local_playbooks:
		# Substitute {HOME}/ for {HOMEDIR}
		if playbook_path.startswith("{HOME}/"):
			playbook_path = f"{HOMEDIR}/{playbook_path[len('{HOME}/'):]}"
		# Skip non-existing playbook paths
		if not os.path.isdir(playbook_path):
			continue
		# We can have multiple directories with local playbooks;
		# the first match wins
		if os.path.isfile(f"{playbook_path}/{playbook}") == True:
			path = f"{playbook_path}/{playbook}"
			break
	if len(path) == 0:
		path = f"{ANSIBLE_PLAYBOOK_DIR}/{playbook}"
	return path

def get_package_versions(hostname):
	if ansible_support == False or not os.path.isdir(ANSIBLE_PLAYBOOK_DIR):
		return []

	control_plane_k8s_version = ""

	get_versions_path = get_playbook_path("get_versions.yaml")
	retval, ansible_results = ansible_run_playbook_on_selection(get_versions_path, selection = [hostname])

	if len(ansible_results) == 0:
		raise Exception(f"Error: Failed to get package versions from {hostname} (retval: {retval}); aborting.")

	for host in ansible_results:
		data = ansible_results[host]

		for task in data:
			if "package versions" in task.replace("_", " "):
				tmp = str(data[task].get("msg", "")).split("\n")

	if len(tmp) == 0:
		raise Exception(f"Error: Failed to get package versions from {hostname} (retval: {retval}); aborting.")

	package_versions = []

	for line in tmp:
		tmp = re.match(r"^(.*?): (.*)", line)
		if tmp is None:
			continue
		package = tmp[1]
		version = tmp[2]
		package_versions.append((package, version))

	return package_versions

def gather_cluster_info():
	iktprint([("[Gathering cluster information]\n", "phase")])

	# Set global variables that need to be available when executing playbooks
	join_token = kh.get_join_token()
	ca_cert_hash = kh.get_ca_cert_hash()
	control_plane_ip, control_plane_port = kh.get_control_plane_address()
	control_plane_node, control_plane_name = get_control_plane()

	# This is tricky: we get this from the Debian package;
	# since we cannot assume that we're running iku on the [main] control plane
	# we have to ask the [main] control plane, via ansible, what version of kubeadm it's running
	package_versions = get_package_versions(control_plane_name)
	control_plane_k8s_version = ""
	for package, version in package_versions:
		if package == "kubeadm":
			control_plane_k8s_version = version
	if len(control_plane_k8s_version) == 0:
		sys.exit(f"Failed to get kubeadm version from control plane “{control_plane_name}“ (retval: {retval}); aborting.")

	http_proxy = deep_get(iktconfig, "Network#http_proxy", None)
	https_proxy = deep_get(iktconfig, "Network#https_proxy", None)
	no_proxy = deep_get(iktconfig, "Network#no_proxy", None)
	insecure_registries = deep_get(iktconfig, "Docker#insecure_registries", [])
	registry_mirrors = deep_get(iktconfig, "Containerd#registry_mirrors", [])
	packages = deep_get(iktconfig, "Packages", {})

	values = {
		"control_plane_ip": control_plane_ip,
		"control_plane_port": control_plane_port,
		"join_token": join_token,
		"ca_cert_hash": ca_cert_hash,
		"control_plane_k8s_version": control_plane_k8s_version,
		"ntp_server": control_plane_ip,
		"http_proxy": http_proxy,
		"https_proxy": https_proxy,
		"no_proxy": no_proxy,
		"insecure_registries": insecure_registries,
		"registry_mirrors": registry_mirrors,
		"packages": packages,
	}

	ansible_set_vars(ANSIBLE_INVENTORY, "all", values)

	print("\n\n")

def align_and_pad(array, pad, fieldlen, stringlen, ralign, selected):
	if ralign:
		array = [("".ljust(fieldlen - stringlen), ("types", "generic", selected))] + array
	else:
		array.append(("".ljust(fieldlen - stringlen), ("types", "generic", selected)))
	if pad > 0:
		array.append((("separators", "pad"), selected))
	return array

def generator_basic(obj, field, fieldlen, pad, ralign, selected, **formatting):
	value = getattr(obj, field)
	string = str(value)
	field_colors = deep_get(formatting, f"field_colors", [("types", "generic")])

	if string == "None":
		string = "<none>"

	if string in ["<none>", "<unset>", "<unknown>"]:
		formatting = ("types", "none", selected)
	else:
		context, attr_ref = field_colors[0]
		formatting = (context, attr_ref, selected)

	array = [
		(string, formatting)
	]

	return align_and_pad(array, pad, fieldlen, len(string), ralign, selected)

def generator_str_timestamp(obj, field, fieldlen, pad, ralign, selected, **formatting):
	string = processor_str_timestamp(obj, field)

	if len(string) == 0:
		array = [(string, ("types", "generic", selected))]
	else:
		array = format_numerical_with_units(string, "timestamp", selected)

	return align_and_pad(array, pad, fieldlen, len(string), ralign, selected)

def generator_timestamp(obj, field, fieldlen, pad, ralign, selected, **formatting):
	value = getattr(obj, field)

	string = datetime_to_timestamp(value)
	if value is None:
		array = [(string, ("types", "generic", selected))]
	elif value == datetime.fromtimestamp(0).astimezone():
		array = [(string, ("types", "generic", selected))]
	else:
		array = format_numerical_with_units(string, "timestamp", selected)

	return align_and_pad(array, pad, fieldlen, len(string), ralign, selected)

def generator_timestamp_with_age(obj, field, fieldlen, pad, ralign, selected, **formatting):
	values = getattr(obj, field)

	if len(values) > 2 and len(deep_get(formatting, "field_colors", [])) < 2:
		raise ValueError(f"Received more than 2 fields for timestamp_with_age but no formatting to specify what the values signify")
	elif len(values) == 2:
		if values[0] is None:
			array = [
				("<none>", ("types", "none", selected))
			]
		else:
			timestamp_string = datetime_to_timestamp(values[0])
			array = format_numerical_with_units(string, "timestamp", selected)
			array += [
				(" (", ("types", "generic", selected))
			]
			array += _generator_age(values[1], selected)
			array += [
				(")", ("types", "generic", selected))
			]
	else:
		array = []

		for i in range(0, len(values)):
			# If there's no formatting for this field we assume that
			# it's a generic string
			if len(deep_get(formatting, "field_colors", [])) <= i:
				formatting = ("types", "generic", selected)
				array += [values[i], formatting]
			elif formatting["field_colors"][i] == ("types", "timestamp"):
				if values[i] is None:
					array += [
						("<unset>", ("types", "none"), selected)
					]
					break
				else:
					timestamp = timestamp_to_datetime(values[i])
					timestamp_string = timestamp.astimezone().strftime("%Y-%m-%d %H:%M:%S")
					array += format_numerical_with_units(timestamp_string, "timestamp", selected)
			elif formatting["field_colors"][i] == ("types", "age"):
				array += _generator_age(values[i], selected)
			else:
				array += [
					(values[i], formatting["field_colors"][i], selected)
				]

	return align_and_pad(array, pad, fieldlen, themearray_len(array), ralign, selected)

def generator_yesno(obj, field, fieldlen, pad, ralign, selected, **formatting):
	value = getattr(obj, field)

	if value is None:
		string = "N/A"
	elif value == True:
		string = "Yes"
	else:
		string = "No"

	formatting = ("types", "generic", selected)

	array = [
		(string, formatting)
	]

	return align_and_pad(array, pad, fieldlen, len(string), ralign, selected)

def generator_priority_level(obj, field, fieldlen, pad, ralign, selected, **formatting):
	value = getattr(obj, field)

	if value is None:
		string = "<none>"
		formatting = ("types", "none", selected)
	else:
		string = str(value)
		# We need to check whether the priority level exists or not;
		# non-existing priority levels should be highlighted
		obj = kh.get_ref_by_kind_name_namespace(("PriorityLevelConfiguration", "flowcontrol.apiserver.k8s.io"), value, "")
		if obj is None:
			formatting = ("main", "status_not_ok")
		else:
			formatting = ("types", "generic")

	array = [
		(string, formatting, selected)
	]

	return align_and_pad(array, pad, fieldlen, len(string), ralign, selected)

# Will take datetime and format it as (YYYY-MM-DD HH:MM:SS, field_colors)
def format_timestamp(timestamp, localtimezone = False):
	array = []

	if timestamp is None:
		array = [("strings", "none")]
	else:
		if localtimezone == True:
			ftimestamp = timestamp.astimezone().strftime("%Y-%m-%d %H:%M:%S")
		else:
			ftimestamp = timestamp.strftime("%Y-%m-%d %H:%M:%S")
		array = format_numerical_with_units(ftimestamp, "timestamp", False)

	return array

def format_list(items, fieldlen, pad, ralign, selected, item_separator = ("separators", "list"), field_separators = [("separators", "field")], field_colors = [("types", "generic")], ellipsise = -1, ellipsis = ("separators", "ellipsis"), field_prefixes = None, field_suffixes = None, mapping = {}):
	array = []
	totallen = 0

	if type(field_separators) != list:
		raise Exception(f"field_separators should be a list of (context, style) tuple, not a single tuple; {field_separators}")

	if type(field_colors) != list:
		raise Exception(f"field_colors should be a list of (context, style) tuple, not a single tuple; {field_colors}")

	if type(items) is not list:
		items = [items]

	elcount = 0
	skip_separator = True

	for item in items:
		if len(array) > 0:
			totallen += themearray_len([item_separator])
			array.append((item_separator, selected))
			elcount += 1

		if elcount == ellipsise:
			array.append((ellipsis, selected))
			break

		# Treat all types as tuples no matter if they are; since tuples consist of 2+ elements we add None
		if type(item) is not tuple:
			item = (item, None)

		for i in range(0, len(item)):
			if item[i] is None:
				continue

			string = str(item[i])

			if len(string) == 0:
				continue

			if i > 0 and skip_separator == False:
				field_separator = field_separators[min(i - 1, len(field_separators) - 1)]
				totallen += themearray_len([field_separator])
				array.append((field_separator, selected))

			if string == "<none>":
				formatting = ("types", "none", selected)
				formatted_string = (string, formatting)
			elif string == "<not ready>":
				formatting = color_status_group(stgroup.NOT_OK, selected)
				formatted_string = (string, formatting)
			else:
				context, attr_ref = field_colors[min(i, len(field_colors) - 1)]
				formatted_string, __string = map_value(string, selected = selected, default_field_color = (context, attr_ref), mapping = mapping)

			# OK, we know now that we'll be appending the field, so do the prefix
			if field_prefixes is not None and i < len(field_prefixes):
				if type(field_prefixes[i]) == tuple:
					totallen += themearray_len([field_prefixes[i]])
					array.append(field_prefixes[i])
				else:
					for prefix in field_prefixes[i]:
						totallen += themearray_len([prefix])
						array.append((prefix, selected))
			array.append(formatted_string)
			totallen += len(string)
			# And now the suffix
			if field_suffixes is not None and i < len(field_suffixes):
				if type(field_suffixes[i]) == tuple:
					totallen += themearray_len([field_suffixes[i]])
					array.append(field_suffixes[i])
				else:
					for suffix in field_suffixes[i]:
						totallen += themearray_len([suffix])
						array.append((suffix, selected))
				# RequestPrincipals[*@example.com]
			skip_separator = False

	return align_and_pad(array, pad, fieldlen, totallen, ralign, selected)

def generator_list(obj, field, fieldlen, pad, ralign, selected, **formatting):
	items = getattr(obj, field)

	item_separator = deep_get(formatting, "item_separator")
	if item_separator is None:
		item_separator = ("separators", "list")

	field_separators = deep_get(formatting, "field_separators")
	if field_separators is None:
		field_separators = [("separators", "field")]

	field_colors = deep_get(formatting, "field_colors")
	if field_colors is None:
		field_colors = [("types", "field")]

	ellipsise = deep_get(formatting, "ellipsise", -1)

	ellipsis = deep_get(formatting, "ellipsis")
	if ellipsis is None:
		ellipsis = ("separators", "ellipsis")

	field_prefixes = deep_get(formatting, "field_prefixes")
	field_suffixes = deep_get(formatting, "field_suffixes")

	mapping = deep_get(formatting, "mapping", {})

	return format_list(items, fieldlen, pad, ralign, selected, item_separator = item_separator, field_separators = field_separators, field_colors = field_colors, ellipsise = ellipsise, ellipsis = ellipsis, field_prefixes = field_prefixes, field_suffixes = field_suffixes, mapping = mapping)

def generator_list_with_status(obj, field, fieldlen, pad, ralign, selected, **formatting):
	items = getattr(obj, field)
	if type(items) == tuple:
		items = [items]

	item_separator = deep_get(formatting, "item_separator")
	if item_separator is None:
		item_separator = ("separators", "list")

	field_separators = deep_get(formatting, "field_separators")
	if field_separators is None:
		field_separators = [("separators", "field")]

	ellipsise = deep_get(formatting, "ellipsise", -1)

	ellipsis = deep_get(formatting, "ellipsis")
	if ellipsis is None:
		ellipsis = ("separators", "ellipsis")

	field_prefixes = deep_get(formatting, "field_prefixes")
	field_suffixes = deep_get(formatting, "field_prefixes")

	# XXX: Well, this works:ish, but it's ugly beyond belief
	#      it would be solved so much better with a mapping that uses a secondary value
	newitems = []
	field_colors = [("main", "status_done"), ("main", "status_ok"), ("main", "status_pending"), ("main", "status_warning"), ("main", "status_admin"), ("main", "status_not_ok"), ("main", "status_unknown"), ("main", "status_crit"), ("types", "generic")]
	field_separators = [("separators", "no_pad")]

	for item, status in items:
		if status == stgroup.DONE:
			newitems.append((item))
		if status == stgroup.OK:
			newitems.append(("", item))
		elif status == stgroup.PENDING:
			newitems.append(("", "", item))
		elif status == stgroup.WARNING:
			newitems.append(("", "", "", item))
		elif status == stgroup.ADMIN:
			newitems.append(("", "", "", "", item))
		elif status == stgroup.NOT_OK:
			newitems.append(("", "", "", "", "", item))
		elif status == stgroup.UNKNOWN:
			newitems.append(("", "", "", "", "", "", item))
		elif status == stgroup.CRIT:
			newitems.append(("", "", "", "", "", "", "", item))
		elif status == stgroup.NEUTRAL:
			newitems.append(("", "", "", "", "", "", "", "", item))
		else:
			newitems.append(("", "", "", "", "", "", "", "", item))

	return format_list(newitems, fieldlen, pad, ralign, selected, item_separator = item_separator, field_separators = field_separators, field_colors = field_colors, ellipsise = ellipsise, ellipsis = ellipsis, field_prefixes = field_prefixes, field_suffixes = field_suffixes)

def generator_secret_data(obj, field, fieldlen, pad, ralign, selected, **formatting):
	value = getattr(obj, field)
	string = str(value)

	if len(string) == 0:
		vtype = "empty"
	else:
		vtype = getattr(obj, "vtype", "string")

	if vtype == "empty":
		string = "[empty]"
	elif vtype == "string":
		string = string.ljust(fieldlen)
	elif vtype == "base64-utf-8":
		string = "[base64]"
	else:
		string = "[base64 (binary)]"

	formatting = ("types", "generic", selected)

	array = [
		(string, formatting)
	]

	return align_and_pad(array, pad, fieldlen, len(string), ralign, selected)

def generator_numerical_range(obj, field, fieldlen, pad, ralign, selected, **formatting):
	value = getattr(obj, field)
	if type(value) == int:
		value = [value]

	i = 0
	ranges = deep_get(field_templates, f"{field}#ranges")
	formatting = ("types", "generic", selected)
	for start, end, formatting in ranges:
		if type(start) == str and int(start) < len(value):
			start = value[int(start)]
		if type(end) == str and int(end) < len(value):
			end = value[int(end)]

		if value[0] >= start and value[0] < end:
			context, attr = formatting
			formatting = (context, attr, selected)
			break

	if value[0] == -1:
		string = ""
	else:
		string = str(value[0])

	array = [
		(string, formatting)
	]

	return align_and_pad(array, pad, fieldlen, len(string), ralign, selected)

def generator_numerical(obj, field, fieldlen, pad, ralign, selected, **formatting):
	value = getattr(obj, field)

	if value == -1:
		string = ""
	else:
		string = str(value)

	formatting = ("types", "timestamp", selected)

	array = [
		(string, formatting)
	]

	return align_and_pad(array, pad, fieldlen, len(string), ralign, selected)

def generator_numerical_with_units(obj, field, fieldlen, pad, ralign, selected, **formatting):
	value = getattr(obj, field)

	if value in ["<none>", "<unset>", "<unknown>"]:
		formatting = ("types", "none", selected)
		array = [(value, formatting, selected)]
		return align_and_pad(array, pad, fieldlen, len(value), ralign, selected)

	if value == -1 and deep_get(formatting, "allow_signed") == False:
		string = ""
	else:
		string = str(value)

	array = format_numerical_with_units(string, "numerical", selected)

	return align_and_pad(array, pad, fieldlen, len(string), ralign, selected)

def generator_mem_single(obj, field, fieldlen, pad, ralign, selected, **formatting):
	value = getattr(obj, field)
	string = str(value)

	array = format_numerical_with_units(string, "field", selected)

	return align_and_pad(array, pad, fieldlen, len(string), ralign, selected)

def generator_hex(obj, field, fieldlen, pad, ralign, selected, **formatting):
	value = getattr(obj, field)
	string = str(value)

	array = format_numerical_with_units(string, "field", selected, non_units = set("0123456789abcdefABCDEF"))

	return align_and_pad(array, pad, fieldlen, len(string), ralign, selected)

def format_numerical_with_units(string, ftype, selected, non_units = set("0123456789"), separator_lookup = {}):
	substring = ""
	array = []
	numeric = None
	# This is necessary to be able to use pop
	string = list(string)

	if "default" not in separator_lookup:
		separator_lookup["default"] = ("types", "unit")

	non_units = set(non_units)

	while len(string) > 0:
		char = string.pop(0)
		if numeric is None:
			numeric = char in non_units
			substring += char
		elif numeric == True:
			# Do we need to flush?
			if not char in non_units:
				array.append((substring, ("types", ftype), selected))
				substring = ""
				numeric = False

			substring += char
		else:
			# Do we need to flush?
			if char in non_units:
				formatting = deep_get_with_fallback(separator_lookup, [substring, "default"])
				array.append((substring, formatting, selected))
				substring = ""
				numeric = True
			substring += char

		if len(string) == 0:
			if numeric == True:
				array.append((substring, ("types", ftype), selected))
			else:
				formatting = deep_get_with_fallback(separator_lookup, [substring, "default"])
				array.append((substring, formatting, selected))

	if len(array) == 0:
		array = [("", ("types", "generic", selected))]

	return array

def _generator_age(value, selected):
	if value == -1:
		string = ""
	else:
		string = iktlib.seconds_to_age(value, negative_is_skew = True)

	if string in ["<none>", "<unset>", "<unknown>"]:
		formatting = ("types", "none", selected)
		array = [(string, formatting, selected)]
	elif string in ["<clock skew detected>"]:
		formatting = ("main", "status_not_ok", selected)
		array = [(string, formatting, selected)]
	else:
		array = format_numerical_with_units(string, "age", selected)

	return array

def generator_age(obj, field, fieldlen, pad, ralign, selected, **formatting):
	value = getattr(obj, field)

	array = _generator_age(value, selected)

	return align_and_pad(array, pad, fieldlen, themearray_len(array), ralign, selected)

def generator_address(obj, field, fieldlen, pad, ralign, selected, **formatting):
	items = getattr(obj, field, [])
	if items is None:
		items = []

	if type(items) == str and items in ["<unset>", "<none>"]:
		return format_list([items], fieldlen, pad, ralign, selected)

	if type(items) in [str, tuple]:
		items = [items]

	separator_lookup = {}

	addresstype = None

	separators = deep_get(formatting, "field_separators")
	if len(separators) == 0:
		separators = [("separators", "ipv4address"), ("separators", "ipv6address"), ("separators", "ipmask")]

	for separator in separators:
		string = themearray_to_string([separator])
		separator_lookup[string] = separator

	vlist = []
	field_colors = []
	field_separators = []

	subnet = False
	first = True

	for item in items:
		_vlist = []
		tmp = ""
		for ch in item:
			if ch in separator_lookup:
				_vlist.append(tmp)
				if first == True:
					if subnet == True:
						field_colors.append(("types", "ipmask"))
					else:
						field_colors.append(("types", "address"))
					field_separators.append(separator_lookup[ch])
				tmp = ""

				if ch == "/":
					subnet = True
			else:
				tmp += ch

		if len(tmp) > 0:
			_vlist.append(tmp)
			if first == True:
				if subnet == True:
					field_colors.append(("types", "ipmask"))
				else:
					field_colors.append(("types", "address"))
		first = False
		vlist.append(tuple(_vlist))

	return format_list(vlist, fieldlen, pad, ralign, selected, field_separators = field_separators, field_colors = field_colors)

def generator_mem(obj, field, fieldlen, pad, ralign, selected, **formatting):
	free, total = getattr(obj, field)

	if free is None and total is None:
		return generator_basic(obj, field, fieldlen, pad, ralign, selected)

	used = "{:0.1f}".format(100 - (100 * int(free) / int(total)))

	if float(used) < 80.0:
		attribute = ("types", "watermark_low")
	elif float(used) < 90.0:
		attribute = ("types", "watermark_medium")
	else:
		attribute = ("types", "watermark_high")

	total = "{:0.1f}".format(int(total) / (1024 * 1024))
	unit = "GiB"

	array = [
		(used, attribute, selected),
		(("separators", "percentage"), selected),
		(" ", attribute, selected),
		(("separators", "fraction"), selected),
		(" ", attribute, selected),
		(total, ("types", "numerical"), selected),
		(unit, ("types", "unit", selected)),
	]
	stringlen = themearray_len(array)

	return align_and_pad(array, pad, fieldlen, stringlen, ralign, selected)

# Generator for {available,ready} / total
def generator_total(obj, field, fieldlen, pad, ralign, selected, **formatting):
	free, total = getattr(obj, field)

	if free is None and total is None:
		return generator_basic(obj, field, fieldlen, pad, ralign, selected)

	# Strip millicores
	if type(free) == str and free.endswith("m"):
		_free = int(free.strip("m")) // 1000
	else:
		_free = int(free)
	if type(total) == str and total.endswith("m"):
		_total = int(total.strip("m")) // 1000
	else:
		_total = int(total)

	stringlen = len(str(_free)) + themearray_len([("separators", "fraction")]) + len(str(_total))

	ranges = deep_get(field_templates, f"{field}#ranges", [])
	formatting = ("types", "numerical", selected)

	# If the values are -1/-1 we substitute with an empty string of the same length
	if free == -1 and total == -1:
		array = [
			("".ljust(stringlen), ("types", "generic", selected))
		]
	else:
		for start, end, formatting in ranges:
			# exact match against total, or value inside range
			if start == -1 and end == -1:
				if _free == _total:
					context, attr = formatting
					formatting = (context, attr, selected)
					break
				else:
					continue
			if (_free >= start and _free < end) or (_free >= start and end == -1):
				context, attr = formatting
				formatting = (context, attr, selected)
				break

		array = [
			(str(_free), formatting),
			(("separators", "fraction"), selected),
			(str(_total), ("types", "numerical", selected)),
		]

	return align_and_pad(array, pad, fieldlen, stringlen, ralign, selected)

def generator_status(obj, field, fieldlen, pad, ralign, selected, **formatting):
	status = getattr(obj, field)
	status_group = getattr(obj, "status_group")
	attribute = color_status_group(status_group, selected)

	array = [
		(status, attribute)
	]
	stringlen = len(status)

	return align_and_pad(array, pad, fieldlen, stringlen, ralign, selected)

# references is unused for now, but will eventually be used to compare against
# reference values (such as using other paths to get the range, instead of getting
# it static from formatting#mapping)
def map_value(value, references = None, selected = False, default_field_color = ("types", "generic"), mapping = {}):
	# If we lack a mapping, use the default color for this field
	if len(mapping) == 0:
		context, attr_ref = default_field_color
		return (value, (context, attr_ref, selected)), value

	substitutions = deep_get(mapping, "substitutions", {})
	ranges = deep_get(mapping, "ranges", [])
	match_case = deep_get(mapping, "match_case", True)
	_mapping = deep_get(mapping, "mappings", {})

	field_colors = None

	if value in substitutions:
		value = substitutions[value]
		# If the substitution is a dict it's a themearray; typically either a separator or a string
		if type(value) == dict:
			context = deep_get(value, "context", "main")
			attr_ref = deep_get(value, "type")
			return ((context, attr_ref), selected), themearray_to_string([(context, attr_ref)])

	if type(value) in [int, float] and len(ranges) > 0:
		default_index = -1
		for i in range(0, len(ranges)):
			if deep_get(ranges[i], "default", False) == True:
				if default_index != -1:
					raise Exception(f"Field {field}: range cannot contain more than one default")
				default_index = i
				continue
			_min = deep_get(ranges[i], "min")
			_max = deep_get(ranges[i], "max")
			if (_min is None or value >= _min) and (_max is None or value < _max):
				field_colors = deep_get(ranges[i], "field_colors")
				break
		if field_colors is None and default_index != -1:
			field_colors = deep_get(ranges[default_index], "field_colors")
		string = str(value)
	elif type(value) in [str, bool] or len(ranges) == 0:
		string = str(value)
		_string = string
		if match_case is False:
			matched = False
			if string in _mapping and string.lower() in _mapping and string != string.lower():
				raise Exception(f"Field {field}: when using match_case == False the mapping cannot contain keys that only differ in case")
			for key in _mapping:
				if key.lower() == string.lower():
					_string = key
				matched = True
			if matched == False and "__default" in _mapping:
				_string = "__default"
		elif _string not in _mapping and "__default" in _mapping:
			_string = "__default"
		field_colors = deep_get(_mapping, f"{_string}#field_colors")
	else:
		raise Exception(f"Unknown type {type(value)} for mapping/range")

	attr_ref = None
	if field_colors is not None:
		context = deep_get(field_colors[0], "context", "main")
		attr_ref = deep_get(field_colors[0], "type")
	if attr_ref is None:
		context, attr_ref = ("types", "generic")
	formatting = (context, attr_ref, selected)
	return (string, formatting), string

def generator_value_mapper(obj, field, fieldlen, pad, ralign, selected, **formatting):
	value = getattr(obj, field)

	default_field_color = deep_get(formatting, "field_colors", [("types", "generic")])[0]

	formatted_string, string = map_value(value, selected = selected, default_field_color = default_field_color, mapping = deep_get(formatting, "mapping", {}))
	array = [
		formatted_string
	]
	return align_and_pad(array, pad, fieldlen, len(string), ralign, selected)

def processor_str_timestamp(obj, field):
	value = getattr(obj, field)
	timestamp = ""

	if value is not None:
		for fmt in ["%Y-%m-%d %H:%M:%S.%f%z", "%Y-%m-%d %H:%M:%S%z", "%Y-%m-%dT%H:%M:%S.%f%z", "%Y-%m-%dT%H:%M:%S%z"]:
			try:
				timestamp = datetime.strptime(value, fmt).astimezone().strftime("%Y-%m-%d %H:%M:%S")
				break
			except ValueError:
				pass

	return timestamp

def processor_timestamp(obj, field):
	value = getattr(obj, field)

	if value is None:
		return ""

	string = value.astimezone().strftime("%Y-%m-%d %H:%M:%S")
	return string

def processor_timestamp_with_age(obj, field):
	values = getattr(obj, field)

	if len(values) > 2 and len(deep_get(formatting, "field_colors", [])) < 2:
		raise ValueError(f"Received more than 2 fields for timestamp_with_age but no formatting to specify what the values signify")
	elif len(values) == 2:
		if values[0] is None:
			array = [
				("<none>", ("types", "none", selected))
			]
		else:
			timestamp_string = datetime_to_timestamp(values[0])
			array = format_numerical_with_units(string, "timestamp", selected)
			array += [
				(" (", ("types", "generic", selected))
			]
			array += _generator_age(values[1], selected)
			array += [
				(")", ("types", "generic", selected))
			]
	else:
		array = []

		for i in range(0, len(values)):
			# If there's no formatting for this field we assume that
			# it's a generic string
			if len(deep_get(formatting, "field_colors", [])) <= i:
				formatting = ("types", "generic", selected)
				array += [values[i], formatting]
			elif formatting["field_colors"][i] == "timestamp":
				if values[i] is None:
					array += [
						("<none>", ("types", "none"), selected)
					]
				else:
					timestamp_string = datetime_to_timestamp(values[0])
					array += format_numerical_with_units(string, "timestamp", selected)
			elif formatting["field_colors"][i] == "age":
				array += _generator_age(values[i], selected)
			else:
				array += [
					(values[i], formatting["field_colors"][i], selected)
				]

	return themearray_to_string(array)

def processor_total(obj, field):
	free, total = getattr(obj, field)

	# Strip millicores
	if type(free) == str and free.endswith("m"):
		_free = int(free.strip("m")) // 1000
	else:
		_free = int(free)
	if type(total) == str and total.endswith("m"):
		_total = int(total.strip("m")) // 1000
	else:
		_total = int(total)
	return "%s/%s" % (str(_free), str(_total))

# For the list processor to work we need to know the length of all the separators
def processor_list(obj, field, item_separator = ("separators", "list"), field_separators = [("separators", "field")], ellipsise = -1, ellipsis = ("separators", "ellipsis"), field_prefixes = None, field_suffixes = None):
	items = getattr(obj, field)

	strings = []

	elcount = 0
	skip_separator = True

	if type(items) is tuple:
		items = [items]

	for item in items:
		if elcount == ellipsise:
			strings.append(themearray_to_string([ellipsis]))
			break

		if type(item) is not tuple:
			item = (item, None)

		# Join all elements of the field into one string
		string = ""

		for i in range(0, len(item)):
			if item[i] is None:
				continue

			tmp = str(item[i])

			if len(tmp) == 0:
				continue

			if i > 0 and skip_separator == False:
				string += themearray_to_string([field_separators[min(i - 1, len(field_separators) - 1)]])

			if field_prefixes is not None and i < len(field_prefixes):
				if type(field_prefixes[i]) == tuple:
					string += themearray_to_string([field_prefixes[i]])
				else:
					for _item in field_prefixes[i]:
						string += themearray_to_string([_item])
			string += tmp
			if field_suffixes is not None and i < len(field_suffixes):
				if type(field_suffixes[i]) == tuple:
					string += themearray_to_string([field_suffixes[i]])
				else:
					for _item in field_suffixes[i]:
						string += themearray_to_string([_item])
			skip_separator = False

		strings.append(string)
		elcount += 1

	vstring = themearray_to_string([item_separator]).join(strings)

	return vstring

# For the list processor to work we need to know the length of all the separators
def processor_list_with_status(obj, field, item_separator = ("separators", "list"), field_separators = [("separators", "field")], ellipsise = -1, ellipsis = ("separators", "ellipsis"), field_prefixes = None, field_suffixes = None):
	items = getattr(obj, field)

	strings = []

	elcount = 0
	skip_separator = True

	newitems = []
	for item in items:
		newitems.append(item[0])

	for item in newitems:
		if elcount == ellipsise:
			strings.append(themearray_to_string([ellipsis]))
			break

		if type(item) is not tuple:
			item = (item, None)

		# Join all elements of the field into one string
		string = ""

		for i in range(0, len(item)):
			if item[i] is None:
				continue

			tmp = str(item[i])

			if len(tmp) == 0:
				continue

			if i > 0 and skip_separator == False:
				string += themearray_to_string([field_separators[min(i - 1, len(field_separators) - 1)]])

			if field_prefixes is not None and i < len(field_prefixes):
				string += themearray_to_string([field_prefixes[i]])
			string += tmp
			if field_suffixes is not None and i < len(field_suffixes):
				string += themearray_to_string([field_suffixes[i]])
			skip_separator = False

		strings.append(string)
		elcount += 1

	vstring = themearray_to_string([item_separator]).join(strings)

	return vstring

def processor_age(obj, field):
	seconds = getattr(obj, field)
	return iktlib.seconds_to_age(seconds, negative_is_skew = True)

def processor_mem(obj, field):
	free, total = getattr(obj, field)

	string = "{:0.1f}".format(100 - (100 * int(free) / int(total)))
	string += themearray_to_string([("separators", "percentage")])
	string += " "
	string += themearray_to_string([("separators", "fraction")])
	string += " "
	string += "{:0.1f}".format(int(total) / (1024 * 1024))
	string += "GiB"

	return string

default_processor = {
	generator_age: processor_age,
	generator_list: processor_list,
	generator_list_with_status: processor_list_with_status,
	generator_mem: processor_mem,
	generator_timestamp: processor_timestamp,
	generator_str_timestamp: processor_str_timestamp,
	generator_total: processor_total,
}

def update_field_widths(field_dict, field_names, objects):
	linelen = 0
	pos = 0

	for field_name in field_names:
		field_dict[field_name]["pos"] = pos
		field_dict[field_name]["fieldlen"] = 0

		# These are necessary to calculate width of list items
		item_separator = field_dict[field_name].get("item_separator", ("separators", "list"))
		field_separators = field_dict[field_name].get("field_separators", [("separators", "field")])
		ellipsise = field_dict[field_name].get("ellipsise", -1)
		ellipsis = field_dict[field_name].get("ellipsis", ("separators", "ellipsis"))
		field_prefixes = field_dict[field_name].get("field_prefixes", None)
		field_suffixes = field_dict[field_name].get("field_suffixes", None)

		for obj in objects:
			generator = field_dict[field_name].get("generator")
			processor = field_dict[field_name].get("processor")

			if processor is None:
				processor = default_processor.get(generator)

			if processor is not None:
				if processor in [processor_list, processor_list_with_status]:
					tmp = processor(obj, field_name, item_separator = item_separator, field_separators = field_separators, ellipsise = ellipsise, ellipsis = ellipsis, field_prefixes = field_prefixes, field_suffixes = field_suffixes)
				else:
					tmp = processor(obj, field_name)
			else:
				tmp = str(getattr(obj, field_name))

			tmplen = max(field_dict[field_name].get("fieldlen", 0), len(str(tmp)))

			field_dict[field_name]["fieldlen"] = max(len(str(tmp)), field_dict[field_name]["fieldlen"])

		field_dict[field_name]["fieldlen"] = max(field_dict[field_name]["fieldlen"], len(field_dict[field_name]["header"]))

		linelen += field_dict[field_name].get("fieldlen") + themearray_len([("separators", "pad")])
		pos = linelen

	# The last element shouldn't be padded
	if linelen > 0:
		linelen -= themearray_len([("separators", "pad")])

	return linelen

def get_hpa_metrics(obj, **kwargs):
	vlist = []
	status = 200

	for metric in deep_get(obj, "spec#metrics", []):
		if "type" not in metric:
			continue
		metric_type = deep_get(metric, "type")
		metric_name = metric_type[0].lower() + metric_type[1:]
		target_type = deep_get(metric, f"{metric_name}#target#type", "")
		if target_type == "Utilization":
			target_type = "AverageUtilization"
		target_type_name = target_type[0].lower() + target_type[1:]

		described_object = None
		kind = ""
		api_group = ""
		object_name = ""

		if metric_name in ["resource", "containerResource"]:
			name = deep_get(metric, f"{metric_name}#name")
		elif metric_name in ["pods", "object", "external"]:
			name = deep_get(metric, f"{metric_name}#metric#name")
			api_version = ""
			if metric_type == "Object":
				kind = deep_get(metric, f"{metric_name}#describedObject#kind")
				api_version = deep_get(metric, f"{metric_name}#describedObject#apiVersion")
				object_name = deep_get(metric, f"{metric_name}#describedObject#name")
			api_group = api_version.split("/")[0]
		else:
			metric_type += " (Unsupported)"

		target_value = deep_get(metric, f"{metric_name}#target#{target_type_name}", "")
		selector = deep_get(metric, f"{metric_name}#metric#selector#matchLabels", {})

		d = {
			"metric_type": metric_type,
			"name": name,
			"target_type": target_type,
			"described_object_kind": kind,
			"described_object_api_group": api_group,
			# The autoscaler shares namespace with the described object
			"described_object_namespace": deep_get(obj, "metadata#namespace", ""),
			"described_object_name": object_name,
			"selector": selector,
			"target_value": target_value,
		}
		vlist.append(d)
	return vlist, status

def get_metrics_list(**kwargs):
	vlist = []

	metrics, status = kh.get_metrics()

	# metrics are on the form:
	# aggregator_openapi_v2_regeneration_count{apiservice="*",reason="startup"} 0
	# apiserver_requested_deprecated_apis{group="autoscaling",removed_release="1.25",resource="horizontalpodautoscalers",subresource="",version="v2beta1"} 1
	for line in metrics:
		tmp = re.match(r"^(\S+?){(.*)}\s\d+$", line)
		if tmp is None:
			continue
		metric = tmp[1]
		if deep_get(kwargs, "filter") is not None:
			if metric not in deep_get(kwargs, "filter"):
				continue

		fields = ['{}'.format(x) for x in next(csv.reader([tmp[2]], delimiter = ",", quotechar = "\""))]
		if len(fields) == 0:
			continue
		d = {
			"name": metric,
			"fields": {},
		}
		for field in fields:
			key_value = ['{}'.format(x) for x in next(csv.reader([field], delimiter = "=", quotechar = "\""))]
			key, value = key_value
			d["fields"][key] = value.strip("\"")

		vlist.append(d)

	return vlist, status

class ContextInfo:
	def __init__(self, current, name, cluster, authinfo, namespace):
		self.current = current
		self.name = name
		self.cluster = cluster
		self.authinfo = authinfo
		self.namespace = namespace
	def __repr__(self):
		return repr((self.current, self.name, self.cluster, self.authinfo, self.namespace))

def get_context_info(**kwargs):
	info = []

	vlist = kh.list_contexts()

	# If the number of contexts is 0 we don't have a cluster configured
	if len(vlist) == 0:
		return []

	tag_prefix = themearray_to_string([("separators", "tag")])
	for context in vlist:
		current, name, cluster, authinfo, namespace = context
		if current == True:
			current = tag_prefix
		else:
			current = "".ljust(len(tag_prefix))
		info.append(ContextInfo(current, name, cluster, authinfo, namespace))

	return info

class ContainerInfo:
	def __init__(self, name, ref, container_type, image_version, instances, image_id, pods, pod_references):
		self.name = name
		self.ref = ref
		self.container_type = container_type
		self.image_version = image_version
		self.instances = instances
		self.image_id = image_id
		self.pods = pods
		self.pod_references = pod_references
	def __repr__(self):
		return repr((self.name, self.ref, self.container_type, self.image_version, self.instances, self.image_id, self.pods, self.pod_references))

def get_image_tuple(image):
	tmp = re.match(r"^(.*):(.*)", image)
	if tmp is not None:
		image_name = f"{tmp[1]}"
		image_version = f"{tmp[2]}"
	else:
		image_name = f"{image}"
		image_version = "<undefined>"
	return image_name, image_version

def __get_container_info(obj, container_type, spec_path, status_path):
	containers = {}

	for container in deep_get(obj, spec_path, []):
		container_name = deep_get(container, "name")
		container_image = deep_get(container, "image")
		image_version = kh.get_image_version(container_image)

		# To get the image ID we need to cross-reference container_image against status#{status_path}->image"
		image_id = None
		for item in deep_get(obj, status_path, []):
			if deep_get(item, "name", "") == container_name:
				image_id = deep_get(item, "imageID")
		# This (most likely) means that the pod hasn't managed to instantiate a container
		if image_id is None:
			image_id = "<unknown>"
		key = (container_name, container_type, image_version, image_id)

		# If this container is in the dict already, just add a pod reference
		# This is unlikely to ever happen (this would mean that the same pod uses the same image multiple times,
		# which seems unlikely), but better safe than sorry
		if key not in containers:
			containers[key] = {}
			containers[key]["pod_references"] = []
			containers[key]["instances"] = 0

		containers[key]["pod_references"].append(obj)
		containers[key]["instances"] += 1

	return containers

def get_container_info(**kwargs):
	info = []
	containers = {}

	# There's no direct way to get a list of unique containers
	# as defined by the tuple (name, type, version, image_id),
	# so we need to iterate the list of all pods and extract this
	# information.
	vlist, status = kh.get_list_by_kind_namespace(("Pod", ""), "")
	if status != 200:
		return info

	for obj in vlist:
		pod_reference = obj
		tmp = __get_container_info(obj, "InitContainer", "spec#initContainers", "status#initContainerStatuses")
		for key in tmp:
			instances = tmp[key]["instances"]
			pod_references = tmp[key]["pod_references"]
			if key not in containers:
				containers[key] = {}
				containers[key]["instances"] = 0
				containers[key]["pod_references"] = []

			containers[key]["instances"] += instances
			containers[key]["pod_references"] += pod_references
		tmp = __get_container_info(obj, "Container", "spec#containers", "status#containerStatuses")
		for key in tmp:
			instances = tmp[key]["instances"]
			pod_references = tmp[key]["pod_references"]
			if key not in containers:
				containers[key] = {}
				containers[key]["instances"] = 0
				containers[key]["pod_references"] = []

			containers[key]["instances"] += instances
			containers[key]["pod_references"] += pod_references

	for name, container_type, image_version, image_id in containers:
		pod_references = containers[(name, container_type, image_version, image_id)]["pod_references"]
		pods = []
		for pod in pod_references:
			pods.append((deep_get(pod, "metadata#namespace"), deep_get(pod, "metadata#name")))
		instances = containers[(name, container_type, image_version, image_id)]["instances"]
		# This replaces ref
		obj = {
			"name": name,
			"container_type": container_type,
			"image_version": image_version,
			"image_id": image_id,
			"pod_references": pod_references,
		}
		info.append(ContainerInfo(name, obj, container_type, image_version, instances, image_id, pods, pod_references))
	return info

class LogInfo:
	def __init__(self, name, action, log_path, created_at, log_type):
		self.name = name
		self.action = action
		self.ref = log_path
		self.created_at = created_at
		self.log_type = log_type
	def __repr__(self):
		return repr((self.name, self.ref, self.created_at, self.log_type))

def get_log_info(**kwargs):
	info = []

	# Get the list of available Ansible logs
	ansible_logs = ansible_get_logs()

	# TODO: Here we might possibly want to insert other logs?

	for name, action, ref, created_at in ansible_logs:
		log_type = "Ansible Play"
		info.append(LogInfo(name, action, ref, created_at, log_type))

	return info

def get_pod_containers_list(**kwargs):
	vlist = []
	_vlist, status = kh.get_list_by_kind_namespace(("Pod", ""), "")

	if status == 200:
		for obj in _vlist:
			namespace = deep_get(obj, "metadata#namespace")
			name = deep_get(obj, "metadata#name")
			node_name = deep_get(obj, "spec#nodeName")
			for container in deep_get(obj, "spec#containers"):
				container_name = deep_get(container, "name")
				reason, status_group, restarts, message, age = get_container_status(deep_get(obj, "status#containerStatuses"), container_name, ("Container", ""))
				for container_status in deep_get(obj, "status#containerStatuses", []):
					if deep_get(container_status, "name") == container_name:
						break
				if container_status is not None:
					image_id = deep_get(container_status, "imageID", "")
				else:
					image_id = "<unavailable>"
				vlist.append({
					"namespace": namespace,
					"name": name,
					"container": container_name,
					"status": reason,
					"status_group": status_group,
					"node_name": node_name,
					"image_id": image_id,
				})

	return vlist, status

def get_sidecar_rule_list(obj, **kwargs):
	vlist = []

	for traffic_type, items in [("Ingress", deep_get(obj, "spec#ingress", [])), ("Egress", deep_get(obj, "spec#egress", []))]:
		for item in items:
			pport = deep_get(item, "port#number", "")
			name = deep_get(item, "port#name", "")
			protocol = deep_get(item, "port#protocol", "")
			port = (name, pport, protocol)
			ref = item
			bind = deep_get(item, "bind", "")
			capture_mode = deep_get(item, "captureMode", "NONE")
			# Required
			default_endpoint = deep_get(item, "defaultEndpoint", "")
			# N/A
			hosts = deep_get(item, "hosts", [])
			vlist.append({
				"traffic_type": traffic_type,
				"port": port,
				"ref": ref,
				"bind": bind,
				"capture_mode": capture_mode,
				"default_endpoint": default_endpoint,
				"hosts": hosts,
			})

	return vlist, 200

def normalise_cpu_usage_to_millicores(_cpu_usage):
	cpu_usage = 0

	if _cpu_usage.isnumeric():
		cpu_usage = int(_cpu_usage) * 1000
	elif _cpu_usage.endswith("m"):
		cpu_usage = int(_cpu_usage[0:-1])
	elif _cpu_usage.endswith("u"):
		cpu_usage = int(_cpu_usage[0:-1]) / 1000
	elif _cpu_usage.endswith("n"):
		cpu_usage = int(_cpu_usage[0:-1]) / 1000000
	else:
		raise ValueError(f"Unknown unit for CPU usage in {_mem}")
	return cpu_usage

def normalise_mem_to_bytes(_mem):
	mem = 0

	if _mem.isnumeric():
		mem = _mem
	elif _mem.endswith("Ki"):
		mem = int(_mem[0:-2]) * 1024
	elif _mem.endswith("Mi"):
		mem = int(_mem[0:-2]) * 1024 ** 2
	elif _mem.endswith("Gi"):
		mem = int(_mem[0:-2]) * 1024 ** 3
	elif _mem.endswith("Ti"):
		mem = int(_mem[0:-2]) * 1024 ** 4
	elif _mem.endswith("Pi"):
		mem = int(_mem[0:-2]) * 1024 ** 5
	elif _mem.endswith("Ei"):
		mem = int(_mem[0:-2]) * 1024 ** 6
	elif _mem.endswith("Zi"):
		mem = int(_mem[0:-2]) * 1024 ** 7
	elif _mem.endswith("Yi"):
		mem = int(_mem[0:-2]) * 1024 ** 8
	else:
		raise ValueError(f"Unknown unit for memory usage in {_mem}")

	return mem

def normalise_mem_bytes_to_str(_mem):
	suffix = ""
	mem = 0

	if _mem < 1024 ** 1:
		mem = _mem
	elif _mem < 1024 ** 2:
		mem = _mem / 1024 ** 1
		suffix = "Ki"
	elif _mem < 1024 ** 3:
		mem = _mem / 1024 ** 2
		suffix = "Mi"
	elif _mem < 1024 ** 4:
		mem = _mem / 1024 ** 3
		suffix = "Gi"
	elif _mem < 1024 ** 5:
		mem = _mem / 1024 ** 4
		suffix = "Ti"
	elif _mem < 1024 ** 6:
		mem = _mem / 1024 ** 5
		suffix = "Pi"
	elif _mem < 1024 ** 7:
		mem = _mem / 1024 ** 6
		suffix = "Ei"
	elif _mem < 1024 ** 8:
		mem = _mem / 1024 ** 7
		suffix = "Zi"
	else:
		mem = _mem / 1024 ** 8
		suffix = "Yi"

	return f"{mem:0.1f}{suffix}B"

def datagetter_api_support(obj, path, default):
	if obj is None:
		return default

	kind = deep_get(obj, "spec#names#kind", "")
	api_family = deep_get(obj, "spec#group", "")

	available_views = []

	try:
		_kind, _api_group = kh.guess_kind((kind, api_family))
		available_views.append("Known")
	except:
		pass

	for view in views:
		if deep_get(views, f"{view}#kind", ("", "")) == (kind, api_family):
			available_views.append("List")

	if (kind, api_family) in infoviews:
		if (kind, api_family) in infoviews_builtin:
			available_views.append("Info")
		else:
			available_views.append("*Info")

	if len(available_views) == 0:
		available_views = default

	return available_views, {}

def datagetter_latest_version(obj, path, default):
	if obj is None or path is None:
		return default

	# path is paths to kind, api_family
	kind = deep_get(obj, path[0])
	api_family = deep_get(obj, path[1])
	old_version = deep_get(obj, path[2])
	kind = kh.guess_kind((kind, api_family))

	latest_api = kh.get_latest_api(kind)
	if "/" in latest_api:
		group, version = latest_api.split("/")
	else:
		group = ""
		version = latest_api

	message = ""
	if old_version == version:
		message = "(No newer version available; the API might be deprecated)"
	return (group, version, f"{message}"), {}

def datagetter_metrics(obj, path, default):
	if obj is None or path is None:
		return default

	# fields is a dict
	fields = deep_get(obj, "fields", {})
	result = []

	if type(path[0]) == list:
		return_type = path[1]
		rfields = path[0]
	else:
		return_type = "list"
		rfields = path

	for field in rfields:
		result.append(deep_get(obj, f"fields#{field}", ""))

	if return_type == "str":
		result = str("".join(result))
	elif return_type == "tuple":
		result = tuple(result)
	elif return_type != "list":
		raise Exception(f"datagetter_metrics: Invalid return type {return_type}; this is a programming error")

	return result, {}

def datagetter_deprecated_api(obj, path, default):
	result, extra_vars = datagetter_metrics(obj, path, default)
	kind = kh.guess_kind((result[0], result[1]))
	return (kind[0], kind[1], result[2]), extra_vars

def datagetter_access_modes(obj, path, default):
	if obj is None or path is None:
		return default

	access_modes = []

	for mode in deep_get(obj, path, []):
		access_modes.append(abbreviate_access_mode(mode))

	return access_modes, {}

def datagetter_endpoint_ips(obj, path, default):
	subsets = deep_get(obj, path)
	endpoints = get_endpoint_endpoints(subsets)
	return endpoints, {}

def datagetter_controller(obj, path, default):
	owr = deep_get(obj, path[0])
	show_kind = path[1]
	controller = get_controller_from_owner_references(owr)
	return format_controller(controller, show_kind), {}

def datagetter_ingress_address(obj, paths, default):
	address = []

	for host in deep_get(obj, "status#loadBalancer#ingress", []):
		address.append((deep_get(host, "hostname", deep_get(host, "ip"))))

	return address, {}

def datagetter_ingress_hosts(obj, path, default):
	hosts, ports = get_ingress_hosts(obj)
	if path == "hosts":
		return hosts, {}
	elif path == "ports":
		return ports, {}
	else:
		raise Exception("Unknown ingress field")

def datagetter_regex_split_to_tuples(obj, paths, default):
	if obj is None or paths is None or len(paths) < 2:
		return default

	# paths is a tuple; the first item is a regex that specifies how to split,
	# the second one is either a path to a list or a list of paths

	list_fields = []

	if type(paths[1]) == str:
		for item in deep_get(obj, paths[1], []):
			tmp = re.match(paths[0], item)
			if tmp is not None:
				# This handles ("").*("") | (""); we need to generalise this somehow
				if len(tmp.groups()) >= 2 and tmp[1] is not None and tmp[2] is not None:
					list_fields.append((tmp[1], tmp[2]))
				elif len(tmp.groups()) >= 3:
					list_fields.append(("", tmp[3]))
			else:
				list_fields.append(("", ""))
	else:
		for path in paths[1]:
			item = deep_get(obj, path, "")
			tmp = re.match(paths[0], str(item))
			if tmp is not None:
				# This handles ("").*("") | (""); we need to generalise this somehow
				if len(tmp.groups()) == 1 and tmp[1] is not None:
					list_fields.append(tmp[1])
				if len(tmp.groups()) >= 2 and tmp[1] is not None and tmp[2] is not None:
					list_fields.append((tmp[1], tmp[2]))
				elif len(tmp.groups()) >= 3:
					list_fields.append(("", tmp[3]))
			else:
				list_fields.append(("", ""))

	return list_fields, {}

def datagetter_list_len(obj, path, default):
	if obj is None or path is None or len(path) == 0:
		return 0, {}

	return len(deep_get(obj, [])), {}

def datagetter_list_fields(obj, path, default):
	if obj is None or path is None or len(path) == 0:
		return default

	list_fields = []

	subpath, fields = path

	for item in deep_get(obj, subpath):
		tmp = []
		for field in fields:
			tmp.append(deep_get(item, f"{field}", ""))
		list_fields.append(tuple(tmp))

	return list_fields, {}

def datagetter_containers(obj, paths, default):
	if obj is None or paths is None or len(paths) == 0:
		return default

	containers = []
	for path, status_path in paths:
		containers += get_containers(deep_get(obj, path, []), deep_get(obj, status_path, []))

	return containers, {}

def datagetter_request(obj, path, default):
	if obj is None or path is None or len(path) == 0:
		return default

	request = []

	for resource in deep_get(obj, "spec#hard", []):
		used = deep_get(obj, f"status#used#{resource}", [])
		hard = deep_get(obj, f"spec#hard#{resource}", [])
		request.append((resource, used, hard))

	return request, {}

def datagetter_age(obj, path, default):
	if obj is None or path is None or len(path) == 0:
		return default

	timestamp = timestamp_to_datetime(deep_get(obj, path))
	return get_since(timestamp), {}

def datagetter_count(obj, path, default):
	if obj is None or path is None or len(path) == 0:
		return default

	tmp = deep_get(obj, path)
	if tmp is None:
		tmp = []
	return len(tmp), {}

def datagetter_pod_status(obj, path, default):
	if obj is None:
		return default

	status, status_group = get_pod_status(obj)

	return status, {"status_group": status_group}

def datagetter_container_status(obj, path, default):
	if obj is None:
		return default
	status = deep_get(obj, "status")
	status_group = deep_get(obj, "status_group")

	return status, {"status_group": status_group}

def datagetter_node_status(obj, path, default):
	if obj is None:
		return default

	status, status_group, taints, full_taints = get_node_status(obj)

	return status, {"status_group": status_group}

def datagetter_event_status(obj, path, default):
	if obj is None or path is None or len(path) == 0:
		return default

	status = deep_get(obj, "type")
	status_group = get_event_status_group(status)

	return status, {"status_group": status_group}

def __get_timestamp_with_fallback(obj, paths):
	return timestamp_to_datetime(deep_get_with_fallback(obj, paths))

def datagetter_pathlist_to_tuple(obj, path, default):
	if obj is None or path is None or len(path) == 0:
		return default

	info = []

	# Path here can have multiple components; it's a list,
	# not a single path, although the name says otherwise
	for item in path:
		default = None
		if type(item) == tuple:
			default = item[1]
			item = item[0]
		info.append(deep_get(obj, item, default))

	return tuple(info), {}

def datagetter_node_addresses(obj, path, default):
	if obj is None:
		return default

	# for now we don't do anything with external IPs; we should
	name, internal_ips, external_ips = get_node_addresses(deep_get(obj, "metadata#name"), deep_get(obj, "status#addresses"))

	if path == "name":
		return name, {}
	elif path == "internal":
		return internal_ips, {}
	elif path == "external":
		return external_ips, {}
	else:
		raise Exception(f"Unknown address type {path} requested")

def datagetter_node_roles(obj, path, default):
	if obj is None:
		return default

	return kh.get_node_roles(obj), {}

def datagetter_status_latest_condition(obj, path, default):
	status, status_group, status_message = get_status_latest_condition(deep_get(obj, path))

	return status, {"status_group": status_group, "status_message": status_message}

def datagetter_status_deployment(obj, path, default):
	status, status_group, status_message = get_dep_status(deep_get(obj, path))

	return status, {"status_group": status_group, "status_message_deployment": status_message}

def datagetter_status_message_deployment(obj, path, default):
	status, status_group, status_message = get_dep_status(deep_get(obj, path))

	return status_message, {}

def datagetter_ep_ports(obj, path, default):
	if obj is None:
		return default

	subsets = deep_get(obj, path)

	return get_endpoint_ports(subsets), {}

def datagetter_eps_endpoints(obj, path, default):
	if obj is None:
		return default

	return get_endpointslices_endpoints(obj), {}

def datagetter_timestamp(obj, path, default):
	if obj is None or path is None or len(path) == 0:
		return default

	return timestamp_to_datetime(deep_get(obj, path)), {}

def datagetter_phase(obj, path, default):
	if obj is None:
		return default

	phase = deep_get(obj, path)

	if phase in ["Active", "Available", "Bound", "Running", "Succeeded"]:
		# Note: A Running Pod can be failed if any of its containers have failed
		status_group = stgroup.OK
	elif phase in ["Pending", "Released", "Terminating"]:
		status_group = stgroup.PENDING
	elif phase in ["Error", "Failed"]:
		status_group = stgroup.NOT_OK
	# TODO: add remaining phases, if any
	else:
		status_group = stgroup.UNKNOWN

	return phase, { "status_group": status_group }

def datagetter_pod_selector(obj, path, default):
	if obj is None:
		return default

	pod_selector = []
	for key, value in deep_get(obj, "spec#podSelector#matchLabels", {}).items():
		pod_selector.append((key, value))
	return pod_selector, {}

def datagetter_condition_field(obj, path, default):
	if obj is None:
		return default

	field = ""
	extra_vars = {}

	# path is a list of tuples
	# each tuple has element 0 as the condition list,
	# element 1 the condition type,
	# element 2 the field of the condition to return
	for conditions in path:
		for condition in deep_get(obj, conditions[0], []):
			if deep_get(condition, "type", "") == conditions[1]:
				field = deep_get(condition, conditions[2], "")
				if deep_get(condition, "status", "True") == "True":
					extra_vars = { "status_group": stgroup.OK }
				else:
					extra_vars = { "status_group": stgroup.NOT_OK }
				return field, extra_vars

	return field, extra_vars

def datagetter_condition_ready(obj, path, default):
	if obj is None:
		return default

	ready, message, status_group = get_condition_ready(obj)
	return ready, { "status_message": message, "status_group": status_group }

def datagetter_substitute_quotationmarks(obj, path, default):
	if obj is None or path is None or len(path) == 0:
		return default

	return deep_get(obj, path, "").replace("\\\"", "“").replace("\n", "\\n").rstrip(), {}

def get_default(generator):
	if generator is None:
		default = None, {}
	elif generator in [generator_basic, generator_priority_level, generator_str_timestamp]:
		# This expects indata to be a string
		default = "", {}
	elif generator == generator_status:
		# This expects indata to be a string
		default = "", {"status_group": stgroup.NOT_OK, "status_message": ""}
	elif generator == generator_yesno:
		# Valid indata is either None, True, or False,
		# yielding N/A, Yes, or No respectively.
		# Let's default to N/A
		default = None, {}
	elif generator == generator_timestamp:
		# This expects indata to be a timestamp,
		# but returns an empty string if None is passed in
		default = None, {}
	elif generator in [generator_list, generator_list_with_status]:
		# Expects a list or a tuple; an empty list yields
		# no output, which suits us fine
		default = [], {}
	elif generator == generator_secret_data:
		# Expects an extra entry that specifies the type of data;
		# passing vtype == empty will yield "[empty]" which is good enough
		default = "", {}
	elif generator in [generator_numerical, generator_numerical_range, generator_age]:
		# Yields an empty string from -1
		default = -1, {}
	elif generator in [generator_mem, generator_total]:
		default = (None, None), {}
	elif generator in [generator_mem_single]:
		default = "0", {}
	else:
		raise Exception(f"No default defined for generator {generator}")
	return default

latest_info = None

def process_value(field_name, value, vtype, view, field_index, action, formatter, replace_quotes, _regex):
	override_kind = deep_get_with_fallback(iktconfig, [f"{view}#kind_format_{field_index}", f"{view}#kind_format", f"Global#kind_format_{field_index}", f"Global#kind_format"], "mixed")

	if vtype == "str":
		# We don't want any newlines, and extra trailing whitespace
		if value is None:
			value = ""
		value = value.replace("\n", "\\n").rstrip()
		if replace_quotes == "pretty":
			value = value.replace("\\\"", "“")
		elif replace_quotes == "same":
			value = value.replace("\\\"", "\"")
	elif vtype in ["float", "int", "bool"]:
		if action == "sum" and type(value) in [list, tuple]:
			value = sum(value)

		if type(value) == tuple:
			tmp = []
			for tmp1 in value:
				tmp.append(str(value))
			value = tmp
		else:
			value = str(value)
	elif vtype == "cpu_usage":
		if action == "sum" and type(value) == list:
			tmp = 0
			for tmp1 in value:
				tmp += normalise_cpu_usage_to_millicores(tmp1)
		else:
			tmp = normalise_cpu_usage_to_millicores(value)
		value = f"{tmp:0.1f}"
	elif vtype == "mem_usage":
		if action == "sum" and type(value) == list:
			tmp = 0
			for tmp1 in value:
				tmp += normalise_mem_to_bytes(tmp1)
		else:
			tmp = normalise_mem_to_bytes(value)
		value = normalise_mem_bytes_to_str(tmp)
	elif vtype in ["regex_to_tuples", "regex_to_list"]:
		_values = []
		if len(value) > 0:
			if type(value) == str:
				value = [value]
			for item in value:
				tmp = re.match(_regex, item)
				groups = []
				if tmp is not None:
					for group in tmp.groups():
						if group is not None:
							groups.append(group)
					if vtype == "regex_to_tuples":
						_values.append(tuple(groups))
					else:
						_values += groups
		value = _values
		if len(value) == 1:
			value = value[0]
	elif vtype == "len":
		if value is None:
			value = []
		value = str(len(value))
	elif vtype == "timestamp":
		if action in ["earliest", "latest"] and type(value) in [list, tuple]:
			tmp = None
			for tmp1 in value:
				if tmp1 is None:
					continue
				if tmp1 == -1:
					timestamp = -1
				else:
					timestamp = timestamp_to_datetime(tmp1)
				if tmp is None or timestamp == -1:
					tmp = timestamp
				else:
					if timestamp < tmp and action == "earliest":
						tmp = timestamp
					elif timestamp > tmp and action == "latest":
						tmp = timestamp
			value = tmp
		else:
			value = timestamp_to_datetime(value)

		# If we're gonna format this as age we want this passed through get_since()
		if formatter == "age":
			value = get_since(value)
	elif type(vtype) == list:
		if type(value) not in [list, tuple]:
			raise Exception(f"Field {field_name}: type({value}) is {vtype}; for type {vtype} pathtype must be a multi-element type")
		_values = []
		override_kind = deep_get_with_fallback(iktconfig, [f"{view}#kind_format_{field_index}", f"{view}#kind_format", f"Global#kind_format_{field_index}", f"Global#kind_format"], "mixed")
		for i in range(0, len(value)):
			if i < len(vtype):
				_vtype = vtype[i]
			else:
				_vtype = "raw"
			if _vtype in ["raw", "name"]:
				_values.append(value[i])
			elif _vtype == "kind":
				if override_kind == "skip":
					_values.append("")
				else:
					_values.append(value[i])
			elif _vtype == "api_group":
				if override_kind == "skip":
					_values.append("")
					continue

				if value[i] is not None and "/" in value[i]:
					if override_kind == "full" or override_kind == "mixed" and "." in value[i]:
						_values.append(value[i].split("/")[0])
					else:
						_values.append("")
				else:
					_values.append("")
			elif _vtype in ["skip"]:
				_values.append("")
			else:
				raise Exception(f"Field {field_name}: type[{i}] ({vtype}) is unknown")
		if type(value) == list:
			value = _values
		elif type(value) == tuple:
			value = tuple(_values)
	elif vtype == "raw":
		# Don't convert this type
		pass
	else:
		theme = get_theme_ref()

		# Is a custom type used for theming?
		if vtype not in theme["types"]:
			raise Exception(f"Unknown value type {vtype}; the view file is probably invalid")
	return value

def transform_filter(transformations, value):
	if value in transformations:
		value = deep_get(transformations, value)
	return value

def when_filter(when_path, item, key = None, value = None):
	if type(deep_get(when_path, "when", [])) == dict:
		when_conditions = [deep_get(when_path, "when", {})]
	else:
		when_conditions = deep_get(when_path, "when", [])

	_key = key
	_value = value

	for when_condition in when_conditions:
		# These apply to the key
		if _key is None:
			key = deep_get(when_condition, "key")

		# These don't make sense when using when#key, since we already know the key
		when_key_eq = deep_get(when_condition, "key_eq")
		when_key_ne = deep_get(when_condition, "key_ne")
		when_key_in = deep_get(when_condition, "key_in")
		when_key_notin = deep_get(when_condition, "key_notin")
		when_key_startswith = deep_get(when_condition, "key_startswith")
		when_key_notstartswith = deep_get(when_condition, "key_notstartswith")
		when_key_endswith = deep_get(when_condition, "key_endswith")
		when_key_notendswith = deep_get(when_condition, "key_notendswith")
		if when_key_eq is not None and when_key_eq != key:
			return False
		if when_key_ne is not None and when_key_eq == key:
			return False
		if when_key_in is not None and key not in when_key_in:
			return False
		if when_key_notin is not None and key in when_key_in:
			return False
		if when_key_startswith is not None and not key.startswith(when_key_startswith):
			return False
		if when_key_notstartswith is not None and key.startswith(when_key_notstartswith):
			return False
		if when_key_endswith is not None and not key.endswith(when_key_endswith):
			return False
		if when_key_notendswith is not None and key.endswith(when_key_notendswith):
			return False

		# Check for none
		if _value is None:
			value = deep_get(item, key)

		# These check whether the key has a value
		when_none = deep_get(when_condition, "none")
		when_notnone = deep_get(when_condition, "notnone")

		# All these check the value
		when_eq = deep_get(when_condition, "eq")
		when_ne = deep_get(when_condition, "ne")
		when_lt = deep_get(when_condition, "lt")
		when_lte = deep_get(when_condition, "lte")
		when_gt = deep_get(when_condition, "gt")
		when_gte = deep_get(when_condition, "gte")
		when_in = deep_get(when_condition, "in")
		when_notin = deep_get(when_condition, "notin")
		when_missing = deep_get(when_condition, "missing")
		when_notmissing = deep_get(when_condition, "notmissing")
		when_startswith = deep_get(when_condition, "startswith")
		when_notstartswith = deep_get(when_condition, "notstartswith")
		when_endswith = deep_get(when_condition, "endswith")
		when_notendswith = deep_get(when_condition, "notendswith")

		# These check dict values
		when_isdict = deep_get(when_condition, "isdict")
		when_notisdict = deep_get(when_condition, "notisdict")
		when_dicthaskey = deep_get(when_condition, "dicthaskey")
		when_notdicthaskey = deep_get(when_condition, "notdicthaskey")

		# Check for existance
		if when_missing is not None and when_missing in item:
			return False
		if when_notmissing is not None and when_notmissing not in item:
			return False

		if when_notnone is not None and value is None:
			return False
		if when_none is not None and value is not None:
			return False

		# dict-based checks
		if when_isdict is not None and type(value) == dict:
			return False
		if when_notisdict is not None and type(value) != dict:
			return False
		if when_dicthaskey is not None and (type(value) != dict or when_dicthaskey not in value):
			return False
		if when_notdicthaskey is not None and (type(value) != dict or when_notdicthaskey in value):
			return False

		# Set-based checks
		if when_in is not None and value not in when_in:
			return False
		if when_notin is not None and value in when_notin:
			return False

		# Check for equality
		if when_eq is not None and (value is None or value != type(value)(when_eq)):
			return False
		if when_ne is not None and (value is None or value == type(value)(when_ne)):
			return False

		if when_lt is not None and not value < type(value)(when_lt):
			return False
		if when_lte is not None and not value <= type(value)(when_lte):
			return False
		if when_gt is not None and not value > type(value)(when_gt):
			return False
		if when_gte is not None and value >= type(value)(when_gte):
			return False

	return True

def transform_list(vlist, transform = {}):
	sort = deep_get(transform, "sorted", False)
	key_regexes = deep_get(transform, "key#regex", [])
	key_groups = deep_get(transform, "key#groups", [])
	key_join = deep_get(transform, "key#join")
	key_defaults = deep_get(transform, "key#default", [])
	value_regexes = deep_get(transform, "value#regex", [])
	value_groups = deep_get(transform, "value#groups", [])
	value_join = deep_get(transform, "value#join")
	value_pad_empty = deep_get(transform, "value#pad_empty", "")
	value_defaults = deep_get(transform, "value#default", [])
	output = deep_get(transform, "output", ["key", "value"])

	result = []

	# This handles both lists and dicts
	for key in vlist:
		if not type(vlist) == dict:
			value = None
		else:
			value = vlist[key]

		key_data = []
		for _regex in key_regexes:
			if key is None:
				continue

			key = str(key)

			_tmp = re.match(_regex, key)
			if _tmp is not None:
				for group in key_groups:
					if group < len(_tmp.groups()):
						_tmp2 = _tmp.groups()[group]
						if _tmp2 is None and group < len(key_defaults):
							key_data.append(key_defaults[group])
						else:
							key_data.append(_tmp2)
			if key_join is not None and len(key_data) > 1:
				tmp = ""
				for i in range(0, len(key_data)):
					tmp += key_data[i]
					if i < len(key_data) - 1:
						tmp += key_join[min(i, len(key_join) - 1)]
				key_data = [tmp]

		value_data = []
		for _regex in value_regexes:
			if value is None:
				continue

			value = str(value)

			_tmp = re.match(_regex, value)
			if _tmp is not None:
				for group in value_groups:
					if group < len(_tmp.groups()):
						_tmp2 = _tmp.groups()[group]
						if _tmp2 is None and group < len(value_defaults):
							value_data.append(value_defaults[group])
						else:
							value_data.append(_tmp2)
			if value_join is not None and len(value_data) > 1:
				tmp = ""
				for i in range(0, len(value_data)):
					tmp += value_data[i]
					if i < len(value_data) - 1:
						tmp += value_join[min(i, len(value_join) - 1)]
				value_data = [tmp]

		tmp = []
		for _output in output:
			if _output == "key":
				if len(key_data) == 1:
					tmp.append(key_data[0])
				else:
					tmp.append(tuple(key_data))
			elif _output == "value":
				if len(value_data) == 1:
					tmp.append(value_data[0])
				else:
					tmp.append(tuple(value_data))
		if len(tmp) == 1:
			tmp = tmp[0]
		else:
			tmp = tuple(tmp)
		result.append(tmp)

	if sort == True:
		return natsorted(result)
	else:
		return result

def get_obj(obj, field_dict, field_names, field_index = "normal", view = "", filters = {}):
	d = {}

	# fields both specify formatting and where to get the data from; here we're only concerned with the data
	for field_name in field_names:
		name = field_name
		field = field_dict[name]
		path = deep_get(field, "path")
		paths = deep_get(field, "paths", [])
		datagetter = deep_get(field, "datagetter")
		if type(datagetter) == str:
			datagetter = eval(datagetter)
		converters = deep_get(field, "converters", [])
		if "default" not in field:
			default = ""
		else:
			default = deep_get(field, "default")
		global_default = default
		formatter = deep_get(field, "formatter")
		action = None
		replace_quotes = None

		if (path is None and len(paths) == 0 or path is not None and len(paths) > 0) and datagetter is None:
			raise Exception(f"Field {name}: exactly one of path and paths must be non-empty unless a datagetter is specified\npath={path}\npaths={paths}\ndatagetter={datagetter}")

		if datagetter is not None:
			d[name], extradata = datagetter(obj, path, default)
			for key, value in extradata.items():
				d[key] = value
		else:
			_values = []

			if path is not None:
				if deep_get(field, "type") is None:
					raise Exception(f"Field {name}: the path field has no default type; type must always be specified")
				_values.append((deep_get(obj, path, global_default), deep_get(field, "type")))

			_path = None
			for _path in paths:
				default = deep_get(_path, "default")
				vtype = deep_get(_path, "type", "raw")
				path = deep_get(_path, "path")
				mpaths = deep_get(_path, "paths")
				if path is not None and mpaths is not None or path is None and mpaths is None:
					raise Exception(f"Field {name}: exactly one of path & paths must be used in a 'paths:' block\npath={path}\npaths={paths}")

				if mpaths is None:
					if type(path) == str:
						path = [path]
					mpaths = [path]

				ptype = deep_get(_path, "pathtype", "list")
				limit = deep_get(_path, "limit")
				action = deep_get(_path, "action")
				subpath = deep_get(_path, "subpath", "")
				subpaths = deep_get(_path, "subpaths", [])
				fallback_on_empty = deep_get(_path, "fallback_on_empty", False)
				replace_quotes = deep_get(_path, "replace_quotes", "no")
				if ptype == "list":
					tmp = deep_get_with_fallback(obj, path, default = default, fallback_on_empty = fallback_on_empty)
					if deep_get(_path, "sorted", False) == True and tmp is not None:
						tmp = natsorted(tmp)

					if tmp is not None and tmp in ["None", ["None"]] and deep_get(_path, "none_str_as_none", False) == True:
						tmp = default

					# Just return the list, unless a subset has been requested
					if limit is not None and tmp is not None:
						value = tmp[0:limit]
					else:
						value = tmp

					_values.append((value, vtype))
				elif ptype == "dictlist":
					_raw = deep_get_with_fallback(obj, path, default = default, fallback_on_empty = fallback_on_empty)
					transform = deep_get(_path, "transform", {})
					if _raw is not None:
						for tmp in transform_list(_raw, transform = transform):
							_values.append((tmp, vtype))
				# This takes a list of paths as indata, and--for all numerical entries in the list,
				# builds ranges; all non-numerical entries are included as is
				elif ptype == "ranges":
					rawvals = []
					for p in path:
						tmp = deep_get(obj, p)
						if tmp is not None:
							rawvals += tmp
					rangevals = []
					if tmp is not None:
						firstnum = None
						lastnum = None
						sortedvals = natsorted(tmp)
						for i in range(0, len(sortedvals)):
							# The range is sorted; this means that we add everything as is except None
							# until we reach the first numerical, create ranges for the numericals,
							# then add everything as is except None until the end
							if sortedvals[i] is None:
								continue
							elif type(sortedvals[i]) == int:
								if firstnum is None:
									firstnum = sortedvals[i]
								else:
									if lastnum is None or sortedvals[i] == lastnum + 1:
										lastnum = sortedvals[i]
									else:
										# Flush and start a new range
										rangevals.append((f"{firstnum}", f"{lastnum}", ""))
										firstnum = sortedvals[i]
										lastnum = None
							else:
								if firstnum is not None:
									if lastnum is None:
										rangevals.append((f"{firstnum}", "", ""))
									else:
										rangevals.append((f"{firstnum}", f"{lastnum}", ""))
										lastnum = None
									firstnum = None
								rangevals.append(("", "", sortedvals[i]))
						if firstnum is not None:
							if lastnum is None:
								rangevals.append((f"{firstnum}", "", ""))
							else:
								rangevals.append((f"{firstnum}", f"{lastnum}", ""))
					_values.append((rangevals, "raw"))
				elif ptype == "key_value":
					value = []
					for _key, _value in deep_get_with_fallback(obj, path, {}).items():
						subpaths = deep_get(_path, "subpaths", [])
						if len(subpaths) > 0:
							_value = deep_get_with_fallback(_value, subpaths)
						if when_filter(_path, item = None, key = _key, value = _value) == False:
							continue
						_regexes_key = deep_get(_path, "key#regex", [])
						_regexes_value = deep_get(_path, "value#regex", [])
						if type(_regexes_key) == str:
						       _regexes_key = [_regexes_key]
						if type(_regexes_value) == str:
						       _regexes_value = [_regexes_value]
						_key = transform_filter(deep_get(_path, "key#transform", {}), _key)
						_value = transform_filter(deep_get(_path, "value#transform", {}), _value)
						# A regex for key/value is required to capture only one group;
						# (though conceivably there might be scenario for joining),
						# thus the first non-None capture group will exit the match;
						# when using multiple regexes the first matching regex exits
						match = False
						for _regex in _regexes_key:
							_tmp = re.match(_regex, _key)
							if _tmp is None:
								continue

							for group in _tmp.groups():
								if group is not None:
									_key = group
									match = True
							if match == True:
								break
						match = False
						for _regex in _regexes_value:
							_tmp = re.match(_regex, _value)
							if _tmp is None:
								continue

							for group in _tmp.groups():
								if group is not None:
									_value = group
									match = True
							if match == True:
								break
						# A transform might yield multiple identical key/value pairs;
						# ignore all except the first one
						if (_key, _value) in value:
							continue
						value.append((_key, _value))
					if len(value) == 0:
						if default is None:
							value = []
						else:
							value = default
					for tmp in value:
						_values.append((tmp, vtype))
				elif ptype == "match_expression":
					tmp = deep_get_with_fallback(obj, path)
					if type(tmp) == list:
						value = []
						subpath = deep_get(_path, "subpath")
						for _tmp in tmp:
							__tmp = deep_get(_tmp, subpath)
							value.append(make_set_expression_list(__tmp))
						if len(value) == 1:
							_values.append((value[0], "raw"))
						else:
							for tmp in value:
								_values.append((tmp, "raw"))
					else:
						if tmp is not None:
							value = make_set_expression_list(tmp)
							_values.append((value, "raw"))
						else:
							_values.append((default, "raw"))
				elif ptype == "lookup":
					lookup_kind, lookup_api_group, lookup_namespace, lookup_name, tmp_lookup_selector = path
					if type(lookup_kind) == list:
						lookup_kind = deep_get_with_fallback(obj, lookup_kind, "")
					if type(lookup_api_group) == list:
						lookup_api_group = deep_get_with_fallback(obj, lookup_api_group, "")
					if type(lookup_namespace) == list:
						lookup_namespace = deep_get_with_fallback(obj, lookup_namespace, "")
					if type(lookup_name) == list:
						lookup_name = deep_get_with_fallback(obj, lookup_name, "")
					if len(tmp_lookup_selector) == 0:
						lookup_selector = ""
					else:
						_lookup_selector = {}
						for ls in tmp_lookup_selector:
							ls_key = ls[0]
							ls_value = ls[1]
							if type(ls_value) == list:
								ls_value = deep_get_with_fallback(obj, ls_value)
							_lookup_selector[ls_key] = ls_value
						lookup_selector = kh.make_selector(_lookup_selector)

					try:
						if len(lookup_name) == 0:
							lookup_obj, status = kh.get_list_by_kind_namespace((lookup_kind, lookup_api_group), lookup_namespace, label_selector = lookup_selector)
						else:
							lookup_obj = kh.get_ref_by_kind_name_namespace((lookup_kind, lookup_api_group), lookup_name, lookup_namespace)
					except NameError:
						unknown = deep_get(_path, "unknown", "Unknown Kind")
						_values.append((unknown, "raw"))
						continue
					if type(lookup_obj) == dict and when_filter(_path, item = lookup_obj) == False:
						continue
					subpaths = deep_get(_path, "subpaths", [])
					value = []
					if len(subpaths) > 0:
						tmp = []
						if type(lookup_obj) == dict:
							lookup_obj = [lookup_obj]

						for _lookup_obj in lookup_obj:
							for i in range(0, len(subpaths)):
								tmp.append(deep_get(_lookup_obj, subpaths[i]))
						if len(tmp) == 1:
							value.append(tmp[0])
						else:
							value.append(tuple(tmp))

					if len(value) == 0:
						value = default

					substitute = deep_get(_path, "substitute")
					if substitute is not None:
						value = substitute
					_values.append((value, "raw"))
				elif ptype == "remap":
					value = []
					substitutions = deep_get(_path, "substitutions", "")
					tmp = deep_get_with_fallback(obj, path)
					if tmp is None:
						tmp = []

					if type(tmp) in [bool, int, str]:
						tmp = [tmp]

					if type(tmp) in [list]:
						for _tmp in tmp:
							if _tmp in substitutions:
								value.append(substitutions.get(_tmp))
							elif "__default" in substitutions:
								value.append(substitutions.get("__default"))
							else:
								value.append(_tmp)
					else:
						raise Exception(f"remap is not supported yet for type {type(tmp)}")
					if len(value) == 0:
						if default is None:
							continue
						else:
							value.append(default)
					for tmp in value:
						_values.append((tmp, vtype))
				elif ptype == "substitution":
					value = []
					substitute = deep_get(_path, "substitute", "")
					tmp = deep_get_with_fallback(obj, path)
					if tmp is None:
						tmp = []
					if type(tmp) == dict:
						tmp = [tmp]
					for _tmp in tmp:
						if when_filter(_path, item = _tmp) == False:
							continue
						value.append(substitute)
						break
					else:
						if "else" in _path:
							tmp = deep_get(_path, "else")
							if type(tmp) == list:
								tmp = deep_get_with_fallback(obj, tmp)
							if len(tmp) > 0:
								value.append(tmp)
					if len(value) == 0:
						if default is None:
							continue
						else:
							value.append(default)
					for tmp in value:
						_values.append((tmp, vtype))
				elif ptype == "timediff":
					if len(mpaths) != 2:
						raise ValueError(f"Field {name}: when using pathtype: 'timediff' path must be [start_time_path(s), end_time_path(s)]")
					start_time = iktlib.deep_get_with_fallback(obj, mpaths[0], default = None)
					end_time = iktlib.deep_get_with_fallback(obj, mpaths[1], default = None)
					if end_time is None or start_time is None:
						duration = -1
					else:
						timediff = timestamp_to_datetime(end_time) - timestamp_to_datetime(start_time)
						duration = timediff.days * 24 * 60 * 60 + timediff.seconds
						_values.append((duration, "raw"))
				elif ptype == "timestamp_with_age":
					# The first array is assumed to be the start time, the second array the end time
					start_time = None
					end_time = None
					start_time_index = -1
					end_time_index = -1
					for i in range(0, len(mpaths)):
						if type(mpaths[i]) == list:
							if start_time_index == -1:
								start_time_index = i
								start_time = iktlib.deep_get_with_fallback(obj, mpaths[i], default = None)
							elif end_time_index == -1:
								end_time_index = i
								end_time = iktlib.deep_get_with_fallback(obj, mpaths[i], default = None)
					if end_time is None or start_time is None:
						end_time = None
						duration = -1
					else:
						timediff = timestamp_to_datetime(end_time) - timestamp_to_datetime(start_time)
						duration = timediff.days * 24 * 60 * 60 + timediff.seconds
					__values = []
					for i in range(0, len(mpaths)):
						if i == start_time_index:
							__values.append(end_time)
						elif i == end_time_index:
							__values.append(duration)
						else:
							__values.append(mpaths[i])
					_values.append((tuple(__values), "raw"))
				elif ptype == "items":
					if len(subpath) > 0:
						if len(subpaths) > 0:
							raise ValueError(f"Field {name}: when using action: 'items' exactly one of subpath and subpaths must be specified")
						else:
							subpaths = [subpath]
					value = []
					items = []
					for mpath in mpaths:
						if type(mpath) == str:
							mpath = [mpath]
						items += iktlib.deep_get_list(obj, mpath, default = [], fallback_on_empty = fallback_on_empty)

					for item in items:
						if when_filter(_path, item) == False:
							continue

						tmp = []
						for i in range(0, len(subpaths)):
							if type(default) == list:
								if i < len(default):
									_default = default[i]
								else:
									_default = None
							else:
								_default = default

							if (vtype in ["int", "float"] or action in ["sum"]) and type(default) not in [int, float]:
								_default = 0

							if type(subpaths[i]) == dict:
								_subpath = deep_get(subpaths[i], "subpath")
								if type(_subpath) == str:
									_subpath = [_subpath]
								_regexes = deep_get(subpaths[i], "regex", [])
								if type(_regexes) == str:
									_regexes = [_regexes]
								_raw = deep_get_with_fallback(item, _subpath, _default)
								_raw = transform_filter(deep_get(subpaths[i], "transform", {}), _raw)
								for _regex in _regexes:
									_tmp = re.match(_regex, _raw)
									if _tmp is not None:
										for group in _tmp.groups():
											if group is not None:
												tmp.append(group)
										break
							else:
								prefix = deep_get(_path, "prefix", [])
								suffix = deep_get(_path, "suffix", [])
								_subpath = subpaths[i]
								if type(_subpath) == str:
									_subpath = [_subpath]
								_tmp = deep_get_with_fallback(item, _subpath, _default)
								if type(prefix) == str:
									if type(_tmp) == str:
										_tmp = prefix + _tmp
									else:
										_tmp = [prefix] + _tmp
								else:
									tmp += prefix

								if type(suffix) == str:
									if type(_tmp) == str:
										_tmp += suffix
									else:
										_tmp += [suffix]

								tmp.append(_tmp)

								if type(suffix) == list:
									tmp += suffix
						if len(tmp) == 1:
							value.append(tmp[0])
						else:
							value.append(tuple(tmp))
					if len(value) == 0:
						value = default
					if value is not None:
						if action in ["sum", "latest", "earliest"]:
							_values.append((value, vtype))
						else:
							for tmp in value:
								_values.append((tmp, vtype))
				elif ptype == "split":
					value = []
					separator = deep_get(_path, "separator", ",")
					_raw = deep_get_with_fallback(obj, path, "")
					if _raw is not None:
						for tmp in _raw.split(separator):
							_values.append((tmp, vtype))
				elif ptype == "regex":
					value = []
					_raw = deep_get_with_fallback(obj, path, "")
					_regexes = deep_get(_path, "regex", [])
					if type(_regexes) == str:
						_regexes = [_regexes]
					for _regex in _regexes:
						_tmp = re.match(_regex, _raw)
						if _tmp is not None:
							for group in _tmp.groups():
								if group is not None:
									value.append(group)
							break
					value = tuple(value)
					_values.append((value, "raw"))
				elif ptype == "tuple":
					value = []
					if when_filter(_path, item = obj) == False:
						continue
					for i in range(0, len(path)):
						if type(default) == list:
							if i < len(default):
								_default = default[i]
							else:
								_default = None
						else:
							_default = default

						if vtype in ["int", "float"] and type(default) not in [int, float]:
							_default = 0

						# This is a literal string, not a path
						if type(path[i]) == str:
							tmp = path[i]
						else:
							tmp = deep_get_with_fallback(obj, path[i], default = _default, fallback_on_empty = fallback_on_empty)

						if vtype == "api_group":
							override_kind = deep_get_with_fallback(iktconfig, [f"{view}#kind_format_{field_index}", f"{view}#kind_format", f"Global#kind_format_{field_index}", f"Global#kind_format"], "mixed")
							if override_kind == "skip" or override_kind == "mixed" and "." not in tmp:
								tmp = ""
							vtype = "kind"
						value.append(tmp)
					if type(deep_get(_path, "substitute")) == list:
						value = deep_get(_path, "substitute")
					value = tuple(value)
					_values.append((value, vtype))
				elif ptype == "status_tuple":
					if "lookup" in _path:
						lookup_kind = deep_get(_path, "lookup#kind")
						lookup_api_family = deep_get(_path, "lookup#api_family")
						lookup_status = deep_get(_path, "lookup#status")
					else:
						raise Exception(f"Field {name}: currently status_tuple only supports 'lookup'")
					path = deep_get(_path, "path")
					value = deep_get(obj, path)
					tmp = kh.get_ref_by_kind_name_namespace((lookup_kind, lookup_api_family), value, "")
					if lookup_status == "highlight":
						if tmp is None:
							status_group = stgroup.NOT_OK
						else:
							status_group = stgroup.OK
						value = (value, status_group)
					elif lookup_status == "message":
						if tmp is None:
							value = (deep_get(_path, "lookup#messages#not_ok"), stgroup.NEUTRAL)
						else:
							value = (deep_get(_path, "lookup#messages#ok"), stgroup.NEUTRAL)
					_values.append((value, "raw"))
				elif ptype == "dictfields":
					subpaths = deep_get_with_fallback(_path, ["subpaths", "subpath"], [])
					if type(subpaths) == str:
						subpaths = [[subpaths]]
					for mpath in mpaths:
						tmp = deep_get_with_fallback(obj, mpath)
						if when_filter(_path, item = tmp) == False:
							continue
						value = []
						for key in subpaths:
							if type(key) == str:
								value.append(key)
							else:
								value.append(deep_get_with_fallback(tmp, key, default))
						if len(value) == 1:
							_values.append((value[0], "raw"))
						else:
							_values.append((tuple(value), "raw"))
				else:
					value = deep_get_with_fallback(obj, path, default)
					_values.append((value, vtype))

			values = []

			for value, _vtype in _values:
				_regex = deep_get(_path, "regex")
				if type(_vtype) == list:
					if value is None or len(value) == 0:
						value = []
				if type(value) == list and _vtype == "raw":
					values += value
					continue
				elif type(value) == list and type(_vtype) == list:
					tmp = []
					for _value in value:
						tmp.append(process_value(name, _value, _vtype, view, field_index, action, formatter, replace_quotes, _regex))
				else:
					tmp = process_value(name, value, _vtype, view, field_index, action, formatter, replace_quotes, _regex)
				values.append(tmp)

			if len(values) == 0:
				values = global_default

			if type(values) == list and len(values) == 1 and formatter != "list":
				d[name] = values[0]
			else:
				d[name] = values

	# We've got all the information we can get now; time to apply filters
	skip = False
	for f in filters:
		if deep_get(filters[f], "enabled", True) == False:
			continue

		# If len(allow) > 0, we only allow fields that match
		allow = deep_get(filters[f], "allow", [])
		# If len(block) > 0, we skip fields that match
		block = deep_get(filters[f], "block", [])
		source = deep_get(filters[f], "source", "")
		if source == "object":
			src = obj
		else:
			src = d
		if len(allow) > 0:
			# If all field + value pairs match we allow
			for rule in allow:
				key = deep_get(rule, "key", "")
				values = deep_get(rule, "values", "")

				if deep_get(src, key, "").rstrip() not in values:
					skip = True
					break
		if len(block) > 0:
			# If all field + value pairs match we block
			for rule in block:
				key = deep_get(rule, "key", "")
				values = deep_get(rule, "values", "")
				if deep_get(src, key, "").rstrip() in values:
					skip = True
					break
		if skip == True:
			break
	if skip == True:
		entry = None
	else:
		d["ref"] = obj
		entry = type("InfoClass", (), d)

	return entry

def generic_infogetter(**kwargs):
	info = []

	vlist = deep_get(kwargs, "_vlist", [])

	# Generate an empty entry
	if vlist == []:
		return []

	field_dict = deep_get(kwargs, "_field_dict", {})
	field_names = deep_get(kwargs, "_field_names", [])
	field_index = deep_get(kwargs, "_field_index", "normal")
	filters = deep_get(kwargs, "_filters", {})
	extra_data = deep_get(kwargs, "extra_data", {})

	if len(field_dict) == 0 or len(field_names) == 0:
		sys.exit(f"generic_infogetter() received empty field_dict {field_dict} or field_names {field_names}; this is a programming error")

	# If we know the view we can use it to get overrides from ikt.yaml
	view = deep_get(kwargs, "_view", "")
	for obj in vlist:
		if len(extra_data) > 0:
			obj["_extra_data"] = extra_data
		tmp = get_obj(obj, field_dict = field_dict, field_names = field_names, field_index = field_index, view = view, filters = filters)
		if tmp is None:
			continue

		info.append(tmp)

	return info

def disksize_to_human(size):
	size_suffixes = [
		" bytes",
		"kiB",
		"MiB",
		"GiB",
		"TiB",
		"PiB",
	]
	for i in range(0, len(size_suffixes)):
		if size < 1024:
			break
		size = size // 1024
	suffix = size_suffixes[i]
	return f"{size}{suffix}"

def get_device_model(obj, device):
	for dev in deep_get(obj, "ansible_devices", {}):
		partitions = deep_get(obj, f"ansible_devices#{dev}#partitions", {})
		model = deep_get(obj, f"ansible_devices#{dev}#model", "")
		for partition in partitions:
			if device in partitions:
				return model
	return ""

# Takes a list and splits it into four lists;
# exacts, strings starting _and_ ending with "*", strings starting with "*",
# and strings ending with "*"
def split_matchlist(matchlist, exacts = [], prefixes = [], suffixes = [], ins = []):
	tmp_exacts = []
	tmp_prefixes = []
	tmp_suffixes = []
	tmp_ins = []
	for item in matchlist:
		if item.startswith("*") and item.endswith("*"):
			tmp_ins.append(item[1:-1])
		elif item.endswith("*"):
			tmp_prefixes.append(item[:-1])
		elif item.startswith("*"):
			tmp_suffixes.append(item[1:])
		else:
			tmp_exacts.append(item)
	if len(tmp_exacts) == 0:
		tmp_exacts = exacts
	if len(tmp_prefixes) == 0:
		tmp_prefixes = prefixes
	if len(tmp_suffixes) == 0:
		tmp_suffixes = suffixes
	if len(tmp_ins) == 0:
		tmp_ins = ins
	return tmp_exacts, tuple(tmp_prefixes), tuple(tmp_suffixes), tmp_ins

def check_matchlists(item, exacts = [], prefixes = (), suffixes = (), ins = []):
	if item in exacts:
		return True
	for _in in ins:
		if _in in item:
			return True
	if len(prefixes) > 0 and item.startswith(prefixes) or len(suffixes) > 0 and item.endswith(suffixes):
		return True
	return False

# Takes an unprocessed matchlist, splits it into individual matchlists, and checks for matches
def check_matchlist(item, matchlist):
	exacts, prefixes, suffixes, ins = split_matchlist(matchlist)
	return check_matchlists(item, exacts = exacts, prefixes = prefixes, suffixes = suffixes, ins = ins)

def listgetter_ansible_volumes(obj, **kwargs):
	info = []

	# Find all mounts
	for item in deep_get(obj, "ansible_mounts", []):
		d = {}
		device = deep_get(item, "device", "")
		if len(device) == 0:
			continue
		fstype = deep_get(item, "fstype", "")
		size_total = deep_get(item, "size_total", 0)
		if size_total == 0:
			continue
		size_available = deep_get(item, "size_available", 0)
		partition_size_total = disksize_to_human(size_total)
		partition_size_used = disksize_to_human(size_total - size_available)
		mountpoint = deep_get(item, "mount", "")
		options = deep_get(item, "options", "").split(",")
		# NFS mounts can be added directly; no need to do lookups
		if fstype == "nfs":
			d = {
				"mountpoint": mountpoint,
				"fstype": fstype,
				"options": options,
				"device": device,
				"model": "",
				"partition_size_used": partition_size_used,
				"partition_size_total": partition_size_total,
			}
			info.append(d)
			continue
		device = os.path.basename(device)

		if check_matchlist(mountpoint, deep_get(iktconfig, "Inventory#mountpoint_skiplist", ["/boot/efi", "/var/lib/origin/*", "/run/*", "*@docker*"])):
			continue
		if check_matchlist(device, deep_get(iktconfig, "Inventory#device_skiplist", ["loop*"])):
			continue

		model = get_device_model(obj, device)
		d = {
			"mountpoint": mountpoint,
			"fstype": fstype,
			"options": options,
			"device": device,
			"partition_size_used": partition_size_used,
			"partition_size_total": partition_size_total,
			"model": model,
		}
		info.append(d)

	return info, "OK"

def objgetter_ansible_facts(obj):
	get_facts_path = get_playbook_path("get_facts.yaml")
	retval, ansible_results = ansible_run_playbook_on_selection(get_facts_path, [obj])
	if retval != 0:
		return {}

	ar = ansible_clean_results(ansible_results)

	return deep_get(ar, f"{obj}#TASK: Gathering host facts#ansible_facts", {})

def objgetter_ansible_log(obj):
	tmpobj = {}

	with open(f"{obj}/metadata.yaml", "r") as f:
		tmpobj = yaml.safe_load(f)
		tmpobj["log_path"] = obj

	try:
		with open(tmpobj["playbook_path"], "r") as f:
			playbook = yaml.safe_load(f)[0]
			tmpobj["name"] = deep_get(playbook, "vars#metadata#description")
			tmpobj["playbook_types"] = deep_get(playbook, "vars#metadata#playbook_types", ["<any>"])
			tmpobj["category"] = deep_get(playbook, "vars#metadata#category", "Uncategorized")
	except FileNotFoundError:
		tmpobj["name"] = "File not found"
		tmpobj["playbook_types"] = ["Unavailable"]
		tmpobj["category"] = "Unavailable"
		pass

	logs = []
	for path in natsorted(os.listdir(obj)):
		if path == "metadata.yaml":
			continue
		with open(f"{obj}/{path}", "r") as f:
			logs.append({
				"index": path.split("-")[0],
				"log": yaml.safe_load(f)
			})
	tmpobj["logs"] = logs

	return tmpobj

def objgetter_ansible_task_log(obj):
	tmpobj = {}

	with open(f"{obj}", "r") as f:
		tmpobj = yaml.safe_load(f)

	return tmpobj

def get_task_log(obj):
	field = []

	stdout_lines = deep_get(obj, "log#stdout_lines", [])
	stderr_lines = deep_get(obj, "log#stderr_lines", [])
	msg_lines = deep_get(obj, "log#msg_lines", [])

	if len(stderr_lines) > 0:
		field.append([("stderr:", curses.A_BOLD | curses.A_UNDERLINE)])
		for line in stderr_lines:
			field.append([(f"{line}", color_status_group(stgroup.NOT_OK, False))])

	if len(stdout_lines) > 0:
		if len(field) > 0:
			field.append([("", curses.A_NORMAL)])
			field.append([("", curses.A_NORMAL)])
		field.append([("stdout:", curses.A_BOLD | curses.A_UNDERLINE)])
		for line in stdout_lines:
			field.append([(f"{line}", curses.A_NORMAL)])

	if len(msg_lines) > 0:
		if len(field) > 0:
			field.append([("", curses.A_NORMAL)])
			field.append([("", curses.A_NORMAL)])
		field.append([("msg:", curses.A_BOLD | curses.A_UNDERLINE)])
		for line in msg_lines:
			field.append([(f"{line}", color_status_group(stgroup.OK, False))])

	return field

def get_themearrays(obj):
	return obj

def logpad_msg_getter(obj, **kwargs):
	messages = []

	path = deep_get(kwargs, "path")
	tmp = deep_get(obj, path, "")

	for line in split_msg(tmp):
		messages.append([(f"{line}", curses.A_NORMAL)])
		
	return messages

def get_netpol_rule_list(obj, **kwargs):
	vlist = []
	for item in deep_get(obj, "spec#ingress", []):
		policy_type = "ingress"
		ports = []
		for port in deep_get(item, "ports", []):
			ports.append((deep_get(port, "port", ""), deep_get(port, "protocol", "")))
		pod_label_selector = deep_get(item, "podSelector#matchLabels", {})
		namespace_label_selector = deep_get(item, "namespaceSelector#matchLabels", {})
		for source in deep_get(item, "from", []):
			ipblock = deep_get(source, "cidr")
			ipblock_exceptions = deep_get(source, "except")
			vlist.append({
				"policy_type": policy_type,
				"ipblock": ipblock,
				"ipblock_exceptions": ipblock_exceptions,
				"ports": ports,
				"pod_label_selector": pod_label_selector,
				"namespace_label_selector": namespace_label_selector,
			})
		else:
			vlist.append({
				"policy_type": policy_type,
				"ipblock": "",
				"ipblock_exceptions": [],
				"ports": ports,
				"pod_label_selector": pod_label_selector,
				"namespace_label_selector": namespace_label_selector,
			})

	for item in deep_get(obj, "spec#egress", []):
		policy_type = "egress"
		ports = []
		for port in deep_get(item, "ports", []):
			ports.append((deep_get(port, "port", ""), deep_get(port, "protocol", "")))
		pod_label_selector = deep_get(item, "podSelector#matchLabels", {})
		namespace_label_selector = deep_get(item, "namespaceSelector#matchLabels", {})
		for source in deep_get(item, "to", []):
			ipblock = deep_get(source, "cidr")
			ipblock_exceptions = deep_get(source, "except")
			vlist.append({
				"policy_type": policy_type,
				"ipblock": ipblock,
				"ipblock_exceptions": ipblock_exceptions,
				"ports": ports,
				"pod_label_selector": pod_label_selector,
				"namespace_label_selector": namespace_label_selector,
			})
		else:
			vlist.append({
				"policy_type": policy_type,
				"ipblock": "",
				"ipblock_exceptions": [],
				"ports": ports,
				"pod_label_selector": pod_label_selector,
				"namespace_label_selector": namespace_label_selector,
			})

	return vlist, 200

def get_virtsvc_rule_list(obj, **kwargs):
	vlist = []

	for rule_path, rule_type in [("spec#http", "HTTP"), ("spec#tls", "TLS"), ("spec#tcp", "TCP")]:
		destinations = []

		for rule in deep_get(obj, rule_path, []):
			for item in deep_get(rule, "route", []):
				host = deep_get(item, "destination#host", "")
				subset = deep_get(item, "destination#subset")
				if subset is None:
					subset = "*"
				port = deep_get(item, "destination#port#number", "")
				destinations.append((host, subset, port))

		if len(destinations) > 0:
			vlist.append({
				"rule_type": rule_type,
				"destinations": destinations,
			})

	return vlist, 200

def get_condition_ready(obj):
	ready = "False"
	status_group = stgroup.NOT_OK
	message = ""
	for condition in deep_get(obj, "status#conditions"):
		if len(message) == 0:
			# If we cannot find another message, then get the first
			message = deep_get(condition, "message", "")

		if deep_get(condition, "type", "") == "Ready":
			ready = deep_get(condition, "status", "False")

			if ready == "True":
				status_group = stgroup.OK
				message = deep_get(condition, "message", "")
			break
	return ready, message, status_group

def get_certsignreq_conditions(status):
	conditions = []
	for condition in deep_get(status, "conditions", {}):
		condition_name = deep_get(condition, "type", "")
		ready = deep_get(condition, "status", "False")
		if ready == "True":
			conditions.append(condition_name)

	certificate = deep_get(status, "certificate")

	if certificate is not None and len(certificate) > 0:
		conditions.append("Issued")

	return conditions

class PromRulesInfo:
	def __init__(self, group, ref, rtype, alertrecord, duration):
		self.group = group
		# The reference to the "true" resource object
		self.ref = ref
		self.rtype = rtype
		self.alertrecord = alertrecord
		self.duration = duration
	def __repr__(self):
		return repr((self.group, self.ref, self.rtype, self.alertrecord, self.duration))

def get_promrules_info(**kwargs):
	obj = deep_get(kwargs, "_obj")
	info = []

	if obj is None:
		return []

	for group in deep_get(obj, "spec#groups", []):
		for rule in deep_get(group, "rules"):
			name = deep_get(group, "name")
			alert = deep_get(rule, "alert", "")
			record = deep_get(rule, "record", "")
			if len(alert) > 0 and len(record) > 0:
				sys.exit("We need a better way to handle PrometheusRule; this one has both an alert and a record")
			elif len(alert) > 0:
				rtype = "Alert"
				alertrecord = alert
			elif len(record) > 0:
				rtype = "Record"
				alertrecord = record
			else:
				sys.exit("We need a better way to handle PrometheusRule; this one has neither alert nor record")
			_extra_data = {
				"name": alertrecord,
				"group": name,
				"rtype": rtype,
			}
			if "_extra_data" not in rule:
				rule["_extra_data"] = _extra_data
			ref = rule
			age = deep_get(rule, "for", "")
			duration = iktlib.age_to_seconds(age)
			info.append(PromRulesInfo(name, ref, rtype, alertrecord, duration))

	return info

class SVCMonEndpointsInfo:
	def __init__(self, bearer_token_file, ref, port, target_port, interval, scheme, path, honor_labels, proxy_url):
		self.bearer_token_file = bearer_token_file
		# The reference to the "true" resource object
		self.ref = ref
		self.port = port
		self.target_port = target_port
		self.interval = interval
		self.scheme = scheme
		self.path = path
		self.honor_labels = honor_labels
		self.proxy_url = proxy_url
	def __repr__(self):
		return repr((self.bearer_token_file, self.ref, self.port, self.target_port, self.interval, self.scheme, self.path, self.honor_labels, self.proxy_url))

def get_svcmon_endpoints_info(**kwargs):
	obj = deep_get(kwargs, "_obj")
	info = []

	if obj is None:
		return []

	for item in deep_get(obj, "spec#endpoints"):
		bearer_token_file = deep_get(item, "bearerTokenFile", "")
		ref = item
		port = deep_get(item, "port", "")
		target_port = deep_get(item, "targetPort", "")
		interval = deep_get(item, "interval", "")
		scheme = deep_get(item, "scheme", "")
		path = deep_get(item, "path", "")
		honor_labels = deep_get(item, "honorLabels", "")
		proxy_url = deep_get(item, "proxyUrl", "")
		info.append(SVCMonEndpointsInfo(bearer_token_file, ref, port, target_port, interval, scheme, path, honor_labels, proxy_url))

	return info

class LimitInfo:
	def __init__(self, ltype, name, ref, lmin, lmax, default_request, default_limit, max_lr_ratio):
		self.ltype = ltype
		self.name = name
		self.ref = ref
		self.lmin = lmin
		self.lmax = lmax
		self.default_request = default_request
		self.default_limit = default_limit
		self.max_lr_ratio = max_lr_ratio
	def __repr__(self):
		return repr((self.ltype, self.name, self.ref, self.lmin, self.lmax, self.default_request, self.default_limit, self.max_lr_ratio))

def get_limit_info(**kwargs):
	obj = deep_get(kwargs, "_obj")
	info = []

	if obj is None:
		return []

	for limit in deep_get(obj, "spec#limits", []):
		resources = set()

		for item in deep_get(limit, "default", []):
			resources.add(item)
		for item in deep_get(limit, "defaultRequest", []):
			resources.add(item)
		for item in deep_get(limit, "min", []):
			resources.add(item)
		for item in deep_get(limit, "max", []):
			resources.add(item)
		for item in deep_get(limit, "max", []):
			resources.add(item)
		for item in deep_get(limit, "maxLimitRequestRatio", []):
			resources.add(item)
		ltype = deep_get(limit, "type")
		ref = limit

		for item in resources:
			name = item
			lmin = deep_get(limit, f"min#{item}", "-")
			lmax = deep_get(limit, f"max#{item}", "-")
			default_request = deep_get(limit, f"defaultRequest#{item}", "-")
			default_limit = deep_get(limit, f"default#{item}", "-")
			max_lr_ratio = deep_get(limit, f"maxLimitRequestRatio#{item}", "-")
			info.append(LimitInfo(ltype, name, ref, lmin, lmax, default_request, default_limit, max_lr_ratio))

	return info

class AuthRuleInfo:
	def __init__(self, source, operation, condition):
		self.source = source
		self.operation = operation
		self.condition = condition
	def __repr__(self):
		return repr((self.source, self.operation, self.condition))

def get_auth_rule_info(**kwargs):
	obj = deep_get(kwargs, "_obj")
	info = []

	if obj is None:
		return []

	for item in deep_get(obj, "spec#rules", []):
		sources = []
		operations = []
		conditions = []

		for source in deep_get(item, "from", []):
			principals = ",".join(deep_get(source, "source#principals", []))
			not_principals = ",".join(deep_get(source, "source#notPrincipals", []))
			request_principals = ",".join(deep_get(source, "source#requestPrincipals", []))
			not_request_principals = ",".join(deep_get(source, "source#notRequestPrincipals", []))
			namespaces = ",".join(deep_get(source, "source#namespaces", []))
			not_namespaces = ",".join(deep_get(source, "source#notNamespaces", []))
			ip_blocks = ",".join(deep_get(source, "source#ipBlocks", []))
			not_ip_blocks = ",".join(deep_get(source, "source#notIpBlocks", []))
			sources.append((principals, not_principals, request_principals, not_request_principals, namespaces, not_namespaces, ip_blocks, not_ip_blocks))

		for operation in deep_get(item, "to", []):
			hosts = ",".join(deep_get(operation, "operation#hosts", []))
			not_hosts = ",".join(deep_get(operation, "operation#notHosts", []))
			ports = ",".join(deep_get(operation, "operation#ports", []))
			not_ports = ",".join(deep_get(operation, "operation#notPorts", []))
			methods = ",".join(deep_get(operation, "operation#methods", []))
			not_methods = ",".join(deep_get(operation, "operation#notMethods", []))
			paths = ",".join(deep_get(operation, "operation#paths", []))
			not_paths = ",".join(deep_get(operation, "operation#notPaths", []))
			operations.append((hosts, not_hosts, ports, not_ports, methods, not_methods, paths, not_paths))

		for condition in deep_get(item, "when", []):
			key = deep_get(condition, "key")
			values = ",".join(deep_get(condition, "values", []))
			not_values = ",".join(deep_get(condition, "notValues", []))
			conditions.append((key, values, key, not_values))

		if len(sources) > 0 or len(operations) > 0 or len(conditions) > 0:
			info.append(AuthRuleInfo(sources, operations, conditions))

	return info

def listgetter_policy_rules(obj, **kwargs):
	vlist = []

	if obj is None:
		return []

	# We want one entry per resource, hence a dict
	# Structure:
	# {
	# (api_group, resource): {
	#	"non_resource_urls": [],
	#	"resource_names": [],
	#	"verbs": [],
	# }
	resources = {}

	for rule in deep_get(obj, "rules", []):
		non_resource_urls = deep_get(rule, "nonResourceURLs", [])
		resource_names = deep_get(rule, "resourceNames", [])
		verbs = deep_get(rule, "verbs", [])
		api_groups = deep_get(rule, "apiGroups", [""])
		resourcelist = deep_get(rule, "resources", [""])

		for api_group in api_groups:
			for resource in resourcelist:
				tmp = (resource, api_group)
				if tmp not in resources:
					resources[tmp] = {
						"non_resource_urls": {},
						"resource_names": {},
						"verbs": {},
					}
				for non_resource_url in non_resource_urls:
					resources[tmp]["non_resource_urls"][non_resource_url] = {}
				for resource_name in resource_names:
					resources[tmp]["resource_names"][resource_name] = {}
				for verb in verbs:
					resources[tmp]["verbs"][verb] = {}

	for item in resources.items():
		resource, data = item
		resource, api_group = resource
		non_resource_urls = list(deep_get(data, "non_resource_urls", {}))
		resource_names = list(deep_get(data, "resource_names", {}))
		verbs = list(deep_get(data, "verbs", {}))
		verbs_all = "*" in verbs
		# "*" includes all other verbs
		if verbs_all == True:
			verbs_get = True
			verbs_list = True
			verbs_watch = True
			verbs_create = True
			verbs_update = True
			verbs_patch = True
			verbs_delete = True
			verbs_misc = ["*"]
		else:
			verbs_get = "get" in verbs
			verbs_list = "list" in verbs
			verbs_watch = "watch" in verbs
			verbs_create = "create" in verbs
			verbs_update = "update" in verbs
			verbs_patch = "patch" in verbs
			verbs_delete = "delete" in verbs
			verbs_misc = []
			for verb in verbs:
				if verb not in ["*", "get", "list", "watch", "create", "update", "patch", "delete"]:
					verbs_misc.append(verb)

		vlist.append({
			"resource": resource,
			"api_group": api_group,
			"non_resource_urls": non_resource_urls,
			"resource_names": resource_names,
			"verbs": verbs,
			"verbs_all": verbs_all,
			"verbs_get": verbs_get,
			"verbs_list": verbs_list,
			"verbs_watch": verbs_watch,
			"verbs_create": verbs_create,
			"verbs_update": verbs_update,
			"verbs_patch": verbs_patch,
			"verbs_delete": verbs_delete,
			"verbs_misc": natsorted(verbs_misc)
		})

	return vlist, 200

def get_ingress_hosts(obj):
	hosts = []
	ports = []

	for rule in deep_get(obj, "spec#rules", []):
		if deep_get(rule, "host") is not None:
			hosts.append(deep_get(rule, "host"))

		if deep_get(rule, "http") is not None:
			if "80" not in ports:
				ports.append("80")

	if deep_get(obj, "spec#tls") is not None:
		if "443" not in ports:
			ports.append("443")

	if hosts == []:
		hosts.append("*")

	return hosts, ports

class IngressRuleInfo:
	def __init__(self, host, path, backends):
		self.host = host
		self.path = path
		self.backends = backends
	def __repr__(self):
		return repr((self.host, self.path, self.backends))

def get_ingress_rule_info(**kwargs):
	obj = deep_get(kwargs, "_obj")
	ingress_rules = []

	if obj is None:
		return []

	for rule in deep_get(obj, "spec#rules", []):
		host = deep_get(rule, "host", "*")

		if deep_get(rule, "http") is not None:
			rule_backend = []
			for path in deep_get(rule, "http#paths", []):
				rule_path = deep_get(path, "path", "*")
				if "service" in deep_get(path, "backend"):
					service_name = deep_get(path, "backend#service#name")
					service_port = deep_get(path, "backend#service#number")
				else:
					service_name = deep_get(path, "backend#serviceName")
					service_port = deep_get(path, "backend#servicePort")
				ingress_rules.append(IngressRuleInfo(host, rule_path, (service_name, service_port)))
	return ingress_rules

class ServiceAccountSecretInfo:
	def __init__(self, kind, stype, namespace, name, ref):
		self.kind = kind
		self.type = stype
		self.namespace = namespace
		self.name = name
		# The reference to the "true" resource object
		self.ref = ref
	def __repr__(self):
		return repr((self.kind, self.type, self.namespace, self.name, self.ref))

def get_sas_info(**kwargs):
	obj = deep_get(kwargs, "_obj")

	info = []

	if obj is None:
		return []

	saname = deep_get(obj, "metadata#name")
	sanamespace = deep_get(obj, "metadata#namespace")

	for secret in deep_get(obj, "secrets", []):
		snamespace = deep_get(secret, "namespace", deep_get(obj, "metadata#namespace"))
		secret_name = deep_get(secret, "name")

		# Get a reference to the secret
		ref = kh.get_ref_by_kind_name_namespace(("Secret", ""), secret_name, snamespace)

		info.append(ServiceAccountSecretInfo(("Secret", ""), "Mountable", snamespace, secret_name, ref))

	for secret in deep_get(obj, "imagePullSecrets", []):
		deep_set(ref, "kind", "Secret", create_path = True)
		deep_set(ref, "apiVersion", "", create_path = True)
		snamespace = deep_get(secret, "namespace", deep_get(obj, "metadata#namespace"))
		secret_name = deep_get(secret, "name")

		# Get a reference to the secret
		ref = kh.get_ref_by_kind_name_namespace(("Secret", ""), secret_name, snamespace)

		info.append(ServiceAccountSecretInfo(("Secret", ""), "Image Pull", snamespace, secret_name, ref))

	vlist, status = kh.get_list_by_kind_namespace(("RoleBinding", "rbac.authorization.k8s.io"), "")

	# Get all Role Bindings that bind to this ServiceAccount
	for ref in vlist:
		deep_set(ref, "kind", "RoleBinding", create_path = True)
		deep_set(ref, "apiVersion", "rbac.authorization.k8s.io/", create_path = True)
		for subject in deep_get(ref, "subjects", []):
			subjectkind = deep_get(subject, "kind", "")
			subjectname = deep_get(subject, "name", "")
			subjectnamespace = deep_get(subject, "namespace", "")
			if subjectkind == "ServiceAccount" and subjectname == saname and subjectnamespace == sanamespace:
				info.append(ServiceAccountSecretInfo(("RoleBinding", "rbac.authorization.k8s.io"), "", deep_get(ref, "metadata#namespace"), deep_get(ref, "metadata#name"), ref))

				# Excellent, we have a Role Binding, now add the role it binds to
				rolerefkind = (deep_get(ref, "roleRef#kind", ""), deep_get(ref, "roleRef#apiGroup"))
				rolerefname = deep_get(ref, "roleRef#name", "")
				rolerefnamespace = deep_get(ref, "metadata#namespace", "")
				roleref = kh.get_ref_by_kind_name_namespace(rolerefkind, rolerefname, rolerefnamespace)
				if roleref is not None:
					deep_set(roleref, "kind", rolerefkind[0], create_path = True)
					deep_set(roleref, "apiVersion", f"{rolerefkind[1]}/", create_path = True)
				info.append(ServiceAccountSecretInfo(rolerefkind, "", rolerefnamespace, rolerefname, roleref))
				break

	vlist, status = kh.get_list_by_kind_namespace(("ClusterRoleBinding", "rbac.authorization.k8s.io"), "")

	# Get all Cluster Role Bindings that bind to this ServiceAccount
	for ref in vlist:
		deep_set(ref, "kind", "ClusterRoleBinding", create_path = True)
		deep_set(ref, "apiVersion", "rbac.authorization.k8s.io/", create_path = True)
		for subject in deep_get(ref, "subjects", []):
			subjectkind = deep_get(subject, "kind", "")
			subjectname = deep_get(subject, "name", "")
			subjectnamespace = deep_get(subject, "namespace", "")
			if subjectkind == "ServiceAccount" and subjectname == saname and subjectnamespace == sanamespace:
				info.append(ServiceAccountSecretInfo(("ClusterRoleBinding", "rbac.authorization.k8s.io"), "", "", deep_get(ref, "metadata#name"), ref))

				# Excellent, we have a Cluster Role Binding, now add the role it binds to
				rolerefkind = (deep_get(ref, "roleRef#kind", ""), deep_get(ref, "roleRef#apiGroup"))
				rolerefname = deep_get(ref, "roleRef#name", "")
				roleref = kh.get_ref_by_kind_name_namespace(rolerefkind, rolerefname, subjectnamespace)
				if roleref is not None:
					deep_set(roleref, "kind", rolerefkind[0], create_path = True)
					deep_set(roleref, "apiVersion", f"{rolerefkind[1]}/", create_path = True)
				info.append(ServiceAccountSecretInfo(rolerefkind, "", subjectnamespace, rolerefname, roleref))
				break

	return info

def get_name_by_kind_from_owner_references(owner_references = [], kind = ""):
	for owr in owner_references:
		if deep_get(owr, "kind", "") == kind:
			name = deep_get(owr, "name")
			break

	return name

def get_holder_kind_from_owner_references(owner_references = [], holder_name = ""):
	holder_kind = ""

	for owr in owner_references:
		if deep_get(owr, "name") == holder_name:
			holder_kind = deep_get(owr, "kind")
			break

	return holder_kind

def format_controller(controller, show_kind):
	if len(show_kind) > 0:
		if show_kind == "short" or len(controller[0][1]) == 0:
			controller = (f"{controller[0][0]}", f"{controller[1]}")
		elif show_kind == "full":
			controller = (f"{controller[0][0]}.{controller[0][1]}", f"{controller[1]}")
		elif show_kind == "mixed":
			# Strip the API group for standard controllers, but show for custom controllers
			if controller[0] in [("StatefulSet", "apps"), ("ReplicaSet", "apps"), ("DaemonSet", "apps"), ("Job", "batch"), ("CronJob", "batch"), ("Node", "")]:
				controller = (f"{controller[0][0]}", f"{controller[1]}")
			else:
				controller = (f"{controller[0][0]}.{controller[0][1]}", f"{controller[1]}")
		else:
			raise Exception(f"unknown value passed to show_kind: {show_kind}")
	else:
		controller = ("", f"{controller[1]}")

	return controller

def get_controller_from_owner_references(owner_references):
	controller = (("", ""), "")
	if owner_references is not None:
		for owr in owner_references:
			if deep_get(owr, "controller", False) == True:
				api_version = deep_get(owr, "apiVersion", "")
				tmp = re.match(r"(.*)/.*", api_version)
				if tmp is not None:
					api_group = tmp[1]
				else:
					api_group = ""
				kind = (deep_get(owr, "kind"), api_group)
				controller = (kind, deep_get(owr, "name"))

	return controller

def get_endpoint_endpoints(subsets):
	endpoints = []

	if subsets is None:
		subsets = []

	for subset in subsets:
		for address in deep_get(subset, "addresses", []):
			endpoints.append((deep_get(address, "ip"), stgroup.OK))
		for address in deep_get(subset, "notReadyAddresses", []):
			endpoints.append((deep_get(address, "ip"), stgroup.NOT_OK))

	if len(endpoints) == 0:
		endpoints.append(("<none>", stgroup.UNKNOWN))

	return endpoints

def get_endpoint_ips(subsets):
	endpoints = []
	notready = 0

	if subsets is None:
		return ["<none>"]

	for subset in subsets:
		# Keep track of whether we have not ready addresses
		if deep_get(subset, "notReadyAddresses") is not None and len(deep_get(subset, "notReadyAddresses")) > 0:
			notready += 1

		if deep_get(subset, "addresses") is None:
			continue

		for address in deep_get(subset, "addresses", []):
			endpoints.append(deep_get(address, "ip"))

	if endpoints == []:
		if notready > 0:
			return ["<not ready>"]
		else:
			return ["<none>"]

	return endpoints


def get_endpointslices_ports(obj):
	ports = []
	if deep_get(obj, "ports") is None or deep_get(obj, "ports") == []:
		ports.append(("", "<none>", ""))
	else:
		for port in deep_get(obj, "ports", []):
			port_name = deep_get(port, "name", "")
			ports.append((port_name, str(deep_get(port, "port")), deep_get(port, "protocol")))
	return ports

def get_endpointslices_endpoints(obj):
	endpoints = []

	if deep_get(obj, "endpoints") is not None:
		for endpoint in deep_get(obj, "endpoints", []):
			for address in deep_get(endpoint, "addresses", []):
				ready = deep_get(endpoint, "conditions#ready", False)
				if ready == True:
					status_group = stgroup.OK
				else:
					status_group = stgroup.NOT_OK
				endpoints.append((address, status_group))
	else:
		endpoints.append(("<none>", stgroup.UNKNOWN))
	return endpoints

def get_endpoint_ports(subsets):
	ports = []

	if subsets is None:
		return [("", "<none>", "")]

	for subset in subsets:
		if deep_get(subset, "addresses") is None or deep_get(subset, "ports") is None:
			continue
		else:
			for port in deep_get(subset, "ports", []):
				name = deep_get(port, "name", "")
				ports.append((name, str(deep_get(port, "port")), deep_get(port, "protocol")))

	return ports

class SubsetsInfo:
	def __init__(self, addresses, ports_ep, status, status_group):
		self.addresses = addresses
		self.ports_ep = ports_ep
		self.status = status
		self.status_group = status_group
	def __repr__(self):
		return repr((self.addresses, self.ports_ep, self.status, self.status_group))

def get_subsets_info(**kwargs):
	obj = deep_get(kwargs, "_obj")
	subsets = []

	if obj is None:
		return []

	# Policy for subsets expansion
	expand_subsets = deep_get(iktconfig, "Endpoints#expand_subsets", "None")

	for subset in deep_get(obj, "subsets", []):
		ready_addresses = []
		not_ready_addresses = []
		ports = []

		if deep_get(subset, "ports") is None:
			continue

		if len(deep_get(subset, "addresses", [])) == 0 and len(deep_get(subset, "notReadyAddresses", [])) == 0:
			continue

		for port in deep_get(subset, "ports", []):
			name = deep_get(port, "name", "")
			ports.append((name, deep_get(port, "port"), deep_get(port, "protocol")))

		for address in deep_get(subset, "addresses", []):
			ready_addresses.append(deep_get(address, "ip"))

		for not_ready_address in deep_get(subset, "notReadyAddresses", []):
			not_ready_addresses.append(deep_get(not_ready_address, "ip"))

		if expand_subsets == "None":
			if len(ready_addresses) > 0:
				subsets.append(SubsetsInfo(ready_addresses, ports, "Ready", stgroup.OK))
			if len(not_ready_addresses) > 0:
				subsets.append(SubsetsInfo(not_ready_addresses, ports, "Not Ready", stgroup.NOT_OK))
		elif expand_subsets == "Port":
			for port in ports:
				if len(ready_addresses) > 0:
					subsets.append(SubsetsInfo(ready_addresses, [port], "Ready", stgroup.OK))
				if len(not_ready_addresses) > 0:
					subsets.append(SubsetsInfo(not_ready_addresses, [port], "Not Ready", stgroup.NOT_OK))
		elif expand_subsets == "Address":
			for address in ready_addresses:
				subsets.append(SubsetsInfo([address], ports, "Ready", stgroup.OK))
			for address in not_ready_addresses:
				subsets.append(SubsetsInfo([address], ports, "Not Ready", stgroup.NOT_OK))
		elif expand_subsets == "Both":
			for port in ports:
				for address in ready_addresses:
					subsets.append(SubsetsInfo([address], [port], "Ready", stgroup.OK))
				for address in not_ready_addresses:
					subsets.append(SubsetsInfo([address], [port], "Not Ready", stgroup.NOT_OK))

	return subsets

class EPSSubsetsInfo:
	def __init__(self, addresstype, addresses, ports_eps, status, status_group, target_ref, topology):
		self.addresstype = addresstype
		self.addresses = addresses
		self.ports_eps = ports_eps
		self.status = status
		self.status_group = status_group
		self.target_ref = target_ref
		self.topology = topology
	def __repr__(self):
		return repr((self.addresstype, self.addresses, self.ports_eps, self.status, self.status_group, self.target_ref, self.topology))

def get_eps_subsets_info(**kwargs):
	obj = deep_get(kwargs, "_obj")
	subsets = []

	if obj is None:
		return []

	addresstype = deep_get(obj, "addressType")
	ports = []

	for port in deep_get(obj, "ports", []):
		port_name = deep_get(port, "name", "")
		ports.append((port_name, deep_get(port, "port"), deep_get(port, "protocol")))

	for endpoint in deep_get(obj, "endpoints", []):
		ready_addresses = []
		not_ready_addresses = []

		for address in deep_get(endpoint, "addresses", []):
			if deep_get(endpoint, "conditions#ready") == True:
				ready_addresses.append(address)
			else:
				not_ready_addresses.append(address)
		target_ref = (deep_get(endpoint, "targetRef#kind", ""), deep_get(endpoint, "targetRef#apiVersion", ""), deep_get(endpoint, "targetRef#namespace", ""), deep_get(endpoint, "targetRef#name", ""))
		topology = []
		# If nodeName is available this is the new API where topology is replaced by nodeName and zone
		if "nodeName" in endpoint:
			topology.append(("nodeName", deep_get(endpoint, "nodeName", "<unset>")))
			if "zone" in endpoint:
				topology.append(("zone", deep_get(endpoint, "zone", "<unset>")))
		else:
			for key, value in deep_get(endpoint, "topology", {}).items():
				topology.append((key, value))

		if len(ready_addresses) > 0:
			subsets.append(EPSSubsetsInfo(addresstype, ready_addresses, ports, "Ready", stgroup.OK, target_ref, topology))
		if len(not_ready_addresses) > 0:
			subsets.append(EPSSubsetsInfo(addresstype, not_ready_addresses, ports, "Not Ready", stgroup.NOT_OK, target_ref, topology))

	return subsets

def get_as_status_and_service(conditions, service):
	available = "<unset>"
	message = ""
	status_group = stgroup.UNKNOWN

	for condition in conditions:
		if deep_get(condition, "type") == "Available":
			if deep_get(condition, "reason") == "Local":
				service = [("", "Local", "")]
			else:
				namespace = deep_get(service, "namespace")
				name = deep_get(service, "name")
				port = deep_get(service, "port")
				service = [(namespace, name, port)]
			available = deep_get(condition, "status")
			message = deep_get(condition, "message", "").rstrip()
			if available == "True":
				status_group = stgroup.OK
			else:
				status_group = stgroup.NOT_OK

	return available, service, message, status_group

class PodMetricsInfo:
	def __init__(self, name, cpu_millicores, mem_bytes):
		self.name = name
		self.cpu_millicores = cpu_millicores
		self.mem_bytes = mem_bytes
	def __repr__(self):
		return repr((self.name, self.cpu_millicores, self.mem_bytes))

def cpu_usage_to_millicores(cpu_usage):
	if cpu_usage == "0":
		return float(cpu_usage)
	elif cpu_usage.endswith("n"):
		cpu_usage = f"{float(cpu_usage[:-1]) / 1000000:0.1f}"
		return cpu_usage
	elif cpu_usage.endswith("m"):
		cpu_usage = f"{float(cpu_usage[:-1]) / 1000:0.1f}"
		return cpu_usage
	elif cpu_usage.endswith("u"):
		cpu_usage = f"{float(cpu_usage[:-1]):0.1f}"
		return cpu_usage
	else:
		raise Exception(f"Unknown cpu usage metrics: {cpu_usage}")

class AppStatusInfo:
	def __init__(self, name, status, status_group, link):
		self.name = name
		self.status = status
		self.status_group = status_group
		self.link = link
	def __repr__(self):
		return repr((self.name, self.status, self.status_group, self.link))

def get_app_status_info(**kwargs):
	obj = deep_get(kwargs, "_obj")
	info = []

	if obj is None:
		return []

	for item in deep_get(obj, "status#components", []):
		name = deep_get(item, "name")
		status = deep_get(item, "status")
		if status == "Ready":
			status_group = stgroup.OK
		else:
			status_group = stgroup.NOT_OK
		link = deep_get(item, "link")
		info.append(AppStatusInfo(name, status, status_group, link))

	return info

def listgetter_configmap_data(obj, **kwargs):
	vlist = []

	cm_name = deep_get(obj, "metadata#name")
	cm_namespace = deep_get(obj, "metadata#namespace", "")

	for key, value in deep_get(obj, "binary_data", {}).items():
		vlist.append({
			"cm_name": cm_name,
			"cm_namespace": cm_namespace,
			"configmap": key,
			"type": "Binary",
			"formatter": None,
			"data": value,
		})

	for key, value in deep_get(obj, "data", {}).items():
		data_type, formatter = identify_cmdata(key, cm_name, cm_namespace, value)
		vlist.append({
			"cm_name": cm_name,
			"cm_namespace": cm_namespace,
			"configmap": key,
			"type": data_type,
			"formatter": formatter,
			"data": value,
		})

	return vlist, 200

class StrategyInfo:
	def __init__(self, strategy, name, operator, target):
		self.strategy = strategy
		self.name = name
		self.operator = operator
		self.target = target
	def __repr__(self):
		return repr((self.operator, self.rule, self.operator, self.target))

def get_strategy_info(**kwargs):
	obj = deep_get(kwargs, "_obj")
	info = []

	if obj is None:
		return []

	deschedule_rules = deep_get(obj, "spec#strategies#deschedule#rules", [])
	dontschedule_rules = deep_get(obj, "spec#strategies#dontschedule#rules", [])
	scheduleonmetric_rules = deep_get(obj, "spec#strategies#scheduleonmetric#rules", [])

	if len(deschedule_rules) > 0:
		strategy = "deschedule"
		rule = deschedule_rules[0]

		# Even though this is an array there's only one rule
		name = deep_get(rule, "metricname", "")
		operator = deep_get(rule, "operator", "")
		target = deep_get(rule, "target", -1)
		info.append(StrategyInfo(strategy, name, operator, target))

	if len(dontschedule_rules) > 0:
		strategy = "dontschedule"
		# dontschedule can have multiple rules; if it does we build a hackish tree
		if len(dontschedule_rules) > 1:
			info.append(StrategyInfo(strategy, "", "", -1))
			for rule in dontschedule_rules:
				name = rule.get("metricname", "")
				operator = rule.get("operator", "")
				target = rule.get("target", -1)
				info.append(StrategyInfo("", name, operator, target))
		else:
			rule = dontschedule_rules[0]
			name = rule.get("metricname", "")
			operator = rule.get("operator", "")
			target = rule.get("target", -1)
			info.append(StrategyInfo(strategy, name, operator, target))

	if len(scheduleonmetric_rules) > 0:
		strategy = "scheduleonmetric"
		rule = deschedule_rules[0]

		# Even though this is an array there's only one rule
		name = rule.get("metricname", "")
		operator = rule.get("operator", "")
		target = rule.get("target", -1)
		info.append(StrategyInfo(strategy, name, operator, target))

	return info

# Returns a list of tuples with their latest status
def get_conditions(conditions):
	condition_list = []

	if conditions is not None:
		for condition in conditions:
			ctype = deep_get(condition, "type")
			state = deep_get(condition, "status")
			reason = deep_get(condition, "reason")
			message = deep_get(condition, "message")
			condition_list.append((ctype, state, reason, message))

	return condition_list

# Raw events
def __get_events(obj, **kwargs):
	event_list = []

	kind = deep_get(obj, "kind")
	api_version = deep_get(obj, "apiVersion", "")
	name = deep_get(obj, "metadata#name")
	namespace = deep_get(obj, "metadata#namespace", "")
	event_list = get_events_by_kind_name_namespace(kh.kind_api_version_to_kind(kind, api_version), name, namespace)

	return event_list

# Raw conditions
def __get_conditions(obj, **kwargs):
	condition_list = []

	path = deep_get(kwargs, "path", "status#conditions")

	for condition in deep_get(obj, path, []):
		ctype = deep_get(condition, "type", "")
		status = deep_get_with_fallback(condition, ["status", "phase"], "")
		last_probe = deep_get(condition, "lastProbeTime")
		if last_probe is None:
			last_probe = "<unset>"
		else:
			timestamp = timestamp_to_datetime(last_probe)
			last_probe = timestamp.astimezone().strftime("%Y-%m-%d %H:%M:%S")
		last_transition = deep_get(condition, "lastTransitionTime")
		if last_transition is None:
			last_transition = "<unset>"
		else:
			timestamp = timestamp_to_datetime(last_transition)
			last_transition = timestamp.astimezone().strftime("%Y-%m-%d %H:%M:%S")
		message = deep_get(condition, "message", "")
		condition_list.append((ctype, status, last_probe, last_transition, message))
	return condition_list

def get_status_latest_condition(conditions):
	latest_condition = None
	update_time = None

	if conditions is not None:
		for condition in conditions:
			last_heartbeat_time = deep_get(condition, "lastHeartbeatTime")
			last_transition_time = deep_get(condition, "lastTransitionTime", last_heartbeat_time)
			last_update_time = deep_get(condition, "lastUpdateTime", last_transition_time)

			if update_time is None or (last_update_time is not None and last_update_time > update_time):
				update_time = last_update_time
				latest_condition = condition

	status = "Unknown"
	status_group = stgroup.UNKNOWN
	status_message = ""

	if latest_condition is not None:
		ctype = deep_get(latest_condition, "type")
		cstatus = deep_get(latest_condition, "status")
		status_message = deep_get(latest_condition, "message", "")

		if ctype == "Failed" and cstatus == "True":
			status = ctype
			status_group = stgroup.NOT_OK
		elif ctype in ["ControllerHealthy", "Running"] and cstatus == "True":
			status = ctype
			status_group = stgroup.OK
		elif ctype == "Created" and cstatus == "True":
			status = ctype
			status_group = stgroup.PENDING

	return status, status_group, status_message

def get_dep_status(conditions):
	status = "Unknown"
	message = ""
	status_group = stgroup.UNKNOWN

	for condition in conditions:
		ctype = deep_get(condition, "type")
		message = deep_get(condition, "message", "").rstrip()

		if ctype == "Available":
			if deep_get(condition, "status") == "True":
				status = "Available"
				status_group = stgroup.OK
				# Available has highest priority
				break
			else:
				status = "Not Available"
				status_group = stgroup.NOT_OK
		elif ctype == "Progressing":
			if deep_get(condition, "status") == "True":
				status = "Progressing"
				status_group = stgroup.PENDING
			else:
				status = "Not Progressing"
				status_group = stgroup.NOT_OK
		elif ctype == "ReplicaFailure":
				status = "Replica Failure"
				status_group = stgroup.NOT_OK
		else:
			sys.exit(f"Unknown deployment condition: {ctype}, reason: {message}")

	return status, status_group, message

def get_desired_replicas(rs):
	desired = -1
	max_replicas = -1
	for annotation, value in deep_get(rs, "metadata#annotations", {}).items():
		if annotation == "deployment.kubernetes.io/desired-replicas":
			desired = value
		elif annotation == "deployment.kubernetes.io/max-replicas":
			max_replicas = value
	return desired, max_replicas

class RQItemInfo:
	def __init__(self, resource, used, hard):
		self.resource = resource
		self.used = used
		self.hard = hard
	def __repr__(self):
		return repr((self.resource, self.used, self.hard))

def get_rq_item_info(**kwargs):
	obj = deep_get(kwargs, "_obj")
	info = []

	if obj is None:
		return []

	for resource in deep_get(obj, "spec#hard", []):
		used = deep_get(obj, f"status#used#{resource}", [])
		hard = deep_get(obj, f"spec#hard#{resource}", [])

		info.append(RQItemInfo(resource, used, hard))

	return info

class KeyValueInfo:
	def __init__(self, key, decoded_value, value, vtype, vlen):
		self.key = key
		self.decoded_value = decoded_value
		self.value = value
		self.vtype = vtype
		self.vlen = vlen
	def __repr__(self):
		return repr((self.key, self.decoded_value, self.value, self.vtype, self.vlen))

def decode_value(value):
	# Is this base64?
	try:
		tmp = base64.b64decode(value)
		vtype = "base64"
	except Exception as e:
		vtype = "string"

	if vtype == "base64":
		try:
			tmp = base64.b64decode(value).decode("utf-8")
			if "\n" in tmp:
				vtype = "base64-utf-8"
			else:
				vtype = "string"
				value = tmp
		except UnicodeDecodeError as e:
			vtype = "base64-binary"

		try:
			tmp = base64.b64decode(base64.b64decode(value))
			if tmp[0] == 0x1f and tmp[1] == 0x8b:
				vtype = "gzip"
				value = tmp
		except:
			pass

	return vtype, value

def get_key_value_info(**kwargs):
	info = []

	vlist = deep_get(kwargs, "_vlist")
	if vlist is None:
		return info

	for key, value in vlist.items():
		decoded_value = ""

		vtype, value = decode_value(value)
		vlen = len(value)
		decoded_value = value

		if vlen == 0:
			value = ""
			vtype = "empty"

		if len(decoded_value) > 8192 and len(decoded_value) > 0:
			vtype = f"{vtype} [truncated]"
			decoded_value = value[0:8192 - 1]

		info.append(KeyValueInfo(key, decoded_value, value, vtype, vlen))

	return info

def get_external_ips(svc):
	external_ips = []

	for xip in deep_get(svc, "spec#externalIPs", []):
		external_ips.append(xip)

	if external_ips == []:
		external_ips.append("<none>")

	return external_ips

def get_port(obj):
	port = ("", "", "")

	if obj is not None:
		name = deep_get(obj, "name", "")
		if "port" in obj:
			pport = deep_get(obj, "port", "")
		else:
			pport = deep_get(obj, "number", "")
		protocol = deep_get(obj, "protocol", "")
		port = (name, pport, protocol)

	return port

def get_svc_port_target_endpoints(obj, **kwargs):
	svcname = deep_get(obj, "metadata#name")
	svcnamespace = deep_get(obj, "metadata#namespace")
	port_target_endpoints = []
	stype = deep_get(obj, "spec#type")
	cluster_ip = deep_get(obj, "spec#clusterIP")
	endpoints = []

	ref = kh.get_ref_by_kind_name_namespace(("Endpoints", ""), svcname, svcnamespace)
	endpoints = get_endpoint_ips(deep_get(ref, "subsets"))

	for port in deep_get(obj, "spec#ports", []):
		name = deep_get(port, "name", "")
		svcport = deep_get(port, "port", "")
		protocol = deep_get(port, "protocol", "")
		if stype in ["NodePort", "LoadBalancer"]:
			node_port = deep_get(port, "nodePort", "Auto Allocate")
		else:
			node_port = "N/A"
		if cluster_ip is not None:
			target_port = deep_get(port, "targetPort", "")
		else:
			target_port = ""
		endpointstr = (":%s, " % target_port).join(endpoints)
		if len(endpointstr) > 0:
			endpointstr += ":%s" % target_port
		port_target_endpoints.append((f"{name}:{svcport}/{protocol}", f"{node_port}", f"{target_port}/{protocol}", endpointstr))

	if len(port_target_endpoints) == 0:
		port_target_endpoints = [("<none>", "", "", "")]

	return port_target_endpoints

def get_event_status_group(status):
	if status == "Error":
		status_group = stgroup.NOT_OK
	elif status == "Warning":
		status_group = stgroup.ADMIN
	elif status == "Normal":
		status_group = stgroup.OK
	else:
		# FIXME
		status_group = stgroup.UNKNOWN

	return status_group

class ResourceInfo:
	def __init__(self, resource_tuple, ref, rtype, kind, status, status_group, restarts, message, age = -1):
		self.resource_tuple = resource_tuple
		# The reference to the "true" resource object
		self.ref = ref
		self.rtype = rtype
		self.kind = kind
		self.status = status
		self.status_group = status_group
		self.restarts = restarts
		self.message = message
		self.age = age
	def __repr__(self):
		return repr((self.resource_tuple, self.ref, self.rtype, self.kind, self.status, self.status_group, self.restarts, self.message, self.age))

def get_container_status(src_statuses, container, kind):
	reason = "UNKNOWN"
	status_group = stgroup.UNKNOWN
	restarts = 0
	message = ""

	if src_statuses is None:
		return reason, status_group, -1, message, -1

	for container_status in src_statuses:
		if deep_get(container_status, "name") == container:
			restarts = deep_get(container_status, "restartCount")
			running = deep_get(container_status, "state#running")
			ts = deep_get_with_fallback(container_status, ["state#terminated#finishedAt", "lastState#terminated#finishedAt", "state#running#startedAt"], None)
			age = timestamp_to_datetime(ts)

			if deep_get(container_status, "ready") == False:
				status_group = stgroup.NOT_OK

				if running is not None:
					reason = "Running"
				elif deep_get(container_status, "state#terminated") is not None:
					reason = deep_get(container_status, "state#terminated#reason", "ErrNotSet")
					if deep_get(container_status, "state#terminated#exitCode") == 0:
						status_group = stgroup.DONE

					if deep_get(container_status, "state#terminated#message") is not None:
						message = deep_get(container_status, "state#terminated#message", "").rstrip()
				else:
					reason = deep_get(container_status, "state#waiting#reason", "").rstrip()

					if deep_get(container_status, "state#waiting#message") is not None:
						message = deep_get(container_status, "state#waiting#message", "").rstrip()
			else:
				if running is None:
					reason = deep_get(container_status, "state#terminated#reason", "").rstrip()

					if deep_get(container_status, "state#terminated#message") is not None:
						message = deep_get(container_status, "state#terminated#message", "").rstrip()

					if deep_get(container_status, "state#terminated#exitCode") == 0:
						status_group = stgroup.DONE
					else:
						status_group = stgroup.NOT_OK
				else:
					reason = "Running"
					status_group = stgroup.OK
			break

	return reason, status_group, restarts, message, age

def make_set_expression_list(expression_list):
	expressions = []

	if expression_list is not None:
		for expression in expression_list:
			operator = deep_get(expression, "operator", "")
			if operator == "In":
				operator = "In "
			elif operator == "NotIn":
				operator = "Not In "
			elif operator == "Exists":
				operator = "Exists"
			elif operator == "DoesNotExist":
				operator = "Does Not Exist"
			elif operator == "Gt":
				operator = "> "
			elif operator == "Lt":
				operator = "< "
			key = deep_get_with_fallback(expression, ["key", "scopeName"], "")

			tmp = deep_get(expression, "values", [])
			values = ",".join(tmp)
			if len(values) > 0 and operator not in ["Gt", "Lt"]:
				values = f"[{values}]"

			expressions.append((key, operator, values))
	return expressions

def make_set_expression(expression_list):
	vlist = make_set_expression_list(expression_list)
	xlist = []
	for key, operator, values in vlist:
		xlist.append(f"{key} {operator}{values}")
	return ", ".join(xlist)

def get_pv_from_pvc_name(pvc_name):
	pv = None
	pv_name = None
	field_selector = f"metadata.name={pvc_name}"

	vlist, status = kh.get_list_by_kind_namespace(("PersistentVolumeClaim", ""), "", field_selector = field_selector)
	if status == 200:
		for pvc in vlist:
			if deep_get(pvc, "metadata#name") == pvc_name:
				volume_name = deep_get(pvc, "spec#volumeName")
				if volume_name is not None:
					pv_name = volume_name
					pv = kh.get_ref_by_kind_name_namespace(("PersistentVolume", ""), pv_name, None)
					break

	return pv, pv_name

def get_pv_status(pv):
	phase = deep_get(pv, "status#phase")

	if phase in ["Bound", "Available"]:
		reason = phase
		status_group = stgroup.OK
	elif phase in ["Released", "Pending"]:
		reason = phase
		status_group = stgroup.PENDING
	else:
		reason = deep_get(pv, "status#reason", "").strip()
		status_group = stgroup.NOT_OK
	return reason, status_group

def get_pods_by_node(node):
	pods = []

	vlist, status = kh.get_list_by_kind_namespace(("Pod", ""), "")
	if status == 200:
		for pod in vlist:
			if deep_get(pod, "spec#nodeName") == node:
				pods.append(pod)

	return pods, status

def abbreviate_access_mode(mode):
	if mode == "ReadWriteOnce":
		abbr = "RWO "
	elif mode == "ReadWriteOncePod":
		abbr = "RWOP"
	elif mode == "ReadWriteMany":
		abbr = "RWM "
	elif mode == "ReadOnlyMany":
		abbr = "ROX "
	else:
		raise Exception(f"Unknown access mode {mode}")

	return abbr

def get_pod_log_by_name_namespace_container(name, namespace, container, tail_lines = default_tail_lines):
	internal_error = False

	rawmsg, status = kh.read_namespaced_pod_log(name, namespace, container = container, tail_lines = tail_lines)
	if status == 200:
		# Everything is successful
		internal_error = False
	elif status == 400:
		# Not successful; error in rawmsg
		rawmsg = "%s CRITICAL: %s" % (datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S"), rawmsg)
		internal_error = True
	elif status == 500:
		# Not successful; error in rawmsg
		internal_error = True
	else:
		rawmsg = "%s CRITICAL: Failed to fetch log for pod (name: %s, namespace: %s, container: %s); Request Status: %s" % (datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S"), name, namespace, container, status)
		internal_error = True

	if rawmsg.startswith("unable to retrieve container logs for"):
		rawmsg = "%s CRITICAL: %s" % (datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S"), rawmsg)
		internal_error = True

	return rawmsg, internal_error

def resource_kind_to_rtype(resource):
	rtypes = {
		("AntreaAgentInfo", "crd.antrea.io"): "[antrea_agent_info]",
		("AntreaControllerInfo", "crd.antrea.io"): "[antrea_controller_info]",
		("CiliumEndpoint", "cilium.io"): "[cilium_endpoint]",
		("ConfigMap", ""): "[configmap]",
		("Container", ""): "[container]",
		("Controller", ""): "[controller]",
		("ControllerRevision", "apps"): "[controller_revision]",
		("CronJob", "batch"): "[job_controller]",
		("DaemonSet", "apps"): "[controller]",
		("Deployment", "apps"): "[controller]",
		("Endpoints", ""): "[endpoints]",
		("EndpointSlice", "discovery.k8s.io"): "[endpoint_slice]",
		("EphemeralContainer", ""): "[ephemeral_container]",
		("Event", ""): "[event]",
		("Event", "events.k8s.io"): "[event]",
		("HorizontalPodAutoscaler", "autoscaling"): "[pod_autoscaler]",
		("Ingress", "networking.k8s.io"): "[ingress]",
		("InitContainer", ""): "[init_container]",
		("Job", "batch"): "[controller]",
		("Lease", "coordination.k8s.io"): "[lease]",
		("LimitRange", ""): "[limit]",
		("MutatingWebhookConfiguration", "admissionregistration.k8s.io"): "[webhook_configuration]",
		("Node", ""): "[node]",
		("PersistentVolume", ""): "[volume]",
		("PersistentVolumeClaim", ""): "[volume_claim]",
		("Pod", ""): "[pod]",
		("PodDisruptionBudget", "policy"): "[pod_disruption_budget]",
		("PodMetrics", "metrics.k8s.io"): "[pod_metrics]",
		("PriorityClass", "scheduling.k8s.io"): "[priority_class]",
		("ReplicaSet", "apps"): "[controller]",
		("ReplicationController", ""): "[controller]",
		("Role", "rbac.authorization.k8s.io"): "[role]",
		("RoleBinding", "rbac.authorization.k8s.io"): "[role_binding]",
		("RuntimeClass", "node.k8s.io"): "[runtime_class]",
		("Scheduler", ""): "[scheduler]",
		("Secret", ""): "[secret]",
		("Service", ""): "[service]",
		("ServiceAccount", ""): "[service_account]",
		("ServiceEntry", ""): "[service_entry]",
		("StatefulSet", "apps"): "[controller]",
		("TASPolicy", "telemetry.intel.com"): "[scheduling_policy]",
		("TFJob", "kubeflow.org"): "[controller]",
		("ValidatingWebhookConfiguration", "admissionregistration.k8s.io"): "[webhook_configuration]",
		("Workflow", "argoproj.io"): "[controller]",
	}

	return rtypes.get(resource, "[unknown]")

def get_resource_info_by_last_applied_configuration(obj, **kwargs):
	kind = deep_get(kwargs, "kind")
	if kind is None:
		return [], 404

	configuration = {
		"kind": kind[0]
	}

	if deep_get(kwargs, "match_api_version", False) == True:
		version_path = deep_get(kwargs, "version_path")
		group_path = deep_get(kwargs, "group_path")
		api_version = f"{deep_get(obj, group_path)}/{deep_get(obj, version_path)}"
		configuration["apiVersion"] = api_version

	resource_info = []
	status = None

	items, _status = kh.get_list_by_kind_namespace(kind, "")
	if _status != 200:
		return resource_info, _status

	for item in items:
		last_applied_configuration = deep_get(item, "metadata#annotations#kubectl.kubernetes.io/last-applied-configuration", {})
		if last_applied_configuration is None or len(last_applied_configuration) == 0:
			continue
		data = json.loads(last_applied_configuration)
		match = True
		for key in configuration:
			if key not in data or configuration[key] != data[key]:
				match = False
				break
		if match == True:
			name = deep_get(item, "metadata#name")
			namespace = deep_get(item, "metadata#namespace", "")
			d = {
				"kind": kind,
				"metadata": {
					"namespace": namespace,
					"name": name,
				}
			}
			resource_info.append(d)

	return resource_info, status

def get_pod_resource_list(obj, **kwargs):
	vlist = []

	init_containers = True
	containers = True
	ephemeral_containers = True

	resource_info = []

	pod_name = deep_get(obj, "metadata#name")
	pod_namespace = deep_get(obj, "metadata#namespace")

	container_resources = []
	if init_containers == True:
		kind = ("InitContainer", "")
		for container in deep_get(obj, "spec#initContainers", []):
			# We need these when iterating containers
			container_resources.append((kind, container, deep_get(obj, "status#initContainerStatuses")))
	if containers == True:
		kind = ("Container", "")
		for container in deep_get(obj, "spec#containers", []):
			# We need these when iterating containers
			container_resources.append((kind, container, deep_get(obj, "status#containerStatuses")))
	if ephemeral_containers == True:
		kind = ("EphemeralContainer", "")
		for container in deep_get(obj, "spec#ephemeralContainers", []):
			# We need these when iterating containers
			container_resources.append((kind, container, deep_get(obj, "status#ephemeralContainerStatuses")))

	for kind, container, container_status in container_resources:
		rtype = resource_kind_to_rtype(kind)
		ref = container
		name = deep_get(container, "name")
		resource_tuple = ("", "", name)
		status, status_group, restarts, message, age = get_container_status(container_status, name, kind)
		vlist.append({
			"ref": ref,
			"namespace": pod_namespace,
			"name": name,
			"kind": kind[0],
			"api_group": kind[1],
			"type": rtype,
			"resource_tuple": resource_tuple,
			"status": status,
			"restarts": restarts,
			"message": message,
			"age": get_since(age),
		})

	if "node" not in deep_get(iktconfig, "Pods#filter_resources", []):
		kind = ("Node", "")
		rtype = resource_kind_to_rtype(kind)
		name = deep_get(obj, "spec#nodeName")
		ref = None
		if name is not None:
			ref = kh.get_ref_by_kind_name_namespace(("Node", ""), name, None)
		if name is None:
			name = "<unset>"
		resource_tuple = ("", "", name)

		if ref is not None:
			status, status_group, taints, full_taints = get_node_status(ref)
		else:
			status = "<unset>"

		vlist.append({
			"ref": ref,
			"namespace": pod_namespace,
			"name": name,
			"kind": kind[0],
			"api_group": kind[1],
			"type": rtype,
			"resource_tuple": resource_tuple,
			"status": status,
			"restarts": "",
			"message": "",
			"age": -1,
		})

	for owr in deep_get(obj, "metadata#ownerReferences", []):
		owr_kind = deep_get(owr, "kind", "")
		owr_api_version = deep_get(owr, "apiVersion", "")
		if "/" in owr_api_version:
			owr_api_version = owr_api_version.split("/")[0]
		else:
			owr_api_version = ""
		owr_kind = (owr_kind, owr_api_version)
		owr_name = deep_get(owr, "name", "")
		is_controller = deep_get(owr, "controller", False)
		if is_controller == True:
			if "controller" in deep_get(iktconfig, "Pods#filter_resources", []):
				continue
			rtype = "[controller]"
		elif owr_kind == ("CronJob", "batch"):
			if "cronjob" in deep_get(iktconfig, "Pods#filter_resources", []):
				continue
			rtype = "[cronjob]"
		else:
			if "owner_reference" in deep_get(iktconfig, "Pods#filter_resources", []):
				continue
			rtype = "[owner_reference]"

		status = ""

		ref = kh.get_ref_by_kind_name_namespace(owr_kind, owr_name, pod_namespace)
		# XXX: Maybe we should get the ref status here?
		if ref is None:
			status = "<missing>"

		resource_tuple = (owr_kind[0], owr_kind[1], owr_name)
		vlist.append({
			"ref": ref,
			"namespace": pod_namespace,
			"name": owr_name,
			"kind": owr_kind[0],
			"api_group": owr_kind[1],
			"type": rtype,
			"resource_tuple": resource_tuple,
			"status": status,
			"restarts": "",
			"message": "",
			"age": -1,
		})

	if "persistent_volume_claim" not in deep_get(iktconfig, "Pods#filter_resources", []):
		for volume in deep_get(obj, "spec#volumes", []):
			if deep_get(volume, "persistentVolumeClaim") is None:
				continue

			kind = ("PersistentVolume", "")
			rtype = resource_kind_to_rtype(kind)

			claim_name = deep_get(volume, "persistentVolumeClaim#claimName")
			pv, pv_name = get_pv_from_pvc_name(claim_name)

			if pv is not None:
				status, status_group = get_pv_status(pv)
			else:
				pv_name = "<INVALID PV>"
				status = "Error"
			ref = pv
			resource_tuple = ("", "", pv_name)
			vlist.append({
				"ref": ref,
				"namespace": pod_namespace,
				"name": name,
				"kind": kind[0],
				"api_group": kind[1],
				"type": rtype,
				"resource_tuple": resource_tuple,
				"status": status,
				"restarts": "",
				"message": "",
				"age": -1,
			})

	if "service_account" not in deep_get(iktconfig, "Pods#filter_resources", []) and deep_get(obj, "spec#serviceAccountName") is not None:
		kind = ("ServiceAccount", "")
		rtype = resource_kind_to_rtype(kind)

		name = deep_get(obj, "spec#serviceAccountName")
		ref = kh.get_ref_by_kind_name_namespace(kind, name, pod_namespace)
		resource_tuple = ("", "", name)
		vlist.append({
			"ref": ref,
			"namespace": pod_namespace,
			"name": name,
			"kind": kind[0],
			"api_group": kind[1],
			"type": rtype,
			"resource_tuple": resource_tuple,
			"status": "",
			"restarts": "",
			"message": "",
			"age": -1,
		})

	for vol in deep_get(obj, "spec#volumes", []):
		status = ""

		if deep_get(vol, "secret") is not None and "secret" not in deep_get(iktconfig, "Pods#filter_resources", []):
			kind = ("Secret", "")
			rtype = resource_kind_to_rtype(kind)
			secret_name = deep_get(vol, "secret#secretName")
			optional = deep_get(vol, "secret#optional", False)
			resource_tuple = ("", "", secret_name)
			ref = kh.get_ref_by_kind_name_namespace(kind, secret_name, pod_namespace)
			if ref is None:
				if optional == False:
					status = "<missing>"
				else:
					status = "<optional>"
			vlist.append({
				"ref": ref,
				"namespace": pod_namespace,
				"name": secret_name,
				"kind": kind[0],
				"api_group": kind[1],
				"type": rtype,
				"resource_tuple": resource_tuple,
				"status": status,
				"restarts": "",
				"message": "",
				"age": -1,
			})

		if deep_get(vol, "configMap") is not None and "config_map" not in deep_get(iktconfig, "Pods#filter_resources", []):
			kind = ("ConfigMap", "")
			rtype = resource_kind_to_rtype(kind)
			cm_name = deep_get(vol, "configMap#name")
			optional = deep_get(vol, "configMap#optional", False)
			resource_tuple = ("", "", cm_name)
			ref = kh.get_ref_by_kind_name_namespace(kind, cm_name, pod_namespace)
			if ref is None:
				if optional == False:
					status = "<missing>"
				else:
					status = "<optional>"
			else:
				if len(deep_get(ref, "data", [])) == 0:
					status = "<empty>"
			vlist.append({
				"ref": ref,
				"namespace": pod_namespace,
				"name": cm_name,
				"kind": kind[0],
				"api_group": kind[1],
				"type": rtype,
				"resource_tuple": resource_tuple,
				"status": status,
				"restarts": "",
				"message": "",
				"age": -1,
			})

	for vol in deep_get(obj, "spec#imagePullSecrets", []):
		if "secret" not in deep_get(iktconfig, "Pods#filter_resources", []):
			kind = ("Secret", "")
			rtype = "[image_pull_secret]"
			secret_name = deep_get(vol, "name")
			resource_tuple = ("", "", secret_name)
			ref = kh.get_ref_by_kind_name_namespace(kind, secret_name, pod_namespace)
			vlist.append({
				"ref": ref,
				"namespace": pod_namespace,
				"name": secret_name,
				"kind": kind[0],
				"api_group": kind[1],
				"type": rtype,
				"resource_tuple": resource_tuple,
				"status": "",
				"restarts": "",
				"message": "",
				"age": -1,
			})

	if "event" not in deep_get(iktconfig, "Pods#filter_resources", []):
		#kind = ("Event", "events.k8s.io")
		kind = ("Event", "")
		rtype = resource_kind_to_rtype(kind)

		_vlist, status = kh.get_list_by_kind_namespace(kind, "")
		for event in _vlist:
			event_involved_object_name = deep_get_with_fallback(event, ["regarding#name", "involvedObject#name"])
			event_involved_object_namespace = deep_get_with_fallback(event, ["regarding#namespace", "involvedObject#namespace"])
			if event_involved_object_name == pod_name and event_involved_object_namespace == pod_namespace:
				ref = event
				# For kind we don't want the api_family
				event_name = deep_get(event, "metadata#name")
				resource_tuple = (kind[0], "", event_name)
				status = deep_get(event, "type")
				tmp = __get_timestamp_with_fallback(event, ["series#lastObservedTime", "deprecatedLastTimestamp", "lastTimestamp", "eventTime", "deprecatedFirstTimestamp", "firstTimestamp"])
				seen = get_since(tmp)
				message = deep_get(event, "message", "")
				message = message.replace("\n", "\\n").rstrip()
				resource_info.append(ResourceInfo(resource_tuple, event, rtype, kind, status, status_group, -1, message, age = seen))
				vlist.append({
					"ref": ref,
					"namespace": pod_namespace,
					"name": event_name,
					"kind": kind[0],
					"api_group": kind[1],
					"type": rtype,
					"resource_tuple": resource_tuple,
					"status": status,
					"restarts": "",
					"message": message,
					"age": seen,
				})

	if "pod_disruption_budget" not in deep_get(iktconfig, "Pods#filter_resources", []):
		# XXX: Are there are other means of specifying what pod to apply the PDB to than this?
		if "app" in deep_get(obj, "metadata#labels", {}):
			kind = ("PodDisruptionBudget", "policy")
			_vlist, status = kh.get_list_by_kind_namespace(kind, "", label_selector = f"app={deep_get(obj, 'metadata#labels')['app']}")
			for pdb in _vlist:
				rtype = resource_kind_to_rtype(kind)
				pdb_name = deep_get(pdb, "metadata#name")
				pdb_namespace = deep_get(pdb, "metadata#namespace")
				resource_tuple = ("", "", pdb_name)
				ref = kh.get_ref_by_kind_name_namespace(kind, pdb_name, pdb_namespace)
				vlist.append({
					"ref": ref,
					"namespace": pdb_namespace,
					"name": pdb_name,
					"kind": kind[0],
					"api_group": kind[1],
					"type": rtype,
					"resource_tuple": resource_tuple,
					"status": "",
					"restarts": "",
					"message": "",
					"age": -1,
				})

	if "pod_metrics" not in deep_get(iktconfig, "Pods#filter_resources", []):
		kind = ("PodMetrics", "metrics.k8s.io")
		podmetrics = kh.get_ref_by_kind_name_namespace(kind, pod_name, pod_namespace)
		if podmetrics is not None:
			ref = podmetrics
			rtype = resource_kind_to_rtype(kind)
			resource_tuple = ("", "", pod_name)
			vlist.append({
				"ref": ref,
				"namespace": pod_namespace,
				"name": pod_name,
				"kind": kind[0],
				"api_group": kind[1],
				"type": rtype,
				"resource_tuple": resource_tuple,
				"status": "",
				"restarts": "",
				"message": "",
				"age": -1,
			})

	if "antrea_agent" not in deep_get(iktconfig, "Pods#filter_resources", []) and deep_get(obj, "metadata#labels#component", "") == "antrea-agent":
		# OK, this pod is an antrea-agent, so we should look for one that matches it
		kind = ("AntreaAgentInfo", "crd.antrea.io")
		_vlist, status = kh.get_list_by_kind_namespace(kind, "")
		for item in _vlist:
			if deep_get(item, "podRef#namespace", "") == pod_namespace and deep_get(item, "podRef#name", "") == pod_name:
				ref = item
				name = deep_get(item, "metadata#name")
				status = "Unknown"
				for condition in deep_get(item, "agentConditions", {}):
					if deep_get(condition, "type") == "AgentHealthy":
						healthy = deep_get(condition, "status", "Unknown")
						if healthy == "True":
							status = "Healthy"
						elif healhty == "False":
							status = "Unhealthy"
				rtype = resource_kind_to_rtype(kind)
				resource_tuple = ("", "", name)
				resource_info.append(ResourceInfo(resource_tuple, ref, rtype, kind, status, status_group, -1, ""))
				vlist.append({
					"ref": ref,
					"namespace": pod_namespace,
					"name": name,
					"kind": kind[0],
					"api_group": kind[1],
					"type": rtype,
					"resource_tuple": resource_tuple,
					"status": status,
					"restarts": "",
					"message": "",
					"age": -1,
				})
				break

	if "antrea_controller" not in deep_get(iktconfig, "Pods#filter_resources", []) and deep_get(obj, "metadata#labels#component", "") == "antrea-controller":
		# OK, this pod is an antrea-agent, so we should look for one that matches it
		kind = ("AntreaControllerInfo", "crd.antrea.io")
		_vlist, status = kh.get_list_by_kind_namespace(kind, "")
		for item in _vlist:
			if deep_get(item, "podRef#namespace", "") == pod_namespace and deep_get(item, "podRef#name", "") == pod_name:
				ref = item
				name = deep_get(item, "metadata#name")
				status = "Unknown"
				for condition in deep_get(item, "controllerConditions", {}):
					if deep_get(condition, "type") == "ControllerHealthy":
						healthy = deep_get(condition, "status", "Unknown")
						if healthy == "True":
							status = "Healthy"
						elif healhty == "False":
							status = "Unhealthy"
				rtype = resource_kind_to_rtype(kind)
				resource_tuple = ("", "", name)
				vlist.append({
					"ref": ref,
					"namespace": pod_namespace,
					"name": name,
					"kind": kind[0],
					"api_group": kind[1],
					"type": rtype,
					"resource_tuple": resource_tuple,
					"status": status,
					"restarts": "",
					"message": "",
					"age": -1,
				})
				break

	if "cilium_endpoint" not in deep_get(iktconfig, "Pods#filter_resources", []):
		# Check if there's a matching cilium endpoint
		kind = ("CiliumEndpoint", "cilium.io")
		ref = kh.get_ref_by_kind_name_namespace(kind, pod_name, pod_namespace)
		if ref is not None:
			rtype = resource_kind_to_rtype(kind)
			resource_tuple = ("", "", pod_name)
			vlist.append({
				"ref": ref,
				"namespace": pod_namespace,
				"name": pod_name,
				"kind": kind[0],
				"api_group": kind[1],
				"type": rtype,
				"resource_tuple": resource_tuple,
				"status": "",
				"restarts": "",
				"message": "",
				"age": -1,
			})

	if "service" not in deep_get(iktconfig, "Pods#filter_resources", []):
		# Find service(s) that has a selector that points to this pod
		kind = ("Service", "")
		rtype = resource_kind_to_rtype(kind)
		_vlist, status = kh.get_list_by_kind_namespace(kind, pod_namespace)
		for item in _vlist:
			selector = deep_get(item, "spec#selector", {})
			if len(selector) == 0:
				continue
			_vlist2, status = kh.get_list_by_kind_namespace(("Pod", ""), pod_namespace, label_selector = kh.make_selector(selector), field_selector = f"metadata.name={pod_name},metadata.namespace={pod_namespace}")
			if len(_vlist2) > 0:
				ref = item
				name = deep_get(item, "metadata#name")
				namespace = deep_get(item, "metadata#namespace")
				resource_tuple = ("", "", name)
				vlist.append({
					"ref": ref,
					"namespace": namespace,
					"name": name,
					"kind": kind[0],
					"api_group": kind[1],
					"type": rtype,
					"resource_tuple": resource_tuple,
					"status": "",
					"restarts": "",
					"message": "",
					"age": -1,
				})

	if "runtimeclass" not in deep_get(iktconfig, "Pods#filter_resources", []):
		kind = ("RuntimeClass", "node.k8s.io")
		name = deep_get(obj, "spec#runtimeClassName")
		ref = kh.get_ref_by_kind_name_namespace(kind, name, "")
		if ref is not None:
			rtype = resource_kind_to_rtype(kind)
			resource_tuple = ("", "", name)
			vlist.append({
				"ref": ref,
				"namespace": pod_namespace,
				"name": name,
				"kind": kind[0],
				"api_group": kind[1],
				"type": rtype,
				"resource_tuple": resource_tuple,
				"status": "",
				"restarts": "",
				"message": "",
				"age": -1,
			})

	return vlist, 200

class InventoryInfo:
	def __init__(self, name, ips, kubernetes_roles, ansible_groups, status):
		self.name = name
		self.ref = name
		self.ips = ips
		self.kubernetes_roles = kubernetes_roles
		self.ansible_groups = ansible_groups
		self.status = status
	def __repr__(self):
		return repr((self.name, self.ips, self.kubernetes_roles, self.ansible_groups, self.status))

def get_inventory_info(**kwargs):
	global latest_info
	info = []
	nodes = []

	control_plane_node, control_plane_name = get_control_plane()

	vlist, status = kh.get_list_by_kind_namespace(("Node", ""), "")

	for node in vlist:
		roles = kh.get_node_roles(node)
		if "control-plane" in roles:
			continue
		nodes.append(deep_get(node, "metadata#name"))
	if len(nodes) > 0:
		ansible_add_hosts(ANSIBLE_INVENTORY, nodes, group = "nodes")

	# This returns a YAML tree with the inventory of nodes
	inventory = ansible_get_inventory_dict()

	if deep_get(inventory, "all#hosts") == {}:
		# name, IP, isnode
		info.append(InventoryInfo("<none>", "", "", [], "", stgroup.UNKNOWN))
		return info

	# Before we ping the hosts their status is unknown
	for host in deep_get(inventory, "all#hosts", []):
		# We don't want to risk overwriting hostvars
		if deep_get(inventory, "all#hosts#%s" % host) is None:
			inventory["all"]["hosts"][host] = {}
		inventory["all"]["hosts"][host]["status"] = "UNKNOWN"

	ping_hosts = deep_get(iktconfig, "Inventory#ping_hosts", "Lazy")

	# FIXME
	if ping_hosts == "Always" or (ping_hosts == "Lazy" and latest_info in ["Inventory", "*Inventory"]):
		# ping all nodes and update their status accordingly
		retval, output = ansible_ping(ANSIBLE_INVENTORY)

		if output is None or len(output) == 0:
			sys.exit("Internal error; ansible -m ping failed with: %s" % (retval))

		# This needs to be improved; if there's a message we need to tell the difference
		# between "Permission denied" and "No route to host"
		for (host, status) in output:
			if host in deep_get(inventory, "all#hosts"):
				# We don't want to risk overwriting hostvars
				if deep_get(inventory, "all#hosts#%s" % host) is None:
					inventory["all"]["hosts"][host] = {}
				inventory["all"]["hosts"][host]["status"] = status

	for host in deep_get(inventory, "all#hosts", []):
		# There's no point in trying gethostbyname() on hosts that cannot be resolved

		# For now we don't do anything with external IPs; we should
		name = host
		ips = []

		try:
			ips = [socket.gethostbyname(name)]
		except socket.gaierror as e:
			if str(e).endswith("Name or service not known"):
				pass
			elif str(e).endswith("Temporary failure in name resolution"):
				pass
			else:
				sys.exit("gethostbyname failed on %s; %s" % (name, e))
		except Exception as e:
			sys.exit("gethostbyname failed on %s; %s" % (name, e))

		# This only happens if you run the command on one of the hosts in the inventory
		if ips != [] and ips[0].startswith("127."):
			ips = []

			# Get all interfaces with global scope
			output = subprocess.check_output(["ip", "-o", "addr", "show", "scope", "global"]).decode("utf-8")
			for line in output.splitlines():
				tmp = re.match(r"^\d+: (.*?)\s+inet6? (.*?)/\d+ .*", line)
				if tmp is not None:
					iface = tmp[1]
					addr = tmp[2]
					# There are probably a lot of other things we should exclude,
					# but let's start with these
					if iface.startswith("docker") or iface.startswith("weave"):
						continue
					ips.append(addr)

		kubernetes_roles = []

		# We don't have this information if the network is down
		if host == control_plane_name:
			kubernetes_roles.append("control-plane")

		# We don't have this information if the network is down
		if host in nodes:
			kubernetes_roles.append("[node]")

			node = kh.get_ref_by_kind_name_namespace(("Node", ""), host, "")
			if node is not None:
				roles = kh.get_node_roles(node)

				for role in roles:
					if len(role) > 0 and role not in ["control-plane", "node"]:
						kubernetes_roles.append(role)
		ansible_groups = ansible_get_groups_by_host(inventory, host)
		status = deep_get(inventory, f"all#hosts#{name}#status", "UNKNOWN")
		if control_plane_name == "":
			kubernetes_roles = ["<unknown>"]
		info.append(InventoryInfo(name, ips, kubernetes_roles, ansible_groups, status))

	return info

class NodeInfo:
	def __init__(self, name, ref, status, status_group, kubernetes_roles, age, kubelet_version, internal_ips, os, kernel, container_runtime, cpu, mem, taints):
		self.name = name
		# The reference to the "true" resource object
		self.ref = ref
		self.status = status
		self.status_group = status_group
		self.kubernetes_roles = kubernetes_roles
		self.age = age
		self.kubelet_version = kubelet_version
		self.internal_ips = internal_ips
		self.os = os
		self.kernel = kernel
		self.container_runtime = container_runtime
		self.cpu = cpu
		self.mem = mem
		self.taints = taints
	def __repr__(self):
		return repr((self.name, self.ref, self.status, self.status_group, self.age, self.kubernetes_roles, self.kubelet_version, self.internal_ips, self.os, self.kernel, self.container_runtime, self.cpu, self.mem, self.taints))

def get_node_status(node):
	status = "Unknown"
	status_group = stgroup.UNKNOWN
	taints = []
	full_taints = []

	for condition in deep_get(node, "status#conditions", []):
		if deep_get(condition, "type") == "Ready":
			condition_status = deep_get(condition, "status")
			if condition_status == "True":
				status = "Ready"
				status_group = stgroup.OK
			elif condition_status == "Unknown":
				status = "Unreachable"
				status_group = stgroup.NOT_OK
			else:
				status = "NotReady"
				status_group = stgroup.NOT_OK

	for nodetaint in deep_get(node, "spec#taints", []):
		key = deep_get(nodetaint, "key")
		if key == "node-role.kubernetes.io/master":
			key = "node-role.kubernetes.io/control-plane"
		effect = deep_get(nodetaint, "effect")
		full_taints.append((key, effect))

		# Control Plane having scheduling disabled
		# is expected behaviour and does not need
		# any form of highlighting
		if deep_get(nodetaint, "effect") == "NoSchedule":
			if key == "node-role.kubernetes.io/control-plane":
				taints.append(("control-plane", effect))
				continue

			if key.startswith("node.kubernetes.io/"):
				key = key[len("node.kubernetes.io/"):]

			taints.append((key, effect))

			# If status is already "worse" than OK,
			# we don't override it.
			# Scheduling being disabled is not an error,
			# but it's worth highlighting
			if status_group == stgroup.OK:
				status_group = stgroup.ADMIN
		else:
			if key.startswith("node.kubernetes.io/"):
				key = key[len("node.kubernetes.io/"):]

			taints.append((key, effect))

	return status, status_group, taints, full_taints

def get_node_addresses(name, addresses):
	iips = []
	eips = []

	for address in addresses:
		address_type = deep_get(address, "type")
		address_address = deep_get(address, "address")
		if address_type == "InternalIP":
			iips.append(address_address)
		elif address_type == "ExternalIP":
			eips.append(address_address)
		# handle external IPs too
		elif address_type == "Hostname":
			if name is None:
				name = address_address
			elif name != address_address:
				sys.exit("We need to handle multiple hostnames somehow!")
		else:
			continue

	if iips == []:
		iips = ["<unset>"]
		eips = ["<unset>"]
	if eips == []:
		eips = ["<none>"]
	if name is None:
		name = "<unset>"

	return name, iips, eips

def get_node_info(vlist, extra_vars = {}):
	info = []

	if vlist == []:
		return []

	for obj in vlist:
		# for now we don't do anything with external IPs; we should
		name, internal_ips, external_ips = get_node_addresses(deep_get(obj, "metadata#name"), deep_get(obj, "status#addresses"))
		ref = obj
		kubernetes_roles = kh.get_node_roles(obj)
		timestamp = timestamp_to_datetime(deep_get(obj, "metadata#creationTimestamp"))
		age = get_since(timestamp)
		cpu = (deep_get(obj, "status#allocatable")["cpu"], deep_get(obj, "status#capacity")["cpu"])
		# Strip Ki suffix
		mem = (deep_get(obj, "status#allocatable")["memory"][:-2], deep_get(obj, "status#capacity")["memory"][:-2])
		status, status_group, taints, full_taints = get_node_status(obj)
		kubelet_version = deep_get(obj, "status#nodeInfo#kubeletVersion")
		container_runtime = deep_get(obj, "status#nodeInfo#containerRuntimeVersion")
		os = deep_get(obj, "status#nodeInfo#osImage")
		kernel = deep_get(obj, "status#nodeInfo#kernelVersion")

		info.append(NodeInfo(name, ref, status, status_group, kubernetes_roles, age, kubelet_version, internal_ips, os, kernel, container_runtime, cpu, mem, taints))

	return info

# To make the failure case easier, return both the ref and the name of the control plane
def get_control_plane():
	vlist, status = kh.get_list_by_kind_namespace(("Node", ""), "")
	control_planes = []

	if vlist is None or len(vlist) == 0 or status != 200:
		return None, ""

	# Find control planes; but for now only return the first match
	for obj in vlist:
		labels = deep_get(obj, "metadata#labels", {})
		if "node-role.kubernetes.io/control-plane" in labels or "node-role.kubernetes.io/master" in labels:
			control_planes.append((obj, deep_get(obj, "metadata#name")))

	# If we have exactly one node, assume that it is the control plane even if it lacks that label
	if len(control_planes) == 0 and len(vlist) == 1:
		control_planes.append((vlist[0], deep_get(vlist[0], "metadata#name")))

	if len(control_planes) > 1:
		iktprint([(f"Warning: ", "warning"), ("multiple control planes not supported yet, found multiple; returning first entry:", "default")], stderr = True)
		for control_plane in control_planes:
			print(f"  {control_plane[1]}")

	return control_planes[0][0], control_planes[0][1]

class PodInfo:
	def __init__(self, namespace, name, ref, status, status_group, node, pod_ip, age, restarts, last_restart, controller, tolerations, containers):
		self.namespace = namespace
		self.name = name
		# The reference to the "true" resource object
		self.ref = ref
		self.status = status
		self.status_group = status_group
		self.node = node
		self.pod_ip = pod_ip
		self.age = age
		self.restarts = restarts
		self.last_restart = last_restart
		self.controller = controller
		self.tolerations = tolerations
		self.containers = containers
	def __repr__(self):
		return repr((self.namespace, self.name, self.ref, self.status, self.status_group, self.node, self.pod_ip, self.age, self.restarts, self.last_restart, self.controller, self.tolerations, self.containers))

def get_pod_restarts_total(pod):
	restarts = 0
	restarted_at = None

	#for status in deep_get(pod, "status#initContainerStatuses", []) + deep_get(pod, "status#containerStatuses", []):
	for status in deep_get(pod, "status#containerStatuses", []):
		restart_count = deep_get(status, "restartCount", 0)
		restarts += restart_count
		if restart_count > 0:
			started_at = timestamp_to_datetime(deep_get_with_fallback(status, ["state#running#startedAt", "lastState#terminated#finishedAt"], None))
			if started_at is not None and (restarted_at is None or restarted_at < started_at):
				restarted_at = started_at

	if restarts == 0:
		restarted_at = -1
	return restarts, restarted_at

def get_pod_status(pod):
	if deep_get(pod, "metadata#deletionTimestamp") is not None:
		status = "Terminating"
		status_group = stgroup.PENDING
		return status, status_group

	phase = deep_get(pod, "status#phase")

	if phase == "Pending":
		status = phase
		status_group = stgroup.PENDING

		# Any containers in ContainerCreating or similar?
		for condition in deep_get(pod, "status#conditions", []):
			condition_type = deep_get(condition, "type")
			condition_status = deep_get(condition, "status")
			reason = deep_get(condition, "reason", "")

			if condition_type == "PodScheduled" and condition_status == "False" and reason == "Unschedulable":
				status = reason
				status_group = stgroup.NOT_OK
				break
			elif condition_type == "ContainersReady" and condition_status == "False":
				for container in deep_get(pod, "status#initContainerStatuses", []):
					if deep_get(container, "ready") == False:
						reason = deep_get(container, "state#waiting#reason", "").rstrip()
						if reason is not None and len(reason) > 0:
							return reason, status_group
				for container in deep_get(pod, "status#containerStatuses", []):
					if deep_get(container, "ready") == False:
						reason = deep_get(container, "state#waiting#reason", "").rstrip()
						if reason is not None and len(reason) > 0:
							return reason, status_group

		return status, status_group
	elif phase == "Running":
		status = "Running"
		status_group = stgroup.OK
		last_state = ""
		exit_code = 0

		# Any container failures?
		for condition in deep_get(pod, "status#conditions", []):
			condition_type = deep_get(condition, "type")
			condition_status = deep_get(condition, "status")
			ready = True

			if condition_type == "Ready" and condition_status == "False":
				status_group = stgroup.NOT_OK
				status = "NotReady"
				# Can we get more info? Is the host available?
				node_name = deep_get(pod, "spec#nodeName")
				node = kh.get_ref_by_kind_name_namespace(("Node", ""), node_name, None)
				node_status = get_node_status(node)
				if node_status[0] == "Unreachable":
					status = "NodeUnreachable"
				ready = False
				break
			elif condition_type == "ContainersReady" and condition_status == "False":
				status_group = stgroup.NOT_OK

				for container in deep_get(pod, "status#initContainerStatuses", []):
					kind = "InitContainer"
					status, status_group, restarts, message, age = get_container_status(deep_get(pod, "status#initContainerStatuses"), deep_get(container, "name"), kind)
					# If we have a failed container,
					# break here
					if status_group == stgroup.NOT_OK:
						break

				for container in deep_get(pod, "status#containerStatuses", []):
					kind = "Container"
					status, status_group, restarts, message, age = get_container_status(deep_get(pod, "status#containerStatuses"), deep_get(container, "name"), kind)
					# If we have a failed container,
					# break here
					if status_group == stgroup.NOT_OK:
						break

		return status, status_group
	elif phase == "Failed":
		# Failed
		status_group = stgroup.NOT_OK
		status = deep_get(pod, "status#reason", phase).rstrip()
		return status, status_group
	else:
		# Succeeded
		status_group = stgroup.DONE
		return phase, status_group

def get_pod_affinity(obj, **kwargs):
	affinities = []

	for affinity in deep_get(obj, "spec#affinity", []):
		atype = affinity
		for policy in deep_get(obj, f"spec#affinity#{atype}", ""):
			tmp = re.match(r"^(ignored|preferred|required)DuringScheduling(Ignored|Preferred|Required)DuringExecution$", policy)
			if tmp is None:
				scheduling = "Unknown"
				execution = "Unknown"
			else:
				scheduling = tmp[1].capitalize()
				execution = tmp[2]

			selectors = ""
			for item in deep_get(obj, f"spec#affinity#{atype}#{policy}", []):
				topology = ""
				if type(item) == dict:
					items = [item]
				elif type(item) == str:
					items = deep_get(obj, f"spec#affinity#{atype}#{policy}#{item}", [])

				for selector in items:
					weight = deep_get(selector, f"weight", "")
					if type(weight) == int:
						weight = f"/{weight}"
					topology = deep_get(selector, f"topologyKey", "")
					# We're combining a few different policies, so the expressions can be in various places; not simultaneously though
					selectors += make_set_expression(deep_get(selector, "labelSelector#matchExpressions", {}))
					selectors += make_set_expression(deep_get(selector, "labelSelector#matchFields", {}))
					selectors += make_set_expression(deep_get(selector, "preference#matchExpressions", {}))
					selectors += make_set_expression(deep_get(selector, "preference#matchFields", {}))
					selectors += make_set_expression(deep_get(selector, "matchExpressions", {}))
					selectors += make_set_expression(deep_get(selector, "matchFields", {}))
					affinities.append((atype, f"{scheduling}{weight}", execution, selectors, topology))

	return affinities

def get_pod_tolerations(obj, **kwargs):
	tolerations = []

	for toleration in deep_get_with_fallback(obj, ["spec#tolerations", "scheduling#tolerations"], []):
		status_group = stgroup.OK

		effect = deep_get(toleration, "effect", "All")
		key = deep_get(toleration, "key", "All")
		operator = deep_get(toleration, "operator", "Equal")

		# According to spec only "Exists"
		# is valid in combination with "All"
		if key == "All" and operator != "Exists":
			status_group = stgroup.NOT_OK

		# Eviction timeout
		toleration_seconds = deep_get(toleration, "tolerationSeconds")
		if toleration_seconds is None:
			timeout = "Never"
		elif toleration_seconds <= 0:
			timeout = "Immediately"
		else:
			timeout = str(toleration_seconds)

		value = deep_get(toleration, "value", "")

		# According to spec only an empty value
		# is valid in combination with "Exists"
		if operator == "Exists" and value != "":
			status_group = stgroup.NOT_OK

		tolerations.append((key, operator, value, effect, timeout))

	return tolerations

def set_cluster_context(uip, **kwargs):
	global available_api_families

	name = deep_get(kwargs, "selected").name

	retval = kh.set_context(name = name)
	# If we actually changed context we need to force an API reload,
	# since we might have changed between different clusters (or switched
	# to a role that does not have access to a particular API)
	if retval == True:
		available_api_families = []

def get_security_context(obj, **kwargs):
	security_policies = []

	tmp = [
		("Run as User", deep_get_with_fallback(obj, ["spec#securityContext#runAsUser", "spec#template#spec#securityContext#runAsUser"])),
		("Run as non-Root", deep_get_with_fallback(obj, ["spec#securityContext#runAsNonRoot", "spec#template#spec#securityContext#runAsNonRoot"])),
		("Run as Group", deep_get_with_fallback(obj, ["spec#securityContext#runAsGroup", "spec#template#spec#securityContext#runAsGroup"])),
		("FS Group", deep_get_with_fallback(obj, ["spec#securityContext#fsGroup", "spec#template#spec#securityContext#fsGroup"])),
		("FS Group-change Policy", deep_get_with_fallback(obj, ["spec#securityContext#fsGroupChangePolicy", "spec#template#spec#securityContext#fsGroupChangePolicy"])),
		("Allow Privilege Escalation", deep_get_with_fallback(obj, ["spec#securityContext#allowPrivilegeEscalation", "spec#template#spec#securityContext#allowPrivilegeEscalation"])),
		("Capabilities",deep_get_with_fallback(obj, ["spec#securityContext#capabilities", "spec#template#spec#securityContext#capabilities"])),
		("Privileged", deep_get_with_fallback(obj, ["spec#securityContext#privileged", "spec#template#spec#securityContext#privileged"])),
		("Proc Mount", deep_get_with_fallback(obj, ["spec#securityContext#procMount", "spec#template#spec#securityContext#procMount"])),
		("Read-only Root Filesystem", deep_get_with_fallback(obj, ["spec#securityContext#readOnlyRootFilesystem", "spec#template#spec#securityContext#readOnlyRootFilesystem"])),
		("SELinux Options", deep_get_with_fallback(obj, ["spec#securityContext#seLinuxOptions", "spec#template#spec#securityContext#seLinuxOptions"])),
		("Seccomp Profile", deep_get_with_fallback(obj, ["spec#securityContext#seccompProfile", "spec#template#spec#securityContext#seccompProfile"])),
		("Windows Options", deep_get_with_fallback(obj, ["spec#securityContext#windowsOptions", "spec#template#spec#securityContext#windowsOptions"])),
	]

	for policy in tmp:
		if policy[1] is not None:
			security_policies.append((policy[0], str(policy[1])))

	return security_policies

def get_allowed_ips(obj, **kwargs):
	allowed_ips = []

	for addr in deep_get(obj, "spec#allowedIPs"):
		if "/" in addr:
			tmp = re.match(r"^(\d+\.\d+\.\d+\.\d+)\/(\d+)", addr)
			if tmp is None:
				raise Exception(f"Could not parse {addr} as an address/address mask")
			ip = tmp[1]
			mask = tmp[2]
			allowed_ips.append((widgetlineattrs.NORMAL, [(f"{ip}", ("windowwidget", "default")), ("/", ("windowwidget", "dim")), (f"{mask}", ("windowwidget", "default"))]))
		else:
			allowed_ips.append((widgetlineattrs.NORMAL, [(f"{addr}", ("windowwidget", "default"))]))

	return allowed_ips

def get_volume_properties(obj, **kwargs):
	volume_properties = []

	# First find out what kind of volume we're dealing with
	pv_type = get_pv_type(obj)
	if pv_type is None:
		return volume_properties

	properties = deep_get(known_pv_types, f"{pv_type}#properties", {})
	for volume_property in properties:
		default = deep_get(properties, f"{volume_property}#default", "")
		path = deep_get(properties, f"{volume_property}#path", "")
		value = deep_get(obj, f"spec#{pv_type}#{path}", default)
		if type(value) == list:
			value = ",".join(value)
		elif type(value) == dict:
			value = ",".join(f"{key}:{val}" for (key, val) in value.items())
		elif type(value) in [int, float, bool]:
			value = str(value)
		elif type(value) == str:
			value = value
		else:
			raise Exception(f"Unhandled type {type(value)} for {field}={value}")
		volume_properties.append((volume_property, value))

	return volume_properties

def get_endpoint_slices(obj, **kwargs):
	svcname = deep_get(obj, "metadata#name")
	svcnamespace = deep_get(obj, "metadata#namespace")
	# We need to find all Endpoint Slices in the same namespace as the service that have this service
	# as its controller
	vlist, status = kh.get_list_by_kind_namespace(("EndpointSlice", "discovery.k8s.io"), svcnamespace, label_selector = f"kubernetes.io/service-name={svcname}")
	tmp = []
	for item in vlist:
		epsnamespace = deep_get(item, "metadata#namespace")
		epsname = deep_get(item, "metadata#name")
		tmp.append((epsnamespace, epsname))
	return tmp

def get_key_value(obj, **kwargs):
	vlist = []
	if "path" in kwargs:
		path = deep_get(kwargs, "path", "")
		d = deep_get(obj, path, {})

		for _key in d:
			_value = d[_key]
			if type(_value) == list:
				value = ",".join(_value)
			elif type(_value) == dict:
				value = ",".join(f"{key}:{val}" for (key, val) in _value.items())
			elif type(_value) in [int, bool, float]:
				value = str(_value)
			elif type(_value) == str:
				value = _value
			else:
				raise Exception(f"Unhandled type {type(_value)} for {field}={value}")
			vlist.append((_key, _value))

	return vlist

def get_list_as_list(obj, **kwargs):
	vlist = []
	if "path" in kwargs:
		path = deep_get(kwargs, "path")
		_regex = deep_get(kwargs, "regex")
		items = deep_get(obj, path, [])
		for item in items:
			if _regex is not None:
				tmp = re.match(_regex, item)
				vlist.append(tmp.groups())
			else:
				vlist.append([item])
	elif "paths" in kwargs:
		# lists that run out of elements will return ""
		# strings will be treated as constants and thus returned for every row
		paths = deep_get(kwargs, "paths", [])
		maxlen = 0
		for column in paths:
			tmp = deep_get(obj, column)
			if type(tmp) == list:
				maxlen = max(len(tmp), maxlen)
		for i in range(0, maxlen):
			item = []
			for column in paths:
				tmp = deep_get(obj, column)
				if type(tmp) == str:
					item.append(tmp)
				elif type(tmp) == list:
					if len(tmp) > i:
						item.append(tmp[i])
					else:
						item.append(" ")
			vlist.append(item)

	return vlist

def get_list_fields(obj, **kwargs):
	vlist = []

	if "path" in kwargs and "fields" in kwargs:
		path = deep_get(kwargs, "path")
		fields = deep_get(kwargs, "fields", [])
		override_types = deep_get(kwargs, "override_types", [])
		for item in deep_get(obj, path, []):
			tmp = []
			for i in range(0, len(fields)):
				field = fields[i]
				_value = deep_get(item, field, "")
				if type(_value) == list or (i < len(fields) and i < len(override_types) and override_types[i] == "list"):
					value = ",".join(_value)
				elif type(_value) == dict or (i < len(fields) and i < len(override_types) and override_types[i] == "dict"):
					value = ",".join(f"{key}:{val}" for (key, val) in _value.items())
				elif type(_value) in [int, float, bool] or (i < len(fields) and i < len(override_types) and override_types[i] == "str"):
					value = str(_value)
				elif type(_value) == str:
					if i < len(fields) and i < len(override_types) and override_types[i] == "timestamp":
						if _value is None:
							value = "<unset>"
						else:
							timestamp = timestamp_to_datetime(_value)
							value = timestamp.astimezone().strftime("%Y-%m-%d %H:%M:%S")
					elif i < len(fields) and i < len(override_types) and override_types[i] == "age":
						if _value is None:
							value = "<unset>"
						else:
							timestamp = timestamp_to_datetime(_value)
							value = iktlib.seconds_to_age(get_since(timestamp))
					else:
						value = _value
				else:
					raise Exception(f"Unhandled type {type(_value)} for {field}={value}")
				tmp.append(value)
			vlist.append(tmp)
	return vlist

def get_strings_from_string(obj, **kwargs):
	vlist = []
	if "path" in kwargs:
		path = deep_get(kwargs, "path")
		tmp = deep_get(obj, path, [])
		if tmp is not None and len(tmp) > 0:
			for line in split_msg(tmp):
				vlist.append([line])
	return vlist

def get_package_version_list(obj, **kwargs):
	name_path = deep_get(kwargs, "name_path", "")
	hostname = deep_get(obj, name_path)
	hostname = deep_get(kwargs, "name", hostname)
	try:
		package_versions = get_package_versions(hostname)
	except:
		package_versions = None
	return package_versions

def get_image_list(obj, **kwargs):
	vlist = []
	path = deep_get(kwargs, "path", "")

	for image in deep_get(obj, path, []):
		name = ""
		for name in deep_get(image, "names", []):
			# This is the preferred name
			if "@sha256:" not in name:
				break

		if len(name) == 0:
			continue
		size = disksize_to_human(deep_get(image, "sizeBytes", 0))
		vlist.append([name, size])
	return natsorted(vlist)

def get_resources(obj, **kwargs):
	resources = []

	for limit in list(deep_get(obj, "spec#resources#limits", {})):
		if limit == "cpu":
			resources.append(("CPU", "Limit", deep_get(obj, "spec#resources#limits#cpu")))
		elif limit == "memory":
			resources.append(("CPU", "Limit", deep_get(obj, "spec#resources#limits#memory")))
		elif limit.startswith("hugepages-"):
			resources.append((f"H{limit[1:]}", "Limit", deep_get(obj, "spec#resources#limits#" + limit)))

	for request in list(deep_get(obj, "spec#resources#requests", {})):
		if request == "cpu":
			resources.append(("CPU", "Limit", deep_get(obj, "spec#resources#requests#cpu")))
		elif request == "memory":
			resources.append(("CPU", "Limit", deep_get(obj, "spec#resources#requests#memory")))
		elif request.startswith("hugepages-"):
			resources.append((f"H{request[1:]}", "Limit", deep_get(obj, "spec#resources#requests#" + request)))

	return resources

def get_containers(containers = [], container_statuses = []):
	container_dict = {}

	container_list = []

	for container in containers:
		container_name = deep_get(container, "name")
		container_image = deep_get(container, "image")
		image_version = kh.get_image_version(container_image)
		container_dict[container_name] = image_version

	for container in container_statuses:
		container_name = deep_get(container, "name")
		container_image = deep_get(container, "image")
		if container_dict[container_name] == "<undefined>":
			image_version = kh.get_image_version(container_image, "<undefined>")
			container_list.append((container_name, image_version))
		else:
			container_list.append((container_name, container_dict[container_name]))

	return container_list

def get_workload_labels(obj, **kwargs):
	return curses_helper.get_labels(deep_get(obj, "spec#workloadLabels"))

def get_pod_info_with_kind(**kwargs):
	deep_set(kwargs, "extra_vars#show_kind", "mixed")
	return get_pod_info(**kwargs)

# Returns True if the item should be skipped
def filter_list_entry(obj, caller_obj, filters = []):
	skip = False
	for f in filters:
		if deep_get(filters[f], "enabled", True) == False:
			continue

		# If len(allow) > 0, we only allow fields that match
		allow = deep_get(filters[f], "allow", [])
		# If len(block) > 0, we skip fields that match
		block = deep_get(filters[f], "block", [])
		if len(allow) > 0:
			# If all field + value pairs match we allow
			for rule in allow:
				key = deep_get(rule, "key", "")
				values = deep_get(rule, "values", [])
				if type(values) == dict:
					if deep_get(rule, "values#source", "object") == "caller":
						src = caller_obj
					else:
						src = obj
					values_path = deep_get(rule, "values#path", "")
					values = deep_get(src, values_path, [])
					if type(values) == str:
						values = [values]

				_listref = deep_get(rule, "list")
				if _listref is not None:
					_list = deep_get(obj, _listref, [])
					for _item in _list:
						if deep_get(_item, key, "").rstrip() in values:
							break
					else:
						skip = True
						break
				elif deep_get(obj, key, "").rstrip() not in values:
					skip = True
					break
		if len(block) > 0:
			# If all field + value pairs match we block
			for rule in block:
				key = deep_get(rule, "key", "")
				values = deep_get(rule, "values", [])
				if type(values) == dict:
					if deep_get(rule, "values#source", "object") == "caller":
						src = caller_obj
					else:
						src = obj
					values_path = deep_get(rule, "values#path", "")
					values = deep_get(src, values_path, [])
					if type(values) == str:
						values = [values]
				if deep_get(obj, key, "").rstrip() in values:
					skip = True
					break
		if skip == True:
			break
	return skip

def generic_listgetter(kind, namespace, **kwargs):
	label_selector = deep_get(kwargs, "label_selector", "")
	field_selector = deep_get(kwargs, "field_selector", "")
	filters = deep_get(kwargs, "filters", [])
	vlist, status = kh.get_list_by_kind_namespace(kind, namespace, label_selector = label_selector, field_selector = field_selector)
	if len(vlist) == 0 or status != 200 or len(filters) == 0:
		return vlist, status

	vlist2 = []

	for item in vlist:
		if filter_list_entry(item, deep_get(kwargs, "_obj", {}), filters) == True:
			continue
		vlist2.append(item)

	return vlist2, status

def listgetter_field(obj, **kwargs):
	path = deep_get(kwargs, "path")
	vlist = deep_get(obj, path)
	return vlist, 200

# Return all items of a dict as a list of dicts
# with the key and the value in the fields
# "key" and "value", respectively
def listgetter_dict_list(obj, **kwargs):
	path = deep_get(kwargs, "path")
	vlist = []
	for key, value in deep_get(obj, path, {}).items():
		vlist.append({"key": key, "value": value})
	return vlist, 200

# key_paths: the dict keys that should be turned into values
# key_name: name for the key that holds these values
# fields: paths the fields in the dict that should be added to the list
#
# Thus:
# "a": {
#     "b": {
#        "d": 1,
#        "e": 2
#     },
#     "c": {
#        "d": 2,
#        "e": 3,
#     },
# }
# key_paths = ["a#b", "a#c"]
# key_name = "foo"
# fields = [{"path": "a#b", "name": "bar"}, {"path": "a#c", "name": "baz"}]
# would generate the list
# [{"foo": "d", "bar": 1, "baz": 2}, {"foo": "e", "bar": 2, "baz": 3}]
def listgetter_join_dicts_to_list(obj, **kwargs):
	vlist = []
	key_paths = deep_get(kwargs, "key_paths", "")
	key_name = deep_get(kwargs, "key_name", "")
	fields = deep_get(kwargs, "fields", [])

	keys = set()

	for key_path in key_paths:
		for key in deep_get(obj, key_path, {}).keys():
			keys.add(key)

	for key in keys:
		d = {
			key_name: key
		}
		for field in fields:
			path = deep_get(field, "path", "")
			name = deep_get(field, "name")
			default = deep_get(field, "default")
			if name is None:
				continue
			value = deep_get(obj, f"{path}#{key}")
			d[name] = value
		if len(d) <= 1:
			continue
		vlist.append(d)

	return vlist, 200

def get_events_by_kind_name_namespace(kind, name, namespace):
	events = []
	vlist, status = kh.get_list_by_kind_namespace(("Event", "events.k8s.io"), "")
	for obj in vlist:
		__involved_kind = deep_get_with_fallback(obj, ["regarding#kind", "involvedObject#kind"])
		__involved_api_version = deep_get_with_fallback(obj, ["regarding#apiVersion", "involvedObject#apiVersion"])
		involved_kind = kh.kind_api_version_to_kind(__involved_kind, __involved_api_version)
		involved_name = deep_get_with_fallback(obj, ["regarding#name", "involvedObject#name"])
		ev_name = deep_get(obj, "metadata#name")
		ev_namespace = deep_get(obj, "metadata#namespace", "")
		last_seen = datetime_to_timestamp(__get_timestamp_with_fallback(obj, ["series#lastObservedTime", "deprecatedLastTimestamp", "lastTimestamp", "eventTime", "deprecatedFirstTimestamp", "firstTimestamp"]))
		status = deep_get(obj, "type", "")
		reason = deep_get(obj, "reason", "").replace("\\\"", "“").replace("\n", "\\n").rstrip()
		src_component = deep_get(obj, "reportingController", "")
		if len(src_component) == 0:
			src_component = deep_get_with_fallback(obj, ["deprecatedSource#component", "source#component"], "")
		src_host = deep_get(obj, "reportingInstance", "")
		if len(src_host) == 0:
			src_host = deep_get_with_fallback(obj, ["deprecatedSource#host", "source#host"], "")
		if len(src_component) == 0:
			source = src_host
		elif len(src_host) == 0:
			source = src_component
		else:
			source = f"{src_host}/{src_component}"
		first_seen = datetime_to_timestamp(__get_timestamp_with_fallback(obj, ["eventTime", "deprecatedFirstTimestamp", "firstTimestamp"]))

		count = deep_get_with_fallback(obj, ["series#count", "deprecatedCount", "count"], "")
		if count is None:
			count = ""
		else:
			count = str(count)
		message = deep_get(obj, "message", "").replace("\\\"", "“").replace("\n", "\\n").rstrip()
		if kind == involved_kind and name == involved_name and ev_namespace == namespace:
			event = (ev_namespace, ev_name, last_seen, status, reason, source, first_seen, count, message)
			events.append(event)
	return events

def get_pod_info(**kwargs):
	vlist = deep_get(kwargs, "_vlist")
	extra_vars = deep_get(kwargs, "extra_vars", {"show_kind": "", "show_evicted": True})
	filters = deep_get(kwargs, "filters", [])
	info = []

	if vlist == []:
		return []

	for obj in vlist:
		skip = False

		# Sadly field_labels don't support all fields we might want to filter on,
		# so we have to complicate things a bit
		if len(filters) > 0:
			for key, value in filters:
				ovalue = deep_get(obj, key, None)
				if ovalue is None or ovalue != value:
					skip = True
					break

		if skip == True:
			continue

		phase = deep_get(obj, "status#phase")
		reason = deep_get(obj, "status#reason", "").rstrip()

		if deep_get(extra_vars, "show_evicted", False) == False and phase == "Failed" and reason == "Evicted":
			continue

		namespace = deep_get(obj, "metadata#namespace")
		name = deep_get(obj, "metadata#name")
		ref = obj
		nodename = deep_get(obj, "spec#nodeName", "<none>")

		timestamp = timestamp_to_datetime(deep_get(obj, "metadata#creationTimestamp"))
		age = get_since(timestamp)

		owr = deep_get(obj, "metadata#ownerReferences", [])
		controller = get_controller_from_owner_references(owr)
		show_kind = deep_get(extra_vars, "show_kind", "").lower()
		controller = format_controller(controller, show_kind)

		pod_ip = deep_get(obj, "status#podIP", "<unset>")
		status, status_group = get_pod_status(obj)
		pod_restarts, restarted_at = get_pod_restarts_total(obj)
		if restarted_at == -1:
			last_restart = -1
		else:
			last_restart = get_since(restarted_at)
		tolerations = get_pod_tolerations(obj)
		containers = get_containers(deep_get(obj, "spec#initContainers", []), deep_get(obj, "status#initContainerStatuses", []))
		containers += get_containers(deep_get(obj, "spec#containers", []), deep_get(obj, "status#containerStatuses", []))

		info.append(PodInfo(namespace, name, ref, status, status_group, nodename, pod_ip, age, pod_restarts, last_restart, controller, tolerations, containers))

	return info

def generate_listheader(uip, headerpad, field_list, is_taggable = False):
	headerarray = []
	first = True

	tabstops = []

	tabstop = 0

	# Is the list taggable?
	if is_taggable:
		tabstops.append(tabstop)
		headerarray.append(("separators", "tag"))
		tabstop = themearray_len(headerarray)

	for field in field_list:
		generator = field_list[field].get("generator")
		if generator is None:
			continue

		tabstops.append(tabstop)

		theme = get_theme_ref()
		if uip.get_sortcolumn() == field:
			if uip.reversible == False:
				sort_direction_char = theme["boxdrawing"]["arrownone"]
			elif uip.sortorder_reverse:
				sort_direction_char = theme["boxdrawing"]["arrowup"]
			else:
				sort_direction_char = theme["boxdrawing"]["arrowdown"]
		else:
			sort_direction_char = theme["boxdrawing"]["arrownone"]

		# We always want this much padding between the headers,
		# except if this is the first header
		#
		# Note that we need to subtract the width of sort direction char
		# from the width of pad; this only works if len(pad) > 0
		if first == False:
			headerarray.append(("".ljust(themearray_len([("separators", "pad")]) - len(sort_direction_char)), ("types", "generic")))

		tabstop = themearray_len(headerarray)

		# This tells the length of the alignment of the header
		fieldlen = deep_get(field_list, f"{field}#fieldlen")
		header = deep_get(field_list, f"{field}#header")
		ralign = deep_get(field_list, f"{field}#ralign", False)

		# We cannot use ljust/rjust on the string,
		# because we want the string and arrow in different colours,
		# so just prepend/append whitespace instead
		if ralign == True:
			headerarray.append(("".ljust(fieldlen - len(header)), ("types", "generic")))
		headerarray.append((header, ("main", "listheader", uip.get_sortcolumn() == field)))
		headerarray.append((sort_direction_char, ("main", "listheader_arrows")))
		if ralign == False:
			headerarray.append(("".ljust(fieldlen - len(header)), ("types", "generic")))
		first = False

	# We've got to account for the last entry
	if len(field_list) > 0:
		tabstops.append(tabstop)

	# We've processed all fields, time to output the header
	uip.addthemearray(headerpad, headerarray, y = 0, x = 0)
	uip.tabstops = tabstops

def generate_item(uip, data, generator, fieldlen = 0, ralign = False, fpad = 0, is_selected = False):
	if generator is None:
		return None

	formatting = {
		"item_separator": field_list[field].get("item_separator", ("separators", "list")),
		"field_separators": field_list[field].get("field_separators", [("separators", "field")]),
		"field_colors": field_list[field].get("field_colors", [("types", "field")]),
		"ellipsise": field_list[field].get("ellipsise", -1),
		"ellipsis": field_list[field].get("ellipsis", ("separators", "ellipsis")),
		"field_prefixes": field_list[field].get("field_prefixes", None),
		"field_suffixes": field_list[field].get("field_suffixes", None),
		"mapping": field_list[field].get("mapping", {}),
	}

	return generator(data, field, fieldlen, fpad, ralign, is_selected, **formatting)

def generate_list(uip, listpad, data, field_list, ypos, is_selected, is_taggable = False, is_tagged = False):
	first = True

	i = 0

	for field in field_list:
		i += 1

		attribute = curses.A_NORMAL

		if is_taggable:
			tagprefixlen = themearray_len([("separators", "tag")])

			if is_tagged:
				tagprefix = [("separators", "tag")]
			else:
				tagprefix = [("".ljust(tagprefixlen), ("types", "generic"))]
		else:
			tagprefix = ""
			tagprefixlen = 0

		generator = field_list[field].get("generator")
		if generator is None:
			continue

		fieldlen = field_list[field]["fieldlen"]
		if i < len(field_list):
			fpad = themearray_len([("separators", "pad")])
		else:
			fpad = 0

		ralign = field_list[field].get("ralign", False)

		formatting = {
			"item_separator": field_list[field].get("item_separator", ("separators", "list")),
			"field_separators": field_list[field].get("field_separators", [("separators", "field")]),
			"field_colors": field_list[field].get("field_colors", [("types", "field")]),
			"ellipsise": field_list[field].get("ellipsise", -1),
			"ellipsis": field_list[field].get("ellipsis", ("separators", "ellipsis")),
			"field_prefixes": field_list[field].get("field_prefixes", None),
			"field_suffixes": field_list[field].get("field_suffixes", None),
			"mapping": field_list[field].get("mapping", {}),
		}

		tmp = generator(data, field, fieldlen, fpad, ralign, is_selected, **formatting)

		pos = field_list[field]["pos"]

		if first and is_taggable:
			uip.addthemearray(listpad, tagprefix, y = ypos, x = pos)
			first = False

		uip.addthemearray(listpad, tmp, y = ypos, x = pos + tagprefixlen)

builtin_fields = {
	"age": {
		"header": "Age:",
		"paths": [{
			"path": ["metadata#creationTimestamp"],
			"type": "timestamp",
			"default": -1,
		}],
		"formatter": "age",
		"align": "right",
	},
	"api_support": {
		"header": "API Support:",
		"datagetter": datagetter_api_support,
		"formatter": "list",
	},
	"name": {
		"header": "Name:",
		"path": "metadata#name",
		"type": "str",
	},
	"namespace": {
		"header": "Namespace:",
		"path": "metadata#namespace",
		"type": "str",
		"formatting": {
			"field_colors": [
				{
					"type": "namespace",
				},
			],
		},
	},
	"pod_status": {
		"header": "Status:",
		"datagetter": datagetter_pod_status,
		"generator": generator_status,
	},
}

field_templates = {
	"access_modes": {
		"header": "Access Modes:",
		"path": "spec#accessModes",
		"datagetter": datagetter_access_modes,
		"generator": generator_list,
	},
	"action": {
		"header": "Action:",
	},
	"addresses": {
		# [address, ...]
		"header": "Addresses:",
		"generator": generator_list,
	},
	"age": {
		"header": "Age:",
		"path": "metadata#creationTimestamp",
		"datagetter": datagetter_age,
		"generator": generator_age,
		"ralign": True,
	},
	"alertrecord": {
		"header": "Alert/Record:",
	},
	"allocatable_count": {
		"header": "Allocatable (Count):",
		"generator": generator_numerical,
		"ralign": True,
	},
	"available_replicas": {
		"header": "Available:",
		"path": "status#availableReplicas",
		"type": "int",
		"generator": generator_numerical,
		"ralign": True,
	},
	"available_replicas_ds": {
		"header": "Available:",
		"path": "status#numberAvailable",
		"type": "int",
		"generator": generator_numerical,
		"ralign": True,
	},
	"backends": {
		# [(service_name, service_port), ...]
		"header": "Backends:",
		"generator": generator_list,
		"field_separators": [("separators", "port")],
	},
	"completions": {
		"header": "Completions:",
		"path": [("status#succeeded", 0), "spec#completions"],
		"datagetter": datagetter_pathlist_to_tuple,
		"generator": generator_list,
		"field_separators": [("separators", "fraction")],
		"ralign": True,
	},
	"configmap": {
		"header": "Data:",
	},
	"container_count": {
		"header": "# of Containers:",
		"path": "containers",
		"datagetter": datagetter_count,
		"generator": generator_numerical,
		"ralign": True,
	},
	"containers": {
		# [(name, version), ...]
		"header": "Containers:",
		"path": [("spec#initContainers", "status#initContainerStatuses"), ("spec#containers", "status#containerStatuses")],
		"datagetter": datagetter_containers,
		"generator": generator_list,
		"field_colors": [("types", "generic"), ("types", "version")],
		"field_separators": [("separators", "version")],
	},
	"controller": {
		# (kind, name)
		"header": "Controller:",
		"path": ("metadata#ownerReferences", "mixed"),
		"datagetter": datagetter_controller,
		"generator": generator_list,
		"field_colors": [("types", "kind"), ("types", "generic")],
	},
	"controller_conditions": {
		"header": "Status:",
		"path": "controllerConditions",
		"datagetter": datagetter_status_latest_condition,
		"generator": generator_status,
	},
	"created_at": {
		"header": "Created At:",
		"path": "metadata#creationTimestamp",
		"datagetter": datagetter_timestamp,
		"generator": generator_timestamp,
	},
	"current_replicas": {
		"header": "Current:",
		"path": "status#replicas",
		"type": "int",
		"generator": generator_numerical,
		"ralign": True,
	},
	"current_replicas_ds": {
		"header": "Current:",
		"path": "status#currentNumberScheduled",
		"type": "int",
		"generator": generator_numerical,
		"ralign": True,
	},
	"current_replicas_tuple": {
		# (current, desired)
		"header": "Replicas:",
		"path": ["status#currentReplicas", "status#desiredReplicas"],
		"datagetter": datagetter_pathlist_to_tuple,
		"generator": generator_total,
		"ralign": True,
	},
	"danger_count": {
		"header": "Danger #:",
		"generator": generator_numerical_range,
		"ranges": [(0, 1, ("types", "watermark_low")), (1, sys.maxsize, ("types", "watermark_high"))],
		"path": "report#summary#dangerCount",
		"ralign": True,
	},
	"desired_replicas": {
		"header": "Desired:",
		"path": "spec#replicas",
		"type": "int",
		"generator": generator_numerical,
		"ralign": True,
	},
	"desired_replicas_ds": {
		"header": "Desired:",
		"path": "status#desiredNumberScheduled",
		"type": "int",
		"generator": generator_numerical,
		"ralign": True,
	},
	"docker_reference": {
		"header": "Docker Reference:",
		"path": "dockerImageReference",
	},
	"docker_reference_image": {
		"header": "Docker Reference:",
		"path": "image#dockerImageReference",
	},
	"docker_repo": {
		"header": "Docker Repo:",
		"path": "status#dockerImageRepository",
	},
	"drivers": {
		"header": "Drivers:",
		"path": "spec#drivers",
		"datagetter": datagetter_count,
		"generator": generator_numerical,
		"ralign": True,
	},
	"error": {
		"header": "Error:",
	},
	"event_status": {
		"header": "Status:",
		"path": "type",
		"datagetter": datagetter_event_status,
		"generator": generator_status,
	},
	"ftype": {
		"header": "Type:",
	},
	"group": {
		"header": "Group:",
	},
	"groups": {
		# [group, ...]
		"header": "Groups:",
		"path": "groups",
		"generator": generator_list,
	},
	"healthy_antrea": {
		"header": "Healthy:",
		"datagetter": datagetter_condition_field,
		"generator": generator_status,
		"path": [("agentConditions", "AgentHealthy", "status"), ("controllerConditions", "ControllerHealthy", "status")],
	},
	"host": {
		"header": "Host:",
		"path": "spec#host",
	},
	"identity": {
		"header": "Identity:",
		"path": "identity#name",
	},
	"identity_id": {
		"header": "Identity ID:",
	},
	"image_reference": {
		"header": "Image ID:",
	},
	"index": {
		"header": "Index:",
		"ralign": True,
	},
	"ingress_address": {
		# (hostname, ip) (xor)
		"header": "Address:",
		"datagetter": datagetter_ingress_address,
		"generator": generator_list,
	},
	"ingress_hosts": {
		"header": "Hosts:",
		# Note: Artificial path
		"path": "hosts",
		"datagetter": datagetter_ingress_hosts,
		"generator": generator_list,
	},
	"ingress_ports": {
		"header": "Ports:",
		# Note: Artificial path
		"path": "ports",
		"datagetter": datagetter_ingress_hosts,
		"generator": generator_list,
		"field_colors": [("types", "service"), ("types", "port"), ("types", "protocol")],
		"field_separators": [("separators", "port"), ("separators", "service")],
	},
	"kind": {
		# (kind, api_group)
		"header": "Kind:",
		"path": "kind",
		"generator": generator_list,
		"field_colors": [("types", "kind"), ("types", "api_group")],
		"field_separators": [("separators", "kind_api_group")],
	},
	"last_heartbeat_antrea": {
		"header": "Last Heartbeat:",
		"datagetter": datagetter_condition_field,
		"generator": generator_str_timestamp,
		"path": [("agentConditions", "AgentHealthy", "lastHeartbeatTime"), ("controllerConditions", "ControllerHealthy", "lastHeartbeatTime")],
	},
	"limit": {
		"header": "Limit:",
		# FIXME datagetter
	},
	"link": {
		"header": "Link:",
	},
	"log_type": {
		"header": "Log Type:",
	},
	"match": {
		"header": "Match:",
		"generator": generator_list,
		"field_colors": [("types", "key"), ("types", "value")],
		"field_separators": [("separators", "keyvalue")],
	},
	"max_replicas": {
		"header": "Max:",
		"generator": generator_numerical,
		"ralign": True,
	},
	"mem": {
		"header": "Mem% / Total:",
		"path": (r"^(\d+).*", ["status#allocatable#memory", "status#capacity#memory"]),
		"datagetter": datagetter_regex_split_to_tuples,
		"generator": generator_mem,
		"ralign": True,
	},
	"mem_bytes": {
		"header": "Memory:",
		"path": "mem_bytes",
		"generator": generator_mem_single,
		"ralign": True,
	},
	"message": {
		"header": "Message:",
		"path": "message",
		"datagetter": datagetter_substitute_quotationmarks,
	},
	"methods": {
		"header": "Methods:",
		"generator": generator_list,
	},
	"misscheduled_replicas": {
		"header": "Misscheduled:",
		"path": "status#numberMisscheduled",
		"type": "raw",
		"generator": generator_numerical_range,
		"ranges": [(0, 1, ("types", "generic")), (1, sys.maxsize, ("types", "watermark_high"))],
		"ralign": True,
	},
	"name": {
		"header": "Name:",
		"path": "metadata#name",
	},
	"name_version": {
		"header": "Name:",
		"path": (r"^(.*):(.*)", ["metadata#name"]),
		"datagetter": datagetter_regex_split_to_tuples,
		"generator": generator_list,
		"field_colors": [("types", "generic"), ("types", "version")],
		"field_separators": [("separators", "version")],
	},
	"namespace": {
		"header": "Namespace:",
		"path": "metadata#namespace",
	},
	"namespace_selector": {
		# [(key, value), ...]
		"header": "Pod Selector:",
		"generator": generator_list,
		"field_colors": [("types", "generic"), ("types", "generic")],
		"field_separators": [("separators", "selector")],
	},
	"node": {
		"header": "Node:",
	},
	"node_id": {
		"header": "Node ID:",
	},
	"operator": {
		"header": "Operator:",
	},
	"overhead": {
		"header": "Overhead:",
	},
	"path": {
		"header": "Path:",
	},
	"paths": {
		"header": "Paths:",
		"generator": generator_list,
	},
	"phase": {
		"header": "Phase:",
		"path": "status#phase",
		"datagetter": datagetter_phase,
		"generator": generator_status,
	},
	"pod_ip": {
		"header": "Pod IP:",
		"path": "status#podIP",
		"default": "<unset>",
	},
	"pod_selector": {
		# [(key, value), ...]
		"header": "Pod Selector:",
		"datagetter": datagetter_pod_selector,
		"generator": generator_list,
		"field_colors": [("types", "generic"), ("types", "generic")],
		"field_separators": [("separators", "selector")],
	},
	"port": {
		# (name, port, protocol)
		"header": "Port:",
		"generator": generator_list,
		"field_colors": [("types", "service"), ("types", "port"), ("types", "protocol")],
		"field_separators": [("separators", "port"), ("separators", "service")],
	},
	"port_linkerd": {
		"header": "Port:",
		"path": "spec#port",
	},
	"ports_ep": {
		# (name, port, protocol)
		"header": "Ports:",
		"path": "subsets",
		"datagetter": datagetter_ep_ports,
		"formatter": "list",
		"formatting": {
			"field_colors": [
				{
					"type": "service",
				},
				{
					"type": "port",
				},
				{
					"type": "protocol",
				},
			],
			"field_separators": [
				{
					"type": "port",
				},
				{
					"type": "service",
				},
			],
		},
	},
	"priority_level": {
		"header": "Priority Level:",
		"path": "spec#priorityLevelConfiguration#name",
		"generator": generator_priority_level,
		"type": "str",
	},
	"pod_status": {
		"header": "Status:",
		"datagetter": datagetter_pod_status,
		"generator": generator_status,
	},
	"repository": {
		"header": "Repository:",
		"path": "report#artifact#repository",
	},
	"ready": {
		"header": "Ready:",
		"generator": generator_status,
		"sortkey1": "status_group",
	},
	"ready_scheduled_plugins": {
		"header": "Ready:",
		"path": [("status#numberReady", 0), ("status#desiredNumberScheduled", 0)],
		"datagetter": datagetter_pathlist_to_tuple,
		"generator": generator_total,
		"ranges": [(-1, -1, ("types", "numerical")), (0, 1, ("types", "watermark_high")), (1, -1, ("types", "watermark_medium"))],
		"ralign": True,
	},
	"ready_replicas": {
		"header": "Ready:",
		"path": [("status#readyReplicas", 0), ("status#replicas", 0)],
		"datagetter": datagetter_pathlist_to_tuple,
		"generator": generator_numerical_range,
		"ranges": [(0, "1", ("types", "watermark_high")), ("1", sys.maxsize, ("types", "generic"))],
		"ralign": True,
	},
	"ready_replicas_ds": {
		"header": "Ready:",
		"path": ["status#numberReady", "status#currentNumberScheduled"],
		"datagetter": datagetter_pathlist_to_tuple,
		"generator": generator_numerical_range,
		"ranges": [(0, "1", ("types", "watermark_high")), ("1", sys.maxsize, ("types", "generic"))],
		"ralign": True,
	},
	"ready_replicas_tuple": {
		# (ready, total)
		"header": "Ready:",
		"path": [("status#readyReplicas", 0), ("status#replicas", 0)],
		"datagetter": datagetter_pathlist_to_tuple,
		"generator": generator_total,
		"ranges": [(-1, -1, ("types", "numerical")), (0, 1, ("types", "watermark_high")), (1, -1, ("types", "watermark_medium"))],
		"ralign": True,
	},
	"request": {
		# [(resource, used, hard), ...]
		"header": "Request:",
		"datagetter": datagetter_request,
		"generator": generator_list,
		"field_colors": [("types", "resource"), ("types", "numerical"), ("types", "numerical")],
		"field_separators": [("separators", "resource"), ("separators", "fraction")],
	},
	"role": {
		"header": "Role:",
		"path": "roleRef#name",
	},
	"service": {
		# (namespace, name, port)
		"header": "Service:",
		"generator": generator_list,
		"field_colors": [("types", "namespace"), ("types", "generic"), ("types", "port")],
		"field_separators": [("separators", "namespace"), ("separators", "port")],
	},
	"serviceaccounts": {
		"header": "Service Accounts:",
		"generator": generator_list,
	},
	"services": {
		"header": "Services:",
		"generator": generator_list,
	},
	"source": {
		# (component, host)
		"header": "Source:",
		"path": ["source#component", "source#host"],
		"datagetter": datagetter_pathlist_to_tuple,
		"generator": generator_list,
	},
	"source_port": {
		"header": "Source Port:",
	},
	"start_time": {
		"header": "Start Time:",
		"generator": generator_timestamp,
	},
	"state": {
		"header": "State:",
		"generator": generator_status,
	},
	"status": {
		"header": "Status:",
		"generator": generator_status,
	},
	"status_deployment": {
		"header": "Status:",
		"path": "status#conditions",
		"datagetter": datagetter_status_deployment,
		"generator": generator_status,
	},
	"status_latest_condition": {
		"header": "Status:",
		"path": "status#conditions",
		"datagetter": datagetter_status_latest_condition,
		"generator": generator_status,
	},
	"status_message_deployment": {
		"header": "Message:",
		"path": "status#conditions",
		"datagetter": datagetter_status_message_deployment,
	},
	"status_message_mpi_jobs": {
		"header": "Message:",
		"datagetter": datagetter_condition_ready,
	},
	"strategy": {
		"header": "Strategy:",
	},
	"stype": {
		"header": "Type:",
	},
	"subject_count": {
		"header": "# of Subjects:",
		"path": "subjects",
		"datagetter": datagetter_count,
		"generator": generator_numerical,
		"ralign": True,
	},
	"tag": {
		"header": "Tag:",
		"path": "report#artifact#tag",
	},
	"tags": {
		"header": "Tags:",
		"path": ("status#tags", ["tag"]),
		"datagetter": datagetter_list_fields,
		"generator": generator_list,
	},
	"target": {
		"header": "Target:",
		"generator": generator_numerical,
		"ralign": True,
	},
	"topology_keys": {
		"header": "Topology Keys:",
		"generator": generator_list,
	},
	"uptodate_replicas": {
		"header": "Up to Date:",
		"path": "status#updatedReplicas",
		"type": "int",
		"generator": generator_numerical,
		"ralign": True,
	},
	"uptodate_replicas_ds": {
		"header": "Up to Date:",
		"path": "status#updatedNumberScheduled",
		"type": "int",
		"generator": generator_numerical,
		"ralign": True,
	},
	"version": {
		"header": "Version:",
		"path": "spec#version",
		"type": "str",
	},
}

# The return type of the formatting will be the same
# as the type of the default, so default == None is a programming error
def get_formatting(field, formatting, default):
	result = []
	items = deep_get(field, f"formatting#{formatting}")
	if items is None:
		return default

	if default is None:
		raise Exception(f"default cannot be None for field {field}, formatting {formatting}; this is a programming error")

	if type(default) == tuple:
		items = [items]

	if len(items) < 1:
		raise Exception(f"field {field}, formatting {formatting}: format list item is empty; this is likely an error in the view file")

	for item in items:
		context = None
		if formatting in ["item_separator", "field_separators", "ellipsis", "field_prefixes", "field_suffixes"]:
			context = "separators"
		elif formatting == "field_colors":
			context = "types"
		# field_prefixes/suffixes can be either a list of a list of lists
		if type(item) == tuple or formatting not in ["field_prefixes", "field_suffixes"]:
			context = deep_get(item, "context", context)
			ftype = deep_get(item, "type")
			if ftype is None or context is None:
				raise Exception(f"field {field}, formatting {formatting}: context={context} type={ftype}; list type or context missing/formatting has no implicit context; this is likely an error in the view file")
			result.append((context, ftype))
		else:
			_result = []
			for _item in item:
				_context = deep_get(_item, "context", context)
				ftype = deep_get(_item, "type")
				if ftype is None or context is None:
					raise Exception(f"field {field}, formatting {formatting}: context={context} type={ftype}; list type or context missing/formatting has no implicit context; this is likely an error in the view file")
				_result.append((_context, ftype))
			result.append(_result)

	if type(default) == tuple:
		if len(result) > 1:
			raise Exception(f"field {field}, formatting {formatting}: default is of type {type(default)}, but formatting is a list with length {len(result)} that cannot be represented as a tuple; this is likely an error in the view file")
		result = result[0]

	return result

# This generates old-style fields from new-style fields
def get_formatter(field):
	tmp_field = {}

	formatter = deep_get(field, "formatter")
	generator = deep_get(field, "generator", generator_basic)
	processor = deep_get(field, "processor")

	field_separators_default = [("separators", "field")]

	if formatter is None:
		pass
	elif formatter == "mem":
		generator = generator_mem_single
		processor = None
	elif formatter == "float":
		# The generator is the same, but the name is unfortunate
		generator = generator_mem_single
		processor = None
	elif formatter == "list":
		generator = generator_list
		processor = processor_list
	elif formatter == "list_with_status":
		generator = generator_list_with_status
		processor = processor_list_with_status
	elif formatter == "hex":
		generator = generator_hex
		processor = None
	elif formatter == "numerical":
		generator = generator_numerical
		processor = None
	elif formatter == "numerical_with_units":
		generator = generator_numerical_with_units
		processor = None
	elif formatter == "address":
		generator = generator_address
		processor = None
		field_separators_default = []
	elif formatter == "timestamp":
		generator = generator_timestamp
		processor = processor_timestamp
	elif formatter == "timestamp_with_age":
		generator = generator_timestamp_with_age
		processor = processor_timestamp_with_age
	elif formatter == "age":
		generator = generator_age
		processor = processor_age
	elif formatter == "value_mapper":
		generator = generator_value_mapper
		processor = None
	else:
		raise Exception(f"Unknown formatter {formatter}")

	theme = get_theme_ref()
	if deep_get(field, "formatting#field_colors") is None:
		if "type" in field and field["type"] in theme["types"]:
			field_colors = [("types", deep_get(field, "type"))]
		else:
			field_colors = get_formatting(field, "field_colors", [("types", "field")])
	else:
		field_colors = get_formatting(field, "field_colors", [("types", "field")])

	field_prefixes = get_formatting(field, "field_prefixes", [])
	field_suffixes = get_formatting(field, "field_suffixes", [])
	field_separators = get_formatting(field, "field_separators", field_separators_default)
	ellipsise = deep_get(field, "formatting#ellipsise", -1)
	ellipsis = get_formatting(field, "ellipsis", ("separators", "ellipsis"))
	item_separator = get_formatting(field, "item_separator", ("separators", "list"))
	mapping = deep_get(field, "formatting#mapping", {})

	tmp_field["generator"] = generator
	tmp_field["processor"] = processor
	# Fix all of these to use the new format
	tmp_field["field_colors"] = field_colors
	tmp_field["field_prefixes"] = field_prefixes
	tmp_field["field_suffixes"] = field_suffixes
	tmp_field["field_separators"] = field_separators
	tmp_field["ellipsise"] = ellipsise
	tmp_field["ellipsis"] = ellipsis
	tmp_field["item_separator"] = item_separator
	tmp_field["mapping"] = mapping
	if "align" in field:
		align = deep_get(field, "align", "left")
		tmp_field["ralign"] = align == "right"

	formatting = {
		"item_separator": item_separator,
		"field_separators": field_separators,
		"field_colors": field_colors,
		"ellipsise": ellipsise,
		"ellipsis": ellipsis,
		"field_prefixes": field_prefixes,
		"field_suffixes": field_suffixes,
		"mapping": mapping,
	}

	tmp_field["formatting"] = formatting

	return tmp_field

def fieldgenerator(view, field_index, field_indexes, fields = {}, sortcolumn = None, denylist = []):
	global namespace

	if field_indexes is None or len(field_indexes) == 0:
		return None, None, None

	if namespace != "" and "namespace" not in denylist:
		denylist.append("namespace")

	field_names = field_indexes[field_index]

	# delete all denylisted fields
	for field in denylist:
		try:
			field_names.remove(field)
		except ValueError:
			pass

	# OK, we've pruned the denylisted fields; now we need to check
	# whether the sort column still applies, and if not try to pick
	# another sortcolumn
	if sortcolumn is None or sortcolumn not in field_names:
		if "name" in field_names:
			sortcolumn = "name"
		elif "namespace" in field_names:
			sortcolumn = "namespace"
		else:
			sortcolumn = field_names[0]

	# XXX: Remove compat when fully converted
	field_dict = {}
	for field in field_names:
		if type(fields) == dict and field in fields and type(deep_get(fields, f"{field}")) == dict:
			field_dict[field] = deep_get(fields, field, {})
		elif field in builtin_fields:
			field_dict[field] = deep_get(builtin_fields, field, {})
		elif field in field_templates:
			field_dict[field] = deep_get(field_templates, field, {})
		else:
			sys.exit(f"View {view}: field \"{field}\" cannot be found in view, builtin_fields, or field_templates\nView fields: {fields}\nfield_names: {field_names}")

	tmp_fields = OrderedDict()

	for field_name in field_dict:
		field = deep_get(field_dict, field_name)

		# This is a custom field, so we need to construct one that's usable here
		tmp_fields[field_name] = copy.deepcopy(field_dict[field_name])

		tmp_field = get_formatter(field)
		if tmp_field is None:
			continue

		for key, value in tmp_field.items():
			tmp_fields[field_name][key] = value
		tmp_fields[field_name]["sortkey1"] = field_name
		# If sortkey1 == sortcolumn this "fails", but it's good enough
		tmp_fields[field_name]["sortkey2"] = sortcolumn


	return tmp_fields, field_names, sortcolumn

def genericlistloop(stdscr, view):
	global namespace
	global initial_name
	global initial_namespace
	global latest_info
	denylist = deep_get(views, f"{view}#field_denylist", [])
	field_indexes = deep_get(views, f"{view}#field_indexes", {})

	if len(field_indexes) == 0:
		sys.exit(f"FIXME: field_indexes for view {view} is empty")

	if "Custom" in field_indexes:
		field_index = "Custom"
	elif "Wide" in field_indexes:
		field_index = "Wide"
	else:
		field_index = list(field_indexes.keys())[0]

	field_dict, field_names, sortcolumn = fieldgenerator(view, field_index = field_index, field_indexes = field_indexes, fields = deep_get(views, f"{view}#fields"), sortcolumn = deep_get(views, f"{view}#sortcolumn"), denylist = denylist)
	uip = UIProps(stdscr)

	windowheader = view
	viewref = views[view]

	kind = viewref["kind"]
	if kind is None or kind[0].startswith("__"):
		is_namespaced = False
	else:
		is_namespaced = kh.is_kind_namespaced(kind)

	if "helptext" in views[view]:
		helptext = viewref["helptext"]
	else:
		helptext = generate_helptext(view, "listview", [])
	if "activatedfun" in viewref:
		activatedfun = viewref["activatedfun"]
	else:
		activatedfun = genericinfoloop
	on_activation = deep_get(viewref, "on_activation", {})
	update_delay = deep_get(viewref, "update_delay", -1)

	sortorder_reverse = deep_get(viewref, "sortorder_reverse", False)
	is_taggable = deep_get(viewref, "is_taggable", True) and "actions" in viewref
	extra_vars = deep_get(viewref, "extra_vars", {})

	uip.init_window(field_dict, view = kind, windowheader = windowheader, update_delay = update_delay, sortcolumn = sortcolumn, sortorder_reverse = sortorder_reverse, helptext = helptext, activatedfun = activatedfun, on_activation = on_activation)

	# For the status bar; position is always at the bottom of the screen and the entire width of the screen
	statusbar = uip.init_statusbar()

	# For the list
	headerpad, listpad = uip.init_listpad(listheight = 1, width = -1, ypos = 1, xpos = 1)

	label_selector = ""

	# These values can be toggled, so we need to read them first
	listview_args = copy.deepcopy(viewref.get("listview_args", {}))

	vlist = None

	while True:
		uip.countdown_to_update()

		if uip.is_update_triggered():
			uip.update_window()

			if "listgetter" in viewref:
				listgetter = deep_get(viewref, "listgetter")
			else:
				listgetter = "kh.get_list_by_kind_namespace"

			infogetter = deep_get(viewref, "infogetter", generic_infogetter)
			infogetter_extra_vars = deep_get(viewref, "extra_vars#infogetter", { "_view": view.strip("*") })
			infogetter_extra_vars["_field_index"] = field_index.lower()
			infogetter_extra_vars["_field_names"] = field_names
			infogetter_extra_vars["_field_dict"] = field_dict
			if "filters" in listview_args:
				infogetter_extra_vars["_filters"] = deep_get(listview_args, "filters")

			if listgetter is not None:
				if listgetter == generic_listgetter:
					listgetter_args = deep_get(viewref, "listgetter_args", {})
					listgetter_args["label_selector"] = label_selector
					vlist, status = listgetter(deep_get(viewref, "kind"), namespace, **listgetter_args)
				else:
					if type(listgetter) == str:
						listgetter = eval(listgetter)
					listgetter_args = deep_get(viewref, "listgetter_args", {})
					if kind[0].startswith("__"):
						vlist, status = listgetter(**listgetter_args)
					else:
						vlist, status = listgetter(deep_get(viewref, "kind"), namespace, label_selector = label_selector)
				infogetter_extra_vars["_vlist"] = vlist
			else:
				status = "OK"
			info = infogetter(**infogetter_extra_vars)

			if status == 42503:
				serverstatus = "Server Unavailable"
			else:
				serverstatus = str(status)

			latest_info = view
			listlen = uip.update_info(info)
			linelen = update_field_widths(field_dict, field_names, uip.info)
			if is_taggable == True:
				linelen += len("✓ ")
			uip.resize_listpad(listlen, linelen)

			tagged_items = set()

		if uip.refresh == True:
			# The data in some fields might become shorter, so we need to trigger a clear
			uip.statusbar.erase()

			if uip.continuous_log == True:
				interval = "Continuous"
			else:
				interval = "Manual"

			statusarray1 = [
				("Fields: ", ("statusbar", "infoheader")), (field_index, ("statusbar", "highlight"))
			]
			if len(label_selector) > 0:
				if len(statusarray1) > 0:
					statusarray1 += [("separators", "statusbar")]
				statusarray1 += [
					("Label selector: ", ("statusbar", "infoheader")), (f"{label_selector}", ("statusbar", "highlight"))
				]
			statusarray2 = [
			]
			if view != "Contexts" and ("namespace" in denylist or "namespace" in field_names):
				statusarray2 += [("Namespace: ", ("statusbar", "infoheader")), (f"{namespace if len(namespace) > 0 else '<All>'}", ("statusbar", "highlight"))]

			if len(statusarray2) > 0:
				statusarray2 += [("separators", "statusbar")]
			statusarray2 += [
				("API Status: ", ("statusbar", "infoheader")),
				(f"{serverstatus}", ("statusbar", "default")),
			]

			for key, path in deep_get(viewref, "statusmsg", []):
				value = str(deep_get(listview_args, path, "<unset>"))
				if len(statusarray2) > 0:
					statusarray2 += [("separators", "statusbar")]
				statusarray2 += [
					(key, ("statusbar", "infoheader")),
					(value, ("statusbar", "default")),
				]

			uip.addthemearray(statusbar, statusarray1, y = 0, x = 0)
			uip.addthemearray(statusbar, statusarray2, y = 1, x = 0)

		# Output list
		y = 0

		uip.update_sorted_list()
		generate_listheader(uip, headerpad, field_dict, is_taggable = is_taggable)
		for item in uip.sorted_list:
			uip.select_if_y(y, item)
			is_tagged = item in tagged_items
			generate_list(uip, listpad, item, field_dict, y, uip.is_selected(item), is_taggable = is_taggable, is_tagged = is_tagged)
			y += 1

		uip.refresh_window()
		uip.refresh_listpad()
		uip.refresh_statusbar()
		curses.doupdate()

		unique_match = uip.goto_first_match_by_name_namespace(initial_name, initial_namespace)
		initial_name = None
		initial_namespace = None
		if unique_match is not None:
			selected = uip.get_selected()
			retval = uip.activatedfun(uip.stdscr, unique_match, kind)
			if retval == curses_helper.retval.RETURNFULL:
				return retval
			uip.force_update()
			uip.refresh_all()
			continue

		uip.stdscr.timeout(100)
		c = uip.stdscr.getch()
		retval = uip.generic_keycheck(c)

		if retval == curses_helper.retval.MATCH:
			continue
		elif retval == curses_helper.retval.RETURNONE:
			return curses_helper.retval.RETURNDONE
		elif retval == curses_helper.retval.RETURNFULL:
			return retval

		if c == curses.KEY_F2:
			retval = selectwindow(stdscr, uip)
			if retval == curses_helper.retval.RETURNFULL:
				return retval
			uip.refresh_all()
		elif c == curses.KEY_F3:
			retval = selectwindow(stdscr, uip, refresh_apis = True)
			if retval == curses_helper.retval.RETURNFULL:
				return retval
			uip.refresh_all()
		elif c == ord("B"):
			uip.toggle_borders()
			uip.refresh_all()
			uip.force_update()
		elif c == ord("W"):
			if len(field_indexes) == 0:
				continue

			_list = list(field_indexes.keys())
			_index = _list.index(field_index)
			field_index = _list[(_index + 1) % len(field_indexes)]

			# Toggle field width
			field_dict, field_names, sortcolumn = fieldgenerator(view, field_index = field_index, field_indexes = field_indexes, fields = deep_get(views, f"{view}#fields"), sortcolumn = deep_get(views, f"{view}#sortcolumn"), denylist = denylist)
			uip.reinit_window(field_dict, sortcolumn = sortcolumn)
			uip.resize_listpad(height = -1, width = -1)
			uip.refresh_all()
			uip.force_update()
		elif c == curses.KEY_F7:
			action_title = "Perform cluster-wide actions"
			action_src_list = listviewactions

			# Populate the list of actions
			actions, actionlist = populate_actionlist(action_list = action_src_list)

			if len(actions) == 0:
				continue

			tmpselection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, actions, title = action_title)
			selection = None
			if tmpselection is not None and type(tmpselection[0]) == int:
				selection = ""
				for i in range(1, len(tmpselection)):
					if len(tmpselection[i]) > 0:
						selection += tmpselection[i][0][0]
			uip.refresh_all()
			curses.doupdate()

			if selection is not None and selection != "":
				actionfunc = None

				# Map the description back to key
				for action in actionlist:
					description = deep_get(actionlist, f"{action}#description")
					tmpdescription = ""
					if type(description) == str:
						tmpdescription = description
					else:
						for i in range(0, len(description)):
							tmpdescription += description[i][0]
					tmpmetadata = deep_get(actionlist, f"{action}#metadata", [])
					for metadata in tmpmetadata:
						tmpdescription += metadata[0]
					if tmpdescription == selection:
						actionfunc = deep_get(actionlist, f"{action}#actionfunc", command_hosts)
						if type(actionfunc) == str:
							actionfunc = eval(actionfunc)
						# These are only relevant for node and inventory view
						allowoncontrolplane = deep_get(actionlist, f"{action}#allow_on_control_plane", True)
						singleoncontrolplane = deep_get(actionlist, f"{action}#single_on_control_plane", False)
						confirm = deep_get(actionlist, f"{action}#confirm", False)
						query = deep_get(actionlist, f"{action}#query")
						queryval = deep_get(actionlist, f"{action}#queryval")
						queryfunc = deep_get(actionlist, f"{action}#queryfunc")
						extravars = deep_get(actionlist, f"{action}#extravars", {})
						break

				if actionfunc is None:
					continue

				selection_vars = extravars

				# This should be modified; we might want to ask multiple queries.
				# At the very least asking for one input plus confirmation.
				# A multi input box might be useful too.
				if queryfunc is not None and queryval is not None and query is not None:
					if queryfunc == "string":
						# Not supported by inputbox widget
						# querydefault = ""
						string = curses_helper.inputbox(uip.stdscr, uip.maxy // 2, 1, uip.maxy - 1, uip.maxx - 1, f"{query}: ")
						if string is None or string == "":
							continue
						else:
							selection_vars[queryval] = string
					elif queryfunc == "confirm":
						querydefault = False
						if curses_helper.confirmationbox(uip.stdscr, uip.maxy // 2, uip.maxx // 2, title = f"{query}?", default = querydefault) == False:
							continue
					elif queryfunc == "filechooser":
						# It's a programming error if either of these two are not set, so it's OK to get an exception
						listgetter = extravars["listgetter"]
						basedir = extravars["basedir"]
						selected_file = None
						selected_ptype = None

						while basedir is not None:
							tmp_file_list = listgetter(basedir)
							file_list = []
							for item in tmp_file_list:
								realpath, filename, ptype = item
								if ptype in ["File", "Configuration File", "Kustomization"]:
									formatting = ("windowwidget", "default")
								elif ptype in ["<dir>"]:
									formatting = ("windowwidget", "highlight")
								else:
									raise Exception(f"Unknown ptype {ptype}")
								file_list.append((widgetlineattrs.NORMAL, [(f"{filename}", formatting)], [(f"{ptype}", ("windowwidget", "description"))]))
							tmpselection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, file_list, title = query, cursor = True)
							if tmpselection is None or tmpselection == (0, [("", None)]):
								# This will break out of the loop
								basedir = None
								selected_file = None
								continue
							selected_entry = tmpselection[1][0][0]
							# Find entry in tmp_file_list
							for item in tmp_file_list:
								realpath, filename, ptype = item
								if filename == selected_entry:
									if ptype in ["<dir>"]:
										basedir = realpath
										uip.refresh_all()
									elif ptype in ["File", "Configuration File", "Kustomization"]:
										selected_file = realpath
										selected_ptype = ptype
										basedir = None
										break

						if selected_file is None:
							uip.force_update()
							continue
						selection_vars = extra_vars
						selection_vars["resource_path"] = (selected_file, selected_ptype)

				if confirm == True:
					if curses_helper.confirmationbox(uip.stdscr, uip.maxy // 2, uip.maxx // 2, title = f"Perform “{description}“?", default = False) == False:
						continue

				retval = actionfunc(uip, items = [], actions = actionlist[action], values = selection_vars, kind = kind)
				if retval is not None and retval == curses_helper.retval.RETURNFULL:
					return retval

				uip.force_update()
				tagged_items.clear()
				continue
			tagged_items.clear()
		elif c == ord("N"):
			if is_namespaced == False:
				continue

			all_ns = "<All>"
			if namespace == "":
				preselection = all_ns
			else:
				preselection = namespace
			namespace_list = [(widgetlineattrs.NORMAL, [(f"{all_ns}", ("windowwidget", "default"))])]

			tmp, status = kh.get_list_by_kind_namespace(("Namespace", ""), "")
			if status == 200:
				for ns in [deep_get(item, "metadata#name") for item in tmp]:
					namespace_list.append((widgetlineattrs.NORMAL, [(f"{ns}", ("windowwidget", "default"))]))

			tmpselection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, namespace_list, title = "Select Namespace", cursor = True, preselection = preselection)
			selection = None
			if tmpselection is not None and type(tmpselection[0]) == int:
				selection = tmpselection[1][0][0]
			uip.refresh_all()
			if selection is not None and len(selection) > 0:
				if selection == all_ns:
					namespace = ""
				else:
					namespace = selection
			field_dict, field_names, sortcolumn = fieldgenerator(view, field_index = field_index, field_indexes = field_indexes, fields = deep_get(views, f"{view}#fields"), sortcolumn = deep_get(views, f"{view}#sortcolumn"), denylist = denylist)
			uip.init_window(field_dict, view = kind, windowheader = windowheader, update_delay = update_delay, sortcolumn = sortcolumn, sortorder_reverse = sortorder_reverse, helptext = helptext, activatedfun = activatedfun, on_activation = on_activation)
			headerpad, listpad = uip.init_listpad(listheight = 1, width = -1, ypos = 1, xpos = 1)

			# For the status bar; position is always at the bottom of the screen and the entire width of the screen
			statusbar = uip.init_statusbar()
		elif (c == ord("t") or c == ord(" ")) and is_taggable == True:
			selected = uip.get_selected()

			if selected is not None:
				if selected in tagged_items:
					tagged_items.remove(selected)
				else:
					tagged_items.add(selected)
				# After we tag an item we advance the cursor (when possible);
				# this way we can select multiple continuous items in a straight-forward manner
				uip.move_cur_with_offset(1)
		elif c == ord("T") and is_taggable == True:
			# Tag by pattern
			pattern = curses_helper.inputbox(uip.stdscr, uip.maxy // 2, 1, uip.maxy - 1, uip.maxx - 1, "Tag '%s' matching: " % (uip.sortcolumn)).rstrip().lower()
			if pattern is None or pattern == "":
				continue

			# XXX: This should search the specified sortcolumn, not always in name
			for item in uip.sorted_list:
				try:
					#Exact match
					#tmp = re.match(r"%s$" % pattern, item.name):
					tmp = re.match(pattern, item.name)

					if tmp is not None and len(tmp[0]) > 0:
						if item not in tagged_items:
							tagged_items.add(item)
				except re.error:
					continue
		elif c == ord("") and is_taggable == True:
			if len(tagged_items) == 0:
				continue

			# Untag by pattern
			pattern = curses_helper.inputbox(uip.stdscr, uip.maxy // 2, 1, uip.maxy - 1, uip.maxx - 1, "Untag '%s' matching: " % (uip.sortcolumn)).rstrip().lower()
			if pattern is None or pattern == "":
				continue

			# XXX: This should search the specified sortcolumn, not always in name
			for item in uip.sorted_list:
				try:
					#Exact match
					#tmp = re.match(r"%s$" % pattern, item.name):
					tmp = re.match(pattern, item.name)

					if tmp is not None and len(tmp[0]) > 0:
						if item in tagged_items:
							tagged_items.remove(item)
				except re.error:
					continue
		elif c == ord("l") and is_taggable == True and vlist is not None and listlen > 0:
			# List the union of all labels of the tagged objects (if the objects support labels)
			if len(tagged_items) == 0:
				selected = uip.get_selected()
				tagged_items.add(selected)
			labellist = []
			labels = []
			if "namespace" in deep_get(vlist[0], "metadata", ""):
				itemlist = [ (item.namespace, item.name) for item in tagged_items ]
			else:
				itemlist = [ item.name for item in tagged_items ]

			if len(itemlist) == 0:
				continue

			for obj in vlist:
				if type(itemlist[0]) == tuple:
					if (deep_get(obj, "metadata#namespace", ""), deep_get(obj, "metadata#name")) not in itemlist:
						continue
				else:
					if deep_get(obj, "metadata#name") not in itemlist:
						continue

				labelref = deep_get(obj, "metadata#labels", {})
				for key in labelref:
					if (key, labelref[key]) not in labels:
						labels.append((key, labelref[key]))
			if len(labels) == 0:
				continue
			for key, value in natsorted(labels):
				labellist.append((widgetlineattrs.NORMAL, [(f"{key}", ("windowwidget", "default"))], [(f"{value}", ("windowwidget", "default"))]))
			label_headers = ["Label:", "Value:"]
			curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, labellist, headers = label_headers, title = "Labels", cursor = False)
			tagged_items.clear()
			uip.refresh_all()
			curses.doupdate()
		elif c == ord("f") and is_taggable == True and vlist is not None and listlen > 0:
			# List the union of all labels of the tagged objects and create a label selector
			# from the choices made by the user (if the objects support labels)
			if len(tagged_items) == 0:
				selected = uip.get_selected()
				tagged_items.add(selected)

			labellist = []
			labels = []
			if "namespace" in deep_get(vlist[0], "metadata", ""):
				itemlist = [ (item.namespace, item.name) for item in tagged_items ]
			else:
				itemlist = [ item.name for item in tagged_items ]

			if len(itemlist) == 0:
				continue

			for obj in vlist:
				if type(itemlist[0]) == tuple:
					if (deep_get(obj, "metadata#namespace", ""), deep_get(obj, "metadata#name")) not in itemlist:
						continue
				else:
					if deep_get(obj, "metadata#name") not in itemlist:
						continue

				labelref = deep_get(obj, "metadata#labels", {})
				for key in labelref:
					if (key, labelref[key]) not in labels:
						labels.append((key, labelref[key]))
			if len(labels) == 0:
				continue
			for key, value in labels:
				labellist.append((widgetlineattrs.NORMAL, [(f"{key}", ("windowwidget", "default"))], [(f"{value}", ("windowwidget", "default"))]))
			label_headers = ["Label:", "Value:"]
			tagged_labels = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, labellist, headers = label_headers, title = "Labels", cursor = True, taggable = True)
			if len(tagged_labels) > 0:
				selectors = {}
				for i in range(0, len(labels)):
					if i in tagged_labels:
						selectors[labels[i][0]] = labels[i][1]
				label_selector = kh.make_selector(selectors)
				uip.force_update()
			tagged_items.clear()
			uip.refresh_all()
			curses.doupdate()
		elif c == ord("A") and view == "Inventory" and len(tagged_items) == 0:
			selected = uip.get_selected()
			groups = ansible_get_groups(ANSIBLE_INVENTORY)
			# These Ansible groups shouldn't be possible to toggle on/off
			for skip in ["all", "controlplane", "controlplanes", "master", "node", "nodes"]:
				try:
					groups.remove(skip)
				except:
					pass
			host_groups = ansible_get_groups_by_host(ANSIBLE_INVENTORY, selected.name)
			grouplist = []
			preselection = set()
			for i in range(0, len(groups)):
				grouplist.append((widgetlineattrs.NORMAL, [(f"{groups[i]}", ("windowwidget", "default"))]))
				if groups[i] in host_groups:
					preselection.add(i)
			group_headers = ["Ansible Groups:"]
			selection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, grouplist, headers = group_headers, title = "Ansible Groups", cursor = True, taggable = True, preselection = preselection)
			new_groups = []
			for keep in ["all", "controlplane", "controlplanes", "master", "node", "nodes"]:
				if keep in host_groups:
					new_groups.append(keep)
			for i in selection:
				new_groups.append(groups[i])

			add_groups = set(new_groups) - set(host_groups)
			remove_groups = set(host_groups) - set(new_groups)

			for group in add_groups:
				retval = ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [selected.name], group = group, skip_all = False)
			for group in remove_groups:
				retval = ansible_remove_hosts(inventory = ANSIBLE_INVENTORY, hosts = [selected.name], group = group)

			if len(add_groups) > 0 or len(remove_groups) > 0:
				uip.force_update()
			uip.refresh_all()
			curses.doupdate()
		elif c == ord("F") and is_taggable == True:
			# Clear the label selector
			if len(label_selector) > 0:
				label_selector = ""
				uip.force_update()
				uip.refresh_all()
				curses.doupdate()
		elif c == ord("L") and is_taggable == True:
			# List tagged items
			taggeditemlist = []
			if len(tagged_items) == 0:
				continue
			for item in tagged_items:
				taggeditemlist.append((widgetlineattrs.NORMAL, [("separators", "widgetbullet"), (f"{item.name}", ("windowwidget", "default"))]))
			curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, taggeditemlist, title = "Tagged items", cursor = False)
			uip.refresh_all()
			curses.doupdate()
		elif c == ord(";") and is_taggable == True and listlen > 0:
			cluster_available = True
			items = []
			autoitem = False
			control_plane = False

			if len(tagged_items) == 0:
				selected = uip.get_selected()
				tagged_items.add(selected)
				autoitem = True

			for item in tagged_items:
				# XXX once all infogetters have been fixed we don't need to check for <none>
				if len(item.name) == 0 or item.name == "<none>":
					break

				if hasattr(item, "kubernetes_roles"):
					if "control-plane" in item.kubernetes_roles:
						control_plane = True
					if "<unknown>" in item.kubernetes_roles:
						cluster_available = False
				if hasattr(item, "namespace"):
					items.append((item.namespace, item.name))
				else:
					items.append(item.name)

			if len(items) == 0:
				tagged_items.clear()
				continue

			action_title = deep_get(viewref, "actions#title", "Perform action on tagged items")
			tmp_action_src_list = deep_get(viewref, "actions#actionlist", {})

			action_src_list = {
			}

			for action in tmp_action_src_list:
				# Override default actions by passing an empty action by the same name
				if action in action_src_list and tmp_action_src_list[action] == {}:
					action_src_list.pop(action)
				else:
					action_src_list[action] = tmp_action_src_list[action]

			# Populate the list of actions
			action_context = deep_get(viewref, "actions#actionlist#context", None)
			actions, actionlist = populate_actionlist(context = action_context, action_list = action_src_list, control_plane_selected = control_plane, single_item = (len(items) == 1), cluster_available = cluster_available)

			# If there are playbook actions, add those too
			if len(deep_get(viewref, "actions#playbooklist", {})) > 0:
				playbook_context = deep_get(viewref, "actions#playbooklist#context", None)
				actions, actionlist = populate_playbooklist(context = playbook_context, actions = [], action_list = actionlist, control_plane_selected = control_plane, single_item = (len(items) == 1), cluster_available = cluster_available)

			if len(actions) == 0:
				if autoitem == True:
					tagged_items.clear()
				continue

			tmpselection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, actions, title = action_title)
			selection = None
			if tmpselection is not None and type(tmpselection[0]) == int:
				selection = ""
				for i in range(1, len(tmpselection)):
					if len(tmpselection[i]) > 0:
						selection += tmpselection[i][0][0]
			uip.refresh_all()
			curses.doupdate()

			if selection is not None and selection != "":
				actionfunc = None

				# Map the description back to key
				for action in actionlist:
					description = deep_get(actionlist, f"{action}#description")
					tmpdescription = ""
					if type(description) == str:
						tmpdescription = description
					else:
						for i in range(0, len(description)):
							tmpdescription += description[i][0]
					tmpmetadata = deep_get(actionlist, f"{action}#metadata", [])
					for metadata in tmpmetadata:
						tmpdescription += metadata[0]
					if tmpdescription == selection:
						actiontype = deep_get(actionlist, f"{action}#action")
						if actiontype is not None:
							if actiontype == "execute":
								actionfunc = execute_command
						else:
							actionfunc = deep_get(actionlist, f"{action}#actionfunc", command_hosts)
							if type(actionfunc) == str:
								actionfunc = eval(actionfunc)
						action_args = deep_get(actionlist, f"{action}#action_args", {})
						# These are only relevant for node and inventory view
						allowoncontrolplane = deep_get(actionlist, f"{action}#allow-on-control-plane", True)
						singleoncontrolplane = deep_get(actionlist, f"{action}#single-on-control-plane", False)
						confirm = deep_get(actionlist, f"{action}#confirm", False)
						query = deep_get(actionlist, f"{action}#query")
						queryval = deep_get(actionlist, f"{action}#queryval")
						queryfunc = deep_get(actionlist, f"{action}#queryfunc")
						extravars = deep_get(actionlist, f"{action}#extravars", {})
						title = deep_get(actionlist, f"{action}#title")
						break

				if actionfunc is None:
					continue

				selection_vars = extravars

				# This should be modified; we might want to ask multiple queries.
				# At the very least asking for one input plus confirmation.
				# A multi input box might be useful too.
				if queryfunc is not None and queryval is not None and query is not None:
					if queryfunc == "string":
						# Not supported by inputbox widget
						# querydefault = ""
						string = curses_helper.inputbox(uip.stdscr, uip.maxy // 2, 1, uip.maxy - 1, uip.maxx - 1, f"{query}: ")
						if string is None or string == "":
							continue
						else:
							selection_vars[queryval] = string
					elif queryfunc == "confirm":
						querydefault = False
						if curses_helper.confirmationbox(uip.stdscr, uip.maxy // 2, uip.maxx // 2, title = f"{query}?", default = querydefault) == False:
							continue
					elif queryfunc == "filechooser":
						# It's a programming error if either of these two are not set, so it's OK to get an exception
						listgetter = extravars["listgetter"]
						basedir = extravars["basedir"]
						selected_file = None
						selected_ptype = None

						while basedir is not None:
							tmp_file_list = listgetter(basedir)
							file_list = []
							for item in tmp_file_list:
								realpath, filename, ptype = item
								if ptype in ["File", "Configuration File", "Kustomization"]:
									formatting = ("windowwidget", "default")
								elif ptype in ["<dir>"]:
									formatting = ("windowwidget", "highlight")
								else:
									raise Exception(f"Unknown ptype {ptype}")
								file_list.append((widgetlineattrs.NORMAL, [(f"{filename}", formatting)], [(f"{ptype}", ("windowwidget", "description"))]))
							tmpselection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, file_list, title = query, cursor = True)
							if tmpselection is None or tmpselection == (0, [("", None)]):
								# This will break out of the loop
								basedir = None
								selected_file = None
								continue
							selected_entry = tmpselection[1][0][0]
							# Find entry in tmp_file_list
							for item in tmp_file_list:
								realpath, filename, ptype = item
								if filename == selected_entry:
									if ptype in ["<dir>"]:
										basedir = realpath
										uip.refresh_all()
									elif ptype in ["File", "Configuration File", "Kustomization"]:
										selected_file = realpath
										selected_ptype = ptype
										basedir = None
										break

						if selected_file is None:
							uip.force_update()
							continue
						selection_vars["resource_path"] = (selected_file, selected_ptype)

				if confirm == True:
					if curses_helper.confirmationbox(uip.stdscr, uip.maxy // 2, uip.maxx // 2, title = f"Are you sure you want to perform “{description}“?", default = False) == False:
						continue

				selection_vars["_tagged_items"] = list(tagged_items)
				selection_vars["action_args"] = action_args
				retval = actionfunc(uip, items, actionlist[action], values = selection_vars, kind = kind, title = title)
				if retval is not None and retval == curses_helper.retval.RETURNFULL:
					return retval

				uip.force_update()
				tagged_items.clear()
				continue
			tagged_items.clear()

		shortcuts = deep_get(viewref, "shortcuts", {})

		# Always include the shortcut for YAML dump, unless overridden
		if deep_get(viewref, "shortcuts#View YAML dump") is None:
			shortcuts["View YAML dump of resource"] = {
				"shortcut": ord("y"),
				"helptext": ("Y", "View YAML dump of resource"),
				"action": "call",
				"action_call": view_yaml,
				"action_args": {
					"title": "YAML dump",
					"_named_title": True,
					"_pass_obj": True,
				},
				"read_only": True,
			}
		# Always include the shortcut for edit resource, unless overridden
		if deep_get(viewref, "shortcuts#Edit resource") is None:
			shortcuts["Edit resource"] = {
				"shortcut": ord("e"),
				"helptext": ("E", "Edit resource"),
				"action": "call",
				"action_call": edit_resource,
				"action_args": {
					"_pass_obj": True,
					"_pass_kind": True,
				},
			}

		for key, value in shortcuts.items():
			shortcut_keys = deep_get(value, "shortcut")
			if shortcut_keys is None:
				continue

			if type(shortcut_keys) != list:
				shortcut_keys = [shortcut_keys]

			if c not in shortcut_keys:
				continue

			query = deep_get(value, "query")
			queryval = deep_get(value, "queryval")
			queryfunc = deep_get(value, "queryfunc")
			force_update = deep_get(value, "force_update", True)

			selection_vars = None

			# This should be modified; we might want to ask multiple queries.
			# At the very least asking for one input plus confirmation.
			# A multi input box might be useful too.
			if queryfunc is not None and queryval is not None and query is not None:
				if queryfunc == "string":
					# Not supported by inputbox widget
					# querydefault = ""
					string = curses_helper.inputbox(uip.stdscr, uip.maxy // 2, 1, uip.maxy - 1, uip.maxx - 1, "%s: " % query)
					if string is None or string == "":
						continue
					else:
						selection_vars = { queryval: string }
				elif queryfunc == "confirm":
					querydefault = False
					if curses_helper.confirmationbox(uip.stdscr, uip.maxy // 2, uip.maxx // 2, title = "%s?" % query, default = querydefault) == False:
						continue
			if deep_get(value, "confirm") == True:
				title = deep_get(value, "title", "")

				uip.force_update()
				if curses_helper.confirmationbox(uip.stdscr, uip.maxy // 2, uip.maxx // 2, title = title, default = False) == False:
					continue

			selected = uip.get_selected()

			action = deep_get(value, "action", None)
			if action is not None:
				action_args = deep_get(value, "action_args", {})
				if "_pass_obj" in action_args and selected is not None:
					action_args["obj"] = selected.ref
				if "_pass_kind" in action_args:
					action_args["kind"] = kind
				if "_pass_selected" in action_args and selected is not None:
					action_args["selected"] = selected
				if "_pass_selection_vars" in action_args:
					action_args["selection_vars"] = selection_vars
				if "_named_title" in action_args and selected is not None and getattr(selected, "name", None):
					action_args["named_title"] = deep_get(action_args, "title", "") + " (" + getattr(selected, "name") + ")"
				action_call = deep_get(value, "action_call")
				if action == "toggle_var":
					var = deep_get(action_args, "var")
					if var is not None:
						tmp = deep_get(listview_args, var)
						deep_set(listview_args, var, not tmp)
				elif action == "call" and action_call is not None:
					retval = action_call(uip.stdscr, **action_args)
					if retval is not None and retval == curses_helper.retval.RETURNFULL:
						return retval

			if force_update == True:
				uip.force_update()

def clusteroverviewloop(stdscr, view):
	#field_list, sortcolumn = fieldgenerator(view)
	field_list, sortcolumn = (None, None)
	uip = UIProps(stdscr)

	windowheader = view
	helptext = views[view]["helptext"]
	activatedfun = views[view]["activatedfun"]
	on_activation = deep_get(views[view], "on_activation", {})
	update_delay = views[view].get("update_delay", -1)

	sortorder_reverse = views[view].get("sortorder_reverse", False)

	uip.init_window(field_list, windowheader = windowheader, update_delay = update_delay, sortcolumn = sortcolumn, sortorder_reverse = sortorder_reverse, helptext = helptext, activatedfun = activatedfun, on_activation = on_activation)

	infopadheight = 9

	# For generic information
	infopad = uip.init_infopad(height = infopadheight, width = -1, ypos = 1, xpos = 1)

	# For the status panes
	headerpad, listpad = uip.init_listpad(listheight = 1, width = -1, ypos = infopadheight + 2, xpos = 1, header = False)

	# For the status bar; position is always at the bottom of the screen and the entire width of the screen
	statusbar = uip.init_statusbar()

	selected_heatmap = "Node"
	selected_node = 0
	selected_pod = 0

	nodeinfo = None

	while True:
		uip.countdown_to_update()

		if uip.is_update_triggered():
			# The data in some fields might become shorter, so we need to trigger a clear
			uip.infopad.erase()
			uip.statusbar.erase()

			uip.update_window()

			# Get control plane node
			control_plane_node, control_plane_name = get_control_plane()
			control_plane_addresses = deep_get(control_plane_node, "status#addresses", [])
			name, iips, eips = get_node_addresses(control_plane_name, control_plane_addresses)

			# XXX: Once we can run Ansible jobs in the background we can replace this with the data from the load_ping playbook
			# Check whether we're running local or not; if we're running local this is easy
			if os.path.exists("/etc/hostname"):
				f = open("/etc/hostname", "r")
				hostname = f.readline().strip()
				islocal = (hostname == name)
				f.close()
			#else:
			#WTF do we do if /etc/hostname doesn't exist?

			if islocal == True:
				# FIXME: handle non-existance
				if os.path.exists("/proc/loadavg"):
					f = open("/proc/loadavg", "r")
					loadavg = f.readline()
					f.close()

					tmp = re.match(r"([0-9]+\.[0-9]+) ([0-9]+\.[0-9]+) ([0-9]+\.[0-9]+) ([0-9]+)/([0-9]+) ([0-9]+)", loadavg)
					if tmp is not None:
						avg1min = tmp[1]
						avg5min = tmp[2]
						avg15min = tmp[3]
						running = tmp[4]
						tasks = tmp[5]

				if os.path.exists("/proc/meminfo"):
					f = open("/proc/meminfo", "r")

					for tmp in f:
						values = tmp.split()
						if values[0] == "MemTotal:":
							memtotal = int(values[1])
						elif values[0] == "MemFree:":
							memfree = int(values[1])
						elif values[0] == "MemShared:":
							memshared = int(values[1])
						elif values[0] == "Buffers:":
							buffers = int(values[1])
						elif values[0] == "Cached:":
							memcached = int(values[1])
						elif values[0] == "SwapTotal:":
							swaptotal = int(values[1])
						elif values[0] == "SwapFree:":
							swapfree = int(values[1])
						elif values[0] == "Shmem:":
							memshared = int(values[1])
						elif values[0] == "SReclaimable:":
							sreclaimable = int(values[1])
					f.close()

					# Total used mem; includes buffers and cache
					memused = memtotal - memfree
					memcached = memcached + sreclaimable - memshared
					swapused = swaptotal - swapfree
					# FIXME
					threads = 42

				if os.path.exists("/proc/stat"):
					f = open("/proc/stat", "r")
					stat = f.readline()
					f.close()

				# cpu  30175835 25947 13018006 435764225 200633 0   3229829 0     0     0
				# ...  normal   niced system   idle      iowait irq softirq steal guest guest_nice
				#      1        2     3        4         5      6   7       8     9     10
				tmp = re.match(r"[A-Za-z]+ +([0-9]+) +([0-9]+) +([0-9]+) +([0-9]+) ([0-9]+) +([0-9]+) +([0-9]+) +([0-9]+) +([0-9]+) ([0-9]+)", stat)
				if tmp is not None:
					cputimeuser = int(tmp[1])
					cputimeusernice = int(tmp[2])
					cputimesystem = int(tmp[3])
					cputimeidle = int(tmp[4])
					cputimeiowait = int(tmp[5])
					cputimeirq = int(tmp[6])
					cputimesoftirq = int(tmp[7])
					cputimesteal = int(tmp[8])
					cputimeguest = int(tmp[9])
					cputimeguestnice = int(tmp[10])
					cputimeuser = cputimeuser - cputimeguest
					cputimeusernice = cputimeusernice - cputimeguestnice
					cputimetotalidle = cputimeidle + cputimeiowait
					cputimetotalsystem = cputimesystem + cputimeirq + cputimesoftirq
					cputimetotalguest = cputimeguest + cputimeguestnice
					cputimetotal = cputimeuser + cputimeusernice + cputimetotalsystem + cputimetotalidle + cputimesteal + cputimetotalguest
					cputimetotalused = cputimeuser + cputimeusernice + cputimetotalsystem + cputimesteal + cputimetotalguest

			# Get the list of all nodes
			vlist, status = kh.get_list_by_kind_namespace(("Node", ""), "")
			nodeinfo = get_node_info(vlist)
			node_statuses = [s.status_group for s in nodeinfo]

			# Get the list of all pods
			vlist, status = kh.get_list_by_kind_namespace(("Pod", ""), "")
			podinfo = get_pod_info(**{"_vlist": vlist})
			pod_statuses = [s.status_group for s in podinfo]

			node_heatmap = curses_helper.generate_heatmap(((uip.maxx - uip.minx - 1) // 2) - 1, node_statuses, selected_node)
			pod_heatmap = curses_helper.generate_heatmap(((uip.maxx - uip.minx - 1) // 2) - 1, pod_statuses, selected_pod)

			# Resize the list pad to fit the heatmaps
			# XXX this needs to be fixed when we add more information
			uip.resize_listpad(max(len(node_heatmap), len(pod_heatmap)), -1)

		namearray = [
			("Control Plane: ", ("main", "infoheader")),
			(f"{name}", ("types", "generic"))
		]
		contextarray = [
			("Cluster Context: ", ("main", "infoheader")),
			(f"{kh.context_name}", ("types", "generic"))
		]
		internaliparray = [
			("Internal IP-address(es): ", ("main", "infoheader")),
		]
		internaliparray += format_list(iips, 0, 0, False, False)
		externaliparray = [
			("External IP-address(es): ", ("main", "infoheader")),
		]
		externaliparray += format_list(eips, 0, 0, False, False)
		# Kubernetes port
		# KubeDNS
		# control plane load, disk, mem, uptime (requires ansible or local)

		uip.addthemearray(infopad, namearray, y = 0, x = 0)
		uip.addthemearray(infopad, contextarray, y = 1, x = 0)
		uip.addthemearray(infopad, internaliparray, y = 2, x = 0)
		uip.addthemearray(infopad, externaliparray, y = 3, x = 0)

		if islocal == True:
			tasksarray = [
				("Tasks: ", ("main", "infoheader")),
				(f"{tasks}", ("types", "numerical")),
				#(", ", ("types", "separator")),
				#(f"{threads} ", ("types", "numerical")),
				#("threads", ("types", "generic")),
				("; ", ("types", "separator")),
				(f"{running} ", ("types", "numerical")),
				("running", ("types", "generic")),
			]

			cpuarray = [
				(" CPU: ", ("main", "infoheader")),
			]
			cpuusagearray = [
				(f"{str(100 * cputimetotalused // cputimetotal).rjust(3)}", ("types", "numerical")),
				("separators", "percentage"),
			]
			memarray = [
				(" Mem: ", ("main", "infoheader")),
			]
			memusagearray = [
				("%s" % str(100 * memused // memtotal).rjust(3), ("types", "numerical")),
				("separators", "percentage"),
			]
			swaparray = [
				("Swap: ", ("main", "infoheader")),
			]
			disabledarray = [
				("Disabled", ("main", "highlight")),
			]

			uip.addthemearray(infopad, tasksarray, y = 5, x = 0)
			uip.addthemearray(infopad, cpuarray, y = 6, x = 0)
			uip.addthemearray(infopad, cpuusagearray, y = 6, x = (uip.infopadwidth - 8))
			uip.addthemearray(infopad, memarray, y = 7, x = 0)
			uip.addthemearray(infopad, memusagearray, y = 7, x = (uip.infopadwidth - 8))
			uip.addthemearray(infopad, swaparray, y = 8, x = 0)

			# cpu usage:
			# low-priority (bold blue) / normal (green) / kernel (red) / virtualized (cyan)
			# This is aggregate over all CPUs
			curses_helper.percentagebar(infopad, 6, 6, uip.infopadwidth - 10, cputimetotal, [
				(cputimeusernice, attr_to_curses_merged("types", "cputime_user_nice")),
				(cputimeuser, attr_to_curses_merged("types", "cputime_user")),
				(cputimetotalsystem, attr_to_curses_merged("types", "cputime_total_system")),
				(cputimetotalguest, attr_to_curses_merged("types", "cputime_total_guest"))
			])

			# memory usage:
			# used (green) / buffers (bold blue) / cache (yellow)
			curses_helper.percentagebar(infopad, 7, 6, uip.infopadwidth - 10, memtotal, [
				(memused - memcached - buffers, attr_to_curses_merged("types", "mem")),
				(buffers, attr_to_curses_merged("types", "buffers")),
				(memcached, attr_to_curses_merged("types", "cached"))
			])

			# swap usage:
			# used (red)
			if swaptotal == 0:
				uip.addthemearray(infopad, disabledarray, y = 8, x = 6)
			else:
				curses_helper.percentagebar(infopad, 8, 6, uip.infopadwidth - 10, swaptotal, [
					(swapused, ("types", "swap_used"))
				])
				swapusagearray = [
					(f"{100 * swapused // swaptotal}", ("main", "dim")),
					("separators", "percentage"),
				]
				uip.addthemearray(infopad, swapusagearray, y = 8, x = (uip.infopadwidth - 8))

		heatmap_width = 0
		if len(nodeinfo) > 0:
			heatmap_width = ((uip.maxx - uip.minx - 1) // 2) - 1
			node_heatmap_xpos = 0
			pod_heatmap_xpos = heatmap_width - 1
			uip.addthemearray(listpad, [("Node heatmap:", ("main", "listheader", selected_heatmap == "Node"))], y = 0, x = node_heatmap_xpos)
			selectednodearray = [
				("N", ("main", "listheader", selected_heatmap == "Node")),
				("ode: ", ("main", "listheader")),
				(f"{nodeinfo[selected_node].name}".ljust(heatmap_width), ("main", "highlight")),
			]
			selectednodestatusarray = [
				("Status: ", ("main", "infoheader")),
				(f"{nodeinfo[selected_node].status}".ljust(heatmap_width), color_status_group(nodeinfo[selected_node].status_group, selected = False)),
			]
			uip.addthemearray(listpad, selectednodearray, y = 1, x = node_heatmap_xpos + 1)
			uip.addthemearray(listpad, selectednodestatusarray, y = 2, x = node_heatmap_xpos + 1)

			node_heatmap = curses_helper.generate_heatmap(heatmap_width, node_statuses, selected_node)
			pod_heatmap = curses_helper.generate_heatmap(heatmap_width, pod_statuses, selected_pod)

			y = 5
			for row in node_heatmap:
				uip.addthemearray(listpad, row, y = y, x = node_heatmap_xpos)
				y += 1

			uip.addthemearray(listpad, [("Pod heatmap:", ("main", "listheader", selected_heatmap == "Pod"))], y = 0, x = pod_heatmap_xpos)
			selectedpodarray = [
				("P", ("main", "listheader", selected_heatmap == "Pod")),
				("od: ", ("main", "listheader")),
				(f"{podinfo[selected_pod].name}".ljust(heatmap_width), ("main", "highlight")),
			]
			selectedpodnamespacearray = [
				("N", ("main", "listheader", selected_heatmap == "Pod")),
				("amespace: ", ("main", "listheader")),
				(f"{podinfo[selected_pod].namespace}".ljust(heatmap_width), ("main", "highlight")),
			]
			selectedpodstatusarray = [
				("Status: ", ("main", "infoheader")),
				(f"{podinfo[selected_pod].status}".ljust(heatmap_width), color_status_group(podinfo[selected_pod].status_group, selected = False)),
			]
			uip.addthemearray(listpad, selectedpodarray, y = 1, x = pod_heatmap_xpos + 1)
			uip.addthemearray(listpad, selectedpodnamespacearray, y = 2, x = pod_heatmap_xpos + 1)
			uip.addthemearray(listpad, selectedpodstatusarray, y = 3, x = pod_heatmap_xpos + 1)

			y = 5
			for row in pod_heatmap:
				uip.addthemearray(listpad, row, y = y, x = pod_heatmap_xpos)
				y += 1

		uip.refresh_window()
		uip.refresh_infopad()
		uip.refresh_listpad()
		uip.refresh_statusbar()
		curses.doupdate()

		uip.stdscr.timeout(100)
		c = uip.stdscr.getch()

		if c == curses.KEY_RESIZE:
			uip.resize_window()
		elif c == ord(""):
			sys.exit()
		elif c == curses.KEY_F1 or c == ord("H"):
			if helptext is not None:
				curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, uip.helptext, title = "Help", cursor = False)
			uip.refresh_all()
		elif c == curses.KEY_F2:
			retval = selectwindow(stdscr, uip)
			if retval == curses_helper.retval.RETURNFULL:
				return retval
			uip.refresh_all()
		elif c == curses.KEY_F3:
			retval = selectwindow(stdscr, uip, refresh_apis = True)
			if retval == curses_helper.retval.RETURNFULL:
				return retval
			uip.refresh_all()
		elif c == ord("B"):
			uip.toggle_borders()
			uip.refresh_all()
			uip.force_update()
		elif c == curses.KEY_SRIGHT:
			if selected_heatmap == "Node":
				selected_heatmap = "Pod"
			uip.refresh_all()
		elif c == curses.KEY_SLEFT:
			if selected_heatmap == "Pod":
				selected_heatmap = "Node"
			uip.refresh_all()
		elif c == curses.KEY_LEFT:
			if selected_heatmap == "Pod":
				selected_pod = max(0, selected_pod - 1)
			elif selected_heatmap == "Node":
				selected_node = max(0, selected_node - 1)
			uip.refresh_all()
		elif c == curses.KEY_RIGHT:
			if selected_heatmap == "Pod":
				selected_pod = min(len(pod_statuses) - 1, selected_pod + 1)
			elif selected_heatmap == "Node":
				selected_node = min(len(node_statuses) - 1, selected_node + 1)
			uip.refresh_all()
		elif c == curses.KEY_UP:
			if selected_heatmap == "Pod":
				if (selected_pod - heatmap_width + 1) >= 0:
					selected_pod -= heatmap_width + 1
			elif selected_heatmap == "Node":
				if (selected_node - heatmap_width + 1) >= 0:
					selected_node -= heatmap_width + 1
		elif c == curses.KEY_DOWN:
			if selected_heatmap == "Pod":
				if (selected_pod + heatmap_width + 1) < len(pod_statuses):
					selected_pod += heatmap_width + 1
			elif selected_heatmap == "Node":
				if (selected_node + heatmap_width + 1) < len(node_statuses):
					selected_node += heatmap_width + 1
		elif c == curses.KEY_HOME:
			if selected_heatmap == "Pod":
				selected_pod = max((selected_pod // (heatmap_width + 1)) * (heatmap_width + 1), 0)
			elif selected_heatmap == "Node":
				selected_node = max((selected_node // (heatmap_width + 1)) * (heatmap_width + 1), 0)
		elif c == curses.KEY_END:
			if selected_heatmap == "Pod":
				selected_pod = min((selected_pod // (heatmap_width + 1)) * (heatmap_width + 1) + heatmap_width, len(pod_statuses) - 1)
			elif selected_heatmap == "Node":
				selected_node = min((selected_node // (heatmap_width + 1)) * (heatmap_width + 1) + heatmap_width, len(node_statuses) - 1)
		elif c == curses.KEY_SHOME:
			if selected_heatmap == "Pod":
				selected_pod = selected_pod - (selected_pod // (heatmap_width + 1)) * (heatmap_width + 1)
			elif selected_heatmap == "Node":
				selected_node = selected_node - (selected_node // (heatmap_width + 1)) * (heatmap_width + 1)
		elif c == curses.KEY_SEND:
			if selected_heatmap == "Pod":
				tmp = selected_pod - (selected_pod // (heatmap_width + 1)) * (heatmap_width + 1) + (len(pod_statuses) // (heatmap_width + 1)) * (heatmap_width + 1)
				if tmp < len(pod_statuses):
					selected_pod = tmp
			elif selected_heatmap == "Node":
				tmp = selected_node - (selected_node // (heatmap_width + 1)) * (heatmap_width + 1) + (len(node_statuses) // (heatmap_width + 1)) * (heatmap_width + 1)
				if tmp < len(node_statuses):
					selected_node = tmp
		elif c == ord("\t"):
			if selected_heatmap == "Pod":
				if selected_pod == len(podinfo) -1:
					continue

				for i in range(selected_pod + 1, len(podinfo)):
					if podinfo[i].status_group != stgroup.OK:
						selected_pod = i
						uip.force_update()
						break
			elif selected_heatmap == "Node":
				if selected_node == len(nodeinfo) - 1:
					continue

				for i in range(selected_node + 1, len(nodeinfo)):
					if nodeinfo[i].status_group != stgroup.OK:
						selected_node = i
						uip.force_update()
						break
		elif c == curses.KEY_BTAB:
			if selected_heatmap == "Pod":
				if selected_pod == 0:
					continue

				for i in range(1, selected_pod):
					if podinfo[selected_pod - i].status_group != stgroup.OK:
						selected_pod -= i
						uip.force_update()
						break
			elif selected_heatmap == "Node":
				if selected_node == 0:
					continue

				for i in range(1, selected_node):
					if nodeinfo[selected_node - i].status_group != stgroup.OK:
						selected_node -= i
						uip.force_update()
						break
		elif c == ord("P"):
			if selected_heatmap == "Pod":
				retval = resourceinfodispatch(stdscr, podinfo[selected_pod].ref, ("Pod", ""))
				if retval is not None and retval == curses_helper.retval.RETURNFULL:
					return retval
			uip.force_update()
		elif c == ord("N"):
			if selected_heatmap == "Pod":
				ref = kh.get_ref_by_kind_name_namespace(("Namespace", ""), podinfo[selected_pod].namespace, "")
				retval = resourceinfodispatch(stdscr, ref, ("Namespace", ""))
				if retval is not None and retval == curses_helper.retval.RETURNFULL:
					return retval
			elif selected_heatmap == "Node":
				retval = resourceinfodispatch(stdscr, nodeinfo[selected_node].ref, ("Node", ""))
				if retval is not None and retval == curses_helper.retval.RETURNFULL:
					return retval
			uip.force_update()
		elif c == ord("V"):
			win = curses_helper.notice(uip.stdscr, uip.maxy // 2, uip.maxx // 2, message = "Fetching package versions...")
			_package_versions = get_package_versions(control_plane_name)
			package_versions = []
			for package, version in _package_versions:
				if version == "N/A":
					versionattr = ("windowwidget", "dim")
				else:
					versionattr = ("windowwidget", "default")
				package_versions.append((widgetlineattrs.NORMAL, [(f"{package}", ("windowwidget", "default"))], [(f"{version}", versionattr)]))
			uip.refresh_window()
			uip.refresh_infopad()
			uip.refresh_listpad()
			uip.refresh_statusbar()
			curses.doupdate()
			if len(package_versions) == 0:
				continue
			title = "Package Versions:"
			headers = ["Package:", "Version:"]
			curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, package_versions, title = title, headers = headers, cursor = False)

# These are based on attributes of the name of the cmdata
cmdata_format = [
	# cm namespace, cm name prefix, cmdata prefix, cmdata suffix, dataformat
	# To do an exact match on cmdata set both cmdata prefix and cmdata suffix to the same string
	# (this will work unless you have a string that contains the same substring twice)
	("", "", "caBundle", "caBundle", "CRT"),
	("", "image-registry-certificates", "", "", "CRT"),
	("", "", "", ".crt", "CRT"),
	("", "", "", ".pem", "CRT"),
	("", "", "", "client-ca-file", "CRT"),
	("", "", "", ".ini", "INI"),
	("", "", "", ".json", "JSON"),
	("", "", "", ".sh", "Shell Script"),
	("", "", "", ".toml", "TOML"),
	("", "", "", ".xml", "XML"),
	("", "", "", ".yaml", "YAML"),
	("", "", "", ".yml", "YAML"),
	("", "canal-config", "cni_network_config", "", "JSON"),
	("", "", "fluentbit.conf", "", "FluentBit"),
	("istio-system", "istio", "", "", "YAML"),
	("", "k10-k10-metering-config", "", "", "YAML"),
	("", "kubeapps-clusters-config", "clusters.conf", "", "JSON"),
	("", "kubeapps-internal-kubeappsapis-configmap", "plugins.conf", "", "JSON"),
	("kube-public", "cluster-info", "kubeconfig", "", "YAML"),
	("kube-system", "antrea", "antrea-agent", "", "YAML"),
	("kube-system", "antrea", "antrea-controller", "", "YAML"),
	("kube-system", "antrea", "antrea-cni", "", "JSON"),
	("kube-system", "coredns", "Corefile", "", "CaddyFile"),
	("kube-system", "kubeadm-config", "", "", "YAML"),
	("kube-system", "kubelet-config", "", "", "YAML"),
	("kube-system", "kube-proxy", "", "config.conf", "YAML"),
	("kube-system", "scheduler-extender-policy", "policy.cfg", "", "JSON"),
	("", "kubeapps", "vhost.conf", "vhost.conf", "NGINX"),
	("", "kubeapps", "k8s-api-proxy.conf", "k8s-api-proxy.conf", "NGINX"),
	("", "linkerd-config", "values", "", "YAML"),
	("", "nfd-worker-conf", "nfd-worker.conf", "", "YAML"),
	("", "", "", ".py", "Python"),
	# Openshift
	("", "dns-default", "Corefile", "", "CaddyFile"),
	("", "v4-0-config-system-cliconfig", "v4-0-config-system-cliconfig", "", "JSON"),
	# Keep last; match everything that doesn't match anything
	("", "", "", "", "Text"),
]

# These are based on the data itself
cmdata_header = [
	("/bin/sh", "Shell Script"),
	("/bin/bash", "BASH"),
	("/bin/dash", "Shell Script"),
	("/bin/zsh", "ZSH"),
	("python", "Python"),
	("perl", "Perl"),
	("perl", "Ruby"),
	("-----BEGIN CERTIFICATE-----", "CRT"),
]

def identify_cmdata(cmdata_name, cm_name, cm_namespace, data):
	if len(data) > 0:
		splitmsg = split_msg(data)
		dataformat = ""
		# We're in luck; there's an interpreter signature
		# or other type of signature to help
		if splitmsg[0].startswith(("#!", "-----")):
			for match_infix, dataformat in cmdata_header:
				if match_infix in data:
					break

		if len(dataformat) == 0:
			for match_cm_namespace, match_cm_name, match_cmdata_prefix, match_cmdata_suffix, dataformat in cmdata_format:
				if (len(match_cm_namespace) == 0 or match_cm_namespace == cm_namespace) and cm_name.startswith(match_cm_name) and cmdata_name.startswith(match_cmdata_prefix) and cmdata_name.endswith(match_cmdata_suffix):
					break
	else:
		dataformat = "Empty"

	if dataformat in ["YAML", "JSON"]:
		formatter = iktlib.format_yaml
	elif dataformat == "TOML":
		formatter = iktlib.format_toml
	elif dataformat == "CRT":
		formatter = iktlib.format_crt
	elif dataformat == "XML":
		formatter = iktlib.format_xml
	elif dataformat == "INI":
		formatter = iktlib.format_ini
	elif dataformat == "FluentBit":
		formatter = iktlib.format_fluentbit
	elif dataformat == "CaddyFile":
		formatter = iktlib.format_caddyfile
	elif dataformat == "NGINX":
		formatter = iktlib.format_nginx
	else:
		formatter = iktlib.format_none

	return dataformat, formatter

def identify_formatter(dataformat, kind = None, obj = None, path = None):
	formatter = iktlib.format_none

	if dataformat is None:
		if kind is not None and obj is not None and path is not None:
			if kind == ("ConfigMap", ""):
				cmdata_name = path
				cm_name = deep_get(obj, "metadata#name")
				cm_namespace = deep_get(obj, "metadata#namespace")
				data = deep_get(obj, f"data#{path}")
				dataformat, formatter = identify_cmdata(cmdata_name, cm_name, cm_namespace, data)
			else:
				raise ValueError(f"We do not know how to auto-identify data for kind {kind}")
		else:
			raise ValueError(f"identify_formatter was called without dataformat and kind, obj, or path=None")

	return formatter

def check_cni_updates(cni, current_version):
	new_version = None

	if cni == "weave":
		# GET /report -H 'Accept: application/json'
		# This should be the IP address of the control plane
		# XXX: We probably need to do this locally on the control plane (via ansible) rather than remotely connecting to the control plane
		weaveaddr = "127.0.0.1"

		conn = http.client.HTTPConnection(weaveaddr, 6784)
		headers = {
			"Accept": "application/json"
		}

		try:
			conn.request("GET", "/report", headers = headers)
			r1 = conn.getresponse()
		except ConnectionRefusedError:
			return "<Version check failed>"

		if r1.status == 200:
			weavestatus = json.loads(r1.read())
			if deep_get(weavestatus, "VersionCheck#Enabled", False) == True and deep_get(weavestatus, "VersionCheck#Success", False) == True:
				candidate_version = deep_get(weavestatus, "VersionCheck#NewVersion", None)
				if candidate_version is not None and versiontuple(current_version) < versiontuple(candidate_version):
					new_version = candidate_version
		conn.close()
	else:
		new_version = "<Update check not implemented>"

	return new_version

# FIXME
def networkinfoloop(stdscr, view):
	#field_list, sortcolumn = fieldgenerator(view)
	field_list, sortcolumn = (None, None)
	uip = UIProps(stdscr)

	windowheader = view
	helptext = views[view]["helptext"]
	activatedfun = views[view]["activatedfun"]
	on_activation = deep_get(views[view], "on_activation", {})
	update_delay = views[view].get("update_delay", -1)

	uip.init_window(None, windowheader = windowheader, update_delay = update_delay, sortcolumn = None, helptext = helptext, activatedfun = activatedfun, on_activation = on_activation)

	# For generic information
	infopad = uip.init_infopad(height = 9, width = -1, ypos = 1, xpos = 1)

	# For the status bar; position is always at the bottom of the screen and the entire width of the screen
	statusbar = uip.init_statusbar()

	candidate_version = ""

	while True:
		uip.countdown_to_update()

		if uip.is_update_triggered():
			# The data in some fields might become shorter, so we need to trigger a clear
			uip.infopad.erase()
			uip.statusbar.erase()

			uip.update_window()

			# Try to figure out which CNI we're using, if any
			_cni = kh.identify_cni()

			if len(_cni) == 0:
				cni = "<unknown>"
				cnistr = [(f"{cni}", color_status_group(stgroup.UNKNOWN, False))]
				cni_version = "N/A"
				cni_version_str = [(f"{cni_version}", color_status_group(stgroup.UNKNOWN, False))]
				cni_status = ("N/A", stgroup.UNKNOWN)
			elif len(_cni) == 1:
				cni = _cni[0][0]
				cnistr = [(f"{cni}", ("types", "generic"))]
				cni_version = _cni[0][1]
				cni_version_str = [(f"{cni_version}", ("types", "version"))]
				cni_status = _cni[0][2]
			else:
				cni = "<unknown>"
				cnistr = [(f"Could not uniquely identify CNI ", ("main", "status_not_ok")), ("(", ("types", "generic")), ("Candidates: ", ("main", "infoheader"))]
				for i in range(0, len(_cni)):
					cnistr += [(f"{_cni[i][0]}", ("types", "generic")), ("separators", "version"), (f"{_cni[i][1]}", ("types", "version"))]
					if i < len(_cni) - 1:
						cnistr.append(("separators", "list"))
				cnistr.append((")", ("types", "generic")))
				cni_version = "N/A"
				cni_version_str = [(f"{cni_version[0]}", color_status_group(stgroup.UNKNOWN, False))]
				cni_status = ("N/A", stgroup.UNKNOWN)

			cni_status_str = [(f"{cni_status[0]}", color_status_group(cni_status[1], False))]

			versionarray = [
				("Version: ", ("main", "infoheader")),
			]
			versionarray +=	cni_version_str
			candidateversionarray = [
				("Candidate version: ", ("main", "infoheader")),
			]

			new_version = check_cni_updates(cni, cni_version)
			if new_version is not None:
				candidateversionarray.append((f"{new_version}", ("types", "version")))
			else:
				candidateversionarray.append(("No newer version available", ("types", "generic")))


			namearray = [
				("Container Network Interface: ", ("main", "infoheader")),
			]
			namearray += cnistr
			statusarray = [
				("Status: ", ("main", "infoheader")),
			]
			statusarray += cni_status_str

			uip.addthemearray(infopad, namearray, y = 0, x = 0)
			uip.addthemearray(infopad, versionarray, y = 1, x = 0)
			uip.addthemearray(infopad, candidateversionarray, y = 2, x = 0)
			uip.addthemearray(infopad, statusarray, y = 3, x = 0)

		uip.refresh_window()
		uip.refresh_infopad()
		uip.refresh_statusbar()
		curses.doupdate()

		uip.stdscr.timeout(100)
		c = uip.stdscr.getch()
		retval = uip.generic_keycheck(c)

		if retval == curses_helper.retval.MATCH:
			continue
		elif retval == curses_helper.retval.RETURNONE:
			return curses_helper.retval.RETURNDONE
		elif retval == curses_helper.retval.RETURNFULL:
			return retval

		if c == curses.KEY_F2:
			retval = selectwindow(stdscr, uip)
			if retval == curses_helper.retval.RETURNFULL:
				return retval
			uip.refresh_all()
		elif c == curses.KEY_F3:
			retval = selectwindow(stdscr, uip, refresh_apis = True)
			if retval == curses_helper.retval.RETURNFULL:
				return retval
			uip.refresh_all()
		elif c == ord("B"):
			uip.toggle_borders()
			uip.refresh_all()
			uip.force_update()
		"""
		elif c == ord("U"): # and len(candidate_version) > 0:
			# If we don't recognise the CNI we cannot update it
			if cni == "Unknown":
				continue

			# Try to download and install an update for weave
			if curses_helper.confirmationbox(uip.stdscr, uip.maxy // 2, uip.maxx // 2, title = f"Update Weave to version {candidate_version}:", default = False):
				weaveupdateaddr = "https://cloud.weave.works"

				# Get the Kubernetes version
				# XXX: we can get this using the playbook
				args = [ "kubectl", "version", "-o", "yaml" ]
				result = subprocess.run(args, stdout = PIPE, stderr = PIPE, universal_newlines = True)
				kubeversionoutput = yaml.safe_load(result.stdout)
				kubeversion = deep_get(kubeversionoutput, "serverVersion#major") + "." + deep_get(kubeversionoutput, "serverVersion#minor")

				page = "/k8s/" + kubeversion + "/net.yaml"

				# FIXME: We need some way to handle no_proxy
				https_proxy = deep_get(iktconfig, "Network#https_proxy", "")
				if https_proxy is not None and https_proxy != "":
					pm = urllib3.ProxyManager(https_proxy)
				else:
					pm = urllib3.PoolManager()

				r1 = pm.request("GET", weaveupdateaddr + page)

				if r1.status == 200:
					# Try to get the new weave version, to do a final check
					# whether we need to update or not
					weaveupdate = yaml.safe_load(r1.data)
					new_version = ""
					for item in weaveupdate.get("items"):
						if item.get("kind") == "DaemonSet":
							containers = deep_get(item, "spec#template#spec#containers")

							for container in containers:
								if container.get("name") == "weave":
									tmp = container.get("image", "")
									new_version = re.sub(r".*:", r"", tmp)

					if new_version != "" and versiontuple(current_version) < versiontuple(candidate_version):
						f = tempfile.NamedTemporaryFile()
						f.write(r1.data)
						f.flush()

						# Apply the new configuration
						args = [ "kubectl" , "apply", "-f" ]
						executecommand_multiple(stdscr, f"Updating weave to {new_version}", args, [ f.name ], True)
						f.close()
				pm.clear()
			uip.refresh_all()
		"""

def field_processor_kind(obj, path, extra_path = None, fallback = None, formatting = None):
	match = True
	if path is None or type(path) != list or len(path) != 2 or obj is None:
		match = False
	else:
		resource = deep_get(obj, path[0])
		api_group = deep_get(obj, path[1])
		kind = kh.guess_kind((deep_get(obj, path[0]), deep_get(obj, path[1])))

	if match == False:
		if fallback is None:
			field = [("strings", "none")]
		else:
			field = fallback
	else:
		resource, api_group = kind
		tmp = [resource]
		if len(api_group) > 0:
			tmp.append(api_group)
		if formatting is not None:
			field = __field_processor_list(tmp, formatting = formatting)
		else:
			field = __field_processor_list(tmp)
	return field

# All field processors have to return format lists (aka lists of tuples)
def field_processor_empty(obj, path, extra_paths = None, fallback = None, formatting = None):
	value = deep_get(obj, path)

	if value is None or value == "" or value == -1:
		if fallback is None:
			field = [("strings", "none")]
		else:
			field = fallback
	else:
		if formatting is None:
			formatting = ("types", "generic")
		field = [(f"{value}", formatting)]

	return field

# All field processors have to return format lists (aka lists of tuples)
def field_processor_description(obj, path, extra_paths = None, fallback = None, formatting = None):
	value = deep_get(obj, path)

	if value is None or value == "" or value == -1:
		if fallback is None:
			field = [("strings", "none")]
		else:
			field = fallback
	else:
		# We're not OK with newlines, but " is fine
		value = value.replace("\n", "\\\n").replace("\\\"", "\"")
		if formatting is None:
			formatting = ("types", "generic")
		field = [(f"{value}", formatting)]

	return field

# XXX: Should be rewritten to handle tuple-lists too
def __field_processor_list(values, formatting = None):
	prefix = deep_get(formatting, "prefix", [])
	field_colors = deep_get(formatting, "field_colors", [("types", "field")])
	item_separators = deep_get(formatting, "item_separators", [("separators", "list")])
	repeat_last_item_separator = deep_get(formatting, "repeat_last_item_separator", True)
	suffix = deep_get(formatting, "suffix")
	conditionals = deep_get(formatting, "conditionals", {})
	field = prefix

	i = 0

	for value in values:
		if i < len(field_colors):
			field_color = field_colors[i]
		# An empty value means that we want the separators listed, but no value
		# unless there's an explicit "<<<empty>>>" conditional
		if "<<<empty>>>" in conditionals and value == "":
			value = "<<<empty>>>"

		noseparator = False

		if value != "":
			conditional = deep_get(conditionals, value)
			if conditional is None:
				tmpvalue = f"{value}:<<<{i}>>>"
				conditional = deep_get(conditionals, tmpvalue)
				if conditional is not None:
					value = tmpvalue
			# If we don't match the conditional, or the conditional doesn't apply to this field
			if conditional is None:
				# Check against matchany conditional
				conditional = deep_get(conditionals, "<<<matchany>>>")
				if conditional is None:
					tmpvalue = f"<<<matchany>>>:<<<{i}>>>"
					conditional = deep_get(conditionals, tmpvalue)
					if conditional is not None:
						value = tmpvalue

			if conditional is not None:
				skip = deep_get(conditional, "skip")
				substitute = deep_get(conditional, "substitute")
				stop = deep_get(conditional, "stop")
				field_color = deep_get(conditional, "field_color", field_color)
				noseparator = deep_get(conditional, "no_separator", False)

				if substitute is not None:
					value = substitute
				if skip is None:
					field.append((f"{value}", field_color))
				if stop is not None:
					break
			else:
				field.append((f"{value}", field_color))

		# If this is the last element in the list, append the suffix instead
		item_separator = None
		if i == len(values) - 1:
			item_separator = suffix
		elif noseparator == False:
			if i < len(item_separators):
				item_separator = item_separators[i]
			elif repeat_last_item_separator == True:
				item_separator = item_separators[len(item_separators) - 1]
		i += 1
		# Inserting an item_separator of None
		# means that these two items shouldn't be separated
		if item_separator is None:
			continue
		field.append(item_separator)
	return field

def field_processor_ansible_processor(obj, path = None, extra_paths = None, fallback = None, formatting = None):
	# This assumes symmetrical processors
	data = deep_get(obj, "ansible_processor", "")
	if data is not None and len(data) > 0:
		value = data[2]
	else:
		value = "<unavailable>"
	if formatting is None:
		formatting = ("types", "generic")
	field = [(f"{value}", formatting)]
	return field

def field_processor_ansible_facts(obj, path = None, extra_paths = None, fallback = None, formatting = None):
	values = []
	for path in extra_paths:
		values.append(str(deep_get(obj, path, "")))

	return __field_processor_list(values, formatting)

# Items in extra_paths are processed one by one,
# and printed according to formatting, as follows:
# [prefix]item1[separator(s)]item2[separator(s)]item...[suffix]
#
# path can be used as conditional; if path returns None or len(path) is 0,
# it will be substituted with fallback.
# If path is a tuple, the second argument is either a path or a list of paths
# that should be tried to obtain a value before using the fallback
def field_processor_list(obj, path = None, extra_paths = None, fallback = None, formatting = None):
	fallback_path = None

	if path is not None:
		if type(path) is tuple:
			path, fallback_path = path
		cpath = deep_get(obj, path)
		if cpath is None or len(cpath) == 0:
			if fallback is None:
				return [("strings", "unset")]
			else:
				return fallback

	values = []

	# Create a list of values
	if type(extra_paths) is str:
		values = deep_get(obj, extra_paths)
		if values is None:
			values = []
	else:
		for epath in extra_paths:
			if epath == "":
				value = ""
			else:
				value = deep_get(obj, epath)
				value = "<<<none>>>" if value is None else str(value)
			values.append(value)
	if len(values) == 0:
		if fallback_path is not None:
			if type(fallback_path) is str:
				fallback_path = [fallback_path]
			tmp = deep_get_with_fallback(obj, fallback_path, None)
			if tmp is not None:
				values = [tmp]
		else:
			if fallback is None:
				return [("strings", "unset")]
			else:
				return fallback

	return __field_processor_list(values, formatting)

# The indata is a string that's been formatted as a list;
# Either
# "[key:value],[key:value],..."
# or
# "value,value,..."
# Trying to infer the format by parsing might not be reliable,
# so pass a flag in formatting to decide
def field_processor_str_to_list(obj, path = None, extra_paths = None, fallback = None, formatting = None):
	if obj is None or path is None or len(path) == 0:
		if fallback is None:
			return [("strings", "unset")]
		else:
			return fallback

	iskeyvalue = False

	if formatting is not None:
		 iskeyvalue = deep_get(formatting, "iskeyvalue", False)

	tmp = deep_get(obj, path, "")

	# Start by splitting the string into substrings
	values = tmp.split(",")

	# If this is key:value pairs we need to split these strings again
	if iskeyvalue == True:
		values = list(s.split(":") for s in values)

	return __field_processor_list(values, formatting)

def field_processor_timestamp(obj, path, extra_paths = None, fallback = None, formatting = None):
	timestamp = deep_get(obj, path)

	if timestamp is None:
		field = [("strings", "unset")]
	elif type(timestamp) == datetime:
		field = format_timestamp(timestamp)
	else:
		timestamp = timestamp_to_datetime(timestamp)
		field = format_timestamp(timestamp, localtimezone = True)

	return field

def field_processor_ingress_backend(obj, path = None, extra_paths = None, fallback = None, formatting = None):
	# In ingress v1 backend is called defaultBackend
	path = "spec#backend"

	# FIXME: defaultBackend can also be a resource (apiGroup, kind, name) instead of (name:port)
	if "defaultBackend" in deep_get(obj, "spec"):
		path = "spec#defaultBackend"

	extra_paths = [f"{path}#serviceName", f"{path}#servicePort"]

	return field_processor_list(obj, path = path, extra_paths = extra_paths, fallback = fallback, formatting = formatting)

def field_processor_component_kinds(obj, path = None, extra_paths = None, fallback = None, formatting = None):
	kinds = []

	for item in deep_get(obj, "spec#componentKinds", []):
		group = deep_get(item, "group", "")
		kind = deep_get(item, "kind", "")
		kinds.append((group, kind))

	if len(kinds) == 0:
		field = [("strings", "none")]
	else:
		field = format_list(kinds, 0, 0, False, False, field_colors = [("types", "kind"), ("types", "api_group")], field_separators = [("separators", "kind_api_group")])
	return field

# All fields except obj and owr_path will be ignored
def field_processor_owr_node(obj, owr_path = None, extra_paths = None, fallback = None, formatting = None):
	if owr_path is None:
		owr_path = "metadata#ownerReferences"

	owner_references = deep_get(obj, owr_path)
	field = format_list(get_name_by_kind_from_owner_references(owner_references, "Node"), 0, 0, False, False, field_colors = [("types", "kind"), ("types", "generic")], field_separators = [("separators", "kind")])
	return field

known_pv_types = {
	"awsElasticBlockStore": {
		"type": "AWS Elastic Block Storage",
		"description": "Represents a Persistent Disk resource in AWS",
		"properties": {
			"Volume ID:": { "path": "volumeID" },
			"Partition #:": { "path": "partition" },
			"Filesystem Type:": { "path": "fsType", "default": "ext4" },
			"Read Only:": { "path": "readyOnly", "default": False },
		},
	},
	"azureDisk": {
		"type": "Azure Disk",
		"description": "Azure Data Disk mount on the host and bind mount to the pod",
		"properties": {
			"Disk Name:": { "path": "diskName" },
			"Disk URI:": { "path": "diskURI" },
			"Filesystem Type:": { "path": "fsType", "default": "ext4" },
			"Read Only:": { "path": "readyOnly", "default": False },
			"Caching Mode:": { "path": "cachingMode" },
			"Kind:": { "path": "kind", "default": "shared" },
		},
	},
	"azureFile": {
		"type": "Azure File",
		"description": "Azure File Service mount on the host and bind mount to the pod",
		"properties": {
			"Share Name:": { "path": "shareName" },
			"Read Only:": { "path": "readyOnly", "default": False },
			# These two should combine to a shortcut to a secret; needs formatting + helper
			"Secret Name:": { "path": "secretName" },
			"Secret Namespace:": { "path": "secretNamespace", "default": "<pod namespace>" },
		},
	},
	"cephfs": {
		"type": "Ceph",
		"properties": {
			"Path:": { "path": "path", "default": "/" },
			"Monitors:": { "path": "monitors", "processor": field_processor_list },
			"Read Only:": { "path": "readOnly", "default": "False" },
			"Rados User": { "path": "user", "default": "admin" },
			# Should be a shortcut to a secret; needs formatting
			#"Secret:": { "path": "secretRef" },
			"Secret File:": { "path": "secretFile", "default": "/etc/ceph/user.secret" },
		},
	},
	"cinder": {
		# Deprecated
		"type": "OpenStack Cinder Volume",
		"properties": {
			"Volume ID:": { "path": "volumeID" },
			"Filesystem Type:": { "path": "fsType", "default": "ext4" },
			"Read Only:": { "path": "readOnly", "default": "False" },
			# Should be a shortcut to a secret; needs formatting
			#"Secret:": { "path": "secretRef" },
		},
	},
	"csi": {
		"type": "External CSI Volume",
		"description": "Storage managed by an external CSI volume driver",
		"properties": {
			"Volume Handle:": { "path": "volumeHandle" },
			"Driver:": { "path": "driver" },
			"Filesystem Type:": { "path": "fsType" },
			#{ "path": "controllerExpandSecretRef" },
			#{ "path": "controllerPublishSecretRef" },
			#{ "path": "nodeExpandSecretRef" },
			#{ "path": "nodePublishSecretRef" },
			"Read Only:": { "path": "readOnly" },
			#{ "path": "volumeAttributes" }, #dict(str, str)
		},
	},
	"fc": {
		"type": "Fibre Channel Volume",
		"properties": {
			"Filesystem Type:": { "path": "fsType", "default": "ext4" },
			"WorldWide Identifiers:": { "path": "wwids", "processor": field_processor_list },
			"Target WorldWide Names:": { "path": "targetWWNs", "processor": field_processor_list },
			"Logical Unit Number:": { "path": "lun" },
			"Read Only:": { "path": "readOnly", "default": "False" },
		},
	},
	"flexVolume": {
		"type": "FlexPersistentVolumeSource",
		"description": "Generic persistent volume resource provisioned/attached using an exec based plugin",
		"properties": {
			"Driver:": { "path": "driver" },
			"Filesystem Type:": { "path": "fsType", "default": "<script dependent>" },
			"Read Only:": { "path": "readOnly", "default": "False" },
			# Should be a shortcut to a secret; needs formatting
			#"Secret:": { "path": "secretRef" },
			"Options": { "path": "options", "default": {} },
		},
	},
	"flocker": {
		"type": "Flocker Volume",
		"description": "Flocker Volume mounted by the Flocker agent",
		"properties": {
			"Dataset Name:": { "path": "datasetName" },
			"Dataset UUID:": { "path": "datasetUUID" },
		},
	},
	"gcePersistentDisk": {
		"type": "GCE Persistent Disk",
		"description": "Google Compute Engine Persistent Disk resource",
		"properties": {
			"PD Name:": { "path": "pdName" },
			"Partition:": { "path": "partition" },
			"Filesystem Type:": { "path": "fsType", "default": "ext4" },
			"Read Only:": { "path": "readOnly", "default": "False" },
		},
	},
	"glusterfs": {
		"type": "GlusterFS",
		"description": "Glusterfs mount that lasts the lifetime of a pod",
		"properties": {
			"Path:": { "path", "path" },
			"Endpoints:": { "path": "endpoints" },
			"Endpoints Namespace:": { "path": "endpoints", "default": "<PVC namespace>" },
			"Read Only:": { "path": "readOnly", "default": "False" },
		},
	},
	"hostPath": {
		# Only works in single-node clusters
		"type": "Host Path",
		"description": "Host path mapped into a pod",
		"properties": {
			"Path:": { "path": "path" },
			"Host Path Type:": { "path": "type", "default": "" },
		},
	},
	"iscsi": {
		"type": "iSCSI Disk",
		"properties": {
			"iSCSI Qualified Name:": { "path": "iqn" },
			"Logical Unit Number:": { "path": "lun" },
			"Target Portal:": { "path": "targetPortal" },
			"Target Portals:": { "path": "targetPortals", "processor": field_processor_list },
			"Filesystem Type:": { "path": "fsType", "default": "ext4" },
			"Chap Auth Discovery:": { "path": "chapAuthDiscovery" },
			"Chap Auth Session:": { "path": "chapAuthSession" },
			"iSCSI Initiator:": { "path": "initiatorName" },
			"iSCSI Interface:": { "path": "iscsiInterface", "default": "tcp" },
			"Read Only:": { "path": "readOnly", "default": "False" },
			# Should be a shortcut to a secret; needs formatting
			#"Secret:": { "path": "secretRef" },
		},
	},
	"local": {
		"type": "Local",
		"description": "Directly-attached storage with node affinity",
		"properties": {
			"Path:": { "path": "path" },
			"Filesystem Type:": { "path": "fsType", "default": "<auto-detect>" },
		},
	},
	"nfs": {
		"type": "NFS",
		"description": "NFS mount that lasts the lifetime of a pod",
		"properties": {
			"Server:": { "path": "server" },
			"Path:": { "path": "path" },
			"Read Only:": { "path": "readOnly", "default": "False" },
		},
	},
	"portworxVolume": {
		"type": "Portworx volume",
		"properties": {
			"Volume ID:": { "path": "volumeID" },
			"Filesystem Type:": { "path": "fsType", "default": "ext4" },
			"Read Only:": { "path": "readOnly", "default": "False" },
		},
	},
	"quobyte": {
		"type": "Quobyte Mount",
		"description": "Quobyte mount that lasts the lifetime of a pod",
		"properties": {
			"Volume Name:": { "path": "volume" },
			"Registry:": { "path": "registry", "processor": field_processor_str_to_list, "formatting": { "iskeyvalue": True, "field_separators": [("separators", "host")] } }, # str(host:port, host:port, ...)
			"Read Only:": { "path": "readOnly", "default": "False" },
			"Tenant:": { "path": "tenant" },
			"User:": { "path": "user", "default": "<service account user>" },
			"Group:": { "path": "group", "default": None },
		},
	},
	"rbd": {
		"type": "RBD",
		"description": "Rados Block Device mount that lasts the lifetime of a pod",
		"properties": {
			"Image:": { "path": "image" },
			"Pool:": { "path": "pool", "default": "rbd" },
			"Filesystem Type:": { "path": "fsType", "default": "ext4" },
			"Monitors:": { "path": "monitors", "processor": field_processor_list },
			"Read Only:": { "path": "readOnly" },
			"Rados User": { "path": "user", "default": "admin" },
			"Keyring:": { "path": "keyring", "default": "/etc/ceph/keyring" },
			# Should be a shortcut to a secret; needs formatting
			#"Secret:": { "path": "secretRef" },
		},
	},
	"scaleIO": {
		# Deprecated
		"type": "Persistent ScaleIO Volume",
		"properties": {
			"Volume Name:": { "path": "volumeName" },
			"Gateway:": { "path": "gateway" },
			"Storage Pool:": { "path": "storagePool" },
			"Storage System:": { "path": "system" },
			"Storage Mode:": { "path": "storageMode", "default": "ThinProvisioned" },
			"Filesystem Type:": { "path": "fsType", "default": "xfs" },
			"Protection Domain:": { "path": "protectionDomain" },
			"SSL Enabled:": { "path": "sslEnabled", "default": "False" },
			"Read Only:": { "path": "readOnly" },
			# Should be a shortcut to a secret; needs formatting
			#"Secret:": { "path": "secretRef" },
		},
	},
	"storageos": {
		"type": "Persistent StorageOS Volume",
		"properties": {
			"Volume Name:": { "path": "volumeName" },
			"Volume Namespace:": { "path": "volumeNamespace", "default": "<pod namespace>" },
			"Filesystem Type:": { "path": "fsType", "default": "ext4" },
			"Read Only:": { "path": "readOnly" },
			# Should be a shortcut to a secret; needs formatting
			#"Secret:": { "path": "secretRef" },
		},
	},
	"vsphereVolume": {
		"type": "vSphere Volume",
		"properties": {
			"Volume Path:": { "path": "volumePath" },
			"Filesystem Type:": { "path": "fsType", "default": "ext4" },
			"Storage Policy ID:": { "path": "storagePolicyID" },
			"Storage Policy Name:": { "path": "storagePolicyName" },
		},
	},
}

def get_pv_type(obj):
	for pv_type, pv_data in known_pv_types.items():
		if pv_type in deep_get(obj, "spec", []):
			return pv_type
	return None

# All fields except obj and path are ignored
def field_processor_secret_type(obj, path, extra_paths, fallback = None, formatting = None):
	secret_type = deep_get(obj, "type", "")

	formatting = {
		"field_colors": [("types", "secret_type"), ("types", "generic")],
		"item_separators": [("separators", "secret_type")],
	}

	tmp = re.match(r"^(.*)/(.*)", secret_type)

	if tmp is not None:
		secret_type = [tmp[1], tmp[2]]
		field = __field_processor_list(secret_type, formatting = formatting)
	elif len(secret_type) > 0:
		field = [("", ("types", "generic")), (f"{secret_type}", ("types", "generic"))]
	else:
		field = [("", ("types", "generic")), ("strings", "unset")]
	return field

# All fields except obj and path are ignored
def field_processor_phase_status(obj, path, extra_paths, fallback = None, formatting = None):
	phase = deep_get(obj, path)
	if phase == "Error":
		status_group = stgroup.NOT_OK
	else:
		status_group = stgroup.OK
	field = [(f"{phase}", color_status_group(status_group, False))]
	return field

def field_processor_label_selector(obj, path, extra_paths, fallback = None, formatting = None):
	selector = deep_get(obj, path)
	if selector is not None:
		field = []
		selector = kh.make_selector(selector)
		split_selector = selector.split(",")
		for i in range(0, len(split_selector)):
			field.append((split_selector[i], ("types", "generic")))
			if i < len(split_selector) - 1:
				field.append(("separators", "selector_list"))
	else:
		field = [("strings", "none")]
	return field

def field_processor_match_expressions(obj, path, extra_paths, fallback = None, formatting = None):
	match_expressions = deep_get(obj, path)
	if match_expressions is not None:
		field = [(make_set_expression(match_expressions), ("types", "generic"))]
	else:
		field = [("strings", "none")]
	return field

# everything except obj and path will be ignored
def field_processor_tls(obj, path, extra_paths = None, fallback = None, formatting = None):
	tls = deep_get(obj, path)

	if tls is None:
		field = [("strings", "none")]
	else:
		secretname = deep_get(tls[0], "secretName")
		hosts = deep_get(tls[0], "hosts")

		if secretname is None or hosts is None:
			field = [("strings", "fixme")]
		else:
			field = [
				(secretname, ("main", "highlight")),
				(" terminates ", ("types", "generic")),
			]
			field += format_list(hosts, 0, 0, False, False, field_colors = [("types", "host")])

	return field

def decode_and_view_data(stdscr, **kwargs):
	if "selected" not in kwargs:
		return

	bvalue = kwargs["selected"].value
	title = kwargs["selected"].key
	bvtype = kwargs["selected"].vtype
	vtype, value = decode_value(bvalue)
	if bvalue == value:
		vtype = bvtype

	if vtype.startswith("string"):
		obj = value
	elif vtype.startswith("base64-utf-8"):
		obj = base64.b64decode(value).decode("utf-8")
	elif vtype.startswith("base64-binary") or vtype.startswith("gzip"):
		return
	else:
		raise Exception(f"Trying to export unknown vtype: {vtype}")
	if title.endswith((".crt", "tls.key", ".pem", "CAKey")):
		formatter = iktlib.format_crt
	else:
		formatter = iktlib.format_none
	return resourceinfodispatch(stdscr, obj, ("__ResourceView", ""), title = title, formatter = formatter)

def decode_and_view_file_templates(stdscr, **kwargs):
	selection = deep_get(kwargs, "selection", {})
	if len(selection) == 0:
		return
	obj = deep_get(kwargs, "obj", {})
	if len(obj) == 0:
		return
	name_path = deep_get(kwargs, "name_path")
	name = selection[1][name_path][0]
	file_path = deep_get(kwargs, "file_path")
	files = deep_get(obj, file_path)
	for file in files:
		if deep_get(file, "path", "") == name:
			break
	else:
		return
	encoding = deep_get(file, "encoding", "")
	content = deep_get(file, "content")
	title = name
	if encoding == "":
		if title.endswith((".yml", ".yaml", ".json")):
			formatter = iktlib.format_yaml
		elif title.endswith((".toml")):
			formatter = iktlib.format_toml
		elif title.endswith((".crt", "tls.key", ".pem", "CAKey")):
			formatter = iktlib.format_crt
		elif title.endswith((".xml")):
			formatter = iktlib.format_xml
		elif title.endswith((".ini")):
			formatter = iktlib.format_ini
		else:
			formatter = iktlib.format_none
		return resourceinfodispatch(stdscr, content, ("__ResourceView", ""), title = title, formatter = formatter)
	else:
		vtype, value = decode_value(content)
		if vtype.startswith("string"):
			obj = value
		elif vtype.startswith("base64-utf-8"):
			obj = base64.b64decode(value).decode("utf-8")
		elif vtype.startswith("base64-binary") or vtype.startswith("gzip"):
			return
		if title.endswith((".crt", "tls.key", ".pem", "CAKey")):
			formatter = iktlib.format_crt
		else:
			formatter = iktlib.format_none
		return resourceinfodispatch(stdscr, obj, ("__ResourceView", ""), title = title, formatter = formatter)
	return

def export_data(stdscr, **kwargs):
	if "selected" not in kwargs:
		return

	value = kwargs["selected"].value
	filename = deep_get(kwargs, "result")
	vtype, value = decode_value(value)

	if vtype.startswith("string"):
		f = open(filename, "w")
		f.write(value)
	elif vtype.startswith("base64-utf-8"):
		f = open(filename, "w")
		f.write(base64.b64decode(value).decode("utf-8"))
	elif vtype.startswith("base64-binary") or vtype.startswith("gzip"):
		f = open(filename, "wb")
		f.write(base64.b64decode(value))
	else:
		raise Exception(f"Trying to export unknown vtype: {vtype}")
	f.close()

def generate_helptext(view, viewtype, additional_helptexts = [], shortcuts = []):
	helptext = []

	if viewtype == "infoview":
		helptext += helptexts.infoviewheader

		if view not in infoviews:
			helptext += helptexts.spacer
			helptext += additional_helptexts
			return helptext

		viewref = infoviews[view]

		if "listpad" in viewref:
			if deep_get(viewref, "activatedfun") is not None:
				helptext.append(("[Enter]", "Open info page for selected resource"))

		if len(additional_helptexts) > 0:
			helptext += helptexts.spacer
			helptext += additional_helptexts

		if len(shortcuts) > 0:
			for shortcut in shortcuts:
				tmp = deep_get(shortcuts[shortcut], f"helptext")
				if tmp is not None:
					helptext.append(tmp)

		if "listpad" in viewref:
			helptext += helptexts.spacer

			if deep_get(viewref, "reversible", True) == False:
				helptext += helptexts.irreversiblelistmovement
			else:
				helptext += helptexts.listmovement
		elif "logpad" in viewref:
			helptext += helptexts.linewrap
			helptext += helptexts.toggleformatter
			helptext += helptexts.spacer
			helptext += helptexts.logmovement
	elif viewtype == "listview":
		helptext += helptexts.listviewheader

		viewref = views[view]

		if viewref["kind"] in infoviews:
			helptext += helptexts.openresource

		if "shortcuts" in viewref:
			for shortcut in deep_get(viewref, "shortcuts"):
				tmp = deep_get(viewref, f"shortcuts#{shortcut}#helptext")
				if tmp is not None:
					helptext.append(tmp)
			helptext += helptexts.spacer

		if deep_get(viewref, "is_taggable", True) == True:
			helptext += helptexts.tagactions
			helptext += helptexts.spacer
			if deep_get(viewref, "labels", True) == True:
				helptext += helptexts.selectoractions
				helptext += helptexts.spacer

		helptext += helptexts.listmovement

	return helptext

def genericinfoloop(stdscr, obj, view, **kwargs):
	global initial_container

	# If obj is a tuple we got the object as obj[0]
	# params as obj[1]
	if type(obj) is tuple:
		objparams = obj[1]
		obj = obj[0]
	else:
		objparams = None

	# If we're using the logpad this can be used to format the data
	formatter_path = deep_get(kwargs, "formatter_path")
	# formatter_path has precedence over formatter, to allow ConfigMaps to work properly
	formatter = deep_get(kwargs, "formatter")
	if formatter_path is not None:
		formatter = deep_get(obj, formatter_path)
	elif formatter is not None:
		if type(formatter) == str:
			formatter = eval(formatter)
	obj_path = deep_get(kwargs, "obj_path")
	title = None
	if obj_path is not None:
		title_path = deep_get(kwargs, "title_path")
		if title_path is not None:
			title = deep_get(obj, title_path)
		obj = deep_get(obj, obj_path)

	uip = UIProps(stdscr)

	if view not in infoviews:
		return curses_helper.retval.NOMATCH

	viewref = infoviews[view]

	searchmatch = []

	objgetter = deep_get(viewref, "objgetter")
	if objgetter is not None:
		obj = objgetter(obj)
		if obj is None or len(obj) == 0:
			return curses_helper.retval.NOMATCH

	# XXX: For now we don't support custom fields for the lists on the info pages
	field_indexes = deep_get(viewref, "field_indexes", {})
	field_index = "Normal"

	sortcolumn = deep_get(viewref, "sortcolumn")
	field_denylist = deep_get(viewref, "field_denylist", [])
	field_dict, field_names, sortcolumn = fieldgenerator(view, field_index = field_index, field_indexes = field_indexes, fields = deep_get(viewref, "fields"), sortcolumn = sortcolumn, denylist = field_denylist)

	# If no window header has been specified that overrides the default, just use the view name with " Info" tacked on at the end
	# XXX: The fallback should be removed once we use view files for all info views, since the title is mandatory there
	windowheader = deep_get(viewref, "windowheader", f"{view[0]} Info")
	if title is not None:
		windowheader = title
	elif "title" in kwargs:
		windowheader = deep_get(kwargs, "title")
	elif "title_path" in kwargs:
		windowheader = deep_get(obj, title_path, windowheader)

	sortorder_reverse = deep_get(viewref, "sortorder_reverse", False)
	reversible = deep_get(viewref, "reversible", True)
	activatedfun = deep_get(viewref, "activatedfun")
	on_activation = deep_get(viewref, "listpad#on_activation", {})
	labels = deep_get(viewref, "labels", "metadata#labels")
	annotations = deep_get(viewref, "annotations", "metadata#annotations")
	extraref = deep_get(viewref, "extraref")
	data = deep_get(viewref, "data", None)
	name_path = deep_get(viewref, "name_path", "metadata#name")
	namespace_path = deep_get(viewref, "namespace_path", "metadata#namespace")
	creation_timestamp_path = deep_get(viewref, "creation_timestamp_path", "metadata#creationTimestamp")
	if data is not None:
		data = obj
	viewoverride = deep_get(viewref, "viewoverride", view)
	infopadheight = 0
	if "infopad" in viewref:
		# Number of fields added conditionally
		if name_path is not None and len(name_path) > 0 and deep_get(obj, name_path) is not None:
			infopadheight += 1
		if namespace_path is not None and len(namespace_path) > 0 and deep_get(obj, namespace_path) is not None:
			infopadheight += 1
		if creation_timestamp_path is not None and len(creation_timestamp_path) > 0 and deep_get(obj, creation_timestamp_path) is not None:
			infopadheight += 1
		# Number of custom fields
		infopadheight += len(deep_get(viewref, "infopad", {}))
		# If we *only* have an infopad, then it should cover at least the entire screen; if not it should be as big as needed;
		# it doesn't really matter if we allocate an infopad larger than the screen, but this should be correct.
		if "listpad" not in viewref and "logpad" not in viewref:
			maxyx = stdscr.getmaxyx()
			infopadheight = max(infopadheight, maxyx[0] - 3)

	shortcuts = copy.deepcopy(deep_get(viewref, "shortcuts", {}))

	# Shortcuts
	# Always include the shortcut for namespaces, unless overriden
	# or the namespace_path returns None
	#
	# An override is necessary if metadata#namespace isn't the correct path
	# or some other changes are necessary
	if deep_get(shortcuts, "Namespace") is None and deep_get(obj, namespace_path) is not None:
		shortcuts["Namespace"] = {
			"shortcut": ord("N"),
			"helptext": ("[Shift] + N", "Open info page for Namespace"),
			"call": resourceinfodispatch,
			"kind": ("Namespace", ""),
			"name_path": "metadata#namespace",
		}

	# Always include the shortcut for security contexts,
	# unless the path returns None
	if "securityContext" in deep_get(obj, "spec", {}) or "securityContext" in deep_get(obj, "spec#template#spec", {}):
		shortcuts["Show Security Context"] = {
			"shortcut": ord("x"),
			"helptext": ("X", "Show security context information"),
			"widget": "windowwidget",
			"title": "Security Context Policies:",
			"headers": ["Policy:", "Value:"],
			"itemgetter": get_security_context,
			"formatting": [("windowwidget", "default"), ("windowwidget", "highlight")],
		}

	# Always include the shortcut for conditions,
	# unless the path returns None
	if "conditions" in deep_get(obj, "status", {}):
		shortcuts["Show Resource Conditions"] = {
			"shortcut": ord("c"),
			"helptext": ("C", "Show resource conditions"),
			"widget": "windowwidget",
			"title": "Conditions:",
			"headers": ["Type:", "Status:", "Last Probe:", "Last Transition:", "Message:"],
			"itemgetter": __get_conditions,
		}

	# Always include the shortcut for events unless overriden
	if deep_get(viewref, "shortcuts#Show Events") is None:
		shortcuts["Show Events"] = {
			"shortcut": ord("e"),
			"helptext": ("E", "Show events"),
			"widget": "windowwidget",
			"selectable": True,
			"action": "call",
			"action_call": resourceinfodispatch_with_lookup,
			"action_args": {
				"kind": "Event",
				"namespace_path": 0,
				"name_path": 1,
			},
			"title": "Events:",
			"headers": ["Namespace:", "Name:", "Last Seen:", "Status:", "Reason:", "Source:", "First Seen:", "Count:", "Message:"],
			"itemgetter": __get_events,
		}

	# Always include the shortcut for YAML dump, unless overridden
	if deep_get(viewref, "shortcuts#YAML") is None:
		shortcuts["View YAML dump of resource"] = {
			"shortcut": ord("y"),
			"helptext": ("Y", "View YAML dump of resource"),
			"widget": "callout",
			"title": "YAML dump",
			"callout": infoview_view_yaml,
		}

	# Always include the shortcut for last applied configuration, unless overridden
	if deep_get(viewref, "shortcuts#Last Applied Configuration") is None:
		shortcuts["Last Applied Configuration"] = {
			"shortcut": ord("L"),
			"helptext": ("[Shift] + L", "Show last applied configuration"),
			"widget": "callout",
			"title": "Last applied configuration",
			"callout": infoview_view_last_applied_configuration,
		}

	if deep_get(iktconfig, "Internal#sanity_check_views", False) == True:
		sanity = True
		_shortcuts = {}
		for shortcut in shortcuts:
			_shortcut = shortcuts[shortcut].get("shortcut")
			if _shortcut is None:
				continue
			if type(_shortcut) != list:
				_shortcut = [_shortcut]
			for _sc in _shortcut:
				if _sc in _shortcuts:
					sys.exit(f"infoview {view}: The same keypress ({_sc}) is used for both \"{shortcut}\" and \"{_shortcuts[_sc]}\"; aborting.")
				else:
					_shortcuts[_sc] = shortcut

	# Conditional helptexts
	additional_helptexts = []
	if deep_get(obj, labels) is not None:
		additional_helptexts += helptexts.labels
	if deep_get(obj, annotations) is not None:
		additional_helptexts += helptexts.annotations

	helptext = generate_helptext(view, "infoview", additional_helptexts, shortcuts = shortcuts)

	uip.init_window(field_dict, windowheader = windowheader, view = viewoverride, sortcolumn = sortcolumn, sortorder_reverse = sortorder_reverse, reversible = reversible, helptext = helptext, activatedfun = activatedfun, on_activation = on_activation, extraref = extraref, data = obj)

	# For generic information
	if infopadheight > 0:
		infopad = uip.init_infopad(height = infopadheight, width = -1, ypos = 1, xpos = 1, labels = deep_get(obj, labels), annotations = deep_get(obj, annotations))
	else:
		infopad = None

	# For the status bar; position is always at the bottom of the screen and the entire width of the screen
	statusbar = uip.init_statusbar()

	# For lists
	headerpad = None
	listpad = None
	if len(deep_get(viewref, "listpad", {})) > 0:
		if infopadheight == 0:
			headerpad, listpad = uip.init_listpad(listheight = 1, width = -1, ypos = 1, xpos = 1)
		else:
			headerpad, listpad = uip.init_listpad(listheight = 1, width = -1, ypos = infopadheight + 2, xpos = 1)

	# For log pads; we cannot have both a logpad and a listpad simultaneously;
	# at least not with the current implementation
	logpad = deep_get(viewref, "logpad")
	if logpad is not None:
		if listpad is not None:
			raise Exception("We cannot have listpad and logpad simultaneously")

		timestamps = deep_get_with_fallback(viewref, ["logpad#timestamps", "timestamps"], True)
		if infopadheight == 0:
			tspad, logpad = uip.init_logpad(width = -1, ypos = 1, xpos = 1, timestamps = timestamps)
		else:
			tspad, logpad = uip.init_logpad(width = -1, ypos = infopadheight + 2, xpos = 1, timestamps = timestamps)

	wrap_lines = False
	raw_output = False

	while True:
		uip.countdown_to_update()

		# Output listpad if we have one
		if uip.is_update_triggered():
			# The data in some fields might become shorter, so we need to trigger a clear
			if infopad is not None:
				uip.infopad.erase()
			uip.statusbar.erase()

			# Refresh obj whenever we reload, unless this is a special view
			if not view[0].startswith("__"):
				obj = kh.get_ref_by_kind_name_namespace(view, deep_get(obj, "metadata#name"), deep_get(obj, "metadata#namespace"))

				if obj is None:
					title = "Error!"
					errormsg = [(0,
						[("Resource not available; it may have been deleted", ("types", "generic"))])]
					curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, errormsg, title = title, cursor = False)
					return curses_helper.retval.RETURNDONE

			uip.update_window()

			if listpad is not None:
				listref = deep_get(viewref, "listpad#listref")
				listgetter = deep_get(viewref, "listpad#listgetter")
				listgetter_args = deep_get(viewref, "listpad#listgetter_args", {})
				_kind = deep_get(listgetter_args, "_kind")
				_kind_path = deep_get(listgetter_args, "_kind_path")
				_api_family = deep_get(listgetter_args, "_api_family")
				_api_family_path = deep_get(listgetter_args, "_api_family_path")
				_label_selector_path = deep_get(listgetter_args, "_label_selector_path")
				_label_selector_key_values = deep_get(listgetter_args, "_label_selector_key_values")
				if _label_selector_path is not None:
					listgetter_args["label_selector"] = kh.make_selector(deep_get(obj, _label_selector_path))
				elif _label_selector_key_values is not None:
					label_selectors = {}
					for label_key, label_value in _label_selector_key_values:
						if type(label_value) == str:
							label_selectors[label_key] = label_value
						elif type(label_value) == list:
							label_selectors[label_key] = deep_get_with_fallback(obj, label_value)
					listgetter_args["label_selector"] = kh.make_selector(label_selectors)
				_field_selector = deep_get(listgetter_args, "_field_selector", {})
				if len(_field_selector) > 0:
					field_selectors = {}
					for field_key, field_value in _field_selector.items():
						if type(field_value) == list:
							field_selectors[field_key] = deep_get_with_fallback(obj, field_value)
						else:
							field_selectors[field_key] = field_value
					listgetter_args["field_selector"] = kh.make_selector(field_selectors)
				if _kind is None:
					_kind = deep_get(obj, _kind_path)
				if _api_family is None:
					_api_family = deep_get(obj, _api_family_path, "")
				if _kind is not None:
					_kind = kh.guess_kind((_kind, _api_family))
				_namespace = deep_get(listgetter_args, "namespace")
				_namespace_path = deep_get(listgetter_args, "_namespace_path", "")
				if _namespace is None:
					_namespace = deep_get(obj, _namespace_path, "")
				listgetter_args["kind"] = _kind
				listgetter_args["namespace"] = _namespace
				if "_pass_obj" in listgetter_args:
					listgetter_args["_obj"] = obj
				infogetter = deep_get(viewref, "listpad#infogetter")
				infogetter_filters = deep_get(viewref, "listpad#infogetter_filters", None)
				infogetter_args = deep_get(viewref, "listpad#infogetter_args", {})

				filters = None
				if infogetter_filters is not None:
					filters = []
					if infogetter_filters is not None:
						for key, value in infogetter_filters:
							filters.append((eval(key), eval(value)))
				fields = deep_get(viewref, "fields", [])

				if listref is not None:
					vlist = deep_get(obj, listref)
				elif listgetter is not None:
					if type(listgetter) == str:
						vlist, status = eval(listgetter)
					elif listgetter == generic_listgetter:
						vlist, status = listgetter(**listgetter_args)
					else:
						vlist, status = listgetter(obj, **listgetter_args)
				else:
					vlist = obj

				infogetter_args.pop("_vlist", None)
				infogetter_args["_vlist"] = vlist

				infogetter_args.pop("_field_index", None)
				infogetter_args["_field_index"] = field_index

				infogetter_args.pop("_field_names", None)
				infogetter_args["_field_names"] = field_names

				infogetter_args.pop("_field_dict", None)
				infogetter_args["_field_dict"] = field_dict

				infogetter_args.pop("_filters", None)
				infogetter_args["_filters"] = filters

				infogetter_args.pop("_obj", None)
				infogetter_args["_obj"] = obj

				extra_data = {}
				for key, value in deep_get(infogetter_args, "_extra_data", {}).items():
					if type(value) == list:
						tmp = deep_get_with_fallback(obj, value)
						extra_data[key] = tmp
					else:
						extra_data[key] = value
				infogetter_args["extra_data"] = extra_data
				info = infogetter(**infogetter_args)

				listlen = uip.update_info(info)
				linelen = update_field_widths(field_dict, field_names, uip.info)
				uip.resize_listpad(listlen, linelen)
			elif logpad is not None:
				if formatter is not None:
					formatted_obj = formatter(obj, raw = raw_output)
				else:
					formatted_obj = obj

				infogetter = deep_get(viewref, "logpad#infogetter")
				infogetter_args = deep_get(viewref, "logpad#infogetter_args", {})
				if infogetter is not None:
					messages = infogetter(formatted_obj, **infogetter_args)
					uip.update_log_info(None, None, None, messages)
					uip.loglen = len(messages)

			if infopad is not None:
				y = 0
				if name_path is not None and len(name_path) > 0:
					fieldarray = [
						("Name:", ("main", "infoheader")),
						(f" {deep_get(obj, name_path)}", ("types", "generic"))
					]
					uip.addthemearray(infopad, fieldarray, y = y, x = 0)
					y += 1

				if namespace_path is not None and len(namespace_path) > 0 and deep_get(obj, namespace_path) is not None:
					fieldarray = [
						("N", ("main", "infoheader_shortcut")), ("amespace:", ("main", "infoheader")),
						(f" {deep_get(obj, namespace_path)}", ("types", "generic"))
					]
					uip.addthemearray(infopad, fieldarray, y = y, x = 0)
					y += 1

				for key, value in deep_get(viewref, "infopad", {}).items():
					# If there's a header field, this is from a view file; otherwise it's an old-style field
					fieldarray = []
					header = deep_get(value, "header")

					if header is not None:
						fieldarray += header
						# Only add stuff if there's a path
						if "path" in value or "paths" in value:
							# Use generic_infogetter for this
							data = get_obj(obj = obj, field_dict = {key: value}, field_names = [key])
							_formatter = {key: get_formatter(value)}
							_generator = deep_get(_formatter, f"{key}#generator")
							if _generator is not None:
								ralign = deep_get(_formatter, f"{key}#ralign")
								formatting = deep_get(_formatter, f"{key}#formatting")
								fieldarray += [(" ", ("types", "generic"))]
								fieldarray += _generator(data, key, fieldlen = 0, pad = 0, ralign = ralign, selected = False, **formatting)
						uip.addthemearray(infopad, fieldarray, y = y, x = 0)

						y += 1
						continue

					fieldarray = deep_get(value, "fieldname", [(key, ("main", "infoheader"))])
					uip.addthemearray(infopad, fieldarray, y = y, x = 0)

					path = deep_get(value, "path")
					extra_paths = deep_get(value, "extra_paths")
					fallback = deep_get(value, "fallback")
					if "processor" in value:
						field_processor = deep_get(value, "processor")
					else:
						field_processor = field_processor_empty
					formatting = deep_get(value, "formatting")

					# objparam will replace fallback; this is too ugly for words
					if objparams is not None:
						objparam = deep_get(value, "objparam")
						if objparam is not None and len(objparams) > objparam:
							tmp = objparams[objparam]
							fallback = [(f"{tmp}", ("types", "generic"))]

					# If we neither get a path nor a field processor to use on the object,
					# we only output the field array; to achieve this pass None as processor.
					# If processor is omitted field_processor_empty() will be used by default.
					if field_processor is None and path is None:
						y += 1
						continue

					if field_processor is None:
						val = deep_get(obj, path, "")
						fieldarray = [(" %s" % val, ("types", "generic"))]
					else:
						fieldarray = [(" ", ("types", "generic"))]
						fieldarray += field_processor(obj, path, extra_paths, fallback, formatting)
					uip.addthemearray(infopad, fieldarray, y = y)
					y += 1

				if creation_timestamp_path is not None and len(creation_timestamp_path) > 0 and deep_get(obj, creation_timestamp_path) is not None:
					fieldarray = [
						("Created: ", ("main", "infoheader")),
					]
					fieldarray += field_processor_timestamp(obj, creation_timestamp_path)
					uip.addthemearray(infopad, fieldarray, y = y, x = 0)

		# Output listpad if we have one
		if listpad is not None:
			y = 0

			uip.update_sorted_list()
			generate_listheader(uip, headerpad, field_dict)
			for item in uip.sorted_list:
				uip.select_if_y(y, item)
				generate_list(uip, listpad, item, field_dict, y, uip.is_selected(item))
				y += 1

		# Output logpad if we have one
		if logpad is not None and uip.refresh == True:
			uip.logpad.erase()
			# This is needed in case we get a resize event or toggle borders
			uip.resize_logpad(uip.maxy - uip.logpadypos - 2, 0)
			maxx = 0
			yadd = 0
			for y in range(0, min(uip.logpadheight, len(messages))):
				message = messages[uip.yoffset + y]
				current_match = False
				if len(uip.search_matches) > 0:
					line_match = uip.yoffset + y in uip.search_matches
					match_prefix = [("separators", "matchbullet")]
					if line_match == False:
						match_prefix = [("".ljust(len(curses_helper.themearray_get_string(match_prefix))), ("types", "generic"))]
					if uip.match_index is not None and uip.yoffset + y == uip.match_index:
						current_match = True
					message = match_prefix + message
				if wrap_lines == True:
					sideadjust = 0
					if uip.borders == False:
						sideadjust = 2
					maxwidth = uip.logpadminwidth + sideadjust
				else:
					maxwidth = -1
				_lines = strarray_wrap_line(message, maxwidth, wrap_marker = (uip.borders or get_mousemask() != 0))
				for i in range(0, len(_lines)):
					if y + yadd + i >= uip.logpadheight:
						break
					ypos, xpos = uip.addthemearray(logpad, _lines[i], y = y + yadd + i, x = 0, selected = current_match)
					maxx = max(maxx, xpos)
				yadd += i
			uip.resize_logpad(-1, maxx)

		uip.refresh_window()
		uip.refresh_infopad()
		uip.refresh_listpad()
		uip.refresh_logpad()
		uip.refresh_statusbar()
		curses.doupdate()
		uip.refresh = False

		# XXX: Handle initial containers and configmaps
		#      This should be done by the same code path as a regular activation; this solution is too ugly for words
		if initial_container is not None:
			match = None

			if len(uip.info) > 0:
				match_count = 0

				obj_path = deep_get(viewref, "listpad#on_activation#obj_path")
				for item in uip.info:
					# If we're dealing with a config map we're interested in non-binary types
					# If we're dealing with a pod we're interested in containers
					if hasattr(item, "type") and item.type in ["[container]", "[init_container]"]:
						name = item.ref["name"]
						ikind = item.type
					elif view == ("ConfigMap", "") and item.type in [rtype[4] for rtype in cmdata_format]:
						name = item.data
						ikind = deep_get(viewref, "listpad#on_activation#kind", "")
						if type(ikind) == str:
							iapi_family = deep_get(viewref, "listpad#on_activation#api_family", "")
							ikind = kh.guess_kind((ikind, iapi_family))
					else:
						continue

					# If name isn't set we skip
					if name is None:
						continue
					# If we have an exact match we don't care about partial matches
					elif name == initial_container:
						if view == ("ConfigMap", ""):
							match = item.data
						else:
							match = item.ref
						match_count = 1
						break
					elif name.startswith(initial_container):
						# Since the exact match might occur later than the partial we cannot abort
						# on partial matches; instead just save the match and continue searching.
						# If we get more than one partial match we ignore the partial matches.
						if match_count == 0:
							if view == ("ConfigMap", ""):
								match = item.data
							else:
								match = item.ref
						match_count += 1

				initial_container = None

				if match is not None and match_count == 1:
					on_activation_args = {}
					formatter_path = deep_get(viewref, "listpad#on_activation#formatter_path")
					if deep_get(viewref, "listpad#on_activation#formatter", "") == "identify":
						formatter = identify_formatter(None, kind = view, obj = obj, path = match)
						on_activation_args["formatter"] = formatter
					else:
						formatter = deep_get(viewref, "listpad#on_activation#formatter")
						formatter_path = deep_get(viewref, "listpad#on_activation#formatter_path")
						on_activation_args["formatter"] = formatter
						on_activation_args["formatter_path"] = formatter_path
					if view == ("ConfigMap", ""):
						retval = uip.activatedfun(uip.stdscr, deep_get(obj, f"data#{match}", ""), ikind, info = None, title = name, **on_activation_args)
					else:
						retval = uip.activatedfun(uip.stdscr, match, ikind, info = obj, **on_activation_args)
					if retval == curses_helper.retval.RETURNFULL:
						return retval
					uip.force_update()
					uip.refresh_all()
					continue

		uip.stdscr.timeout(100)
		c = uip.stdscr.getch()
		retval = uip.generic_keycheck(c)

		if retval == curses_helper.retval.MATCH:
			continue
		elif retval == curses_helper.retval.RETURNONE:
			return curses_helper.retval.RETURNDONE
		elif retval == curses_helper.retval.RETURNFULL:
			return retval

		if c == curses.KEY_F2:
			retval = selectwindow(stdscr, uip)
			if retval == curses_helper.retval.RETURNFULL:
				return retval
			uip.refresh_all()
		elif c == curses.KEY_F3:
			retval = selectwindow(stdscr, uip, refresh_apis = True)
			if retval == curses_helper.retval.RETURNFULL:
				return retval
			uip.refresh_all()
		elif c == ord("B"):
			uip.toggle_borders()
			uip.refresh_all()
			uip.force_update()
		elif c == ord("R") and logpad is not None:
			raw_output = not raw_output
			uip.refresh_all()
			uip.force_update()
		elif c == ord("W"):
			wrap_lines = not wrap_lines
			uip.refresh_all()
			uip.force_update()

		for key, value in shortcuts.items():
			shortcut_keys = deep_get(value, "shortcut")
			if shortcut_keys is None:
				continue

			if type(shortcut_keys) != list:
				shortcut_keys = [shortcut_keys]

			if c not in shortcut_keys:
				continue

			widget = deep_get(value, "widget")
			force_update = deep_get(value, "force_update", True)
			changed = False
			tmpselection = None
			if widget is not None:
				if widget == "windowwidget":
					w_title = deep_get(value, "title", "")
					w_headers = deep_get(value, "headers")
					w_itemgetter = deep_get(value, "itemgetter")
					w_itemgetter_args = deep_get(value, "itemgetter_args", {})
					w_selectable = deep_get(value, "selectable", False)
					w_callout = deep_get(value, "callout", None)
					w_kind = deep_get(value, "kind", view)
					if "_slow_task_msg" in w_itemgetter_args:
						w_win = curses_helper.notice(uip.stdscr, uip.maxy // 2, uip.maxx // 2, message = deep_get(w_itemgetter_args, "_slow_task_msg"))
					w_items = w_itemgetter(obj, **w_itemgetter_args)

					# If the first element is an integer we assume that we've been provided
					# a pre-formatted list. Otherwise we apply formatting if available.
					# If not available we try to provide some sensible defaults.
					if w_items is not None and len(w_items) > 0 and type(w_items[0][0]) != int:
						tmp_items = []
						w_formatting = deep_get(value, "formatting", [("windowwidget", "default")])
						# w_item is a line
						for w_item in w_items:
							tmp = [widgetlineattrs.NORMAL]
							# w_item[i] is a column
							for i in range(0, len(w_item)):
								tmp.append([(w_item[i], w_formatting[min(i, len(w_formatting) - 1)])])

							tmp_items.append(tuple(tmp))
						w_items = tmp_items

					if w_items is not None and len(w_items) > 0:
						w_sortcolumn = deep_get(value, "sortcolumn")
						tmpselection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, items = w_items, headers = w_headers, title = w_title, cursor = w_selectable)
						if w_selectable is True and tmpselection != (0, [("", None)]):
							# If callout is None we might still have an action later
							if w_callout is not None:
								retval = w_callout(uip, w_kind, obj, selection = tmpselection)
								if retval is not None and retval == curses_helper.retval.RETURNFULL:
									return retval
						changed = True
				elif widget == "inputbox":
					selected = uip.get_selected()
					w_title = deep_get(value, "inputtitle", "")
					w_result = curses_helper.inputbox(uip.stdscr, uip.maxy // 2, 1, uip.maxy - 1, uip.maxx - 1, w_title)
					if w_result is None or len(w_result) == 0 or w_title == "" or len(selected.value) == 0:
						continue
					# This is necessary because we never go through the normal update cycle for the listpad and infopad
					uip.refresh_infopad()
					uip.refresh_listpad()
					uip.refresh_logpad()
					uip.refresh_statusbar()
					curses.doupdate()
					w_confirm = deep_get(value, "confirm", False)
					# Check this condition before confirming
					w_confirm = deep_get(value, "confirm")
					if type(w_confirm) == str:
						w_confirm = eval(w_confirm)
					if w_confirm == True:
						curses.doupdate()
						w_confirmtitle = deep_get(value, "confirmtitle")
						if curses_helper.confirmationbox(uip.stdscr, uip.maxy // 2, uip.maxx // 2, title = w_confirmtitle, default = False) == False:
							continue
				elif widget == "executecommand":
					selected = uip.get_selected()
					w_kinds = deep_get_with_fallback(value, ["widget_args#kinds", "kinds"])
					if (w_kinds is None):
						continue
					if w_kinds != ["<native>"] and (selected is None or not selected.kind in w_kinds) and w_kinds != [("", "")]:
						continue

					w_inputtitle = deep_get_with_fallback(value, ["widget_args#inputtitle", "inputtitle"])
					if w_inputtitle is not None:
						w_input = curses_helper.inputbox(uip.stdscr, uip.maxy // 2, 1, uip.maxy - 1, uip.maxx - 1, title = w_inputtitle)
						w_command = w_input.split()
					else:
						w_command = deep_get_with_fallback(value, ["widget_args#command", "command"], [])
					if len(w_command) == 0:
						continue

					w_waitforkeypress = deep_get_with_fallback(value, ["widget_args#waitforkeypress", "waitforkeypress"], False)
					if type(selected) == ResourceInfo:
						# This needs to be generalised somehow; so does the message
						containername = selected.ref["name"]
					elif not (w_kinds == ["<native>"] and w_command == ["<dnsutils>"]):
						sys.exit(f"Cannot handle type {type(selected)} in executecommand();\nw_kinds={w_kinds}\nw_command={w_command}")
					if w_command == [ "<ephemeral>" ]:
						ephemeral_image = deep_get(iktconfig, "Debug#ephemeral_image", "busybox")
						msg = [(f"Creating ephemeral ", "action"), (ephemeral_image, "programname"), (" container sharing process namespace with ", "action"), (f"{containername}", "path")]
					elif w_command == [ "<dnsutils>" ]:
						node_name = deep_get(obj, "metadata#name")
						containername = None
						msg = [(f"Opening dnsutils container on ", "action"), (node_name, "hostname")]
					else:
						msg = [(f"Executing ", "action"), (w_command[0], "programname"), (" inside ", "action"), (containername, "path")]
					executecommand(uip.stdscr, obj, containername, msg, command = w_command, waitforkeypress = w_waitforkeypress)
					changed = True
				elif widget == "callout":
					selected = uip.get_selected()
					w_title = deep_get(value, "title", "")
					w_headers = deep_get(value, "headers")
					w_itemgetter = deep_get(value, "itemgetter")
					w_sortcolumn = deep_get(value, "sortcolumn")
					w_callout = deep_get(value, "callout")
					w_callout_args = deep_get(value, "callout_args", {})
					w_kind = deep_get(value, "kind", view)
					# Try to be as generic as we can;
					# pass all kinds of information and let the handler use whatever information it needs
					retval = w_callout(uip, w_kind, obj, selected = selected, title = w_title, headers = w_headers, itemgetter = w_itemgetter, sortcolumn = w_sortcolumn, **w_callout_args)
					if retval is not None and retval == curses_helper.retval.RETURNFULL:
						return retval
			if "action" in value:
				selected = uip.get_selected()
				action = deep_get(value, "action", "")
				action_args = deep_get(value, "action_args", {})
				if "_pass_obj" in action_args:
					action_args["obj"] = obj
				if "_pass_result" in action_args and selected is not None:
					action_args["result"] = w_result
				if "_pass_selected" in action_args and selected is not None:
					action_args["selected"] = selected
				if "_pass_selected_obj" in action_args and selected is not None:
					action_args["selected_obj"] = getattr(selected, "ref", None)
				if tmpselection is not None:
					action_args["selection"] = tmpselection
				action_call = deep_get(value, "action_call")
				if action == "call" and action_call is not None:
					retval = action_call(uip.stdscr, **action_args)
					if retval is not None and retval == curses_helper.retval.RETURNFULL:
						return retval
				elif action == "execute":
					_command = deep_get(action_args, "command", [])
					# replace paths with data
					if len(_command) > 0:
						command = []
						for _cmd in _command:
							if type(_cmd) == list:
								command.append(deep_get_with_fallback(obj, _cmd))
							else:
								command.append(_cmd)
					# Check this condition before confirming
					w_confirm = deep_get(value, "confirm")
					if type(w_confirm) == str:
						w_confirm = eval(w_confirm)
					if w_confirm == True:
						curses.doupdate()
						w_confirmtitle = deep_get(value, "confirmtitle")
						if curses_helper.confirmationbox(uip.stdscr, uip.maxy // 2, uip.maxx // 2, title = w_confirmtitle, default = False) == False:
							continue
					_values = {}
					_values = {
						"action_args": {
							"command": command
						}
					}
					execute_command(uip, values = _values)
			else:
				call = deep_get(value, "call")
				call_name = None
				owner_references_path = deep_get(value, "owner_references_path")
				owner_references_kind = deep_get(value, "owner_references_kind")
				holder_identity_path = deep_get(value, "holder_identity_path")
				if owner_references_path is not None:
					owner_reference = deep_get(obj, owner_references_path, [])
					if holder_identity_path is not None:
						if len(owner_reference) == 0:
							continue
						call_name = deep_get(obj, holder_identity_path)
						kind = get_holder_kind_from_owner_references(owner_reference, call_name)
					elif owner_references_kind is not None:
						call_name = get_name_by_kind_from_owner_references(owner_reference, owner_references_kind)
						kind = owner_references_kind
					else:
						kind, call_name = get_controller_from_owner_references(owner_reference)
					if kind == ("", "") or len(call_name) == 0:
						continue
				else:
					call_name_path = deep_get(value, "name_path")
					kind = deep_get(value, "kind")
					if kind is None:
						kind_path = deep_get(value, "kind_path", "")
						if type(kind_path) == tuple:
							kind = (deep_get(obj, kind_path[0]), deep_get(obj, kind_path[1]))
						else:
							kind = deep_get(obj, kind_path)
					if call_name_path is not None:
						call_name = deep_get(obj, call_name_path)

				call_namespace_path = deep_get(value, "namespace_path")
				call_namespace = ""
				if call_namespace_path is not None:
					call_namespace = deep_get(obj, call_namespace_path)

				call_kind_name_namespace_selection_path = deep_get(value, "call_kind_name_namespace_selection_path")
				if call_kind_name_namespace_selection_path is not None:
					kind_filter = deep_get(value, "kind_filter", None)
					selected = uip.get_selected()

					if kind_filter is None or selected.kind in kind_filter:
						knn_order = deep_get(value, "call_kind_name_namespace_selection_order")
						knn = eval(f"selected.{call_kind_name_namespace_selection_path}")
						if knn_order[0] != -1:
							kind = knn[knn_order[0]]
						if knn_order[1] != -1:
							call_name = knn[knn_order[1]]
						if knn_order[2] != -1:
							call_namespace = knn[knn_order[2]]

				if call is not None and call_name is not None:
					if kind is None or kind == ("", ""):
						retval = call(uip.stdscr, **{"selected": call_name})
						if retval is not None and retval == curses_helper.retval.RETURNFULL:
							return retval
					elif len(kind) > 0:
						if type(kind) == str:
							kind = kh.guess_kind(kind)
						ref = kh.get_ref_by_kind_name_namespace(kind, call_name, call_namespace)
						retval = call(uip.stdscr, ref, kind)
						if retval is not None and retval == curses_helper.retval.RETURNFULL:
							return retval
					changed = True
			if force_update == True:
				uip.force_update()

def eventdispatch(stdscr, **kwargs):
	obj = deep_get(kwargs, "obj")
	if obj is None:
		return curses_helper.retval.RETURNDONE

	kind_path = deep_get(kwargs, "kind_path")
	kind = deep_get_with_fallback(obj, kind_path)
	api_version_path = deep_get(kwargs, "api_version_path")
	api_version = deep_get_with_fallback(obj, api_version_path, "")
	# Is this a core API?
	if "/" not in api_version:
		api_family = ""
	else:
		api_family = api_version.split("/")[0]
	kind = (kind, api_family)

	name_path = deep_get(kwargs, "name_path")
	name = deep_get_with_fallback(obj, name_path)
	namespace_path = deep_get(kwargs, "namespace_path")
	namespace = deep_get_with_fallback(obj, namespace_path + ["metadata#namespace"], "")
	ref = kh.get_ref_by_kind_name_namespace(kind, name, namespace)
	return resourceinfodispatch(stdscr, ref, kind)

def log_add_line(timestamps, facilities, severities, messages, timestamp, facility, severity, message, facility_extended):
	if timestamp is not None:
		timestamps.append(timestamp.astimezone())
	else:
		timestamps.append("")
	if facility_extended is None:
		facilities.append(facility)
	else:
		facilities.append((facility_extended, facility))
	severities.append(severity)
	messages.append(message)

	return timestamps, facilities, severities, messages

def containerinfoloop(stdscr, container, kind, obj, **kwargs):
	global override_tail_lines

	multilog_containers_full = deep_get(kwargs, "multilog_containers_full", [])
	multilog_containers = deep_get(kwargs, "multilog_containers", [])
	all_same_namespace = deep_get(kwargs, "all_same_namespace", False)
	multilog_prefix = ["namespace", "podname", "container"]
	facility_extended = None

	uip = UIProps(stdscr)

	uip.init_window(field_list = None, windowheader = "Container Info", helptext = helptexts.containerinfo)

	# For generic information
	infopad = uip.init_infopad(height = 7, width = -1, ypos = 1, xpos = 1)

	# For the pod log
	tspad, logpad = uip.init_logpad(width = -1, ypos = 9, xpos = 1)

	# For the status bar; position is always at the bottom of the screen and the entire width of the screen
	statusbar = uip.init_statusbar()

	# Number of lines of log to show by default
	if override_tail_lines is None:
		override_tail_lines = deep_get(iktconfig, "Pods#logsize", default_tail_lines)

	tail_lines = override_tail_lines

	uip.continuous_log = False
	merge_repeats = deep_get(iktconfig, "Pods#merge_repeated_messages", False)
	saved_merge_repeats = merge_repeats
	raw_logs = False
	tmp_log_level = deep_get(iktconfig, "Pods#loglevel", "Info")
	log_level = name_to_loglevel(tmp_log_level)
	show_borders = deep_get(iktconfig, "Pods#show_borders", True)
	uip.toggle_borders(show_borders)
	show_timestamps = deep_get(iktconfig, "Pods#show_timestamps", True)
	uip.toggle_timestamps(show_timestamps)
	# Currently not working properly
	compact_timestamps = False
	# Currently not working properly
	only_new_dates = False
	# Currently not working properly
	highlight_new_dates = False
	wrap_lines = False
	# Show severity as text
	severity_prefix = deep_get(iktconfig, "Pods#severity_prefix", [])
	# Backwards compatibility
	if type(severity_prefix) is bool:
		if severity_prefix == False:
			severity_prefix = []
		else:
			severity_prefix = ["[", "4LETTER", "] "]

	# This decides whether or not compound log messages,
	# such as Python dicts and JSON, should be expanded
	fold_msg = deep_get(iktconfig, "Pods#fold_msg", True)
	saved_fold_msg = fold_msg

	# This decides whether or not to show the facility,
	# and if so how it is to be displayed
	show_facility = deep_get(iktconfig, "Pods#show_facility", "Full")
	override_parser = None
	_parser = None

	reload = False

	uip.update_window()
	uip.force_update()
	uip.refresh_window()
	uip.refresh_statusbar()
	curses.doupdate()

	while True:
		uip.countdown_to_update()

		if uip.is_update_triggered():
			# When following the log we update the log continuously, but tail lines is limited to the number of lines
			# that fits on the screen, and cursor movements are disabled; as soon as the user presses a key the log
			# will stop scrolling and the whole log (default number of tail lines) will be loaded
			if uip.continuous_log == True:
				tail_lines = uip.logpadheight

			if len(multilog_containers) == 0:
				pod_info = get_pod_info(**{"_vlist": [obj]})[0]
				podname = pod_info.name
				namespace = pod_info.namespace
				containername = deep_get(container, "name")

				if kind == ("InitContainer", ""):
					src_statuses = deep_get(pod_info.ref, "status#initContainerStatuses", [])
					container_type = "init_container"
				else:
					src_statuses = deep_get(pod_info.ref, "status#containerStatuses", [])
					container_type = "container"
				container_status = None
				for container_status in src_statuses:
					if deep_get(container_status, "name") == containername:
						break
				if container_status is not None:
					image = deep_get(container_status, "imageID", "")
				else:
					image = "<unavailable>"

			# We don't want the "Fetching Log" notification every few seconds; we're just loading a few lines...
			if uip.continuous_log == False:
				notice = curses_helper.notice(None, y = uip.maxy // 2, x = uip.maxx // 2, message = "Fetching log")
			if len(multilog_containers) == 0:
				rawmsg, internal_error = get_pod_log_by_name_namespace_container(podname, namespace, containername, tail_lines = tail_lines)
				splitmsg = split_msg(rawmsg)
			else:
				container_type = "container"
				splitmsg = []
				for namespace, podname, containername, image_id in multilog_containers_full:
					if len(multilog_containers) == 1:
						facility_extended = None
					elif multilog_prefix == ["container"]:
						facility_extended = [
							("separators", "facility_extended_prefix"),
							(f"{containername}", ("types", "facility_extended")),
							("separators", "facility_extended_suffix"),
						]
					elif multilog_prefix == ["podname", "container"] or multilog_prefix == ["namespace", "podname", "container"] and all_same_namespace == True:
						facility_extended = [
							("separators", "facility_extended_prefix"),
							(f"{podname}", ("types", "facility_extended")),
							("separators", "container"),
							(f"{containername}", ("types", "facility_extended")),
							("separators", "facility_extended_suffix"),
						]
					elif multilog_prefix == ["namespace", "podname", "container"]:
						facility_extended = [
							("separators", "facility_extended_prefix"),
							(f"{namespace}", ("types", "facility_extended")),
							("separators", "namespace"),
							(f"{podname}", ("types", "facility_extended")),
							("separators", "container"),
							(f"{containername}", ("types", "facility_extended")),
							("separators", "facility_extended_suffix"),
						]
					rawmsg, internal_error = get_pod_log_by_name_namespace_container(podname, namespace, containername, tail_lines = tail_lines)
					if internal_error == True:
						splitmsg = split_msg(rawmsg)
						break
					# Now we have one per line; now we need to add (podname, containername, image, facility_extended) to each line, to allow the logparser
					# to function without guessing
					for line in split_msg(rawmsg):
						splitmsg.append((line, podname, containername, image_id, facility_extended))
				splitmsg = natsorted(splitmsg, key = itemgetter(0))

			if uip.continuous_log == False:
				del notice
			uip.refresh_window()
			uip.refresh_infopad()
			uip.refresh_logpad()
			uip.refresh_statusbar()
			curses.doupdate()

			timestamps = []
			facilities = []
			severities = []
			messages = []
			parser = ""
			prev_timestamp = None
			prev_facility = ""
			prev_severity = ""
			prev_message = ""
			prev_remnants = None
			repeat_count = 0

			total_msgs = 0
			hidden_msgs = 0
			merged_lines = 0

			linecount = len(splitmsg)
			linepercent = int(linecount * 0.01)

			progressbar = None
			if linecount > 1000:
				progressbar = curses_helper.progressbar(None, y = uip.maxy // 2, minx = (uip.minx + 8), maxx = (uip.maxx - 8), progress = 0, title = "Parsing log")

			i = 0
			while i < len(splitmsg):
				_line = splitmsg[i]

				# We probably need a progress bar once we reach this many lines
				if linecount > 1000 and (i % linepercent) == 0:
					curses_helper.progressbar(progressbar, y = uip.maxy // 2, minx = (uip.minx + 8), maxx = (uip.maxx - 8), progress = 100 - 100 * ((linecount - i) / linecount))
					progressbar.timeout(10)
					c = progressbar.getch()
					if c == 27:	# ESCAPE
						if reload == True:
							break
						else:
							return curses_helper.retval.RETURNDONE

				if type(_line) == tuple:
					line, podname, containername, image, facility_extended = _line
					# We need to identify parser again and again and again for every line
					_parser = None
				else:
					line = _line
				if internal_error == True:
					timestamp, facility, severity, message, remnants, parser, _parser = logparser("internal_error", "", "", message = line, container_type = container_type, line = i)
				elif raw_logs == True:
					timestamp, facility, severity, message, remnants, parser, _parser = logparser("raw", "", "", message = line, container_type = container_type, line = i)
				elif override_parser is not None or _parser is None or parser == "":
					timestamp, facility, severity, message, remnants, parser, _parser = logparser(podname, containername, image, message = line, fold_msg = fold_msg, override_parser = override_parser, container_type = container_type, line = i)
				else:
					timestamp, facility, severity, message, remnants = logparser_initialised(parser = _parser, message = line, fold_msg = fold_msg, line = i)

				i += 1

				# In some cases rather than expanding a single line into multiple lines,
				# we want to parse multiple lines as a single block;
				# we signal this by returning message == ["start_block", processor],
				# then continue parsing until we either get ["end_block", *],
				# ["break", *], or reach the end of the file
				if type(message) == list and message[0] == "start_block" and raw_logs == False:
					_logentries = [(timestamp, facility, severity, remnants)]
					processor = message
					options = {}
					if len(processor) == 3:
						options = processor[2]
					_block_state = "none"
					for j in range(i, len(splitmsg)):
						processor, _logentry = processor[1](splitmsg[j], fold_msg = fold_msg, options = options)
						_block_state = processor[0]
						if _block_state != "end_block_not_processed":
							_logentries.append(_logentry)

						if _block_state in ["end_block", "end_block_not_processed"]:
							# OK, we've got a block; start by appending the first line
							if len(_logentries) > 0:
								timestamps, facilities, severities, messages = log_add_line(timestamps, facilities, severities, messages, timestamp, facility, severity, _logentries[0][3], facility_extended)
							if len(_logentries) > 1:
								for _timestamp, _facility, _severity, _message in _logentries[1:]:
									timestamps, facilities, severities, messages = log_add_line(timestamps, facilities, severities, messages, _timestamp, "".ljust(len(facility)), severity, _message, facility_extended)
								break
						elif _block_state == "break":
							# We got something indicating that this isn't a valid block; abort
							break
					else:
						if len(_logentries) > 0 and deep_get(options, "eof", "break") == "end_block":
							for _timestamp, _facility, _severity, _message in _logentries:
								timestamps, facilities, severities, messages = log_add_line(timestamps, facilities, severities, messages, _timestamp, "".ljust(len(facility)), severity, _message, facility_extended)
							_block_state = "end_block"
						else:
							_block_state = "break"

					if _block_state == "end_block":
						# We've got a block and it's been appended, so go on
						i = j + 1
						continue
					elif _block_state == "end_block_not_processed":
						# We've got a block and it's been appended, but the last line needs processing again
						i = j
						continue
					else:
						message = remnants
						remnants = None

				# If this is a (themestr, severity) tuple, ignore the severity;
				# it's only necessary for remnants since the severity is passed separarely
				if type(message) == tuple:
					message, _ = message

				total_msgs += 1

				if severity > log_level:
					hidden_msgs += 1
					continue

				if prev_message == message and prev_facility == facility and prev_severity == severity and (prev_message != "" or prev_remnants is not None) and prev_remnants == remnants:
					repeat_count += 1
					prev_timestamp = timestamp
					if merge_repeats:
						merged_lines += 1
						continue
				else:
					if repeat_count > 0 and merge_repeats:
						timestamps, facilities, severities, messages = log_add_line(timestamps, facilities, severities, messages, prev_timestamp, prev_facility, prev_severity, [("[previous message repeated ", color_log_severity(prev_severity, False)), (f"{repeat_count}", ("logview", "repeat_count")), (" times]", color_log_severity(prev_severity, False))], facility_extended)
					repeat_count = 0
					prev_timestamp = timestamp
					prev_facility = facility
					prev_severity = severity
					prev_message = message
					prev_remnants = remnants

				timestamps, facilities, severities, messages = log_add_line(timestamps, facilities, severities, messages, timestamp, facility, severity, message, facility_extended)

				if remnants is not None and len(remnants) > 0:
					# Remnants are used for unfolding multi-line messages that have been folded into one,
					# such as YAML/JSON, etc.
					#
					# Remnants can, for the time being, be either:
					# (list of string, severity)
					# (string(newline separated strings), severity)
					# or
					# [(string, severity), ...]
					if type(remnants) == tuple:
						tmpmessages, severity = remnants

						if type(tmpmessages) == list:
							for message in tmpmessages:
								timestamps, facilities, severities, messages = log_add_line(timestamps, facilities, severities, messages, None, "".ljust(len(facility)), severity, message, facility_extended)
						else:
							for message in tmpmessages.split("\n"):
								timestamps, facilities, severities, messages = log_add_line(timestamps, facilities, severities, messages, None, "".ljust(len(facility)), severity, message, facility_extended)
					else:
						for message, severity in remnants:
							timestamps, facilities, severities, messages = log_add_line(timestamps, facilities, severities, messages, None, "".ljust(len(facility)), severity, message, facility_extended)

			reload = True

			# The data in some fields might become shorter, so we need to trigger a clear
			uip.infopad.erase()
			uip.statusbar.erase()

			del progressbar

			# If the last message in the log is a repeat we need to add the repeat signature
			if repeat_count > 0 and merge_repeats:
				timestamps, facilities, severities, messages = log_add_line(timestamps, facilities, severities, messages, prev_timestamp, prev_facility, prev_severity, [("[previous message repeated ", color_log_severity(prev_severity, False)), (f"{repeat_count}", ("logview", "repeat_count")), (" times]", color_log_severity(prev_severity, False))], facility_extended)

			uip.update_log_info(timestamps, facilities, severities, messages)
			uip.loglen = len(messages)
			uip.update_window()

			if len(multilog_containers) == 0:
				containertypearray = f" [Type: {kind[0]}]"
				if kind == ("InitContainer", ""):
					src_statuses = deep_get(pod_info.ref, "status#initContainerStatuses")
				else:
					src_statuses = deep_get(pod_info.ref, "status#containerStatuses")

				if src_statuses is None or len(src_statuses) == 0:
					break

				for container_status in src_statuses:
					if deep_get(container_status, "name") == containername:
						break

				status, status_group, restarts, message, age = get_container_status(src_statuses, containername, kind)
				containerarray = [
					("Container: ", ("main", "infoheader")),
					(f"{containername}{containertypearray}", ("types", "generic"))
				]
				statusarray = [
					("Status: ", ("main", "infoheader")),
					(f"{status}", color_status_group(status_group, False))
				]
				if message != "":
					statusarray.append((f" ({message})", ("types", "generic")))
				restartsarray = [
					("Restarts: ", ("main", "infoheader")),
					(f"{restarts}", ("types", "numerical"))
				]
				podarray = [
					("Pod: ", ("main", "infoheader")),
					(f"{pod_info.name}", ("types", "generic")),
				]
				containeridarray = [
					("Container ID: ", ("main", "infoheader")),
					(f"{deep_get(container_status, 'containerID')}", ("types", "generic")),
				]
				image_name, image_version = get_image_tuple(deep_get(container_status, "image"))
				imagearray = [
					("Image: ", ("main", "infoheader")),
					(f"{image_name}", ("types", "generic")),
					("separators", "version"),
					(f"{image_version}", ("types", "version")),
				]
				image_id = deep_get(container_status, "imageID")
				imageidarray = [
					("I", ("main", "infoheader_shortcut")),
					("mage ID: ", ("main", "infoheader")),
					(f"{image_id}", ("types", "generic")),
				]
				uip.addthemearray(infopad, containerarray, y = 0, x = 0)
				uip.addthemearray(infopad, statusarray, y = 1, x = 0)
				uip.addthemearray(infopad, restartsarray, y = 2, x = 0)
				uip.addthemearray(infopad, podarray, y = 3, x = 0)
				uip.addthemearray(infopad, containeridarray, y = 4, x = 0)
				uip.addthemearray(infopad, imagearray, y = 5, x = 0)
				uip.addthemearray(infopad, imageidarray, y = 6, x = 0)
			else:
				if len(multilog_containers) == 1:
					containerarray = [
						("Container: ", ("main", "infoheader")),
						(f"{containername}", ("types", "generic")),
					]
					podarray = [
						("Pod: ", ("main", "infoheader")),
						(f"{podname}", ("types", "generic")),
					]
					namespacearray = [
						("Namespace: ", ("main", "infoheader")),
						(f"{namespace}", ("types", "namespace")),
					]
					containeridarray = [
						("I", ("main", "infoheader_shortcut")),
						("mage ID: ", ("main", "infoheader")),
						(f"{image_id}", ("types", "generic")),
					]
					uip.addthemearray(infopad, podarray, y = 1, x = 0)
					uip.addthemearray(infopad, namespacearray, y = 2, x = 0)
					uip.addthemearray(infopad, containeridarray, y = 3, x = 0)
				else:
					containerarray = [
						("Containers: ", ("main", "infoheader")),
					]
					containerarray += format_list(multilog_containers, 0, 0, False, False, field_colors = [("types", "namespace"), ("types", "generic"), ("types", "generic")], field_separators = [("separators", "namespace"), ("separators", "container")], ellipsise = 3)
					if all_same_namespace == True:
						namespacearray = [
							("Namespace: ", ("main", "infoheader")),
							(f"{namespace}", ("types", "namespace")),
						]
						uip.addthemearray(infopad, namespacearray, y = 1, x = 0)
				uip.addthemearray(infopad, containerarray, y = 0, x = 0)

			uip.refresh = True

		if uip.refresh == True:
			# FIXME: the status stuff should be done by curses_helper
			theme = get_theme_ref()
			_ltee = theme["boxdrawing"].get("ltee", curses.ACS_LTEE)
			_rtee = theme["boxdrawing"].get("rtee", curses.ACS_RTEE)
			_vline = theme["boxdrawing"].get("vline", curses.ACS_VLINE)

			uip.statusbar.erase()

			if uip.continuous_log == True:
				interval = "Follow"
			else:
				interval = "Manual"

			if tail_lines == sys.maxsize:
				loglimit = "Unlimited"
			else:
				loglimit = f"{tail_lines}"

			loglevel_str = loglevel_to_name(log_level)

			# We have two different widths of the statusbar
			if uip.maxx - uip.minx > 108:
				# Wide version
				statusarray1 = [
					("Updates: ", ("statusbar", "infoheader")), (f"{interval}", ("statusbar", "highlight")),
					("separators", "statusbar"),
					("Loglvl: ", ("statusbar", "infoheader")), (f"{loglevel_str}", ("statusbar", "highlight")),
					("separators", "statusbar"),
					("Log length: ", ("statusbar", "infoheader")), (f"{uip.loglen} ", ("statusbar", "highlight")), ("lines (", ("statusbar", "default")),
				]
				if hidden_msgs > 0:
					statusarray1 += [
						(f"{hidden_msgs}", ("statusbar", "highlight")), (" messages hidden)", ("statusbar", "dim")), ("; ", ("statusbar", "default")),
					]
				statusarray1 += [
					("limit: ", ("statusbar", "default")), (f"{loglimit}", ("statusbar", "highlight")), (")", ("statusbar", "default")),
				]
				statusarray2 = [
				]
				if fold_msg == False:
					statusarray2 += [
						("Unfolding messages", ("statusbar", "highlight")),
						("separators", "statusbar"),
					]
				if merge_repeats == True:
					statusarray2 += [
						("Repeats merged", ("statusbar", "highlight")),
						("separators", "statusbar"),
					]

				statusarray2 += [
					("Facility: ", ("statusbar", "infoheader")),
					(f"{show_facility}", ("statusbar", "highlight")),
					("separators", "statusbar"),
					("Format: ", ("statusbar", "infoheader")),
				]
			else:
				# Compact version
				statusarray1 = [
					("Updates: ", ("statusbar", "infoheader")), (f"{interval}", ("statusbar", "highlight")),
					("separators", "statusbar_compact"),
					("Loglvl: ", ("statusbar", "infoheader")), (f"{loglevel_str}", ("statusbar", "highlight")),
					("separators", "statusbar_compact"),
					(f"{uip.loglen} ", ("statusbar", "highlight")), ("lines (", ("statusbar", "default")),
				]
				if hidden_msgs > 0:
					statusarray1 += [
						(f"{hidden_msgs}", ("statusbar", "highlight")), (" hidden", ("statusbar", "dim")), ("; ", ("statusbar", "default")),
					]
				statusarray1 += [
					("max: ", ("statusbar", "default")), (f"{loglimit}", ("statusbar", "highlight")), (")", ("statusbar", "default")),
				]
				statusarray2 = [
				]
				if fold_msg == False:
					statusarray2 += [
						("Unfolding", ("statusbar", "highlight")),
						("separators", "statusbar_compact"),
					]
				if merge_repeats == True:
					statusarray2 += [
						("Repeats merged", ("statusbar", "highlight")),
						("separators", "statusbar_compact"),
					]

				statusarray2 += [
					("Facility: ", ("statusbar", "infoheader")),
					(f"{show_facility}", ("statusbar", "highlight")),
					("separators", "statusbar_compact"),
					("Format: ", ("statusbar", "infoheader")),
				]

			try:
				if len(rawmsg) == 0 or parser[0] == "":
					statusarray2 += [
						("Empty", ("main", "format_empty")),
					]
				elif parser[0] == "unknown":
					statusarray2 += [
						("Unknown", ("main", "format_unknown")),
					]
				elif raw_logs:
					statusarray2 += [
						("Raw", ("main", "format_raw")),
					]
				else:
					if uip.maxx - uip.minx > 118:
						statusarray2 += [
							(f"{parser[0]}:{parser[1]}", ("statusbar", "highlight")),
						]
					else:
						statusarray2 += [
							(f"{parser[0]}", ("statusbar", "highlight")),
						]
			except Exception as e:
				sys.exit(f"[{parser}]; Exception: {e}")

			uip.addthemearray(statusbar, statusarray1, y = 0, x = 0)
			uip.addthemearray(statusbar, statusarray2, y = 1, x = 0)

			maxlen = 0
			latest_facility_len = -1

			uip.tspad.erase()
			uip.logpad.erase()
			# This is needed in case we get a resize event or toggle borders
			uip.resize_logpad(uip.maxy - uip.logpadypos - 2, 0)
			new_date = False
			if timestamps is not None and len(timestamps) > 0:
				current_datestamp = ("%s" % timestamps[0])[0:len("YYYY-MM-DD")]
				new_date = True
			yadd = 0
			for y in range(0, min(uip.logpadheight, uip.loglen)):
				if uip.yoffset + y >= len(timestamps):
					timestamp = "".ljust(uip.tspadwidth)
				else:
					timestamp = ("%s" % timestamps[uip.yoffset + y]).ljust(uip.tspadwidth)
					datestamp = timestamp[0:len("YYYY-MM-DD ")]
					if current_datestamp is not None and type(timestamps[uip.yoffset + y]) == datetime and datestamp != current_datestamp:
						current_datestamp = datestamp
						new_date = True
				hourstamp = timestamp[len("YYYY-MM-DD "):]

				if new_date == True and highlight_new_dates == True:
					datetype = "timestamp_newdate"
				else:
					datetype = "timestamp"

				if compact_timestamps == False:
					hourxpos = len("YYYY-MM-DD ")
				else:
					hourxpos = 0

				if y + yadd > uip.logpadheight:
					continue

				tsstrarray = None
				# FIXME
				if only_new_dates == True:
					if new_date == True:
						tsthemearray = [(datestamp, ("types", datetype))]
						new_date = False
						# If we do empty lines for new dates we need this
						# uip.addstr(logpad, "", y = y + yadd, x = 0)
						# yadd += 1
				else:
					tsthemearray = [(datestamp, ("types", datetype))]

				tsthemearray += [(hourstamp, ("types", "timestamp"))]

				new_date = False

				if show_facility == "None" or uip.yoffset + y >= len(facilities):
					facility_extended = ""
					facility = ""
				elif show_facility == "Short":
					_facility = facilities[uip.yoffset + y]
					if type(_facility) == tuple:
						facility_extended, _facility = _facility
					if _facility is None:
						_facility = ""
					tmp = re.match(r"^.*/(.*)", _facility)
					if tmp is not None:
						facility = tmp[1]
						latest_facility_len = len(facility)
					elif len(_facility.strip()) != len(_facility) and len(_facility.strip()) == 0:
						if latest_facility_len == -1:
							facility = _facility
						else:
							facility = _facility[0:latest_facility_len]
					else:
						facility = _facility
				else:
					facility = facilities[uip.yoffset + y]
					if type(facility) == tuple:
						facility_extended, facility = facility
					if facility is None:
						facility = ""

				if uip.yoffset + y >= len(severities):
					severity = loglevel.INFO
				else:
					severity = severities[uip.yoffset + y]

				msgstrarray = []

				if len(severity_prefix) > 0:
					_prefix, _severity_type, _suffix = severity_prefix
					if _severity_type.lower() == "letter":
						_severity = lvl_to_letter_severity(severity)
					elif _severity_type.lower() == "4letter":
						_severity = lvl_to_4letter_severity(severity)
					elif _severity_type.lower() == "full":
						_severity = lvl_to_word_severity(severity)

					if _severity_type.startswith(("LE", "4LE", "FU")):
						_severity = f"{_prefix}{_severity.upper()}{_suffix}"
					elif _severity_type.startswith(("Le", "4Le", "Fu")):
						_severity = f"{_prefix}{_severity.capitalize()}{_suffix}"
					else:
						_severity = f"{_prefix}{_severity.lower()}{_suffix}"

					if len(timestamp.strip()) != 0 or y >= len(timestamps):
						msgstrarray.append((f"{_severity}", color_log_severity(severity, False)))
					else:
						msgstrarray.append(("".ljust(len(f"{_severity}")), color_log_severity(severity, False)))

				if facility_extended is not None and len(facility_extended) > 0:
					msgstrarray += facility_extended

				if facility != "":
					facilitystr = [
						("separators", "facility_prefix"),
						(facility, ("logview", "facility")),
						("separators", "facility_suffix"),
						("separators", "facility_padding"),
					]
					# We don't actually want any prefix, but we want empty padding of the same length
					if facility.rstrip() == "":
						facilitystr = [("".ljust(themearray_len(facilitystr)), ("logview", "severity_debug"))]
					msgstrarray += facilitystr

				msg = messages[uip.yoffset + y]
				if type(msg) != list:
					msgstrarray.append((msg, color_log_severity(severity, False)))
				else:
					msgstrarray += msg
				if wrap_lines == True:
					sideadjust = 0
					if uip.borders == False:
						sideadjust = 2
					maxwidth = uip.maxx - uip.logpadxpos + sideadjust
				else:
					maxwidth = -1
				msgstrarrays = strarray_wrap_line(msgstrarray, maxwidth, wrap_marker = (uip.borders or get_mousemask() != 0))
				for i in range(0, len(msgstrarrays)):
					if y + yadd + i >= uip.logpadheight:
						break
					if i == 0:
						uip.addthemearray(tspad, tsthemearray, y = y + yadd, x = 0)
					cury, curx = uip.addthemearray(logpad, msgstrarrays[i], y = y + yadd + i, x = 0)
					maxlen = max(maxlen, themearray_len(msgstrarrays[i]))
				yadd += i
			uip.resize_logpad(-1, maxlen)

			uip.refresh_window()
			uip.refresh_infopad()
			uip.refresh_logpad()
			uip.refresh_statusbar()
			curses.doupdate()
			uip.refresh = False

		uip.stdscr.timeout(100)
		c = uip.stdscr.getch()
		retval = uip.generic_keycheck(c)

		if retval == curses_helper.retval.MATCH:
			continue
		elif retval == curses_helper.retval.RETURNONE:
			return curses_helper.retval.RETURNDONE
		elif retval == curses_helper.retval.RETURNFULL:
			return retval

		if c == curses.KEY_F2:
			retval = selectwindow(stdscr, uip)
			if retval == curses_helper.retval.RETURNFULL:
				return retval
			uip.refresh_all()
		elif c == curses.KEY_F3:
			retval = selectwindow(stdscr, uip, refresh_apis = True)
			if retval == curses_helper.retval.RETURNFULL:
				return retval
			uip.refresh_all()
		elif c == ord("B"):
			uip.toggle_borders()
			uip.refresh_all()
			uip.force_update()
		elif c == curses.KEY_F4:
			if uip.continuous_log:
				# Disable log tailing
				uip.continuous_log = False
				tail_lines = override_tail_lines
				uip.set_update_delay(-1)
				# When we disable tailing we would ideally want to be at the end, but we don't know where the end is
				# so, stay on top...
			else:
				# Enable log tailing
				uip.continuous_log = True
				tail_lines = uip.logpadheight
				uip.set_update_delay(10)
			uip.yoffset = 0
			uip.xoffset = 0
			uip.force_update()
		elif c == curses.KEY_F8:
			if uip.continuous_log:
				continue

			# Toggle full logs; this might be VERY slow
			uip.continuous_log = False

			if tail_lines == override_tail_lines:
				if curses_helper.confirmationbox(uip.stdscr, uip.maxy // 2, uip.maxx // 2, title = "Show full log (Potentially very slow):", default = False):
					tail_lines = sys.maxsize
			else:
				tail_lines = override_tail_lines

			uip.refresh_infopad()
			uip.refresh_logpad()
			uip.refresh_statusbar()
			curses.doupdate()
			uip.force_update()
		elif c == ord("I"):
			# XXX: This is very inefficient
			_vlist = get_container_info()
			retval = None
			for _obj in _vlist:
				if _obj.name == containername and _obj.image_id == image_id:
					retval = resourceinfodispatch(stdscr, _obj.ref, ("__Container", ""))
					uip.force_update()
					break
			if retval is not None and retval == curses_helper.retval.RETURNFULL:
				return retval
		elif c == ord("R"):
			if uip.continuous_log:
				continue

			if raw_logs == False:
				saved_fold_msg = fold_msg
				saved_merge_repeats = merge_repeats
				fold_msg = True
				merge_repeats = False
			else:
				fold_msg = saved_fold_msg
				merge_repeats = saved_merge_repeats
			raw_logs = not raw_logs
			uip.yoffset = 0
			uip.xoffset = 0
			uip.force_update()
		elif c == ord("P"):
			parserlist = [
				(widgetlineattrs.NORMAL, [(f"<autodetect>", ("windowwidget", "default"))]),
			]
			for lvl in natsorted(get_parser_list()):
				parserlist.append((widgetlineattrs.NORMAL, [(f"{lvl}", ("windowwidget", "default"))]))

			if override_parser is None:
				preselection = "<autodetect>"
			else:
				preselection = override_parser
			tmpselection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, parserlist, title = "Override Logparser", cursor = True, preselection = preselection)
			selection = None
			if tmpselection is not None and type(tmpselection[0]) == int:
				selection = tmpselection[1][0][0]
			uip.refresh_all()
			if selection is not None and len(selection) > 0:
				if selection == "<autodetect>":
					override_parser = None
				else:
					override_parser = selection
				_parser = None
			uip.yoffset = 0
			uip.xoffset = 0
			uip.force_update()
		elif c == ord("L"):
			loglevellist = []
			for lvl in get_loglevel_names():
				if lvl.startswith("Diff"):
					continue
				loglevellist.append((widgetlineattrs.NORMAL, [(f"{lvl}", ("windowwidget", "default"))]))

			tmpselection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, loglevellist, title = "Select Loglevel", cursor = True, preselection = loglevel_to_name(log_level))
			selection = None
			if tmpselection is not None and type(tmpselection[0]) == int:
				selection = tmpselection[1][0][0]
			uip.refresh_all()
			if selection is not None and len(selection) > 0:
				log_level = name_to_loglevel(selection)
			uip.yoffset = 0
			uip.xoffset = 0
			uip.force_update()
		elif c == ord("W"):
			wrap_lines = not wrap_lines
			uip.yoffset = 0
			uip.xoffset = 0
			uip.force_update()
		elif c == ord("F"):
			if uip.continuous_log or raw_logs:
				continue

			fold_msg = not fold_msg
			uip.yoffset = 0
			uip.xoffset = 0
			uip.force_update()
		elif c == ord("D"):
			if uip.continuous_log or raw_logs:
				continue

			merge_repeats = not merge_repeats
			uip.yoffset = 0
			uip.xoffset = 0
			uip.force_update()
		elif c == ord("T"):
			uip.toggle_timestamps()
			uip.refresh_all()
			uip.force_update()
		elif c == ord("V"):
			facilitylist = [
				(widgetlineattrs.NORMAL, [("Full", ("windowwidget", "default"))]),
				(widgetlineattrs.NORMAL, [("Short", ("windowwidget", "default"))]),
				(widgetlineattrs.NORMAL, [("None", ("windowwidget", "default"))]),
			]

			tmpselection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, facilitylist, title = "Select Facility Level", cursor = True, preselection = show_facility)
			selection = None
			if tmpselection is not None and type(tmpselection[0]) == int:
				selection = tmpselection[1][0][0]
			uip.refresh_all()
			if selection is not None and len(selection) > 0:
				show_facility = selection
			uip.yoffset = 0
			uip.xoffset = 0
			uip.force_update()
		elif c == ord("E"):
			if uip.continuous_log:
				continue

			uip.refresh = True
			if raw_logs:
				rawprefix = "Raw "
			else:
				rawprefix = ""
			filename = curses_helper.inputbox(uip.stdscr, uip.maxy // 2, 1, uip.maxy - 1, uip.maxx - 1, "Export %slog to file: " % (rawprefix))
			if filename is None or filename == "":
				continue

			# This is necessary because we never go through the normal update cycle for the logpad and infopad
			uip.refresh_infopad()
			uip.refresh_logpad()
			curses.doupdate()

			if os.path.exists(filename):
				curses.doupdate()
				if curses_helper.confirmationbox(uip.stdscr, uip.maxy // 2, uip.maxx // 2, title = "File '%s' already exists; overwrite?:" % (filename), default = False) == False:
					continue

			f = open(filename, "w")
			for y in range(0, uip.loglen):
				# Even when the log is raw we want the first timestamp
				if y >= len(timestamps):
					timestamp = "".ljust(uip.tspadwidth)
				else:
					timestamp = "%s" % (timestamps[y])

				if y >= len(facilities) or facilities[y] == "":
					facility = ""
				else:
					facility = f"<{facilities[y]}> "

				if uip.yoffset + y >= len(severities):
					severity = f"{lvl_to_4letter_severity(loglevel.INFO)}: "
				else:
					severity = f"{lvl_to_4letter_severity(severities[y])}: "

				if raw_logs:
					f.write("%s  %s\n" % (timestamp, messages[y]))
				else:
					f.write("%s  %s%s%s\n" % (timestamp, severity, facility, messages[y]))
			f.close()

def executecommand(stdscr, obj, container, msg, command, waitforkeypress):
	# This should probably be done using connect_get_namespaced_pod_exec()
	curses.endwin()
	os.system("clear")
	iktprint(msg)
	print()
	if obj is not None:
		obj_name = deep_get(obj, "metadata#name")
		obj_namespace = deep_get(obj, "metadata#namespace")
		# This is a request to create a new ephemeral container
		if command == ["<ephemeral>"]:
			ephemeral_image = deep_get(iktconfig, "Debug#ephemeral_image", "busybox")
			args = ["kubectl", "debug", obj_name, "--target", container, "-n", obj_namespace, "-i", "-t", "--image", ephemeral_image, "--attach=false"]
			result = subprocess.run(args, stdout = PIPE, stderr = STDOUT, check = False)
			if result.returncode != 0:
				iktprint([(f"Error: ", "error"), ("Failed to create debug image", "default")], stderr = True)
			else:
				output = result.stdout.decode('utf-8')
				tmp = re.match(r"Creating debugging pod (\S+) with container (\S+) .*", output)
				if tmp is not None:
					pod_name = tmp[1]
					container_name = tmp[2]
				else:
					sys.exit(f"executecommand failed to parse output; {output}; aborting.")

				# We need to wait for the container to start; we should do this in a better way than sleeping
				time.sleep(5)
				# Attach to the image
				# Should we perhaps use subprocess.run here?
				args = ["kubectl", "attach", pod_name, "-c", container_name, "-it", "--pod-running-timeout=1m0s"]
				subprocess.call(args)

				# Delete the image
				# Should we perhaps use subprocess.run here?
				args = ["kubectl", "delete",  "pod", pod_name]
				subprocess.call(args)
		elif command == ["<dnsutils>"]:
			dnsutils_image = deep_get(iktconfig, "Debug#network_image", "gcr.io/kubernetes-e2e-test-images/dnsutils:1.3")
			args = ["kubectl", "debug", f"node/{obj_name}", "-i", "-t", "--image", dnsutils_image, "--attach=false"]
			result = subprocess.run(args, stdout = PIPE, stderr = STDOUT, check = False)
			if result.returncode != 0:
				iktprint([(f"Error: ", "error"), ("Failed to create debug image", "default")], stderr = True)
			else:
				output = result.stdout.decode('utf-8')
				tmp = re.match(r"Creating debugging pod (\S+) with container (\S+) .*", output)
				if tmp is not None:
					pod_name = tmp[1]
					container_name = tmp[2]
				else:
					sys.exit(f"executecommand failed to parse output; {output}; aborting.")

				# We need to wait for the container to start; we should do this in a better way than sleeping
				time.sleep(5)
				# Attach to the image
				# Should we perhaps use subprocess.run here?
				args = ["kubectl", "attach", pod_name, "-c", container_name, "-it", "--pod-running-timeout=1m0s"]
				subprocess.call(args)

				# Delete the image
				# Should we perhaps use subprocess.run here?
				args = ["kubectl", "delete",  "pod", pod_name]
				subprocess.call(args)
		else:
			# Should we perhaps use subprocess.run here?
			args = ["kubectl", "exec", obj_name, "-n", obj_namespace, "-i", "-t", "--container", container, "--"] + command
			subprocess.call(args)
	else:
		sys.exit("Called execute command with obj=None")

	if waitforkeypress:
		input("\nPress Enter to continue...")
	stdscr.refresh()

def listviewdispatch(stdscr, **kwargs):
	obj = deep_get(kwargs, "obj")
	if obj is None:
		return curses_helper.retval.RETURNDONE

	kind_path = deep_get(kwargs, "kind_path")
	kind = deep_get(obj, kind_path)
	api_family_path = deep_get(kwargs, "api_family_path")
	api_family = deep_get(obj, api_family_path, "")

	if kind is None:
		return curses_helper.retval.RETURNDONE

	view = checkforview((kind, api_family))

	if view is not None:
		if "viewfunc" in views[view]:
			viewfunc = views[view]["viewfunc"]
		else:
			viewfunc = genericlistloop
		return viewfunc(stdscr, view)

	return curses_helper.retval.RETURNDONE

# This dispatches to info views; as soon as one is added this function will
# dispatch to that view.
def resourceinfodispatch(stdscr, obj, kind, info = None, **kwargs):
	if obj is None:
		return None

	if kind == ("", ""):
		kind = deep_get(obj, "kind", "")
		if type(kind) == str:
			api_version = deep_get(obj, "apiVersion", "")
			# Is this a core API?
			if "/" not in api_version:
				api_family = ""
			else:
				api_family = api_version.split("/")[0]
			kind = (kind, api_family)

	if kind in infoviews:
		return genericinfoloop(stdscr, obj, kind, **kwargs)
	# Exceptions
	elif kind in [("Container", ""), ("InitContainer", ""), ("EphemeralContainer", "")]:
		# Do not try to open pending containers
		if deep_get(info, "status#phase") in ["Pending", "Failed"]:
			return None
		return containerinfoloop(stdscr, obj, kind, info)
	else:
		return None

def resourceinfodispatch_from_pod_resource_list(stdscr, obj, kind, info = None, **kwargs):
	kind = deep_get(obj, "kind")
	api_family = deep_get(obj, "api_group", "")
	obj = deep_get(obj, "ref")
	return resourceinfodispatch(stdscr, obj, (kind, api_family), info, **kwargs)

# Do not pass both direct and _path versions at the same time
def resourceinfodispatch_with_lookup(stdscr, **kwargs):
	obj = deep_get(kwargs, "obj")
	if obj is None:
		if "selected_obj" in kwargs:
			obj = deep_get(kwargs, "selected_obj")
		elif "selected" in kwargs:
			selected = deep_get(kwargs, "selected")
			if "_selected_objs" in kwargs:
				obj = {}
				for key, attribute in deep_get(kwargs, "_selected_objs", []).items():
					if type(attribute) == list:
						tmp = getattr(selected, attribute[0])
						if tmp is not None:
							obj[key] = tmp[attribute[1]]
						else:
							obj[key] = None
					else:
						obj[key] = getattr(selected, attribute)
			else:
				obj = selected

	selection = deep_get(kwargs, "selection")

	name = deep_get(kwargs, "name")
	namespace = deep_get(kwargs, "namespace")

	name_path = deep_get(kwargs, "name_path")
	if name_path is not None and type(name_path) == str:
		name_path = [name_path]
	namespace_path = deep_get(kwargs, "namespace_path", "")
	if namespace_path is not None and type(namespace_path) == str:
		namespace_path = [namespace_path]

	kind = deep_get(kwargs, "kind")
	kind_path = deep_get(kwargs, "kind_path")
	if kind_path is not None and type(kind_path) == str:
		kind_path = [kind_path]

	api_group = deep_get_with_fallback(kwargs, ["api_family", "api_group"])
	api_group_path = deep_get_with_fallback(kwargs, ["api_family_path", "api_group_path"])
	if api_group_path is not None and type(api_group_path) == str:
		api_group_path = [api_group_path]

	api_version_path = deep_get(kwargs, "api_version_path")
	if api_version_path is not None and type(api_version_path) == str:
		api_version_path = [api_version_path]

	owner_reference_path = deep_get(kwargs, "owner_reference_path")
	holder_identity_path = deep_get(kwargs, "holder_identity_path")

	# When name_path or namespace_path are integers they reference
	# fields in selected
	if type(name_path) == int and selection is not None and selection != (0, [("", None)]):
		name = selection[name_path + 1][0][0]
	if type(namespace_path) == int and selection is not None and selection != (0, [("", None)]):
		namespace = selection[namespace_path + 1][0][0]

	if obj is not None:
		kind = deep_get_with_fallback(obj, kind_path, kind)
		if kind is not None and len(kind) > 0:
			api_version = deep_get_with_fallback(obj, api_version_path)
			if api_version is not None:
				if "/" in api_version:
					api_group = api_version.split("/")[0]
				else:
					api_group = ""
			api_group = deep_get_with_fallback(obj, api_group_path, api_group)

	if type(kind) != tuple:
		if api_group is None:
			api_group = ""
		kind = (kind, api_group)

	controller = None
	non_controller = None

	holder_identity = None
	if holder_identity_path is not None:
		holder_identity = deep_get(obj, holder_identity_path)

	if owner_reference_path is not None and obj is not None:
		# Search for a controller, or the first reference that matches the kind if specified
		for ref in deep_get(obj, owner_reference_path, []):
			ref_name = deep_get(ref, "name")

			# We only want to dispatch if there's an owner reference
			# that matches the holder identity
			if holder_identity is not None and ref_name != holder_identity:
				continue

			ref_kind = deep_get(ref, "kind")
			ref_api_version = deep_get(ref, "apiVersion")
			if "/" in ref_api_version:
				ref_api_family = ref_api_version.split("/")[0]
			else:
				ref_api_family = ""
			ref_kind = (ref_kind, ref_api_family)
			if deep_get(ref, "controller", False) == True:
				controller = (ref_kind, ref_name)
			elif kind is not None and kind == ref_kind or holder_identity is not None:
				if non_controller is None:
					non_controller = (ref_kind, ref_name)

	if controller is not None:
		kind, name = controller
	elif non_controller is not None:
		kind, name = non_controller
	else:
		if name is None and obj is not None:
			name = deep_get_with_fallback(obj, name_path)

	if kind is None:
		return None

	if name is None:
		return None

	if namespace is None and obj is not None:
		namespace = deep_get_with_fallback(obj, namespace_path)

	kind = kh.guess_kind(kind)

        # If the kind is unknown we'll get NameError;
	# in this case we probably don't want to crash
	try:
		obj = kh.get_ref_by_kind_name_namespace(kind, name, namespace)
	except NameError:
		obj = None

	return resourceinfodispatch(stdscr, obj, kind)

def resourceinfodispatch_with_lookup_on_activation(stdscr, obj, kind, **kwargs):
	if "obj" not in kwargs:
		kwargs["obj"] = obj
	if kind not in kwargs:
		kwargs["kind"] = kind
	return resourceinfodispatch_with_lookup(stdscr, **kwargs)

def listgetter_namespaced_resources(obj, **kwargs):
	vlist = []
	status = 200

	namespaced_resources = deep_get(kwargs, "resources", kh.get_list_of_namespaced_resources())

	kind = ("Namespace", "")
	namespace = deep_get(obj, "metadata#name")

	for kind in namespaced_resources:
		_vlist, _status = kh.get_list_by_kind_namespace(kind, namespace)
		if _status != 200:
			status = _status
			continue
		if len(_vlist) == 0:
			continue
		# We're (potentially) listing a lot of different types of resources,
		# and they don't contain kind/apiVersion, so it'll be tricky to tell them apart...
		for obj in _vlist:
			obj["__kind_tuple"] = kind
		vlist += _vlist
	return vlist, status

# Iterate over the list of items and execute command on all of them
def executecommand_multiple(stdscr, msg, command, items, waitforkeypress):
	item = None

	curses.endwin()
	os.system("clear")
	print(msg + "\n")

	for item in items:
		args = command + [item]
		# Should we perhaps use subprocess.run here?
		retval = subprocess.call(args)
		if retval != 0:
			break

	if waitforkeypress or retval > 0:
		if retval > 0:
			iktprint([(f"Error: ", "error")] + format_commandline(args) + [(" returned ", "default"), (f"{retval}", "errorvalue")], stderr = True)
		input("\nPress Enter to continue...")
	stdscr.refresh()

def print_ansible_results(data, host, task, retval):
	if task.startswith("TASK: "):
		task = task[len("TASK: "):]
	elif task.startswith("output"):
		tmp = re.match(r"output.*?_(.*)", task)
		if tmp:
			task = tmp[1].replace("_", " ")
	elif task == "":
		task = "<unnamed>"

	tmp = re.match(r"(.*)#\d*$", task)
	if tmp is not None:
		task = tmp[1]

	if type(data) is str:
		stdout_lines = ""
		stderr_lines = ""
		msg = data
	else:
		stdout_lines = data.get("stdout", "").rstrip(" \t\v\r\n").splitlines()
		stderr_lines = data.get("stderr", "").rstrip(" \t\v\r\n").splitlines()
		msg = data.get("msg", "")
		retval = data.get("rc", retval)

	# If this is an empty debug message we don't need to show it
	if task.startswith("debug") and len(stdout_lines) == 0 and len(stderr_lines) == 0 and len(msg) == 0 and retval == 0:
		return

	# Header for this section
	if data.get("skipped", False) == True or data.get("skip_reason", "") == "Conditional result was False":
		iktprint([("• ", "separator"), (f"{task}", "skip")])
		iktprint([(data.get("skip_reason", "<skipped>"), "default")])
		iktprint([("", "default")])
		return

	if retval != 0:
		iktprint([("• ", "separator"), (f"{task}", "error"), (" (retval: ", "default"), (retval, "errorvalue"), (")", "default")], stderr = True)
	else:
		iktprint([("• ", "separator"), (f"{task}", "success")])

	if len(msg) > 0:
		iktprint([("msg:", "header")])
		for line in msg.splitlines():
			iktprint([(line, "default")])
		iktprint([("", "default")])

	if type(data) is str:
		iktprint([(f"{data}", "default")])
	else:
		# If we have module_stdout or module_stderr,
		# and stderr and stderr are empty, don't show either
		failed_modules = data.get("failed_modules")
		module_stdout_lines = str(data.get("module_stdout", "")).rstrip(" \t\v\r\n").splitlines()
		module_stderr_lines = str(data.get("module_stderr", "")).rstrip(" \t\v\r\n").splitlines()

		if len(stdout_lines) > 0 or (failed_modules is None and len(module_stdout_lines) == 0 and len(module_stderr_lines) == 0):
			iktprint([("stdout:", "header")])
			for line in stdout_lines:
				iktprint([(f"{line}", "default")])
			if len(stdout_lines) == 0 and (failed_modules is None and len(module_stdout_lines) == 0 and len(module_stderr_lines) == 0):
				iktprint([("<no output>\n", "none")])
			else:
				iktprint([("", "default")])

		# If retval isn't 0 we don't really care if stderr is empty
		if len(stderr_lines) > 0 or (retval != 0 and failed_modules is None and len(module_stdout_lines) == 0 and len(module_stderr_lines) == 0):
			iktprint([("stderr:", "header")])
			for line in stderr_lines:
				iktprint([(f"{line}", "default")], stderr = True)
			if len(stderr_lines) == 0 and (failed_modules is None and len(module_stdout_lines) == 0 and len(module_stderr_lines) == 0):
				iktprint([("<no output>\n", "none")])
			else:
				iktprint([("", "default")])

		if len(module_stdout_lines) > 0:
			iktprint([("module_stdout:", "header")])
			for line in module_stdout_lines:
				iktprint([(f"{line}", "default")])
			iktprint([("", "default")])

		if len(module_stderr_lines) > 0:
			iktprint([("module_stderr:", "header")])
			for line in module_stderr_lines:
				iktprint([(f"{line}", "default")])
			iktprint([("", "default")])

		if failed_modules is not None and len(failed_modules) > 0:
			for module in failed_modules:
				iktprint([(f"{module}", "default")])
				iktprint([("module_stdout:", "header")])

				module_stdout_lines = str(failed_modules[module].get("module_stdout", "")).rstrip(" \t\v\r\n").splitlines()
				module_stderr_lines = str(failed_modules[module].get("module_stderr", "")).rstrip(" \t\v\r\n").splitlines()

				if len(module_stdout_lines) > 0:
					for line in module_stdout_lines:
						iktprint([(f"{line}", "default")])
					iktprint([("", "default")])
				else:
					iktprint([("<no output>\n", "none")])

				iktprint([("module_stderr:", "header")])
				if len(module_stderr_lines) > 0:
					for line in module_stderr_lines:
						iktprint([(f"{line}", "default")], stderr = True)
					iktprint([("\n", "default")])
				else:
					iktprint([("<no output>\n", "none")])

def __run_playbook(playbookpath, nodes, values = None):
	http_proxy = deep_get(iktconfig, "Network#http_proxy", "")
	https_proxy = deep_get(iktconfig, "Network#https_proxy", "")
	use_proxy = "no"
	if (http_proxy is not None and len(http_proxy) > 0) or (https_proxy is not None and len(https_proxy) > 0):
		use_proxy = "yes"
	values["use_proxy"] = use_proxy

	retval, ansible_results = ansible_run_playbook_on_selection(playbookpath, selection = nodes, values = values)

	# FIXME: ensure that we tell apart fail from skip
	if retval != 0 and len(ansible_results) == 0:
		iktprint([("Failed to execute playbook; retval: ", "error"), (f"{retval}", "errorvalue")], stderr = True)
	else:
		for host in ansible_results:
			# Start by trying to discern the overall result of the run,
			# to use as the colour for the hostname
			data = ansible_results[host]

			# This task does not log using register/debug;
			# users of ansible-playbook will be unhappy
			if data.get("stdout") or data.get("stderr") or data.get("msg"):
				skipped = False

				retval = data.get("rc", retval)
				if data.get("stdout", "").startswith("[SKIP]") and len(data.get("stderr", "")) == 0 and len(data.get("msg", "")) == 0:
					skipped = True
			else:
				tmpskipped = -1

				for task in ansible_results[host]:
					# Messages (should) always succeed
					if task.startswith("TASK: ") or task.startswith("output"):
						retval = data[task].get("rc", retval)
						if ansible_results[host][task].get("stdout", "").startswith("[SKIP]") and len(ansible_results[host][task].get("stderr", "")) == 0 and len(ansible_results[host][task].get("msg", "")) == 0 and tmpskipped != 0:
							tmpskipped = 1
						elif (len(ansible_results[host][task].get("stdout", "")) > 0 and ansible_results[host][task].get("stdout", "").startswith("[SKIP]") == False) or len(ansible_results[host][task].get("stderr", "")) > 0 or len(ansible_results[host][task].get("msg", "")) > 0:
							tmpskipped = 0

					if retval != 0:
						break

			skipped = bool(tmpskipped)

			# Time to output the messages:
			if retval == 0:
				if skipped == False:
					iktprint([(f"[{host}]", "success")])
				else:
					iktprint([(f"[{host}] N/A (SKIPPED)\n", "skip")])
			else:
				iktprint([(f"[{host}]", "error")])

			if skipped == False:
				if "quiet" in values and values["quiet"] == True:
					print("See Logs for output")
					continue

				# This task does not log using register/debug;
				# users of ansible-playbook will be unhappy
				if data.get("stdout") or data.get("stderr") or data.get("msg"):
					print_ansible_results(data, host, "", retval)
				else:
					for task in ansible_results[host]:
						if task.startswith("TASK: ") or task.startswith("output") or task.startswith("msg"):
							print_ansible_results(data[task], host, task, retval)
					print()

	return retval

def run_playbook(playbook, nodes, values = None):
	return __run_playbook(playbook.get("playbook"), nodes, values = values)

def view_yaml_dump(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	objects = []

	for item in items:
		if type(item) == tuple:
			namespace, name = item
		else:
			name = item
			namespace = ""
		obj = kh.get_ref_by_kind_name_namespace(kind, name, namespace)
		objects.append(obj)

	title = deep_get(kwargs, "title")
	#themearrays = iktlib.format_yaml(objects)
	formatter = iktlib.format_yaml
	return resourceinfodispatch(uip.stdscr, objects, ("__ResourceView", ""), title = title, formatter = formatter)

def view_yaml(stdscr, **kwargs):
	obj = deep_get(kwargs, "obj")
	if obj is None:
		return
	path = deep_get(kwargs, "path")
	if path is not None:
		if deep_get(kwargs, "include_root", False) == True:
			obj = [{f"{path.rsplit('#')[-1]}": deep_get(obj, path)}]
		else:
			obj = [deep_get(obj, path)]
	else:
		obj = [obj]
	title = deep_get_with_fallback(kwargs, ["named_title", "title"])
	formatter = iktlib.format_yaml
	return resourceinfodispatch(stdscr, obj, ("__ResourceView", ""), title = title, formatter = formatter)

def view_pod_logs(stdscr, **kwargs):
	containers = []
	containers_full = []
	items = deep_get(kwargs, "_tagged_items", [])
	selected = deep_get(kwargs, "selected")
	if selected is not None:
		items = [selected]
	namespaces = set()
	for obj in items:
		namespace = getattr(obj, "namespace")
		namespaces.add(namespace)
		name = getattr(obj, "name")
		container_name = getattr(obj, "container")
		image_id = getattr(obj, "image_id")
		containers.append((namespace, name, container_name))
		containers_full.append((namespace, name, container_name, image_id))

	multilog_args = {
		"multilog_containers": containers,
		"multilog_containers_full": containers_full,
		"all_same_namespace": len(namespaces) == 1
	}

	return containerinfoloop(stdscr, container = None, kind = None, obj = None, **multilog_args)

def action_view_pod_logs(uip, items = [], action = {}, values = {}, kind = None, title = ""):
	return view_pod_logs(uip.stdscr, **values)

def infoview_view_yaml(uip, kind, obj, **kwargs):
	if "path" in kwargs:
		path = deep_get(kwargs, "path")
		if deep_get(kwargs, "include_final_path", False) == True:
			_obj = [{f"{path.rsplit('#')[-1]}": deep_get(obj, path)}]
		else:
			_obj = [deep_get(obj, path)]
	else:
		_obj = [obj]
	title = deep_get_with_fallback(kwargs, ["named_title", "title"])
	# themearrays = iktlib.format_yaml(_obj)
	formatter = iktlib.format_yaml
	# return resourceinfodispatch(uip.stdscr, themearrays, ("__ResourceView", ""), title = title)
	return resourceinfodispatch(uip.stdscr, _obj, ("__ResourceView", ""), title = title, formatter = formatter)

def infoview_view_last_applied_configuration(uip, kind, obj, **kwargs):
	last_applied_configuration = deep_get(obj, "metadata#annotations#kubectl.kubernetes.io/last-applied-configuration", {})
	if last_applied_configuration is not None and len(last_applied_configuration) > 0:
		data = json.loads(last_applied_configuration)
	else:
		return
	title = deep_get(kwargs, "title")
	# themearrays = iktlib.format_yaml([data])
	formatter = iktlib.format_yaml
	return resourceinfodispatch(uip.stdscr, [data], ("__ResourceView", ""), title = title, formatter = formatter)

def delete_resource(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	success = True
	force = deep_get(values, "__force", False)

	for item in items:
		namespace, name = item
		message, status = kh.delete_obj_by_kind_name_namespace(kind, name, namespace, force = force)
		if status != 200:
			win = curses_helper.alert(uip.stdscr, uip.maxy // 2, uip.maxx // 2, message = message)
			success = False
			break

	# We successfully deleted everything
	if success == True:
		win = curses_helper.notice(uip.stdscr, uip.maxy // 2, uip.maxx // 2, message = "Successfully deleted all specified resources")

	# Wait for a keypress
	while True:
		uip.stdscr.timeout(100)
		c = uip.stdscr.getch()
		if c != -1:
			del win
			break

def force_delete_resource(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	values["__force"] = True
	return delete_resource(uip, items = items, action = action, values = values, kind = kind)

def __create_namespace(name):
	args = [ "kubectl", "create", "namespace", f"{name}" ]
	result = subprocess.run(args, stdout = PIPE, stderr = PIPE, universal_newlines = True)
	return result

def create_namespace(stdscr, **kwargs):
	selection_vars = deep_get(kwargs, "selection_vars")
	name = deep_get(selection_vars, "namespace")

	curses.endwin()
	os.system("clear")

	# Verify that the name of the new namespace is valid
	if kh.validate_name("dns-label", name) == False:
		msg = [("Error: ", "error"), ("“", "default"), (name, "argument"), ("“ is not a valid name", "default")]
		iktprint(msg, stderr = True)
	elif kh.get_ref_by_kind_name_namespace(("Namespace", ""), name, "") is not None:
		msg = [("Error: ", "error"), ("namespace “", "default"), (name, "argument"), ("“ already exists", "default")]
		iktprint(msg, stderr = True)
	else:
		msg = [("Creating namespace “", "default"), (name, "argument"), ("“", "default")]
		iktprint(msg)
		__create_namespace(name)

	print("\n")

	waitforkeypress = True
	if waitforkeypress:
		input("\nPress Enter to continue...")
	stdscr.refresh()

# Valid kinds:
# ("Deployment", "apps")
def __pause_resource(kind, namespace, name):
	args = ["kubectl", "rollout", "pause", f"{kind[0]}.{kind[1]}/{name}", f"--namespace={namespace}"]
	result = subprocess.run(args, stdout = PIPE, stderr = PIPE, universal_newlines = True)
	return result

# Valid kinds:
# ("Deployment", "apps")
def __resume_resource(kind, namespace, name):
	args = ["kubectl", "rollout", "resume", f"{kind[0]}.{kind[1]}/{name}", f"--namespace={namespace}"]
	result = subprocess.run(args, stdout = PIPE, stderr = PIPE, universal_newlines = True)
	return result

# Valid kinds:
# ("DaemonSet", "apps")
# ("Deployment", "apps")
# ("StatefulSet", apps")
def __restart_resource(kind, namespace, name):
	args = ["kubectl", "rollout", "restart", f"{kind[0]}.{kind[1]}/{name}", f"--namespace={namespace}"]
	result = subprocess.run(args, stdout = PIPE, stderr = PIPE, universal_newlines = True)
	return result

def __get_resource_scale(kind, namespace, name):
	obj = kh.get_ref_by_kind_name_namespace(kind, name, namespace)
	return deep_get(obj, "status#replicas")

# Valid kinds:
# ("Deployment", "apps")
# ("ReplicaSet", "apps")
# ("ReplicationController", "")
# ("StatefulSet", apps")
def __scale_replicas(kind, namespace, name, scale):
	args = ["kubectl", "scale", f"{kind[0]}.{kind[1]}/{name}", f"--namespace={namespace}", f"--replicas={scale}"]
	result = subprocess.run(args, stdout = PIPE, stderr = PIPE, universal_newlines = True)
	return result

def __edit_resource(kind, namespace, name):
	if namespace is None:
		args = ["kubectl", "edit", f"{kind[0]}.{kind[1]}/{name}"]
	else:
		args = ["kubectl", "edit", f"{kind[0]}.{kind[1]}/{name}", f"--namespace={namespace}"]
	result = subprocess.run(args, universal_newlines = True)
	return result.returncode, args

def apply_configuration_from_file(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	curses.endwin()
	os.system("clear")
	resource_path, rtype = values["resource_path"]

	if rtype == "Configuration File":
		args = ["kubectl", "apply", "-f", resource_path]
	elif rtype == "Kustomization":
		args = ["kubectl", "apply", "-k", resource_path]
	else:
		raise Exception(f"Unknown resource type {rtype}; this is a programming error.")

	result = subprocess.run(args, universal_newlines = True)
	return result.returncode, args

def apply_configuration_from_url(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	curses.endwin()
	os.system("clear")
	resource_path = values["resource_url"]

	args = ["kubectl", "apply", "-f", resource_path]
	result = subprocess.run(args, universal_newlines = True)
	return result.returncode, args

# We should probably download and apply locally instead
def create_resource_from_url(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	curses.endwin()
	os.system("clear")
	resource_path, rtype = values["resource_url"]

	args = ["kubectl", "create", "-f", resource_path]
	result = subprocess.run(args, universal_newlines = True)
	return result.returncode, args

def __summarise_resources(path):
	resources = []
	with open(path, "r") as f:
		dicts = yaml.safe_load_all(f)
		for d in dicts:
			kind, api_group = kh.kind_api_version_to_kind(deep_get(d, "kind"), deep_get(d, "apiVersion"))
			if api_group == "":
				merged_kind = kind
			else:
				merged_kind = f"{kind}.{api_group}"
			name = deep_get(d, "metadata#name")
			namespace = deep_get(d, "metadata#namespace", "")
			resources.append((merged_kind, namespace, name))
	return resources

def create_resource_from_file(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	resource_path, rtype = values["resource_path"]
	resource_list = []

	result = 0
	args = []

	if rtype == "Configuration File":
		resources = __summarise_resources(resource_path)

		for kind, namespace, name in resources:
			resource_list.append((widgetlineattrs.NORMAL, [(namespace, ("windowwidget", "default"))], [(name, ("windowwidget", "default"))], [(kind, ("windowwidget", "default"))]))

		headers = ["Namespace:", "Name:", "Kind:"]
		title = "The following resources will be created; accept?"

		uip.refresh_all()
		confirm_buttons = [[ord("y"), ord("Y"), ord("n"), ord("N")], [("[", ("windowwidget", "default")), ("Y", ("windowwidget", "highlight")), ("es", ("windowwidget", "default")), ("]", ("windowwidget", "default"))], [("[", ("windowwidget", "default")), ("N", ("windowwidget", "highlight")), ("o", ("windowwidget", "default")), ("]", ("windowwidget", "default"))]]
		confirm_press, tmpselection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, resource_list, headers = headers, title = title, confirm = True, confirm_buttons = confirm_buttons, cursor = False)

		if confirm_press in [ord("y"), ord("Y")]:
			args = ["kubectl", "create", "-f", resource_path]
	elif rtype == "Kustomization":
		args = ["kubectl", "create", "-k", resource_path]
	else:
		raise Exception(f"Unknown resource type {rtype}; this is a programming error.")

	if len(args) > 0:
		result = subprocess.run(args, universal_newlines = True).returncode

	return result, args

def diff_resource_configuration(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	resource_path, rtype = values["resource_path"]

	if rtype == "Configuration File":
		args = ["kubectl", "diff", "-f", resource_path]
	elif rtype == "Kustomization":
		args = ["kubectl", "diff", "-k", resource_path]
	else:
		raise Exception(f"Unknown resource type {rtype}; this is a programming error.")

	result = subprocess.run(args, stdout = PIPE, stderr = PIPE, universal_newlines = True)

	indent = deep_get(iktconfig, "Global#indent", 4)

	diff = []

	if len(result.stdout) == 0:
		return

	for line in result.stdout.splitlines():
		if line.startswith("+"):
			formatting = ("windowwidget", "diffplus")
		elif line.startswith("-"):
			formatting = ("windowwidget", "diffminus")
		elif line.startswith("@@"):
			formatting = ("windowwidget", "diffatat")
		elif line.startswith("diff "):
			formatting = ("windowwidget", "diffheader")
		else:
			formatting = ("windowwidget", "diffsame")

		# kubectl shows the diff with a 2-space indent;
		# if a different indent is configured we have to modify this
		if indent != 2:
			prefix = line[0]
			tmp = re.match(r"^(\s*)(.*)", line[1:])
			if tmp is not None and len(tmp[1]) % 2 == 0:
				line = prefix + "".ljust(int(len(tmp[1]) / 2) * indent) + tmp[2]

		diff.append((widgetlineattrs.NORMAL, [(line, formatting)]))

	tmpselection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, diff, title = "Diff between current and would be configuration:", cursor = False)

def format_commandline(args, implicit_command = True):
	strarray = []

	command = implicit_command

	for i in range(0, len(args)):
		# The first argument is the program name
		if i == 0:
			strarray += [(args[i], "programname")]
		# This is an option
		elif args[i].startswith(("-")):
			strarray += [(f" {args[i]}", "option")]
		# The first non-option argument is the command
		elif command == False:
			strarray += [(f" {args[i]}", "command")]
			command = True
		else:
			strarray += [(f" {args[i]}", "argument")]

	return strarray

def edit_resource(stdscr, **kwargs):
	obj = deep_get(kwargs, "obj")
	kind = deep_get(kwargs, "kind")
	name = deep_get(obj, "metadata#name")
	namespace = deep_get(obj, "metadata#namespace", "")
	if name is None:
		return

	curses.endwin()
	os.system("clear")
	retval, args = __edit_resource(kind, namespace, name)

	waitforkeypress = False
	if waitforkeypress or retval > 0:
		if retval > 0:
			iktprint([("\nError: ", "error")] + format_commandline(args, implicit_command = False) + [(" returned ", "default"), (retval, "errorvalue")], stderr = True)
		input("\nPress Enter to continue...")
	stdscr.refresh()

def restart_resource_rescale(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	curses.endwin()
	os.system("clear")

	for item in items:
		namespace, name = item
		old_scale = __get_resource_scale(kind, namespace, name)
		__scale_replicas(kind, namespace, name, scale = 0)
		__scale_replicas(kind, namespace, name, scale = old_scale)
		msg = [(f"Restarting {kind[0]}.{kind[1]} “", "default"), (namespace, "argument"), ("::", "separator"), (name, "argument"), ("“ scale: ", "default"), (old_scale, "emphasis")]
		iktprint(msg)

	print("\n")

	waitforkeypress = True
	if waitforkeypress:
		input("\nPress Enter to continue...")
	uip.stdscr.refresh()

def restart_resource_rollout(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	curses.endwin()
	os.system("clear")

	for item in items:
		namespace, name = item
		__restart_resource(kind, namespace, name)
		msg = [(f"Restarting {kind[0]}.{kind[1]} “", "default"), (namespace, "argument"), ("::", "separator"), (name, "argument")]
		iktprint(msg)

	print("\n")

	waitforkeypress = True
	if waitforkeypress:
		input("\nPress Enter to continue...")
	uip.stdscr.refresh()

def rescale_resource(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	curses.endwin()
	os.system("clear")

	for item in items:
		namespace, name = item
		scale = values["scale"]
		old_scale = __get_resource_scale(kind, namespace, name)
		__scale_replicas(kind, namespace, name, scale)
		msg = [(f"Rescaling {kind[0]}.{kind[1]} “", "default"), (namespace, "argument"), ("::", "separator"), (name, "argument"), ("“ scale: ", "default"), (old_scale, "emphasis"), (" => ", "default"), (scale, "emphasis")]
		iktprint(msg)

	print("\n")

	waitforkeypress = True
	if waitforkeypress:
		input("\nPress Enter to continue...")
	uip.stdscr.refresh()

# Valid kinds:
# ("Deployment", "apps")
def pause_resource_rollout(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	curses.endwin()
	os.system("clear")

	for item in items:
		namespace, name = item
		__pause_resource(kind, namespace, name)
		msg = [(f"Pausing {kind[0]}.{kind[1]} “", "default"), (namespace, "argument"), ("::", "separator"), (name, "argument")]
		print(msg)

	print("\n")

	waitforkeypress = True
	if waitforkeypress:
		input("\nPress Enter to continue...")
	uip.stdscr.refresh()

# Valid kinds:
# ("Deployment", "apps")
def resume_resource_rollout(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	curses.endwin()
	os.system("clear")

	for item in items:
		namespace, name = item
		__resume_resource(kind, namespace, name)
		msg = [(f"Resuming {kind[0]}.{kind[1]} “", "default"), (namespace, "argument"), ("::", "separator"), (name, "argument")]
		print(msg)

	print("\n")

	waitforkeypress = True
	if waitforkeypress:
		input("\nPress Enter to continue...")
	uip.stdscr.refresh()

# Valid kinds:
# ("Deployment", "apps")
def stop_resource_rescale(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	curses.endwin()
	os.system("clear")

	for item in items:
		namespace, name = item
		old_scale = __get_resource_scale(kind, namespace, name)
		__scale_replicas(kind, namespace, name, 0)
		msg = [(f"Stopping {kind[0]}.{kind[1]} “", "default"), (namespace, "argument"), ("::", "separator"), (name, "argument"), ("“ scale: ", "default"), (old_scale, "emphasis"), (" => ", "default"), ("0", "emphasis")]
		print(msg)

	print("\n")

	waitforkeypress = True
	if waitforkeypress:
		input("\nPress Enter to continue...")
	uip.stdscr.refresh()

def delete_logs(uip, items = [], action = {}, values = {}, kind = None, title = ""):
	for item in items:
		ansible_delete_log(item)

def execute_command(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	tmpargs = deep_get(values, "action_args#command", [])
	if len(tmpargs) == 0:
		return

	args = []

	for arg in tmpargs:
		if arg == "<<<items>>>":
			args += items
		elif arg.startswith("<<<items:"):
			separator = arg[len("<<<items:"):-len(">>>")]
			args.append(separator.join(items))
		else:
			args.append(arg)

	description = action.get("description")
	if description is None:
		description = " ".join(args)
	msg = [("Executing “", "action"), (description, "argument"), ("“\n", "action")]

	curses.endwin()
	os.system("clear")

	iktprint(msg)

	try:
		result = subprocess.run(args)
		retval = result.returncode
	except FileNotFoundError:
		iktprint([("Error: ", "error"), ("command “", "default"), (f"{args[0]}", "programname"), ("“ not found", "default")])
		retval = 2

	waitforkeypress = True
	if waitforkeypress or retval > 0:
		input("\nPress Enter to continue...")
	uip.stdscr.refresh()

def command_hosts(uip, items = [], action = {}, values = {}, kind = None, **kwargs):
	values.pop("_tagged_items", None)
	hosts = iktlib.join_tuple_list(items, _tuple = "hostname", separator = (", ", "separator"))
	msg = [("Executing playbook “", "action"), (action.get("description"), "argument"), ("“ on the following hosts: ", "action")] + hosts + [("\n", "action")]

	curses.endwin()
	os.system("clear")

	if action.get("requires_cluster_info") == True:
		gather_cluster_info()

	iktprint(msg)

	# If run_before is set we have one or several playbooks that need to be run before this one
	runbefore = action.get("run_before", [])

	retval = 0

	for preplaybook in runbefore:
		preplaybookpath = get_playbook_path(f"{preplaybook}.yaml")
		tmpretval = __run_playbook(preplaybookpath, items, values = values)
		if retval == 0:
			retval = tmpretval
		else:
			break

	# If all pre-requisites completed successfully we perform the main task
	if retval == 0:
		retval = run_playbook(action, items, values = values)

	# If everything was successful it's time for the run_after playbooks
	if retval == 0:
		runafter = action.get("run_after", [])

		for postplaybook in runafter:
			postplaybookpath = get_playbook_path(f"{postplaybook}.yaml")
			tmpretval = __run_playbook(postplaybookpath, items, values = values)
			if retval == 0:
				retval = tmpretval
			else:
				break

	# If everything was successful we execute the add_to_groups/remove_from_groups actions
	if retval == 0:
		for group in action.get("add_to_groups", []):
			ansible_add_hosts(ANSIBLE_INVENTORY, items, group = group, skip_all = True)

		for group in action.get("remove_from_groups", []):
			ansible_remove_hosts(ANSIBLE_INVENTORY, items, group = group)

	waitforkeypress = True
	if waitforkeypress or retval > 0:
		input("\nPress Enter to continue...")
	uip.stdscr.refresh()

nodeplaybooks = {
}

def ssh_to_host(stdscr, **kwargs):
	if "selected" in kwargs:
		selected = deep_get(kwargs, "selected")
		if type(selected) == tuple:
			host = selected[0]
		elif type(selected) == str:
			host = selected
		else:
			host = selected.name
	elif "obj" in kwargs:
		obj = deep_get(kwargs, "obj")
		name_path = deep_get(kwargs, "name_path")
		name = deep_get(obj, name_path)
		host = deep_get(kwargs, "name", name)

	if host is None:
		return

	msg = [("SSH:ing to ", "action"), (host, "hostname"), (":\n", "action")]

	inventory = ansible_get_inventory_dict()

	# ansible_user in the inventory overrides that defined in ikt.yaml
	# thus we get these in ascending over of priority
	# if no user is specified we assume that we're to use the user we're running as;
	# but really, ansible
	sshuser = deep_get(iktconfig, "Ansible#ansible_user")
	sshuser = deep_get(inventory, "all#vars#ansible_user", sshuser)
	sshuser = deep_get(inventory, f"all#hosts#{host}#ansible_user", sshuser)

	curses.endwin()
	os.system("clear")
	iktprint(msg)

	args = [ "/usr/bin/ssh" ]

	if sshuser is not None:
		host = "%s@%s" % (sshuser, host)
	args.append(host)

	subprocess.run(args)

	stdscr.refresh()

def list_configuration_files(basedir):
	# Always provide a means to navigate up in the directory tree
	plist = []
	directories = []
	kustomizations = []
	files = []

	if os.path.isdir(basedir):
		for filename in os.listdir(basedir):
			if filename.startswith("~") or filename.startswith("."):
				continue
			# real path, display name, type
			if filename.endswith(".yaml") or filename.endswith(".yml"):
				files.append((f"{basedir}/{filename}", filename, "Configuration File"))
				ptype = "Configuration File"
			elif os.path.isdir(f"{basedir}/{filename}"):
				if os.path.isfile(f"{basedir}/{filename}/kustomization.yaml"):
					files.append((f"{basedir}/{filename}", filename, "Kustomization"))
				else:
					files.append((f"{basedir}/{filename}", filename, "<dir>"))
			else:
				continue

	plist = [(f"{os.path.dirname(basedir)}", "..", "<dir>")]
	plist += natsorted(directories)
	plist += natsorted(kustomizations)
	plist += natsorted(files)

	return plist

def populate_actionlist(context = None, action_list = None, control_plane_selected = False, single_item = False, cluster_available = True):
	actions = []
	order = []
	for item in action_list:
		context_types = deep_get(action_list, f"{item}#context_types")
		if context is not None and context_types != [] and context not in context_types:
			continue

		description = deep_get(action_list, f"{item}#description")
		category = deep_get(action_list, f"{item}#category", "")
		name = item
		order.append((description, category, name))

	currentcategory = ""
	for item in natsorted(order, key = itemgetter(1, 0)):
		action = item[0]
		category = item[1]
		allowoncontrolplane = deep_get(action_list, f"{item[2]}#allow_on_controlplane", True)
		singleoncontrolplane = deep_get(action_list, f"{item[2]}#single_on_controlplane", False)
		singleonly = deep_get(action_list, f"{item[2]}#single_only", False)
		readonly = deep_get(action_list, f"{item[2]}#read_only", False)
		metadata = deep_get(action_list, f"{item[2]}#metadata", [])
		tmp = []
		for _str, _fmt in metadata:
			if type(_fmt) == list:
				tmp.append((_str, tuple(_fmt)))
			else:
				tmp.append((_str, _fmt))
		metadata = tmp
		if singleonly == True and single_item == False:
			continue
		if singleoncontrolplane == True and control_plane_selected == True and single_item == False:
			continue
		elif allowoncontrolplane == False and control_plane_selected == True:
			continue
		if readonly == False and read_only_mode == True:
			continue

		if currentcategory != category:
			actions.append((widgetlineattrs.SEPARATOR, [(f" {category} ", ("windowwidget", "default"))], [("", ("windowwidget", "default"))]))
			currentcategory = category
		actions.append((widgetlineattrs.NORMAL, [(f"{action}", ("windowwidget", "default"))], metadata))

	return actions, action_list

def __populate_playbooklist(path, action_list = {}):
	if not os.path.isdir(path):
		return

	if action_list is None:
		action_list = {}

	for filename in os.listdir(path):
		if filename.startswith("~") or filename.startswith("."):
			continue

		tmp = re.match(r"(.*)\.ya?ml$", filename)
		if tmp is None:
			continue

		playbookname = tmp[1]

		# Check if the playbook already exists in the action list,
		if playbookname in action_list:
			continue

		playbookpath = f"{path}/{filename}"
		description = None

		with open(playbookpath) as f:
			try:
				d = yaml.safe_load(f)
			except Exception as e:
				# This entry could not be parsed; add a dummy entry
				action_list[playbookname] = {
					"description": playbookpath,
					"playbook": playbookpath,
					"category": "__INVALID__",
					"comments": "Failed to parse (Not valid YAML)",
				}
				continue

			# Empty files are used to disable playbooks completely
			if d is None or len(d) == 0:
				action_list[playbookname] = {
					"description": playbookpath,
					"playbook": playbookpath,
					"category": "__DISABLED__",
				}
				continue

			if type(d) != list:
				# This entry could not be parsed; add a dummy entry
				action_list[playbookname] = {
					"description": playbookpath,
					"playbook": playbookpath,
					"category": "__INVALID__",
					"comments": "Failed to parse (Not a list of plays)",
				}
				continue

			description = deep_get(d[0], "vars#metadata#description")

			# Ignore all playbooks that lack a description;
			# typically they are internal playbooks
			if description is None:
				continue

			query = deep_get(d[0], "vars#metadata#query#string")
			queryval = deep_get(d[0], "vars#metadata#query#variable")
			queryfunc = deep_get(d[0], "vars#metadata#query#function")

			# Sanity check
			if queryfunc is not None:
				if queryfunc not in ["string", "yesno", "filechooser"]:
					raise Exception(f"unknown queryfunc “{queryfunc}“ provided")

			confirm = deep_get(d[0], "vars#metadata#confirm", False)
			tmpallowoncontrolplane = deep_get(d[0], "vars#metadata#allow_on_control_plane")
			if tmpallowoncontrolplane is None or tmpallowoncontrolplane == "always":
				allowoncontrolplane = True
				singleoncontrolplane = False
			elif tmpallowoncontrolplane.lower() == "single":
				allowoncontrolplane = True
				singleoncontrolplane = True
			elif tmpallowoncontrolplane.lower() == "never":
				allowoncontrolplane = False
				singleoncontrolplane = False
			else:
				raise Exception(f"{playbookpath}: Invalid values for allow-on-control-plane")

			requiresclusterinfo = deep_get_with_fallback(d[0], ["vars#metadata#requires_cluster_info", "vars#metadata#requires-cluster-info"], False)
			runbefore = deep_get_with_fallback(d[0], ["vars#metadata#run_before", "vars#metadata#run-before"], [])
			runafter = deep_get_with_fallback(d[0], ["vars#metadata#run_after", "vars#metadata#run-after"], [])
			addtogroups = deep_get_with_fallback(d[0], ["vars#metadata#add_to_groups", "vars#metadata#add-to-groups"], [])
			removefromgroups = deep_get_with_fallback(d[0], ["vars#metadata#remove_from_groups", "vars#metadata#remove-from-groups"], [])
			category = deep_get(d[0], "vars#metadata#category", "Uncategorized")
			playbooktypes = deep_get_with_fallback(d[0], ["vars#metadata#playbook_types", "vars#metadata#playbook-types"], [])
			comments = deep_get(d[0], "vars#metadata#comments", "")
			readonly = deep_get_with_fallback(d[0], ["vars#metadata#read_only", "vars#metadata#read-only"], False)
			extravars = {
				"quiet": deep_get(d[0], "vars#metadata#quiet", False),
			}

			action_list[playbookname] = {
				"description": description,
				"playbook": playbookpath,
				"query": query,
				"queryval": queryval,
				"queryfunc": queryfunc,
				"confirm": confirm,
				"allow_on_control_plane": allowoncontrolplane,
				"single_on_control_plane": singleoncontrolplane,
				"requires_cluster_info": requiresclusterinfo,
				"run_before": runbefore,
				"run_after": runafter,
				"add_to_groups": addtogroups,
				"remove_from_groups": removefromgroups,
				"category": category,
				"playbook_types": playbooktypes,
				"comments": comments,
				"read_only": readonly,
				"extravars": extravars,
			}

	return action_list

def populate_playbooklist(context = None, actions = [], action_list = {}, control_plane_selected = False, single_item = False, cluster_available = True):
	# Only populate the list of playbooks if we have ansible support
	if ansible_support == True:
		local_playbooks = deep_get(iktconfig, "Ansible#local_playbooks", [])
		for playbook_path in local_playbooks:
			# Substitute {HOME}/ for {HOMEDIR}
			if playbook_path.startswith("{HOME}/"):
				playbook_path = f"{HOMEDIR}/{playbook_path[len('{HOME}/'):]}"
			# Skip non-existing playbook paths
			if not os.path.isdir(playbook_path):
				continue
			action_list = __populate_playbooklist(playbook_path, action_list = action_list)
		action_list = __populate_playbooklist(ANSIBLE_PLAYBOOK_DIR, action_list = action_list)

		order = []
		for item in action_list:
			playbooktypes = action_list[item].get("playbook_types", [])
			if context is not None and playbooktypes != [] and context not in playbooktypes:
				continue

			description = action_list[item].get("description")
			category = action_list[item].get("category", "")
			name = item
			order.append((description, category, name))

		currentcategory = ""
		for item in natsorted(order, key = itemgetter(1, 0)):
			action = item[0]
			category = item[1]
			allowoncontrolplane = action_list[item[2]].get("allow_on_control_plane", True)
			singleoncontrolplane = action_list[item[2]].get("single_on_control_plane", True)
			readonly = action_list[item[2]].get("read_only", False)
			comments = action_list[item[2]].get("comments", "")
			lineattrs = widgetlineattrs.NORMAL
			if read_only_mode == True and readonly == False:
				continue
			if singleoncontrolplane == True and control_plane_selected == True and single_item == False:
				continue
			elif allowoncontrolplane == False and control_plane_selected == True:
				continue
			elif action_list[item[2]].get("requires_cluster_info", False) == True and cluster_available == False:
				metadata = []
				if len(comments) > 0:
					metadata.append((f"{comments},", ("windowwidget", "highlight")))
				metadata.append(("<cluster not available>", ("windowwidget", "alert")))
				lineattrs = widgetlineattrs.UNSELECTABLE
			elif category == "__INVALID__":
				lineattrs = widgetlineattrs.UNSELECTABLE & widgetlineattrs.INVALID
				metadata = [(comments, ("windowwidget", "alert"))]
			elif category == "__DISABLED__":
				continue
			else:
				metadata = [(comments, ("windowwidget", "highlight"))]

			if currentcategory != category:
				if category == "__INVALID__":
					actions.append((widgetlineattrs.SEPARATOR, [(f" INVALID ", ("windowwidget", "bright"))], [("", ("windowwidget", "default"))]))
					currentcategory = category
				else:
					actions.append((widgetlineattrs.SEPARATOR, [(f" {category} ", ("windowwidget", "default"))], [("", ("windowwidget", "default"))]))
					currentcategory = category
			if currentcategory == "__INVALID__":
				actions.append((lineattrs, [(f"{action}", ("windowwidget", "alert"))], metadata))
			else:
				actions.append((lineattrs, [(f"{action}", ("windowwidget", "default"))], metadata))

	return actions, action_list

available_api_families = []

def format_selection_list(uip, refresh_apis = False):
	global views
	global available_api_families
	hide_unavailable = deep_get_with_fallback(iktconfig, ["Selector#hide_unavailable_apis", "Global#hide_unavailable_apis"], True)
	categorise = deep_get(iktconfig, "Selector#categorise", True)
	sortcolumn = deep_get(iktconfig, "Selector#sortcolumn", "family")

	if sortcolumn == "family":
		if categorise == True:
			sortkey1 = 1
			sortkey2 = 2
		else:
			sortkey1 = 2
			sortkey2 = 0
	elif sortcolumn == "name":
		if categorise == True:
			sortkey1 = 1
			sortkey2 = 0
		else:
			sortkey1 = 0
			sortkey2 = 2
	else:
		sys.exit(f"Invalid sortcolumn {sortcolumn} for Selector; aborting.")

	if len(available_api_families) == 0 or refresh_apis == True:
		notice = curses_helper.notice(None, y = uip.maxy // 2, x = uip.maxx // 2, message = "Refreshing list of available APIs")
		# First repopulate the list of views, on the off change that a view file has been added
		views = {**views_special}
		populate_views()
		available_api_families, status = kh.get_available_api_families()
		del notice
		curses.doupdate()
	items = []
	order = []

	# Find the correct sort order
	for item in views:
		kind = None
		viewref = views[item]
		if deep_get(viewref, "skip", False) == True:
			continue
		if hide_unavailable == True:
			kind = deep_get(viewref, "kind", ("", ""))
			if kind is not None and kind != ("", ""):
				if not kind[0].startswith("__") and kind not in available_api_families:
					continue
			check_availability = deep_get(viewref, "check_availability", None)
			if check_availability is not None:
				if check_availability() == False:
					continue
		group = views[item].get("group")
		# XXX: Do override in a nicer manner; perhaps we want all "built-in" groups first?
		if group == "Administration":
			group = "0"
		elif group == "Core":
			group = "1"
		elif group == "Workloads":
			group = "2"
		elif "(Deprecated)" in group:
			# This should ensure that all deprecated groups end up last, but still sorted
			group = "ZZZZZ" + group
		if kind is not None:
			api_group = kind[1]
		else:
			api_group = ""

		if group is None:
			raise Exception(f"group shouldn't be None unless skip=True; view: {item}")

		order.append((item, group, api_group))

	currentgroup = ""
	for item in natsorted(order, key = itemgetter(sortkey1, sortkey2)):
		view = item[0]
		viewref = views[view]

		# This allows us to override the sort order
		group = deep_get(viewref, "group", "")
		kind = deep_get(viewref, "kind", ("", ""))
		if kind is not None:
			api_group = kind[1]
		else:
			api_group = ""

		if currentgroup != group and categorise == True:
			items.append((widgetlineattrs.SEPARATOR, [(f" {group} ", ("windowwidget", "highlight"))], [("", ("windowwidget", "default"))]))
			currentgroup = group
		lineattrs = widgetlineattrs.NORMAL
		if kind is not None and kind != ("", "") and not kind[0].startswith("__") and kind not in available_api_families:
			lineattrs = widgetlineattrs.UNSELECTABLE
		if api_group == "":
			items.append((lineattrs, [(f"{view}", ("windowwidget", "default"))], [(f"", ("windowwidget", "dim"))]))
		else:
			items.append((lineattrs, [(f"{view}", ("windowwidget", "default"))], [(f"<{api_group}>", ("windowwidget", "dim"))]))

	return items

def selectwindow(stdscr, uip, refresh_apis = False):
	# Ideally we want to return to the same selection
	global defaultview

	uip.refresh_all()
	items = format_selection_list(uip, refresh_apis)
	title = "Choose view"

	selection = None

	while selection is None:
		extra_args = { "KEY_F6": True }
		tmpselection = curses_helper.windowwidget(uip.stdscr, uip.maxy, uip.maxx, uip.maxy // 2, uip.maxx // 2, items, title = title, preselection = defaultview, **extra_args)
		if tmpselection is not None:
			if type(tmpselection) == int and tmpselection < 0:
				if tmpselection == -curses.KEY_F6:
					if deep_get(iktconfig, "Selector") is None:
						deep_set(iktconfig, "Selector", {})
					categorise = not deep_get(iktconfig, "Selector#categorise", True)
					deep_set(iktconfig, "Selector#categorise", categorise, create_path = True)
					items = format_selection_list(uip, refresh_apis)
					uip.refresh_all()
					continue
			selection = tmpselection[1][0][0]

	if selection != "":
		defaultview = selection
		return curses_helper.retval.RETURNFULL
	else:
		return curses_helper.retval.NOMATCH

def selectorloop(stdscr, view):
	#field_list, sortcolumn = fieldgenerator(view)
	field_list, sortcolumn = (None, None)
	uip = UIProps(stdscr)

	windowheader = views[view].get("windowheader", view)

	uip.init_window(field_list = field_list, windowheader = windowheader, sortcolumn = sortcolumn)

	while True:
		retval = selectwindow(stdscr, uip)
		if retval == curses_helper.retval.RETURNFULL:
			return retval

listviewactions = {
	"Apply configuration from file": {
		"description": "Apply configuration file or Kustomization",
		"confirm": True,
		"actionfunc": apply_configuration_from_file,
		"query": "Choose configuration/Kustomization to apply:",
		"queryval": "resource_path",
		"queryfunc": "filechooser",
		"extravars": {
			"listgetter": list_configuration_files,
			"basedir": DEPLOYMENTDIR,
		},
		#"confirmfunc":
		#"confirmstring": "The following changes will be performed:",
	},
	"Create resources from file": {
		"description": "Create resource from configuration file/Kustomization",
		"actionfunc": create_resource_from_file,
		"query": "Choose configuration/Kustomization to create:",
		"queryval": "resource_path",
		"queryfunc": "filechooser",
		"extravars": {
			"listgetter": list_configuration_files,
			"basedir": DEPLOYMENTDIR,
		},
	},
	"Apply configuration from URL": {
		"description": "Apply configuration URL",
		"confirm": True,
		"actionfunc": apply_configuration_from_url,
		"query": "URL to apply",
		"queryval": "resource_url",
		"queryfunc": "string",
		#"confirmfunc":
		#"confirmstring": "The following changes will be performed:",
	},
	"Create resources from URL": {
		"description": "Create resource from URL",
		"actionfunc": create_resource_from_url,
		"query": "URL to create resource from",
		"queryval": "resource_url",
		"queryfunc": "string",
	},
	#"Delete resources from configuration": {
	#	"description": "Delete resource by reverting configuration file/Kustomization",
	#},
	"Diff resource configuration": {
		"description": "Show what modifications applying configuration file or Kustomization would make",
		"actionfunc": diff_resource_configuration,
		"query": "Choose configuration/Kustomization to show difference against:",
		"queryval": "resource_path",
		"queryfunc": "filechooser",
		"extravars": {
			"listgetter": list_configuration_files,
			"basedir": DEPLOYMENTDIR,
		},
	},
}

# Default infopad fields:
#
# Name		Shortcut	Path				Special
# ---		---		---				---
# Name:				metadata#name			Always first
# Namespace:	[Shift] + N	metadata#namespace		Always second; optional
# Created:			metadata#creationTimestamp	Always last; uses field_processor_timestamp()
#
# Wherever applicable the following shortcuts will be available:
#
# Name                               Shortcut
# ---                                ---
# Show security context information  X
# Show resource conditions           C
# Show events                        E
# View YAML dump of resource         Y
# Show last applied configuration    [Shift] + L
#
# Brief overview of infopad:
#
# "Fieldname:":
#	{
#		"fieldname": formatlist		# Overrides "Fieldname:" as field name; this is a format list
#						# This is mainly intended for highlighting shortcut keys
#		"path": "path",			# Get the value from this path using deep_get(obj, "path")
#	        "processor": "processor",	# Use this function to postprocess the value;
#						# returns a list of (string, (color, attribute)) tuples
#						# The default processor turns None, "", and -1 into
#						# [("strings, "none")]
#						# Example processors:
#						#	field_processor_timestamp()
#						#	field_processor_status()
#						#	field_processor_list()
#						#	field_processor_empty() (the default)
#						#	None (use this to only output the fieldname)
#		"extra_paths": [ "path", ... ]	# Extra paths to pass to the processor
#		"fallback": formatlist		# Fallback format list
#       }
#
# Note: For complex data it might be easier to write a custom processor and just pass in the object
#
# The most versatile, but also complex, processor is field_processor_list();
# it can provide formatting, substitutions, and (limited) flow control
infoviews_builtin = {
	("Application", "app.k8s.io"): {
		"field_indexes": {
			"Normal": ["name", "status", "link"],
		},
		"sortcolumn": "status",
		"infopad": {
			"Add ownerRef:": {
				"path": "spec#addOwnerRef",
				"fallback": [("False", ("types", "generic"))],
			},
			"Label Selector:": {
				"path": "spec#selector#matchLabels",
				"processor": field_processor_label_selector,
			},
			"Kinds:": {
				"processor": field_processor_component_kinds,
			},
			"Description:": {
				"path": "spec#descriptor#description",
				"processor": field_processor_description,
			},
			"Keywords:": {
				"extra_paths": "spec#descriptor#keywords",
				"processor": field_processor_list,
			},
		},
		"listpad": {
			"infogetter": get_app_status_info,
		},
	},
	("CiliumEndpoint", "cilium.io"): {
		"windowheader": "Cilium Endpoint Info",
		"infopad": {
			"Cilium Identity:": {
				"fieldname": [("C", ("main", "infoheader_shortcut")), ("ilium Identity:", ("main", "infoheader"))],
				"path": "status#identity#id",
			},
		},
		"shortcuts": {
			"Pod": {
				"shortcut": ord("P"),
				"helptext": ("[Shift] + P", "Open info page for Pod"),
				"call": resourceinfodispatch,
				"kind": ("Pod", ""),
				"name_path": "metadata#name",
				"namespace_path": "metadata#namespace",
			},
			"Cilium Identity": {
				"shortcut": ord("C"),
				"helptext": ("[Shift] + C", "Open info page for Cilium Identity"),
				"call": resourceinfodispatch,
				"kind": "CiliumIdentity",
				"name_path": "status#identity#id",
			},
			"Show Cilium Identity Labels": {
				"shortcut": ord("I"),
				"helptext": ("[Shift] + I", "Show Cilium identity labels"),
				"widget": "windowwidget",
				"title": "Identity Labels:",
				"itemgetter": get_list_as_list,
				"itemgetter_args": {
					"path": "status#identity#labels",
				},
				"formatting": [("windowwidget", "default"), ("windowwidget", "highlight")],
			},
			"Show Named Ports": {
				"shortcut": ord("S"),
				"helptext": ("[Shift] + S", "Show named ports"),
				"widget": "windowwidget",
				"title": "Named Ports:",
				"headers": ["Name:", "Port:", "Protocol:"],
				"itemgetter": get_list_fields,
				"itemgetter_args": {
					"path": "status#named-ports",
					"fields": ["name", "port", "protocol"],
				},
				"formatting": [("windowwidget", "default"), ("windowwidget", "highlight")],
			},
		},
	},
	("CiliumIdentity", "cilium.io"): {
		"windowheader": "Cilium Identity Info",
		"infopad": {},
		"shortcuts": {
			"Show Security Labels": {
				"shortcut": ord("S"),
				"helptext": ("[Shift] + S", "Show security labels"),
				"widget": "windowwidget",
				"title": "Security Labels:",
				"headers": ["Label:", "Value:"],
				"itemgetter": get_key_value,
				"itemgetter_args": {
					"path": "security-labels",
				},
				"formatting": [("windowwidget", "default"), ("windowwidget", "highlight")],
			},
		},
	},
	("CiliumNode", "cilium.io"): {
		"windowheader": "Cilium Node Info",
		"infopad": {
			"Node:": {
				"fieldname": [("N", ("main", "infoheader_shortcut")), ("ode:", ("main", "infoheader"))],
				"processor": field_processor_owr_node,
			},
			"Health (IPv4):": {
				"path": "spec#health#ipv4",
			},
			"IPAM:": {
				"processor": None,
			},
			"  Pod CIDRs:": {
				"extra_paths": "spec#ipam#podCIDRs",
				"processor": field_processor_list,
			},
		},
		"shortcuts": {
			"Addresses": {
				"shortcut": ord("A"),
				"helptext": ("[Shift] + A", "Show addresses"),
				"widget": "windowwidget",
				"title": "Maintainers:",
				"headers": ["IP:", "Type:"],
				"itemgetter": get_list_fields,
				"itemgetter_args": {
					"path": "spec#addresses",
					"fields": [
						"ip",
						"type",
					],
				},
				"formatting": [("windowwidget", "default"), ("windowwidget", "highlight")],
				# This isn't supported for now
				"sortcolumn": "ip",
			},
			"Node": {
				"shortcut": ord("N"),
				"helptext": ("[Shift] + N", "Open info page for Node"),
				"call": resourceinfodispatch,
				"owner_references_path": "metadata#ownerReferences",
				# Note: This cannot be (kind, api_group)
				"owner_references_kind": "Node",
			},
		},
	},
	("Ingress", "networking.k8s.io"): {
		"field_indexes": {
			"Normal": ["host", "path", "backends"],
		},
		"sortcolumn": "host",
		"infopad": {
			"Backend:": {
				# Note: path and extra_paths will be overriden
				# by field_processor_ingress_backend to handle
				# networking.k8s.io/v1 renames
				"path": "spec#backend",
				"extra_paths": ["spec#backend#serviceName", "spec#backend#servicePort"],
				"fallback": [("default-http-backend", ("types", "generic")), ("separators", "port"), ("80", ("types", "port"))],
				"formatting": {
					"field_colors": [("types", "generic"), ("types", "port")],
					"item_separators": [("separators", "port")],
				},
				"processor": field_processor_ingress_backend,
			},
			"TLS:": {
				"path": "spec#tls",
				"processor": field_processor_tls,
			}
		},
		"listpad": {
			"infogetter": get_ingress_rule_info,
		},
	},
	("__Log", ""): {
		"windowheader": "Playbook Log Info",
		"field_indexes": {
			"Normal": ["index", "name", "host", "start_time", "completion_time", "retval"],
		},
		"fields": {
			"index": {
				"header": "Index:",
				"paths": [
					{
						"path": "index",
						"pathtype": "raw",
					},
				],
				"align": "right",
			},
			"name": {
				"header": "Task:",
				"paths": [
					{
						"path": "log#task",
						"pathtype": "value",
					},
				],
			},
			"host": {
				"header": "Host:",
				"paths": [
					{
						"path": "log#host",
						"pathtype": "value",
					},
				],
			},
			"start_time": {
				"header": "Started At:",
				"paths": [
					{
						"path": "log#start_date",
						"pathtype": "value",
						"type": "timestamp",
					},
				],
				"formatter": "timestamp",
			},
			"completion_time": {
				"header": "Finished At:",
				"paths": [
					{
						"path": "log#end_date",
						"pathtype": "value",
						"type": "timestamp",
					},
				],
				"formatter": "timestamp",
			},
			"retval": {
				"header": "Return Value:",
				"paths": [
					{
						"path": "log#retval",
						"pathtype": "value",
						"type": "int",
					},
				],
				"align": "right",
			},
		},
		"sortcolumn": "index",
		# We're not getting the information the normal way
		"objgetter": objgetter_ansible_log,
		"name_path": "name",
		"creation_timestamp_path": "created_at",
		"activatedfun": resourceinfodispatch,
		"viewoverride": ("__LogView", ""),
		"infopad": {
			"Path:": {
				"path": "playbook_path",
			},
			"Category:": {
				"path": "category",
			},
			"Playbook Types:": {
				"extra_paths": "playbook_types",
				"processor": field_processor_list,
			},
		},
		"listpad": {
			"listgetter": listgetter_field,
			"listgetter_args": {
				"path": "logs",
			},
			"infogetter": generic_infogetter,
		},
		"shortcuts": {
			# Logs have no last applied configuration
			"Last Applied Configuration": {},
		},
	},
	("__LogView", ""): {
		"windowheader": "Task Log View",
		#"objgetter": objgetter_ansible_task_log,
		# We're not getting the information the normal way
		"name_path": "log#task",
		"namespace_path": None,
		"creation_timestamp_path": None,
		"timestamps": False,
		"infopad": {
			"Host:": {
				"path": "log#host",
			},
			"Return Value:": {
				"path": "log#retval",
			},
		},
		"logpad": {
			"infogetter": get_task_log,
		},
	},
	("__ResourceView", ""): {
		"windowheader": "Resource Viewer",
		"timestamps": False,
		"logpad": {
			"infogetter": get_themearrays,
		},
		"shortcuts": {
			# The viewer cannot view...
			"Show Events": {},
			"Last Applied Configuration": {},
			"YAML": {},
		}
	},
}

infoviews = {**infoviews_builtin}

def is_cluster_reachable():
	reachable = False

	if kh is not None:
		reachable = kh.is_cluster_reachable()
	return reachable

# These views are always defined internally and cannot be disabled
views_special = {
	"Selector": {
		"windowheader": "",
		"commandline": ["selector"],
		"viewfunc": selectorloop,
		"fields": None,
		"skip": True,
		"is_taggable": False,
	},
	"Cluster Overview": {
		"commandline": ["clusteroverview", "clusterinfo", "overview", "co", "ci"],
		"group": "Administration",
		"viewfunc": clusteroverviewloop,
		"fields": None,
		"update_delay": 50,
		"sortcolumn": None,
		"helptext": helptexts.clusteroverview,
		"activatedfun": None,
		"listgetter": None,
		"infogetter": None,
		"is_taggable": False,
		"check_availability": is_cluster_reachable,
	},
	"Contexts": {
		"commandline": ["contexts", "context", "ctx"],
		"group": "Administration",
		"field_indexes": {
			"Normal": ["current", "name", "cluster", "authinfo", "namespace"],
		},
		"fields": {
			"current": {
				"header": "Current:",
			},
			"cluster": {
				"header": "Cluster:",
			},
			"authinfo": {
				"header": "Authinfo:",
			},
		},
		"kind": None,
		"activatedfun": None,
		"listgetter": None,
		"infogetter": get_context_info,
		"shortcuts": {
			"Switch Context": {
				"shortcut": [ curses.KEY_ENTER, 10, 13 ],
				"helptext": ("[Enter]", "Switch cluster context"),
				"confirm": True,
				"title": "Switch cluster context",
				"action": "call",
				"action_call": set_cluster_context,
				"action_args": {
					"_pass_selected": True,
				},
			},
			# Override:
			"Edit resource": {},
			"View YAML dump": {},
		},
		"is_taggable": False,
	},
	"Pod Log Viewer": {
		"commandline": ["podlogviewer", "podlog"],
		"group": "Administration",
		"field_indexes": {
			"Normal": ["namespace", "name", "container", "status", "node_name", "image_id"],
		},
		"fields": {
			"namespace": {
				"header": "Pod Namespace:",
				"path": "namespace",
				"type": "namespace",
			},
			"name": {
				"header": "Pod Name:",
				"path": "name",
				"type": "str",
			},
			"container": {
				"header": "Container:",
				"path": "container",
				"type": "str",
			},
			"status": {
				"header": "Status:",
				"datagetter": datagetter_container_status,
				"generator": generator_status,
			},
			"node_name": {
				"header": "Node:",
				"path": "node_name",
				"type": "host",
				"default": "<none>",
			},
			"image_id": {
				"header": "Image:",
				"path": "image_id",
				"type": "str",
			},
		},
		"actions": {
			"actionlist": {
				"View Logs": {
					"description": "View logs for tagged resources interleaved",
					"actionfunc": action_view_pod_logs,
				},
			},
		},
		"shortcuts": {
			"View Log": {
				"shortcut": [ curses.KEY_ENTER, 10, 13 ],
				"helptext": ("[Enter]", "View log for selected resource"),
				"action": "call",
				"action_call": view_pod_logs,
				"action_args": {
					"_pass_selected": True,
				},
			},
			# Override:
			"Edit resource": {},
			"View YAML dump": {},
		},
		"sortcolumn": "status",
		"kind": ("__PodLogMonitor", ""),
		"labels": False,
		"listgetter": "get_pod_containers_list",
	},
	"Logs": {
		"commandline": ["logs", "log"],
		"group": "Administration",
		"field_indexes": {
			"Normal": ["name", "action", "created_at", "log_type"],
		},
		"sortcolumn": "created_at",
		"sortorder_reverse": True,
		"kind": ("__Log", ""),
		"labels": False,
		"listgetter": None,
		"infogetter": get_log_info,
		"actions": {
			"actionlist": {
				"Delete log": {
					"description": "Delete log",
					"confirm": True,
					"actionfunc": delete_logs,
				},
			},
		},
		"shortcuts": {
			# Override:
			"Edit resource": {},
			"View YAML dump": {},
		},
	},
	"Network Info": {
		"commandline": ["network", "net", "cni"],
		"group": "Administration",
		"viewfunc": networkinfoloop,
		"fields": None,
		"sortcolumn": None,
		"helptext": helptexts.networkinfo,
		"activatedfun": None,
		"listgetter": None,
		"infogetter": None,
		"check_availability": is_cluster_reachable,
	},
}

views = {**views_special}

# This function is called before parsing the command-line; it cannot use Kubernetes information,
# since that would be far too slow, so
def populate_views():
	global views

	viewdir = os.path.join(IKTDIR, VIEW_DIRNAME)
	if not os.path.isdir(viewdir):
		sys.exit(f"{viewdir} does not exist; please re-run {about.install_program_name}")

	# Get a full list of views from all view directories
	# Start by adding files from the views directory
	view_dirs = []
	view_dirs += deep_get(iktconfig, "General#local_views", [])

	disable_builtin_views = deep_get(iktconfig, "Internal#disable_builtin_views", False)
	if disable_builtin_views == True:
		views = {**views_special}

	view_dirs.append(viewdir)

	view_files = []

	for view_dir in view_dirs:
		if view_dir.startswith("{HOME}"):
			view_dir = view_dir.replace("{HOME}", HOMEDIR, 1)

		if not os.path.isdir(view_dir):
			continue

		for filename in natsorted(os.listdir(view_dir)):
			if filename.startswith(("~", ".")) or not filename.endswith((".yaml", ".yml")):
				continue

			view_files.append(os.path.join(view_dir, filename))

	for view_file in view_files:
		with open(view_file, "r") as f:
			try:
				d = yaml.safe_load(f)
			except:
				sys.exit(f"View-file {view_file} is invalid; aborting.")

			try:
				for view in d:
					pass
			except:
				sys.exit(f"View-file {view_file} is invalid; aborting.")

			kind = deep_get(d, "kind", "<missing>")
			default_command = deep_get(d, "default_command", "<missing>")
			if kind is None or default_command is None or "<missing>" in [kind, default_command]:
				sys.exit(f"View-file {view_file} is invalid: the following fields cannot be missing or None:\n"
					 f"kind: {kind}\n"
					 f"default_command: {default_command}\n"
					  "Aborting.")

			api_family = deep_get(d, "api_family", "")
			# Use a set to avoid duplicates
			_command = set()
			if not kind.startswith("__"):
				# If there's a "." in the command it means the plural or singular is not unique without api_family;
				# don't add the lowercase form of kind automagically
				if "." not in default_command:
					_command.add(kind.lower())
			if len(deep_get(d, "command", [])) > 0:
				_command = set.union(_command, set(deep_get(d, "command", [])))
			# OK, we've got all commands we wanted; now we want the preferred form first
			_command.discard(default_command)
			_command = [default_command] + list(_command)
			# Finally, now that we have a list, add variants with api_family suffixed
			command = list(_command)
			if len(api_family) > 0:
				for item in _command:
					command.append(f"{item}.{api_family}")

			listview_entry = None

			if "listview" not in d and "infoview" not in d:
				sys.exit(f"View-file {view_file} lacks both listview and infoview; there might be typo somewhere")

			if "listview" in d:
				# Do we need to override kind?
				if deep_get(d, "listview#kind") is not None:
					kind = deep_get(d, "listview#kind")
					api_family = deep_get(d, "listview#api_family", "")
				name = deep_get(d, "listview#name", "<missing>")
				group = deep_get(d, "listview#group")

				check_availability = deep_get(d, "check_availability", None)
				if check_availability is not None:
					check_availability = eval(check_availability)

				sortcolumn = deep_get(d, "listview#sortcolumn")
				reversible = deep_get(d, "listview#reversible", True)
				fields = deep_get(d, "listview#fields", "<missing>")
				fields_wide = deep_get(d, "listview#fields_wide", [])

				field_indexes = deep_get(d, "listview#field_indexes", {})
				if len(field_indexes) == 0:
					sys.exit(f"View-file {view_file} is invalid: field_indexes is either missing or empty for the list view. Aborting.")

				if name is None or group is None or len(fields) == 0 or "<missing>" in [name, group]:
					sys.exit(f"View-file {view_file} is invalid: the following fields cannot be missing, empty or None:\n"
						  "listview:\n"
						 f"  name: {name}\n"
						 f"  group: {group}\n"
						  "Aborting.")

				if name in views:
					conflicting_kind = deep_get(views, f"{name}#kind")
					sys.exit(f"Error when processing view-vile {view_file} for kind: {(kind, api_family)}; a view named {name} already exists (for the kind: {conflicting_kind})")

				infogetter = generic_infogetter
				if "infogetter" in deep_get(d, "listview"):
					infogetter = deep_get(d, "listview#infogetter")
					if infogetter is not None:
						infogetter = eval(infogetter)

				listgetter = generic_listgetter
				if "listgetter" in deep_get(d, "listview"):
					listgetter = deep_get(d, "listview#listgetter")
					if listgetter is not None:
						listgetter = eval(listgetter)

				listgetter_args = deep_get(d, "listview#listgetter_args", {})

				activatedfun = deep_get(d, "listview#activatedfun", genericinfoloop)
				if type(activatedfun) == str:
					activatedfun = eval(activatedfun)

				listview_entry = {
					"kind": (kind, api_family),
					"commandline": command,
					"group": group,
					"check_availability": check_availability,
					"field_indexes": field_indexes,
					"fields": fields,
					"activatedfun": activatedfun,
					"listview_args": deep_get(d, "listview#listview_args", {}),
					"statusmsg": deep_get(d, "listview#statusmsg", {}),
					"is_taggable": deep_get(d, "listview#is_taggable", True),
					"listgetter": listgetter,
					"listgetter_args": listgetter_args,
					"reversible": reversible,
					"infogetter": infogetter,
					"infogetter_args": deep_get(d, "listview#infogetter_args", {}),
					"actions": deep_get(d, "listview#actions", {}),
				}
				if sortcolumn is not None:
					listview_entry["sortcolumn"] = sortcolumn

				shortcuts = {}

				_shortcuts = deep_get(d, "listview#shortcuts", {})
				for shortcut in _shortcuts:
					# If the shortcut is empty we're disabling a default shortcut
					if _shortcuts[shortcut] is None or len(_shortcuts[shortcut]) == 0:
						shortcuts[shortcut] = {}
						continue

					key = deep_get(_shortcuts[shortcut], "key", "<missing>")
					modifier = deep_get(_shortcuts[shortcut], "modifier", "")
					helptext = deep_get(_shortcuts[shortcut], "helptext", "<missing>")
					action = deep_get(_shortcuts[shortcut], "action", "<missing>")
					action_args = deep_get(_shortcuts[shortcut], "action_args", {})
					action_call = deep_get(_shortcuts[shortcut], "action_call")
					queryfunc = deep_get(_shortcuts[shortcut], "queryfunc")
					queryval = deep_get(_shortcuts[shortcut], "queryval")
					query = deep_get(_shortcuts[shortcut], "query")

					if key is None or helptext is None or action is None or "<missing>" in [key, helptext, action]:
						sys.exit(f"View-file {view_file} is invalid: the following fields cannot be missing or None for a shortcut:\n"
							 f"key: {key}\n"
							 f"helptext: {helptext}\n"
							 f"action: {action}\n"
							  "Aborting.")

					key = key.lower()
					modifier = modifier.lower()

					if len(modifier) > 0 and modifier not in ["ctrl", "shift"]:
						sys.exit(f"View-file {view_file} is invalid: unknown modifier {modifier}; valid modifiers are shift, ctrl; aborting")

					if key in ["f1", "f2", "f3", "f4", "f5", "f6", "f7", "f8", "f9", "f10", "f11", "f12"] and len(modifier) == 0:
						shortcut_key = eval(f"curses.KEY_{key.upper()}")
						help_key = key.upper()
					elif key in ["f1", "f2", "f3", "f4", "f5", "f6", "f7", "f8", "f9", "f10", "f11", "f12"] and modifier == "shift":
						num = int(key[1:]) + 12
						shortcut_key = eval(f"curses.KEY_{key[0].upper()}{num}")
						help_key = f"[Shift] + {key.upper()} / {key[0]}{num}"
					elif key in ["f13", "f14", "f15", "f16", "f17", "f18", "f19", "f20", "f21", "f22", "f23", "f24"] and len(modifier) == 0:
						num = int(key[1:]) - 12
						shortcut_key = eval(f"curses.KEY_{key[0].upper()}{num}")
						help_key = f"[Shift] + {key[0]}{num} / {key.upper()}"
					elif key in ["enter", "return"]:
						if len(modifier) > 0:
							help_key = "[Enter]"
							shortcut_key = [curses.KEY_ENTER, 10, 13]
					elif len(modifier) > 0:
						if modifier == "shift":
							help_key = f"[Shift] + {key.upper()}"
							shortcut_key = ord(key.upper())
						elif modifier == "ctrl":
							help_key = f"[Ctrl] + {key.upper()}"
							shortcut_key = ord(key) - 96
					else:
						help_key = f"{key.upper()}"
						shortcut_key = ord(key)

					shortcuts[shortcut] = {
						"shortcut": shortcut_key,
						"helptext": (help_key, helptext),
						"action": action,
						"action_args": action_args,
						"action_call": action_args,
						"queryfunc": queryfunc,
						"queryval": queryval,
						"query": query,
					}
					if action == "call":
						action_call = eval(action_call)
						shortcuts[shortcut]["action_call"] = action_call

				if len(shortcuts) > 0:
					listview_entry["shortcuts"] = shortcuts

				# Replace existing listviews with the same name
				views.pop(name, None)

				# Add the new view
				views[name] = listview_entry

			infoview_entry = None

			if "infoview" in d:
				# Default kind and api_family unless overriden
				kind = deep_get(d, "kind", "<missing>")
				api_family = deep_get(d, "api_family", "")

				# Do we need to override kind?
				if deep_get(d, "infoview#kind") is not None:
					kind = deep_get(d, "infoview#kind")
					api_family = deep_get(d, "infoview#api_family", "")
				name = deep_get(d, "infoview#name", "<missing>")
				infopad = deep_get(d, "infoview#infopad", {})
				# Eventually we should handle this the same way as in genericlistloop,
				# with the row_indexes used on the fly, but let's change a bit at a time
				rows = deep_get(infopad, "row_indexes#Normal", {})
				row_fields = {}

				for row in rows:
					row_fields[row] = deep_get(infopad, f"rows#{row}", {})
					# We need to reformat the header
					_header = deep_get(infopad, f"rows#{row}#header", [["<unset>", ["types", "unset"]]])
					header = []
					for string, formatting in _header:
						header.append((string, tuple(formatting)))
					row_fields[row]["header"] = header

				name_path = deep_get(d, "infoview#infopad#name_path")
				namespace_path = deep_get(d, "infoview#infopad#namespace_path", "")
				creation_timestamp_path = deep_get(d, "infoview#infopad#creation_timestamp_path", "")

				listpad = deep_get(d, "infoview#listpad", {})

				on_activation = deep_get(listpad, "on_activation")
				activatedfun = deep_get(on_activation, "call")
				if type(activatedfun) == str:
					activatedfun = eval(activatedfun)
				override_kind = deep_get(on_activation, "kind")
				override_api_family = deep_get(on_activation, "api_family", "")
				on_activation_extraref = deep_get(on_activation, "extraref")
				on_activation_data = deep_get(on_activation, "data")
				if override_kind is None:
					viewoverride = (kind, api_family)
				else:
					viewoverride = (override_kind, override_api_family)
					on_activation["kind"] = viewoverride
					on_activation.pop("api_family", "")

				annotations = deep_get(d, "infoview#annotations")

				sortcolumn = deep_get(listpad, "sortcolumn")
				reversible = deep_get(listpad, "reversible", True)

				infoview_entry = {
					"windowheader": name,
					"field_indexes": deep_get(listpad, "field_indexes"),
					"fields": deep_get(listpad, "fields"),
					"activatedfun": activatedfun,
					"viewoverride": viewoverride,
					"extraref": on_activation_extraref,
					"data": on_activation_data,
					"infopad": row_fields,
					"listpad": {},
					"reversible": reversible,
					"annotations": annotations,
					"shortcuts": {},
				}
				objgetter = deep_get(d, "infoview#infopad#objgetter")
				if objgetter is not None:
					infoview_entry["objgetter"] = eval(objgetter)

				if len(listpad) > 0:
					infoview_entry["listpad"]["on_activation"] = on_activation

				if sortcolumn is not None:
					infoview_entry["sortcolumn"] = sortcolumn

				if name_path is not None:
					infoview_entry["name_path"] = name_path
				if namespace_path is None or len(namespace_path) > 0:
					infoview_entry["namespace_path"] = namespace_path
				if creation_timestamp_path is None or len(creation_timestamp_path) > 0:
					infoview_entry["creation_timestamp_path"] = creation_timestamp_path

				list_listgetter = deep_get(listpad, "listgetter")
				list_listgetter_args = deep_get(listpad, "listgetter_args", {})
				list_path = deep_get(listpad, "path")
				list_infogetter = deep_get(listpad, "infogetter")
				list_infogetter_args = deep_get(listpad, "infogetter_args")
				if list_infogetter is None:
					if len(listpad) > 0:
						raise Exception("View-file {view_file} is invalid: listpad specified, but no infogetter is provided")
				else:
					infoview_entry["listpad"]["infogetter"] = eval(list_infogetter)
					infoview_entry["listpad"]["infogetter_args"] = list_infogetter_args
				if list_listgetter is not None:
					infoview_entry["listpad"]["listgetter"] = eval(list_listgetter)
					infoview_entry["listpad"]["listgetter_args"] = list_listgetter_args
				if list_path is not None:
					infoview_entry["listpad"]["listref"] = list_path

				shortcuts = {}

				_shortcuts = deep_get(d, "infoview#shortcuts", {})
				for shortcut in _shortcuts:
					# If the shortcut is empty we're disabling a default shortcut
					if _shortcuts[shortcut] is None or len(_shortcuts[shortcut]) == 0:
						shortcuts[shortcut] = {}
						continue

					key = deep_get(_shortcuts[shortcut], "key", "<missing>")
					modifier = deep_get(_shortcuts[shortcut], "modifier", "")
					helptext = deep_get(_shortcuts[shortcut], "helptext", "<missing>")
					action = deep_get(_shortcuts[shortcut], "action", "<missing>")
					action_args = deep_get(_shortcuts[shortcut], "action_args", {})
					action_call = deep_get(_shortcuts[shortcut], "action_call")
					queryfunc = deep_get(_shortcuts[shortcut], "queryfunc")
					queryval = deep_get(_shortcuts[shortcut], "queryval")
					query = deep_get(_shortcuts[shortcut], "query")
					widget = deep_get(_shortcuts[shortcut], "widget")
					widget_args = deep_get(_shortcuts[shortcut], "widget_args")
					inputtitle = deep_get(_shortcuts[shortcut], "inputtitle")
					confirm = deep_get(_shortcuts[shortcut], "confirm")
					confirmtitle = deep_get(_shortcuts[shortcut], "confirmtitle")
					w_title = deep_get(_shortcuts[shortcut], "title")
					w_headers = deep_get(_shortcuts[shortcut], "headers")
					w_selectable = deep_get(_shortcuts[shortcut], "selectable")
					w_itemgetter = deep_get(_shortcuts[shortcut], "itemgetter")
					if w_itemgetter is not None:
						w_itemgetter = eval(w_itemgetter)
					w_itemgetter_args = deep_get(_shortcuts[shortcut], "itemgetter_args", {})
					_w_formatting = deep_get(_shortcuts[shortcut], "formatting")
					w_formatting = None
					if _w_formatting is not None:
						w_formatting = []
						for context, attr in _w_formatting:
							w_formatting.append((context, attr))
					w_sortcolumn = deep_get(_shortcuts[shortcut], "sortcolumn", {})

					if key is None or helptext is None or action is None or "<missing>" in [key, helptext]:
						sys.exit(f"View-file {view_file} is invalid: the following fields cannot be missing or None for a shortcut:\n"
							 f"key: {key}\n"
							 f"helptext: {helptext}\n"
							  "Aborting.")

					if widget is None and "<missing>" in [action]:
						sys.exit(f"View-file {view_file} is invalid: at least one of [widget, action] needs to be specified.\n"
							  "Aborting.")

					key = key.lower()
					modifier = modifier.lower()

					if len(modifier) > 0 and modifier not in ["ctrl", "shift"]:
						sys.exit(f"View-file {view_file} is invalid: unknown modifier {modifier}; valid modifiers are shift, ctrl; aborting")

					if key in ["f1", "f2", "f3", "f4", "f5", "f6", "f7", "f8", "f9", "f10", "f11", "f12"] and len(modifier) == 0:
						shortcut_key = eval(f"curses.KEY_{key.upper()}")
						help_key = key.upper()
					elif key in ["f1", "f2", "f3", "f4", "f5", "f6", "f7", "f8", "f9", "f10", "f11", "f12"] and modifier == "shift":
						num = int(key[1:]) + 12
						shortcut_key = eval(f"curses.KEY_{key[0].upper()}{num}")
						help_key = f"[Shift] + {key.upper()} / {key[0]}{num}"
					elif key in ["f13", "f14", "f15", "f16", "f17", "f18", "f19", "f20", "f21", "f22", "f23", "f24"] and len(modifier) == 0:
						num = int(key[1:]) - 12
						shortcut_key = eval(f"curses.KEY_{key[0].upper()}{num}")
						help_key = f"[Shift] + {key[0]}{num} / {key.upper()}"
					elif key in ["enter", "return"]:
						if len(modifier) > 0 or on_activation is None or len(on_activation) == 0:
							help_key = "[Enter]"
							shortcut_key = [curses.KEY_ENTER, 10, 13]
						else:
							sys.exit(f"View-file “{view_file}“ is invalid: the shortcut “{shortcut}“ uses “enter“ as key; this conflicts with built-in shortcut for “on_activation“.")
					elif len(modifier) > 0:
						if modifier == "shift":
							help_key = f"[Shift] + {key.upper()}"
							shortcut_key = ord(key.upper())
						elif modifier == "ctrl":
							help_key = f"[Ctrl] + {key.upper()}"
							shortcut_key = ord(key) - 96
					else:
						help_key = f"{key.upper()}"
						shortcut_key = ord(key)

					shortcuts[shortcut] = {
						"shortcut": shortcut_key,
						"helptext": (help_key, helptext),
						"action": action,
						"action_args": action_args,
						"action_call": action_args,
						"queryfunc": queryfunc,
						"queryval": queryval,
						"query": query,
						"widget": widget,
						"widget_args": widget_args,
						"inputtitle": inputtitle,
						"confirm": confirm,
						"confirmtitle": confirmtitle,
						"title": w_title,
						"headers": w_headers,
						"itemgetter": w_itemgetter,
						"itemgetter_args": w_itemgetter_args,
						"selectable": w_selectable,
						"formatting": w_formatting,
						"sortcolumn": w_sortcolumn,
					}
					if action == "call":
						action_call = eval(action_call)
						shortcuts[shortcut]["action_call"] = action_call

				logpad = deep_get(d, "infoview#logpad", {})

				if len(logpad) > 0:
					if len(deep_get(infoview_entry, "listpad", {})) > 0:
						sys.exit(f"View-file “{view_file}“ is invalid: listpad and logpad cannot be used concurrently.")

					log_infogetter = deep_get(logpad, "infogetter")
					if log_infogetter is None:
						if len(logpad) > 0:
							raise Exception("View-file {view_file} is invalid: logpad specified, but no infogetter is provided")
					logpad["infogetter"] = eval(log_infogetter)
					infoview_entry["logpad"] = copy.deepcopy(logpad)

				if len(infoview_entry["listpad"]) == 0:
					infoview_entry.pop("listpad")

				if len(shortcuts) > 0:
					infoview_entry["shortcuts"] = shortcuts

				# Replace existing listviews with the same name
				infoviews.pop((kind, api_family), None)

				# Add the new view
				infoviews[(kind, api_family)] = infoview_entry

def setupui(stdscr):
	# Hide the cursor
	curses.curs_set(False)
	# Disable CTRL+C, CTRL+Z, etc.
	curses.raw()
	# Enable mouse support
	enable_mouse = deep_get(iktconfig, "Mouse#enable", True)
	if enable_mouse == True:
		curses_helper.set_mousemask(-1)
	else:
		curses_helper.set_mousemask(0)
	curses_helper.init_curses()

	while True:
		if views.get(defaultview) is not None:
			if "viewfunc" in views[defaultview]:
				viewfunc = views[defaultview]["viewfunc"]
			else:
				viewfunc = genericlistloop
			viewfunc(stdscr, defaultview)
		else:
			iktprint([("Error: ", "error"), ("Unknown view “", "default"), (defaultview, "argument"), ("“; check “", "default"), (IKT_CONFIG_FILE, "path"), ("“ and all files in “", "default"), (IKT_CONFIG_FILE_DIR, "path"), ("“for typos.", "default")], stderr = True)
			sys.exit()

def list_namespaces():
	tmp, status = kh.get_list_by_kind_namespace(("Namespace", ""), "")
	if status == 200:
		namespaces = iktlib.join_tuple_list([deep_get(item, "metadata#name") for item in tmp], _tuple = "argument", separator = (", ", "separator"))
		iktprint([("Valid namespaces: ", "default")] + namespaces + [(".", "separator")])
	elif status == 42503:
		iktprint([("Error: ", "error"), ("API-server unavailable", "default")], stderr = True)
	else:
		iktprint([("Error: ", "error"), ("API-server returned ", "default"), (status, "errorvalue")], stderr = True)

def list_views():
	viewfields = []
	maxviewlen = 0
	maxkindlen = 0

	for view in natsorted(views):
		viewref = views[view]
		if "skip" in viewref:
			continue
		if "kind" not in viewref or viewref["kind"] is None:
			continue
		if "fields" not in viewref:
			continue

		fields = []
		for field in viewref["fields"]:
			if type(field) == dict:
				fieldname = deep_get(field, "name")
			else:
				fieldname = field
			if "sortcolumn" in viewref and viewref["sortcolumn"] == fieldname:
				fields.append((fieldname, "emphasis"))
			elif "sortcolumn" not in viewref and fieldname == "name":
				fields.append((fieldname, "emphasis"))
			else:
				fields.append((fieldname, "default"))
		kind = viewref["kind"][0]
		api_group = viewref["kind"][1]
		if api_group == "":
			viewfields.append((view, f"{kind}", fields))
			maxkindlen = max(maxkindlen, len(f"{kind}"))
		else:
			viewfields.append((view, f"{kind}.{api_group}", fields))
			maxkindlen = max(maxkindlen, len(f"{kind}.{api_group}"))
		maxviewlen = max(maxviewlen, len(view))

	iktprint([("View:", "header"), (f"{''.ljust(maxviewlen + 2 - len('View:'))}", "default"), ("Kind:", "header"), (f"{''.ljust(maxkindlen + 2 - len('Kind:'))}", "default"), ("Supported fields:", "header")])
	for view, kind, fields in viewfields:
		joined_fields = iktlib.join_tuple_list(fields, separator = (", ", "separator"))
		try:
			iktprint([(f"{view.ljust(maxviewlen + 2)}{kind.ljust(maxkindlen + 2)}", "default")] + joined_fields)
		except:
			iktprint([(f"view: {view}\nmaxviewlen + 2: {maxviewlen + 2}\nkind: {kind}\nmaxkindlen + 2: {maxkindlen + 2}\nfields: {fields}", "default")])
			sys.exit()

	iktprint([(f"\nList views can be customised to only show select fields by editing “", "default"), (IKT_CONFIG_FILE, "path"), ("“.\n", "default")])
	iktprint([(f"Simply add “", "default"), ("field:", "emphasis"), ("“ followed by a list of the fields you want the list to a section named like", "default")])
	iktprint([("the list view you want to customise.\n", "default")])

	iktprint([(f"Note that the fields “", "default"), ("name", "emphasis"), ("“ and, if applicable “", "default"), ("namespace", "emphasis"), ("“, will unconditionally", "default")])
	iktprint([("be included even if the list of fields doesn't include them; including them", "default")])
	iktprint([("in the list will only allow reordering the fields.\n", "default")])

	iktprint([(f"The fields in this list are those supported by ", "default"), (f"{about.ui_program_name}", "programname"), ("; it is NOT an exhaustive list", "default")])
	iktprint([("of fields available in the resource.\n", "default")])

	iktprint([("The highlighted field for each View is the default sortcolumn.", "default")])

def usage(progname):
	helptext = [(f"{about.ui_program_name} ", "programname")]
	helptext += helptexts.usage

	helptext += [("Valid views: ", "description")]

	first = True
	for view in natsorted(views):
		if views[view].get("skip", False):
			continue
		if first:
			first = False
		else:
			helptext += [(", ", "separator")]
		helptext += [(views[view]["commandline"][0], "emphasis")]
	helptext += [(".\n", "separator")]

	iktprint(helptext)

def version(progname):
	iktprint([(f"{about.ui_program_name} ", "programname"), (f"{about.ui_program_version}", "version")])
	iktprint([(f"{about.program_suite_full_name} ({about.program_suite_name}) ", "programname"), (f"{about.program_suite_version}", "version")])
	print()
	print(about.copyright)
	print(about.license)
	print()
	print(PROGRAMAUTHORS)
	return 0

def set_default_view(view):
	global defaultview

	if defaultview == "":
		defaultview = view
	else:
		iktprint([(about.ui_program_name, "programname"), (": ", "default"), ("VIEW", "argument"), (" can only be specified once.", "default")], stderr = True)
		iktprint([("Try “", "default"), (f"{about.ui_program_name} ", "programname"), ("help", "command"), ("“ for more information.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

def checkforview(arg):
	for view in views:
		if type(arg) == str:
			if arg in deep_get(views[view], "commandline", []):
				return view
		else:
			if arg == deep_get(views[view], "kind", ("", "")):
				return view

	return None

def customise_listviews():
	for view in views:
		viewref = views[view]
		if "skip" in viewref:
			continue
		if "kind" not in viewref or viewref["kind"] is None:
			continue
		if "fields" not in viewref:
			continue

		# OK, we've now (hopefully) skipped all views that don't have a list view
		fields = deep_get(iktconfig, f"{view}#fields", [])
		if len(fields) == 0:
			continue

		custom_fields = {}

		if "namespace" in viewref["fields"] and "namespace" not in fields:
			custom_fields["namespace"] = None
		if "name" not in fields:
			custom_fields["name"] = None

		for field in fields:
			if field not in fields:
				iktprint([("Error: ", "error"), ("“", "default"), (field, "option"), ("“ is not a valid field for the view “", "default"), (view, "argument"), ("“; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)
			elif field in custom_fields:
				iktprint([("Warning: ", "warning"), ("“", "default"), (field, "option"), ("“ is specified twice (or more) for the view “", "default"), (view, "argument"), ("“; ignoring.", "default")], stderr = True)
				continue
			custom_fields[field] = None
		viewref["fields_custom"] = list(custom_fields)

		# Next up it's time for the field denylist
		if "denylist" in deep_get(iktconfig, f"{view}", {}):
			denylist = deep_get(iktconfig, f"{view}#fields", [])
			viewref["field_denylist"] = denylist

	# As a special case, the configuration option "Inventory#ping_hosts"
	# modifies the denylist, but *only* if the field denylist is unset
	ping_hosts = deep_get(iktconfig, "Inventory#ping_hosts", "Lazy")
	inv_name = "Inventory"
	if inv_name not in views:
		inv_name = "*Inventory"
	if ping_hosts == "Never" and "field_denylist" not in views[inv_name]:
		views[inv_name]["field_denylist"] = ["status"]

def main():
	defaultthemefile = f"{THEMEDIR}/{DEFAULT_THEME}"

	global iktconfig
	global initial_name
	global initial_namespace
	global initial_container
	global read_only_mode
	global namespace
	global defaultview

	iktconfig = iktlib.read_iktconfig()
	themefile = deep_get(iktconfig, "Global#theme")
	if themefile is None or len(themefile) == 0:
		themefile = defaultthemefile
	elif themefile.startswith("{HOME}/"):
		themefile = f"{HOMEDIR}/{themefile[len('{HOME}/'):]}"
	elif "/" not in themefile:
		themefile = f"{THEMEDIR}/{themefile}"
	read_theme(themefile, defaultthemefile)
	init_iktprint(themefile)

	tmpdefaultview = deep_get(iktconfig, "Global#defaultview", "")
	curses_configuration.abouttext = helptexts.about
	curses_configuration.mousescroll_enable = deep_get(iktconfig, "Mouse#enablescroll", False)
	# These values are ignored when scrolling is disabled, so the defaults don't matter
	curses_configuration.mousescroll_up = deep_get(iktconfig, "Mouse#scrollup", 0)
	curses_configuration.mousescroll_down = deep_get(iktconfig, "Mouse#scrolldown", 0)
	# Used by the ansible module
	ansible_configuration.ansible_forks = deep_get(iktconfig, "Ansible#forks", 5)
	ansible_user = deep_get(iktconfig, "Ansible#ansible_user")
	if ansible_user is None or len(ansible_user) == 0:
		ansible_user = getuser()
	ansible_configuration.ansible_user = ansible_user
	ansible_configuration.ansible_password = deep_get(iktconfig, "Ansible#ansible_password")
	ansible_configuration.disable_strict_host_key_checking = deep_get(iktconfig, "Nodes#disablestricthostkeychecking", False)
	ansible_configuration.save_logs = deep_get(iktconfig, "Ansible#save_logs", True)

	# Customises the list views
	populate_views()
	customise_listviews()

	y = 1

	while y < len(sys.argv):
		arg = sys.argv[y]

		tmp = checkforview(arg.lower())

		if tmp is not None and defaultview == "":
			defaultview = tmp
			y += 1
			continue

		elif arg == "list-views":
			list_views()
			sys.exit(0)
		elif arg == "--namespace":
			namespace = sys.argv[y + 1]
			y += 1
		elif arg == "--read-only":
			read_only_mode = True
		elif arg == "list-namespaces":
			init_kubernetes_client()
			list_namespaces()
			sys.exit(0)
		elif arg in ["help", "--help"]:
			usage(os.path.basename(sys.argv[0]))
			sys.exit(0)
		elif arg in ["version", "--version"]:
			version(os.path.basename(sys.argv[0]))
			sys.exit(0)
		elif arg.startswith("--"):
			print("%s: unrecognised option “%s”" % (os.path.basename(sys.argv[0]), arg), file = sys.stderr)
			iktprint([("Try “", "default"), (f"{about.ui_program_name} ", "programname"), ("help", "command"), ("“ for more information.", "default")], stderr = True)
			sys.exit(errno.EINVAL)
		else:
			# After we've received a view we assume that non-flag arguments
			# that follow are used as shortcuts to a specific item
			if initial_name is None:
				tmp = re.match(r"^(.+)/(.+)$", arg)
				if tmp is not None:
					if "/" in tmp[1]:
						print("%s: invalid syntax “%s %s”" % (os.path.basename(sys.argv[0]), os.path.basename(sys.argv[0]), " ".join(sys.argv[1:])), file = sys.stderr)
						print("Format is either NAMESPACE/NAME or NAME NAMESPACE", file = sys.stderr)
						iktprint([("Try “", "default"), (f"{about.ui_program_name} ", "programname"), ("help", "command"), ("“ for more information.", "default")], stderr = True)
						sys.exit(errno.EINVAL)
					else:
						initial_namespace = tmp[1]
						initial_name = tmp[2]
				else:
					initial_name = arg
			elif initial_namespace is None:
				if "/" in arg:
					print("%s: invalid syntax “%s %s”" % (os.path.basename(sys.argv[0]), os.path.basename(sys.argv[0]), " ".join(sys.argv[1:])), file = sys.stderr)
					print("Format is either NAMESPACE/NAME or NAME NAMESPACE", file = sys.stderr)
					iktprint([("Try “", "default"), (f"{about.ui_program_name} ", "programname"), ("help", "command"), ("“ for more information.", "default")], stderr = True)
					sys.exit(errno.EINVAL)
				else:
					initial_namespace = arg
			elif initial_container is None:
				initial_container = arg
			else:
				print("%s: unrecognised option “%s”" % (os.path.basename(sys.argv[0]), arg), file = sys.stderr)
				iktprint([("Try “", "default"), (f"{about.ui_program_name} ", "programname"), ("help", "command"), ("“ for more information.", "default")], stderr = True)
				sys.exit(errno.EINVAL)
		y += 1

	if defaultview == "":
		if initial_name is not None:
			iktprint([(f"{about.ui_program_name}", "programname"), (": unsupported view “", "default"), (f"{initial_name}", "command"), ("“.", "default")], stderr = True)
			iktprint([("Try “", "default"), (f"{about.ui_program_name} ", "programname"), ("help", "command"), ("“ for more information.", "default")], stderr = True)
			sys.exit(errno.EINVAL)

		if tmpdefaultview is not None and tmpdefaultview != "":
			defaultview = tmpdefaultview
		else:
			set_default_view("Selector")

	if defaultview not in views:
		defaultview = f"*{defaultview}"

	if initial_name is not None:
		# Role, RoleBinding, ClusterRole, and ClusterRoleBinding can contain ":"
		# Most resources do not allow ":" at all, and for pods we use it to indicate a container name
		colon_allowlist = ["Roles", "Role Bindings", "Cluster Roles", "Cluster Role Bindings", "Logs"]

		if defaultview.lstrip("*") not in colon_allowlist:
			tmp = re.match(r"^(.+):(.*)$", initial_name)
			if tmp is not None:
				if ":" in tmp[1]:
					iktprint([(f"{about.ui_program_name}", "programname"), (": invalid syntax “", "default"), (f"{about.ui_program_name} ", "programname"), (f"{' '.join(sys.argv[1:])}", "argument"), ("”", "default")], stderr = True)
					iktprint([("Format is either ", "default"), ("NAMESPACE/NAME:", "argument"), ("{", "separator"), ("CONTAINER", "argument"), (",", "separator"), ("CONFIGMAP", "argument"), ("}", "separator"), (" or ", "default"), ("NAME NAMESPACE ", "argument"), ("{", "separator"), ("CONTAINER", "argument"), (",", "separator"), ("CONFIGMAP", "argument"), ("}", "separator")], stderr = True)
					iktprint([("Try “", "default"), (f"{about.ui_program_name} ", "programname"), ("help", "command"), ("“ for more information.", "default")], stderr = True)
					sys.exit(errno.EINVAL)
				else:
					initial_name = tmp[1]
					initial_container = tmp[2]

	# Containers and Config Maps can have a third level (container/data)
	if initial_container is not None and not (defaultview.lstrip("*") in ["Pods", "Config Maps"]):
		iktprint([(f"{about.ui_program_name}", "programname"), (": invalid syntax “", "default"), (f"{about.ui_program_name} ", "programname"), (f"{' '.join(sys.argv[1:])}", "argument"), ("”", "default")], stderr = True)
		iktprint([(f"CONTAINER", "argument"), ("/", "separator"), ("CONFIGMAP", "argument"), (" only makes sense in ", "default"), ("pod", "command"), ("/", "separator"), ("configmap", "command"), (" view.", "default")], stderr = True)
		iktprint([("Try “", "default"), (f"{about.ui_program_name} ", "programname"), ("help", "command"), ("“ for more information.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	# We don't need escape sequences, so cut down on the delay to 25ms
	os.environ.setdefault('ESCDELAY', '25')
	init_kubernetes_client()

	wrapper(setupui)

if __name__ == "__main__":
	main()
