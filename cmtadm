#! /bin/sh
# vim: filetype=python
# pylint: disable-next=anomalous-backslash-in-string,line-too-long
''''eval version=$( ls /usr/bin/python3.* | grep '.*[0-9]$' | sort -nr -k2 -t. | head -n1 ) && version=${version##/usr/bin/python3.} && [ ${version} ] && [ ${version} -ge 8 ] && exec /usr/bin/python3.${version} "$0" "$@" || exec /usr/bin/env python3 "$0" "$@"' #'''
__doc__ = "The above hack is to handle distros that don't have /usr/bin/python3 point to the latest version of python3 they provide"
# Requires: python3 (>= 3.8)
# Requires: python3-natsort
# Requires: python3-paramiko
#
# Copyright the Cluster Management Toolkit for Kubernetes contributors.
# SPDX-License-Identifier: MIT

# pylint: disable=line-too-long

"""
This program is used to install, upgrade and uninstall control planes for Kubernetes clusters,
and to perform various other administrative tasks

For usage, see:
	cmtadm help
"""

import errno
from getpass import getuser
from glob import glob
import grp
import os
from pathlib import Path, PurePath
import pwd
import re
import shutil
import socket
from subprocess import CalledProcessError  # nosec
import sys
import tempfile
from typing import Callable, cast, Dict, List, Optional, Set, Tuple, Union

try:
	from natsort import natsorted
except ModuleNotFoundError:  # pragma: no cover
	sys.exit("ModuleNotFoundError: Could not import natsort; you may need to (re-)run `cmt-install` or `pip3 install natsort`; aborting.")

from cmttypes import deep_get, DictPath, FilePath, FilePathAuditError, SecurityChecks, SecurityPolicy, SecurityStatus
from cmtpaths import BASH_COMPLETION_BASE_DIR, BASH_COMPLETION_DIR, BINDIR, HOMEDIR, SSH_DIR, SSH_KEYGEN_BIN_PATH, SSH_KEYGEN_ARGS
from cmtpaths import DEPLOYMENT_DIR
from cmtpaths import CMT_PRE_PREPARE_DIR, CMT_POST_PREPARE_DIR, CMT_PRE_SETUP_DIR, CMT_POST_SETUP_DIR, CMT_PRE_UPGRADE_DIR
from cmtpaths import CMT_POST_UPGRADE_DIR, CMT_PRE_TEARDOWN_DIR, CMT_POST_TEARDOWN_DIR, CMT_PRE_PURGE_DIR, CMT_POST_PURGE_DIR
from cmtpaths import ANSIBLE_PLAYBOOK_DIR, ANSIBLE_INVENTORY
from cmtpaths import DEFAULT_THEME_FILE, CMT_CONFIG_FILE, CMT_INSTALLATION_INFO_FILE, KUBE_CONFIG_DIR, KUBE_CONFIG_FILE, VERSION_CACHE_DIR

from commandparser import parse_commandline

from ansible_helper import ansible_configuration, ansible_get_inventory_dict, ansible_set_vars
from ansible_helper import ansible_run_playbook_on_selection, ansible_add_hosts, ansible_get_hosts_by_group, get_playbook_path
from ansible_helper import ansible_print_play_results, populate_playbooks_from_paths

import cmtio
from cmtio import check_path, execute_command, execute_command_with_response, join_securitystatus_set, secure_mkdir
from cmtio import secure_read_string, secure_rm, secure_which, secure_write_string
from cmtio_yaml import secure_read_yaml, secure_write_yaml
from networkio import download_files, scan_and_add_ssh_keys

import cmtlib
from cmtlib import check_versions_apt, check_versions_yum, check_versions_zypper, identify_distro, read_cmtconfig, substitute_list, substitute_string

import kubernetes_helper

from ansithemeprint import ANSIThemeString, ansithemeinput, ansithemeinput_password, ansithemeprint
from ansithemeprint import ansithemestring_join_tuple_list, themearray_override_formatting

import checks

import about
PROGRAMDESCRIPTION = "Setup or teardown a Kubernetes cluster"
PROGRAMAUTHORS = "Written by David Weinehall."

DEFAULT_CNI = "cilium"
DEFAULT_POD_NETWORK_CIDR = "10.244.0.0/16"

no_password = False

cri_data: Dict = {
	"containerd": {
		"socket": "unix:///run/containerd/containerd.sock",
	},
	"cri-o": {
		"socket": "unix:///run/crio/crio.sock",
	},
	"docker-shim": {
		"socket": "unix:///run/dockershim.sock",
	}
}

prepare_targets: Dict = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("prepare_passwordless_ansible.yaml"))),
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("install_packages.yaml"))),
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("prepare_control_plane.yaml"))),
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("add_kubernetes_repo.yaml"))),
		],
		"deb_packages": [
		],
		"fedora_packages": [
		],
		"suse_packages": [
		],
	},
	"localhost": {
		"pretty_name": [("host system", "programname")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("prepare_passwordless_ansible.yaml"))),
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("add_kubernetes_repo.yaml"))),
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("install_packages.yaml"))),
		],
		"deb_packages": [
			"ansible",
		],
		"fedora_packages": [
			"ansible-core",
		],
		"suse_packages": [
			"ansible",
		],
	},
	"rke2": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("prepare_passwordless_ansible.yaml"))),
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("install_packages.yaml"))),
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("prepare_control_plane.yaml"))),
		],
		"deb_packages": [
		],
		"fedora_packages": [
		],
		"suse_packages": [
		],
	},
}

setup_control_plane_targets: Dict = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("install_packages.yaml"))),
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("kubeadm_setup_control_plane.yaml"))),
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("fetch_kube_config.yaml"))),
		],
		"deb_packages": [
			"kubeadm",
			"kubectl",
			"kubelet",
			"kubernetes-cni",
		],
		"deb_packages_held": [
			"kubeadm",
			"kubectl",
			"kubelet",
		],
		"fedora_packages": [
			"kubeadm",
			"kubectl",
			"kubelet",
		],
		"fedora_packages_held": [
			"kubeadm",
			"kubectl",
			"kubelet",
		],
		"suse_packages": [
			"kubectl",
			# "kubernetes{major.minor}-client",
			"kubeadm",
			# "kubernetes{major.minor}-kubeadm",
			"kubelet",
			# "kubernetes{major.minor}-kubelet",
		],
		"suse_packages_held": [
			"kubectl",
			# "kubernetes{major.minor}-client",
			"kubeadm",
			# "kubernetes{major.minor}-kubeadm",
			"kubelet",
			# "kubernetes{major.minor}-kubelet",
		],
		"extra_values": {},
	},
	"localhost": {
		"pretty_name": [("host system", "programname")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("install_packages.yaml"))),
		],
		"deb_packages": [
			"kubectl",
		],
		"deb_packages_held": [
			"kubectl",
		],
		"fedora_packages": [
			"kubectl",
		],
		"fedora_packages_held": [
			"kubectl",
		],
		"suse_packages": [
			"kubectl",
			# "kubernetes{major.minor}-client",
		],
		"suse_packages_held": [
			"kubectl",
			# "kubernetes{major.minor}-client",
		],
	},
	"rke2": {
		"pretty_name": [("RKE2", "programname")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("rke2_setup_control_plane.yaml"))),
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("fetch_kube_config.yaml"))),
		],
		"extra_values": {},
	},
}

upgrade_control_plane_targets: Dict = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("kubeadm_upgrade_control_plane.yaml"))),
		],
		"extra_values": {},
	},
	"localhost": {
		"pretty_name": [("host system", "programname")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("install_packages.yaml"))),
		],
		"deb_packages": [
			"kubectl",
		],
		"deb_packages_held": [
			"kubectl",
		],
		"fedora_packages": [
			"kubectl",
		],
		"fedora_packages_held": [
			"kubectl",
		],
	},
	"rke2": {
		"pretty_name": [("RKE2", "programname")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("rke2_upgrade_control_plane.yaml"))),
		],
		"extra_values": {},
	},
}

teardown_control_plane_targets: Dict = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("teardown_cni.yaml"))),
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("kubeadm_teardown_control_plane.yaml"))),
		],
	},
	"rke2": {
		"pretty_name": [("RKE2", "programname")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("rke2_teardown_control_plane.yaml"))),
		],
	},
}

purge_control_plane_targets: Dict = {
	"kubeadm": {
		"pretty_name": [("kubeadm", "programname"), (" (default)", "default")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("kubeadm_purge.yaml"))),
		],
		"deb_packages": [
			"kubeadm",
			"kubectl",
			"kubelet",
			"kubernetes-cni",
		],
		"deb_packages_held": [
			"kubeadm",
			"kubectl",
			"kubelet",
		],
		"fedora_packages": [
			"kubeadm",
			"kubectl",
			"kubelet",
			"kubernetes-cni",
		],
		"fedora_packages_held": [
			"kubeadm",
			"kubectl",
			"kubelet",
		],
	},
	"rke2": {
		"pretty_name": [("rke2", "programname")],
		"playbooks": [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("rke2_purge.yaml"))),
		],
	},
}

def get_control_plane_version(controlplane: str, k8s_distro: str) -> str:
	"""
	Return the Kubernetes version used by the control plane

		Parameters:
			controlplane (str): Name of the node to check the version from
			k8s_distro (str): The Kubernetes distro used
		Returns:
			version (str): The Kubernetes version if discernible, the empty string if not
	"""

	version = None

	if k8s_distro == "rke2":
		# This will only work for running clusters
		from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
		kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

		vlist, status = kh.get_list_by_kind_namespace(("Node", ""), "")
		if status != 200:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": API-server returned ", "default"),
					ANSIThemeString(f"{status}", "errorvalue"),
					ANSIThemeString("; aborting.", "default")], stderr = True)
			sys.exit(errno.EINVAL)
		if vlist is None:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": API-server did not return any data", "default")], stderr = True)
			sys.exit(errno.EINVAL)

		for node in vlist:
			name = deep_get(node, DictPath("metadata#name"))
			if name == controlplane:
				version = deep_get(node, DictPath("status#nodeInfo#kubeletVersion"))
				break
	else:
		# For kubeadm we try to use the package version
		get_versions_path = get_playbook_path(FilePath("get_versions.yaml"))
		retval, ansible_results = ansible_run_playbook_on_selection(get_versions_path, selection = [controlplane])

		if len(ansible_results) == 0:
			raise ValueError(f"Error: Failed to get package versions from {controlplane} (retval: {retval}); aborting.")

		k8s_distro = "<unknown>"
		version = "<unknown>"

		for result in deep_get(ansible_results, DictPath(controlplane), []):
			if deep_get(result, DictPath("task"), "") == "Package versions":
				tmp = deep_get(result, DictPath("msg_lines"), [])
				break

		if len(tmp) == 0:
			raise ValueError(f"Error: Received empty version data from {controlplane} (retval: {retval}); aborting.")

		package_version_regex = re.compile(r"^(.*?): (.*)")

		for line in tmp:
			tmp2 = package_version_regex.match(line)
			if tmp2 is None:
				continue
			package = tmp2[1]
			package_version = tmp2[2]
			if package == "kubeadm":
				version = package_version
				break

	if version is None:
		version = ""

	return version

def rebuild_installation_info(state: Optional[str] = None) -> None:
	"""
	If the installation info file does not exist, but a cluster already exists and is part of the inventory,
	this function will try to rebuild the installation info file

		Parameters:
			state (str): The installation state
	"""

	k8s_distro = None
	controlplane = None
	cri = "<none>"

	# This will only work for running clusters
	from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
	kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

	vlist, status = kh.get_list_by_kind_namespace(("Node", ""), "")
	if status != 200:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": API-server returned ", "default"),
				ANSIThemeString(f"{status}", "errorvalue"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)
	if vlist is None:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": API-server did not return any data", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	for node in vlist:
		name = deep_get(node, DictPath("metadata#name"))
		node_roles = kh.get_node_roles(cast(Dict, node))
		if "control-plane" in node_roles or "master" in node_roles:
			controlplane = name
			cri = deep_get(node, DictPath("status#nodeInfo#containerRuntimeVersion"), "")
			if cri is not None:
				cri = cri.split(":")[0]
			tmp_k8s_distro = None
			minikube_name = deep_get(node, DictPath("metadata#labels#minikube.k8s.io/name"), "")
			labels = deep_get(node, DictPath("metadata#labels"), {})
			images = deep_get(node, DictPath("status#images"), [])
			for image in images:
				names = deep_get(image, DictPath("names"), [])
				for name in names:
					if "openshift-crc-cluster" in name:
						tmp_k8s_distro = "crc"
						break
				if tmp_k8s_distro is not None:
					break
			if minikube_name != "":
				tmp_k8s_distro = "minikube"
			elif deep_get(labels, DictPath("microk8s.io/cluster"), False):
				tmp_k8s_distro = "microk8s"
			elif deep_get(node, DictPath("spec#providerID"), "").startswith("kind://"):
				tmp_k8s_distro = "kind"
			else:
				managed_fields = deep_get(node, DictPath("metadata#managedFields"), [])
				for managed_field in managed_fields:
					manager = deep_get(managed_field, DictPath("manager"), "")
					if manager == "rke2":
						tmp_k8s_distro = "rke2"
						break
					if manager == "k0s":
						tmp_k8s_distro = "k0s"
						break
					if manager.startswith("deploy@k3d"):
						tmp_k8s_distro = "k3d"
						break
					if manager == "k3s":
						tmp_k8s_distro = "k3s"
						break
					if manager == "kubeadm":
						tmp_k8s_distro = "kubeadm"
						break
			if tmp_k8s_distro is not None:
				if k8s_distro is not None:
					ansithemeprint([ANSIThemeString("Critical", "critical"),
							ANSIThemeString(": The control planes are reporting conflicting Kubernetes distros; aborting.", "default")], stderr = True)
					sys.exit(errno.EINVAL)
				else:
					k8s_distro = tmp_k8s_distro

	if controlplane is None:
		ansithemeprint([ANSIThemeString("", "default")])
		ansithemeprint([ANSIThemeString("Critical", "critical"),
				ANSIThemeString(": Could not identify a control plane for the cluster; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	if k8s_distro is None:
		ansithemeprint([ANSIThemeString("Critical", "critical"),
				ANSIThemeString(": Unknown Kubernetes distro; cannot determine Kubernetes version.", "default")], stderr = True)
		sys.exit(errno.EINVAL)
	version = get_control_plane_version(controlplane = controlplane, k8s_distro = k8s_distro)

	if version is None or len(version) == 0:
		ansithemeprint([ANSIThemeString("", "default")])
		ansithemeprint([ANSIThemeString("Critical", "critical"),
				ANSIThemeString(": Failed to get Kubernetes version; currently only kubeadm and RKE2 are supported. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	cluster_name = get_cluster_name()
	pod_network_cidr = kh.get_pod_network_cidr()
	cnis = kh.identify_cni()
	if len(cnis) == 1:
		cni = cnis[0][0]
	else:
		cni = "<unknown>"

	update_installation_info(installation_target = cluster_name, cluster_name = cluster_name, distro = k8s_distro, version = version, requested_version = "<none>",
				 state = state, phase = "<none>", phase_skiplist = [], cni = cni, cri = cri, pod_network_cidr = pod_network_cidr)

def get_installation_info(cluster_name: Optional[str] = None) -> Dict:
	"""
	Return installation info for a cluster, or prepares a new entry if no entry exists yet

		Parameters:
			cluster_name (str): The name of the cluster to get information for
		Returns:
			info (dict): A dictionary with information about a cluster
	"""

	info = None

	# We are OK with the file not existing
	security_checks = [
		SecurityChecks.PARENT_RESOLVES_TO_SELF,
		SecurityChecks.OWNER_IN_ALLOWLIST,
		SecurityChecks.PARENT_OWNER_IN_ALLOWLIST,
		SecurityChecks.PERMISSIONS,
		SecurityChecks.PARENT_PERMISSIONS,
		SecurityChecks.IS_FILE,
	]

	try:
		info = secure_read_yaml(CMT_INSTALLATION_INFO_FILE, checks = security_checks)
	except FileNotFoundError:
		pass

	if info is None or info.get("installation_target") is None or (info.get("installation_target") is not None and cluster_name is not None and cluster_name not in info):
		if info is None:
			info = {}
		info["installation_target"] = cluster_name
		info[cluster_name] = {
			"distro": "<none>",
			"version": "<none>",
			"requested_version": "<none>",
			"state": "<none>",
			"phase": "<none>",
			"phase_skiplist": [],
			"cni": "<none>",
			"pod_network_cidr": "<none>",
			"cri": "<none>",
		}
	elif info.get("installation_target") is None and cluster_name is not None:
		# Old format file; transition it
		tmpinfo = info.copy()
		tmpinfo.pop("cluster_name")
		info = {}
		info["installation_target"] = cluster_name
		info[cluster_name] = tmpinfo

	return info

def update_installation_info(**kwargs) -> Dict:
	"""
	Update installation info for a cluster

		Parameters:
			installation_target (str): The installation info entry to use
			cluster_name (str): The name of the cluster to update information for
			distro (str): The distribution used during installation (currently the only supported distro is kubeadm)
			version (str): The current version of Kubernetes
			requested_version (str): The requested version of Kubernetes
			state (str): The installation state
			phase (str): The installation phase
			phase_skiplist (list[str]): A list of phases to skip
			cni (str): The CNI to use
			pod_network_cidr (str): The CIDR to use for the pod network
			cri (str): The CRI to use
			control_planes ([str]): A list of the control planes
			nodes ([str]): A list of the nodes
		Returns:
			info (dict): The updated installation info
	"""
	installation_target: Optional[str] = deep_get(kwargs, DictPath("installation_target"))
	cluster_name: Optional[str] = deep_get(kwargs, DictPath("cluster_name"))
	distro: Optional[str] = deep_get(kwargs, DictPath("distro"))
	version: Optional[str] = deep_get(kwargs, DictPath("version"))
	requested_version: Optional[str] = deep_get(kwargs, DictPath("requested_version"))
	state: Optional[str] = deep_get(kwargs, DictPath("state"))
	phase: Optional[Union[int, str]] = deep_get(kwargs, DictPath("phase"))
	phase_skiplist: Optional[List[str]] = deep_get(kwargs, DictPath("phase_skiplist"))
	cni: Optional[str] = deep_get(kwargs, DictPath("cni"))
	pod_network_cidr: Optional[str] = deep_get(kwargs, DictPath("pod_network_cidr"))
	cri: Optional[str] = deep_get(kwargs, DictPath("cri"))
	control_planes: Optional[List[str]] = deep_get(kwargs, DictPath("control_plane"))
	nodes: Optional[List[str]] = deep_get(kwargs, DictPath("control_plane"))

	info = get_installation_info(cluster_name = cluster_name)

	if cluster_name is None:
		cluster_name = info.get("installation_target")

	if installation_target is not None:
		info["installation_target"] = installation_target
	elif info.get("installation_target") is None:
		info["installation_target"] = cluster_name

	if distro is not None:
		info[cluster_name]["distro"] = distro
	if version is not None:
		info[cluster_name]["version"] = version
	if requested_version is not None:
		info[cluster_name]["requested_version"] = requested_version
	if state is not None:
		info[cluster_name]["state"] = state
	if phase is not None:
		info[cluster_name]["phase"] = phase
	if phase_skiplist is not None:
		info[cluster_name]["phase_skiplist"] = phase_skiplist
	if cni is not None:
		info[cluster_name]["cni"] = cni
	if pod_network_cidr is not None:
		info[cluster_name]["pod_network_cidr"] = pod_network_cidr
	if cri is not None:
		info[cluster_name]["cri"] = cri
	if control_planes is not None:
		info[cluster_name]["control_planes"] = control_planes
	if nodes is not None:
		info[cluster_name]["nodes"] = nodes

	secure_write_yaml(CMT_INSTALLATION_INFO_FILE, info, sort_keys = False)

	return info

def check_and_print_status(retval: bool) -> None:
	"""
	A wrapper that prints OK if retval is True
	and NOT OK and aborts if retval is False
		Parameters:
			retval (bool): True on success, False on failure
	"""

	if retval:
		ansithemeprint([ANSIThemeString("OK", "ok")])
	else:
		ansithemeprint([ANSIThemeString("NOT OK", "notok"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

def patch_cni_calico(cni_path: FilePath, pod_network_cidr: str) -> None:
	"""
	Patch the configuration for Calico

		Parameters:
			cni_path (FilePath): The path to the CNI configuration to patch
			pod_network_cidr (str): The CIDR for the pod network
	"""

	violations = check_path(cni_path)
	if violations != [SecurityStatus.OK]:
		violations_joined = join_securitystatus_set(",", set(violations))
		raise FilePathAuditError(f"Violated rules: {violations_joined}", path = cni_path)

	# Ideally we should patch this using a round-trip capable YAML parser,
	# such as ruamel
	sedstr = fr's#cidr: 192.168.0.0/16$#cidr: {pod_network_cidr}#'
	args = ["/usr/bin/sed", "-i", "-e", sedstr, cni_path]
	check_and_print_status(execute_command(args))

def patch_cni_canal(cni_path: FilePath, pod_network_cidr: str) -> None:
	"""
	Patch the configuration for Canal

		Parameters:
			cni_path (FilePath): The path to the CNI configuration to patch
			pod_network_cidr (str): The CIDR for the pod network
	"""

	violations = check_path(cni_path)
	if violations != [SecurityStatus.OK]:
		violations_joined = join_securitystatus_set(",", set(violations))
		raise FilePathAuditError(f"Violated rules: {violations_joined}", path = cni_path)

	# Ideally we should patch this using a round-trip capable YAML parser,
	# such as ruamel
	# This seems like the obvious thing to patch
	sedstr = fr's#^\(.*"\)Network": "10.244.0.0/16"\(,.*\)$#\1Network": "{pod_network_cidr}"\2#'
	args = ["/usr/bin/sed", "-i", "-e", sedstr, cni_path]
	check_and_print_status(execute_command(args))
	# According to the canal documentation this should be patched too; let's patch both just in case
	sedstr = r's,# - name: CALICO_IPV4POOL_CIDR$,- name: CALICO_IPV4POOL_CIDR,'
	args = ["/usr/bin/sed", "-i", "-e", sedstr, cni_path]
	check_and_print_status(execute_command(args))
	sedstr = fr's,  value: "192.168.0.0/16"$,#   value: "{pod_network_cidr}",'
	args = ["/usr/bin/sed", "-i", "-e", sedstr, cni_path]
	check_and_print_status(execute_command(args))

def patch_cni_flannel(cni_path: FilePath, pod_network_cidr: str) -> None:
	"""
	Patch the configuration for Flannel

		Parameters:
			cni_path (FilePath): The path to the CNI configuration to patch
			pod_network_cidr (str): The CIDR for the pod network
	"""

	violations = check_path(cni_path)
	if violations != [SecurityStatus.OK]:
		violations_joined = join_securitystatus_set(",", set(violations))
		raise FilePathAuditError(f"Violated rules: {violations_joined}", path = cni_path)

	# Ideally we should patch this using a round-trip capable YAML parser,
	# such as ruamel
	sedstr = fr's#^\(.*"\)Network": "10.244.0.0/16",$#\1Network": "{pod_network_cidr}",#'
	args = ["/usr/bin/sed", "-i", "-e", sedstr, cni_path]
	check_and_print_status(execute_command(args))

def patch_cni_weave(cni_path: FilePath, pod_network_cidr: str) -> None:
	"""
	Patch the configuration for Weave

		Parameters:
			cni_path (FilePath): The path to the CNI configuration to patch
			pod_network_cidr (str): The CIDR for the pod network
	"""

	violations = check_path(cni_path)
	if violations != [SecurityStatus.OK]:
		violations_joined = join_securitystatus_set(",", set(violations))
		raise FilePathAuditError(f"Violated rules: {violations_joined}", path = cni_path)

	# Ideally we should patch this using a round-trip capable YAML parser,
	# such as ruamel
	sedstr_remove_existing = r'/^                - name: IPALLOC_RANGE$/,+1d'
	args = ["/usr/bin/sed", "-i", "-e", sedstr_remove_existing, cni_path]
	execute_command(args)

	sedstr_add_new = fr's#^\(.*\)\(- name: INIT_CONTAINER\)$#\1- name: IPALLOC_RANGE\n\1  value: {pod_network_cidr}\n\1\2#'
	args = ["/usr/bin/sed", "-i", "-e", sedstr_add_new, cni_path]
	check_and_print_status(execute_command(args))

def get_github_version(url: str, version_regex: str) -> List[str]:
	"""
	Given a github repository find the latest released version

		Parameters:
			url (str): The github API URL to check for latest version
			version_regex (str): A regex
		Returns:
			version ([str]): A list of version number elements, or None in case of failure
	"""

	version: List[str] = []

	if url is not None:
		with tempfile.TemporaryDirectory() as td:
			check_and_print_status(download_files(td, [(url, "release.yaml", None, None)], permissions = 0o600))
			tmp = secure_read_yaml(FilePath(f"{td}/release.yaml"))
			result = deep_get(tmp, DictPath("tag_name"), "")
			versionoutput = result.splitlines()
			_version_regex = re.compile(version_regex)
			for line in versionoutput:
				tmp = _version_regex.match(line)
				if tmp is not None:
					version = list(tmp.groups())
					break

	return version

# XXX: We should move all of this code to a separate file to allow it to be used both from cmu and cmtadm
cni_upgrade_data = {
	"antrea": {
		"CNI": {
			"candidate_version_function": get_github_version,
			"candidate_version_url": "https://api.github.com/repos/antrea-io/antrea/releases/latest",
			"candidate_version_regex": r"(v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"urls": [
				{
					"url": "https://raw.githubusercontent.com/antrea-io/antrea/<<<version>>>/build/yamls/antrea.yml",
					"filename": "antrea.yaml",
				}
			]
		}
	},
	"calico": {
		"executable": {
			"candidate_version_function": get_github_version,
			"candidate_version_url": "https://api.github.com/repos/projectcalico/calico/releases/latest",
			"candidate_version_regex": r"(v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"version_command": ["kubectl", "calico", "version"],
			"version_regex": r"^Client Version:\s+(v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"urls": [
				{
					"url": "https://github.com/projectcalico/calico/releases/download/<<<version>>>/calicoctl-linux-<<<arch>>>",
					"checksum_url": "https://github.com/projectcalico/calico/releases/download/<<<version>>>/SHA256SUMS",
					"checksum_type": "sha256",
					"filename": "kubectl-calico",
				}
			]
		},
		"CNI": {
			"version_command": ["kubectl", "calico", "version"],
			"version_regex": r"^Cluster Version:\s*(v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"candidate_version_function": get_github_version,
			"candidate_version_url": "https://api.github.com/repos/projectcalico/calico/releases/latest",
			"candidate_version_regex": r"(v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"urls": [
				{
					"url": "https://raw.githubusercontent.com/projectcalico/calico/<<<version>>>/manifests/tigera-operator.yaml",
					"filename": "tigera-operator-<<<version>>>.yaml",
				}, {
					"url": "https://raw.githubusercontent.com/projectcalico/calico/<<<version>>>/manifests/custom-resources.yaml",
					"filename": "calico-custom-resources-<<<version>>>.yaml",
					"patch": patch_cni_calico,
				}
			]
		}
	},
	"canal": {
		"CNI": {
			"candidate_version_function": get_github_version,
			"candidate_version_url": "https://api.github.com/repos/projectcalico/calico/releases/latest",
			"candidate_version_regex": r"(v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"urls": [
				{
					"url": "https://raw.githubusercontent.com/projectcalico/calico/<<<version>>>/manifests/canal.yaml",
					"filename": "canal.yaml",
					"patch": patch_cni_canal,
				}
			]
		}
	},
	"cilium": {
		"executable": {
			"version_command": ["cilium", "--context", "<<<context>>>", "version"],
			"version_regex": r"^cilium-cli: (v)(\d+)(\.)(\d+)(\.)(\d+) .*$",
			"candidate_version_url": "https://raw.githubusercontent.com/cilium/cilium-cli/master/stable.txt",
			"candidate_version_regex": r"(v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"urls": [
				{
					"url": "https://github.com/cilium/cilium-cli/releases/download/<<<version>>>/cilium-linux-<<<arch>>>.tar.gz",
					"checksum_url": "https://github.com/cilium/cilium-cli/releases/download/<<<version>>>/cilium-linux-<<<arch>>>.tar.gz.sha256sum",
					"checksum_type": "sha256",
					"filename": "cilium",
				}
			],
		},
		"CNI": {
			"version_command": ["cilium", "--context", "<<<context>>>", "version"],
			"version_regex": r"^cilium image \(running\): (v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"candidate_version_command": ["cilium", "--context", "<<<context>>>", "version"],
			"candidate_version_regex": r"^cilium image \(default\): (v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"upgrade": ["cilium", "--context", "<<<context>>>", "upgrade"],
			"install": ["cilium", "--context", "<<<context>>>", "install"],
			"uninstall": ["cilium", "--context", "<<<context>>>", "uninstall"],
		}
	},
	"flannel": {
		"CNI": {
			"candidate_version_function": get_github_version,
			"candidate_version_url": "https://api.github.com/repos/flannel-io/flannel/releases/latest",
			"candidate_version_regex": r"(v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"urls": [
				{
					"url": "https://github.com/flannel-io/flannel/releases/download/<<<version>>>/kube-flannel.yml",
					"filename": "flannel.yaml",
					"patch": patch_cni_flannel,
				}
			]
		}
	},
	"kube-router": {
		"CNI": {
			"candidate_version_function": get_github_version,
			"candidate_version_url": "https://api.github.com/repos/cloudnativelabs/kube-router/releases/latest",
			"candidate_version_regex": r"(v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"urls": [
				{
					"url": "https://raw.githubusercontent.com/cloudnativelabs/kube-router/<<<version>>>/daemonset/kubeadm-kuberouter.yaml",
					"filename": "kube-router.yaml",
				}
			]
		}
	},
	"weave": {
		"CNI": {
			"candidate_version_function": get_github_version,
			"candidate_version_url": "https://api.github.com/repos/weaveworks/weave/releases/latest",
			"candidate_version_regex": r"(v)(\d+)(\.)(\d+)(\.)(\d+)$",
			"urls": [
				{
					"url": "https://github.com/weaveworks/weave/releases/download/<<<version>>>/weave-daemonset-k8s-1.11.yaml",
					"filename": "weave.yaml",
					"patch": patch_cni_weave,
				}
			]
		}
	},
}

def check_version_from_url(url: str, version_regex: str) -> List[str]:
	"""
	Given a URL download a text file and treat the first line that matches version_regex as a version number

		Parameters:
			url (str): A URL
			version_regex (str): A regex
		Returns:
			version (str): The version number, or None in case of failure
	"""

	version: List[str] = []

	if url is not None:
		with tempfile.TemporaryDirectory() as td:
			check_and_print_status(download_files(td, [(url, "version.txt", None, None)], permissions = 0o600))
			tmp = secure_read_string(FilePath(f"{td}/version.txt"))
			versionoutput = tmp.splitlines()
			_version_regex = re.compile(version_regex)
			for line in versionoutput:
				tmp_match = _version_regex.match(cast(str, line))
				if tmp_match is not None:
					version = list(tmp_match.groups())
					break
	return version

def check_version_from_executable(command: FilePath, args: List[str], version_regex: str) -> List[str]:
	"""
	Given a path to an executable, the arguments needed to show version information,
	and a version_regex, return the executable version

		Parameters:
			command (str): A path to an executable
			args ([str]): A list of arguments necessary to show version information
			version_regex (str): A regex
		Returns:
			version ([str]): A list of version number elements, or None in case of failure
	"""

	version: List[str] = []

	security_policy = SecurityPolicy.ALLOWLIST_RELAXED
	fallback_allowlist = ["/bin", "/sbin", "/usr/bin", "/usr/sbin", "/usr/local/bin", "/usr/local/sbin", f"{HOMEDIR}/bin"]

	try:
		cpath = cmtio.secure_which(command, fallback_allowlist = fallback_allowlist,
					   security_policy = security_policy)
	except FileNotFoundError:
		cpath = None

	if cpath is not None:
		result = execute_command_with_response([cpath] + args)

		if result is not None:
			versionoutput = result.splitlines()
			_version_regex = re.compile(version_regex)
			for line in versionoutput:
				tmp = _version_regex.match(line)
				if tmp is not None:
					version = list(tmp.groups())
					break
	return version

def __upgrade_cni(cni: str, upgradetype: str, context: str, pod_network_cidr: str, **kwargs) -> None:
	"""
	A helper that is used when upgrading a CNI; it can either upgrade the CNI itself or a helper executable

		Parameters:
			cni (str): The CNI to upgrade
			upgradetype (str): Valid options CNI, executable
			context (str): The cluster context
			pod_network_cidr (str): The CIDR of the pod network
	"""

	verbose = deep_get(kwargs, DictPath("verbose"), False)

	if upgradetype not in ("CNI", "executable"):
		raise ValueError(f"Unknown upgradetype {upgradetype}; this is a programming error.")

	# FIXME: for now we hardcode this
	arch = "amd64"
	version_command = deep_get(cni_upgrade_data, DictPath(f"{cni}#{upgradetype}#version_command"))
	version_command_regex = deep_get(cni_upgrade_data, DictPath(f"{cni}#{upgradetype}#version_regex"))
	candidate_version_url = deep_get(cni_upgrade_data, DictPath(f"{cni}#{upgradetype}#candidate_version_url"))
	candidate_version_command = deep_get(cni_upgrade_data, DictPath(f"{cni}#{upgradetype}#candidate_version_command"))
	candidate_version_function = deep_get(cni_upgrade_data, DictPath(f"{cni}#{upgradetype}#candidate_version_function"))
	candidate_version_regex = deep_get(cni_upgrade_data, DictPath(f"{cni}#{upgradetype}#candidate_version_regex"))
	install_command = deep_get(cni_upgrade_data, DictPath(f"{cni}#{upgradetype}#install"))
	upgrade_command = deep_get(cni_upgrade_data, DictPath(f"{cni}#{upgradetype}#upgrade"))

	version_substitutions = {
		"<<<arch>>>": arch,
		"<<<context>>>": context,
	}

	version = []
	if version_command is not None:
		ansithemeprint([ANSIThemeString("\n• ", "separator"),
				ANSIThemeString(f"Checking {upgradetype} version", "action")])
		version = check_version_from_executable(version_command[0],
							substitute_list(version_command[1:], version_substitutions), version_command_regex)
	candidate_version = []
	if candidate_version_url is not None:
		ansithemeprint([ANSIThemeString("\n• ", "separator"),
				ANSIThemeString(f"Checking {upgradetype} candidate version", "action")])
		if candidate_version_function is not None:
			candidate_version = candidate_version_function(candidate_version_url, candidate_version_regex)
		else:
			candidate_version = check_version_from_url(substitute_string(candidate_version_url, version_substitutions), candidate_version_regex)
	elif candidate_version_command is not None:
		ansithemeprint([ANSIThemeString("\n• ", "separator"),
				ANSIThemeString(f"Checking {upgradetype} candidate version", "action")])
		candidate_version = check_version_from_executable(candidate_version_command[0],
								  substitute_list(candidate_version_command[1:], version_substitutions),
								  candidate_version_regex)

	if "urls" in deep_get(cni_upgrade_data, DictPath(f"{cni}#{upgradetype}"), {}):
		# pylint: disable-next=too-many-boolean-expressions
		if (version is None or len(version) == 0) or version is not None and (candidate_version is None or len(candidate_version) == 0) or version < candidate_version:
			new_version = "".join(candidate_version)

			ansithemeprint([ANSIThemeString("\n• ", "separator"),
					ANSIThemeString(f"Downloading {upgradetype} ", "action"),
					ANSIThemeString(f"{new_version}", "version")])

			substitutions = {
				"<<<version>>>": new_version,
				"<<<arch>>>": arch,
				"<<<context>>>": context,
			}

			kubectl_path = secure_which(FilePath("/usr/bin/kubectl"), fallback_allowlist = ["/etc/alternatives"], security_policy = SecurityPolicy.ALLOWLIST_RELAXED)
			if upgradetype == "CNI":
				secure_mkdir(DEPLOYMENT_DIR)
				directory = FilePath(str(PurePath(DEPLOYMENT_DIR).joinpath("cni")))
				permissions = 0o644
			elif upgradetype == "executable":
				directory = BINDIR
				permissions = 0o755
			secure_mkdir(directory)

			for url in deep_get(cni_upgrade_data, DictPath(f"{cni}#{upgradetype}#urls"), []):
				download_url = deep_get(url, DictPath("url"), "")
				checksum_url = deep_get(url, DictPath("checksum_url"), None)
				checksum_type = deep_get(url, DictPath("checksum_type"), None)
				filename = deep_get(url, DictPath("filename"), "")

				download_url = substitute_string(download_url, substitutions)
				checksum_url = substitute_string(checksum_url, substitutions)
				filename = substitute_string(filename, substitutions)

				ansithemeprint([ANSIThemeString("\n  • ", "separator"),
						ANSIThemeString("Downloading ", "subaction"),
						ANSIThemeString(f"{filename}", "version")])
				check_and_print_status(download_files(directory, [(download_url, filename, checksum_url, checksum_type)], permissions = permissions))

				if upgradetype == "CNI":
					new_path = FilePath(str(PurePath(directory).joinpath(filename)))
					args = [kubectl_path]
					kubectl_major_version, kubectl_minor_version, _kubectl_git_version, _server_major_version, _server_minor_version, _server_git_version = kubernetes_helper.kubectl_get_version()
					if kubectl_major_version is None or kubectl_minor_version is None:
						ansithemeprint([ANSIThemeString("Critical", "critical"),
								ANSIThemeString(": Could not extract ", "default"),
								ANSIThemeString("kubectl", "programname"),
								ANSIThemeString(" version; aborting.", "default")], stderr = True)
						sys.exit(errno.ENOENT)
					if kubectl_major_version <= 1 and kubectl_minor_version < 22:
						args += ["create"]
					else:
						args += ["apply", "--server-side"]
					args += ["-f", new_path]

					patch_cni_call = deep_get(url, DictPath("patch"))
					if patch_cni_call is not None:
						ansithemeprint([ANSIThemeString("\n  • ", "separator"),
								ANSIThemeString("Patching ", "subaction"),
								ANSIThemeString(f"{filename}", "version")])
						patch_cni_call(new_path, pod_network_cidr)
					ansithemeprint([ANSIThemeString("\n  • ", "separator"),
							ANSIThemeString("Applying ", "subaction"),
							ANSIThemeString(f"{filename}", "version")])
					if verbose:
						# This should check whether kubectl is >= 1.22; otherwise we need to use create
						check_and_print_status(execute_command(args))
					else:
						# This should check whether kubectl is >= 1.22; otherwise we need to use create
						check_and_print_status(execute_command_with_response(args))
		else:
			ansithemeprint([ANSIThemeString("No newer version available.", "default")])
	elif install_command is not None and (version is None or len(version) == 0):
		new_version = "".join(candidate_version)

		ansithemeprint([ANSIThemeString("\n• ", "separator"),
				ANSIThemeString(f"Installing {upgradetype} ", "action"),
				ANSIThemeString(f"{new_version}", "version")])

		substitutions = {
			"<<<version>>>": new_version,
			"<<<arch>>>": arch,
			"<<<context>>>": context,
		}
		check_and_print_status(execute_command(substitute_list(install_command, substitutions)))
	elif upgrade_command is not None:
		if version is None or version < candidate_version:
			new_version = "".join(candidate_version)

			ansithemeprint([ANSIThemeString("\n• ", "separator"),
					ANSIThemeString(f"Upgrading {upgradetype} to ", "action"),
					ANSIThemeString(f"{new_version}", "version")])

			substitutions = {
				"<<<version>>>": new_version,
				"<<<arch>>>": arch,
				"<<<context>>>": context,
			}
			check_and_print_status(execute_command(substitute_list(upgrade_command, substitutions)))
		else:
			ansithemeprint([ANSIThemeString("No newer version available.", "default")])

# pylint: disable-next=unused-argument
def setup_cni(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Install and configure the specified CNI

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): The CNI to install and configure (optional; if not specified the default CNI will be used)
	"""

	confirm = True
	reinstall = False
	verbose = False

	for opt, _optarg in options:
		if opt == "--reinstall":
			reinstall = True
		elif opt == "-Y":
			confirm = False
		elif opt == "--verbose":
			verbose = True

	if not Path(CMT_INSTALLATION_INFO_FILE).is_file():
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Could not find reliable installation information. Aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	cni = deep_get(installation_info, DictPath(f"{cluster_name}#cni"))
	admin_name = f"kubernetes-admin+{cluster_name}"
	context_name = f"{admin_name}@{cluster_name}"

	if cni not in ("", "none", "<none>", "<unknown>") and not reinstall:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": The cluster already has a CNI installed; aborting.", "default")], stderr = True)
		sys.exit(errno.EEXIST)

	if len(args) == 0:
		if not reinstall:
			ansithemeprint([ANSIThemeString("Note", "note"),
					ANSIThemeString(": No CNI specified; defaulting to ", "default"),
					ANSIThemeString(f"{DEFAULT_CNI}", "programname"),
					ANSIThemeString(".", "default")], stderr = True)
	else:
		if reinstall and cni != args[0]:
			ansithemeprint([ANSIThemeString("Error", "note"),
					ANSIThemeString("--reinstall", "option"),
					ANSIThemeString(" cannot be used to change CNI; aborting.", "default")], stderr = True)
			sys.exit(errno.EINVAL)
		cni = args[0]

	if confirm:
		retval = ansithemeinput([ANSIThemeString("\nSetup CNI (", "default"),
					 ANSIThemeString(f"{cni}", "argument"),
					 ANSIThemeString(")? [y/", "default"),
					 ANSIThemeString("N", "emphasis"),
					 ANSIThemeString("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			ansithemeprint([ANSIThemeString("\nAborting:", "error"),
					ANSIThemeString(" User stopped CNI setup.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	ansithemeprint([ANSIThemeString("\n[Installing and configuring CNI]", "phase")])
	result = __setup_cni(cni, context_name, cluster_name, verbose = verbose)
	if result:
		update_installation_info(cluster_name = cluster_name, cni = cni)

# pylint: disable-next=unused-argument
def teardown_cni(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Teardown the CNI

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Unused
	"""

	confirm = True
	cni_version = None

	for opt, optarg in options:
		if opt == "--cni-version":
			cni_version = optarg
		elif opt == "-Y":
			confirm = False

	if not Path(CMT_INSTALLATION_INFO_FILE).is_file():
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Could not find reliable installation information. Aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	# We should get this using kubernetes_helper (and allow for manual override)
	kubectl_path = secure_which(FilePath("/usr/bin/kubectl"), fallback_allowlist = ["/etc/alternatives"], security_policy = SecurityPolicy.ALLOWLIST_RELAXED)
	context = execute_command_with_response([kubectl_path, "config", "current-context"]).splitlines()[0]
	cni = installation_info[cluster_name]["cni"]
	if cni in ("", "<none>", "<unknown>"):
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": No CNI installed; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	directory = FilePath(str(PurePath(DEPLOYMENT_DIR).joinpath("cni")))

	# This will only work for running clusters
	from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
	kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

	cnis = kh.identify_cni()
	if len(cnis) == 1:
		installed_cni = cnis[0][0]
		installed_cni_version = cnis[0][1]
	else:
		installed_cni = "<unknown>"
		installed_cni_version = "<unknown>"

	if installed_cni not in (cni, "<unknown>"):
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString(f"{CMT_INSTALLATION_INFO_FILE}", "path"),
				ANSIThemeString(" disagrees with the cluster about what CNI is installed", "default"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	if installed_cni_version == "<unknown>":
		if cni_version is None:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": the CNI version could not be identified; use ", "default"),
					ANSIThemeString("--cni-version", "option"),
					ANSIThemeString(" to specify it; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
	else:
		if cni_version is None:
			cni_version = installed_cni_version

	cni_filenames = []
	uninstall_command = None

	urls = deep_get(cni_upgrade_data, DictPath(f"{cni}#CNI#urls"), [])
	# We need to remove the files in reverse order
	for url in reversed(urls):
		filename = deep_get(url, DictPath("filename"), "")
		substitutions = {
			"<<<version>>>": cni_version,
		}
		if "<<<version>>>" in filename:
			filename = substitute_string(filename, substitutions)
		cni_filenames.append(filename)
	# We might use an uninstall command rather than files
	uninstall_command = deep_get(cni_upgrade_data, DictPath(f"{cni}#CNI#uninstall"))

	if len(cni_filenames) == 0 and uninstall_command is None:
		ansithemeprint([ANSIThemeString("Critical", "critical"),
				ANSIThemeString(": No data found for CNI. This is most likely a programming error; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	for cni_filename in cni_filenames:
		cni_path = FilePath(str(PurePath(directory).joinpath(cni_filename)))

		security_violations = check_path(cni_path)

		if security_violations != [SecurityStatus.OK]:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": The CNI deployment file {cni_filename} is either missing or unsafe to use; aborting.", "default")], stderr = True)
			sys.exit(errno.EINVAL)

	all_nodes_in_cluster = ansible_get_hosts_by_group(ANSIBLE_INVENTORY, cluster_name)
	if len(all_nodes_in_cluster) == 0:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": The inventory for this cluster does not contain any hosts; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	if confirm:
		input_retval = ansithemeinput([ANSIThemeString("\nUninstall CNI (", "default"),
					       ANSIThemeString(f"{cni}", "argument"),
					       ANSIThemeString(")? [y/", "default"),
					       ANSIThemeString("N", "emphasis"),
					       ANSIThemeString("]: ", "default")])
		if input_retval.lower() not in ("y", "yes"):
			ansithemeprint([ANSIThemeString("\nAborting:", "error"),
					ANSIThemeString(" User stopped CNI removal.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	ansithemeprint([ANSIThemeString("\n[Removing CNI and configuration]", "phase")])

	for cni_filename in cni_filenames:
		cni_path = FilePath(str(PurePath(directory).joinpath(cni_filename)))

		# OK, we have paths to the CNI files; this should be enough to remove it
		kubectl_path = secure_which(FilePath("/usr/bin/kubectl"), fallback_allowlist = ["/etc/alternatives"], security_policy = SecurityPolicy.ALLOWLIST_RELAXED)
		execute_command_with_response([kubectl_path, "delete", "-f", cni_path])

	if uninstall_command is not None:
		# In case we have an uninstall command we run that
		substitutions = {
			"<<<context>>>": context,
		}
		check_and_print_status(execute_command(substitute_list(uninstall_command, substitutions)))

	uninstall_cni_playbooks = [
		FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("teardown_cni.yaml"))),
	]
	playbooks = populate_playbooks_from_paths(uninstall_cni_playbooks)

	retval = run_playbooks(playbooks = playbooks, hosts = all_nodes_in_cluster)
	if retval:
		ansithemeprint([ANSIThemeString("OK", "ok")])
		update_installation_info(cluster_name = cluster_name, cni = "<none>")
		ansithemeprint([ANSIThemeString("\nNote", "note"),
				ANSIThemeString(": It is recommended to reboot the control plane(s) and all nodes after uninstalling the CNI\n", "default")])
	else:
		ansithemeprint([ANSIThemeString("NOT OK", "notok"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

# pylint: disable-next=unused-argument
def upgrade_cni(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Upgrade the specified CNI to the latest version

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): The CNI to upgrade (optional; if not specified the CNI will be taken from installation_info.yaml)
	"""

	kh = None
	pod_network_cidr = None
	verbose = False

	if len(args) > 0:
		cni = args[0]
	else:
		installation_info = get_installation_info()
		cluster_name = installation_info["installation_target"]
		cni = deep_get(installation_info, DictPath(f"{cluster_name}#cni"))
		pod_network_cidr = deep_get(installation_info, DictPath(f"{cluster_name}#pod_network_cidr"))

	if pod_network_cidr is None:
		# If we have a running cluster and we are upgrading by CNI rather than through installation info we need to get the Pod CIDR
		# by some other means; try this. If this fails we give up.
		from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
		kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)
		pod_network_cidr = kh.get_pod_network_cidr()
		if pod_network_cidr is None:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": Could not identify Pod network CIDR; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOTSUP)

	if cni in ("", "<none>", "<unknown>"):
		if kh is None:
			from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
			kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)
		tmp_cni = kh.identify_cni()
		if len(tmp_cni) == 0:
			cni = "<unknown>"
		elif len(tmp_cni) > 1:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": Could not uniquely identify the CNI; multiple potential candidates identified; aborting.", "default")], stderr = True)
			sys.exit(errno.EINVAL)
		else:
			cni = tmp_cni[0][0]

	install_cni = False
	action_str = "Upgrading"
	for opt, _optarg in options:
		if opt == "install":
			install_cni = True
			action_str = "Installing"
		elif opt == "--verbose":
			verbose = True

	if cni not in cni_upgrade_data:
		ansithemeprint([ANSIThemeString(f"{action_str} ", "default"),
				ANSIThemeString(f"{cni}", "command"),
				ANSIThemeString(" is currently not supported; exiting.", "default")])
		sys.exit(errno.ENOTSUP)

	kubectl_path = secure_which(FilePath("/usr/bin/kubectl"), fallback_allowlist = ["/etc/alternatives"], security_policy = SecurityPolicy.ALLOWLIST_RELAXED)
	context_name = execute_command_with_response([kubectl_path, "config", "current-context"]).splitlines()[0]

	if install_cni:
		ansithemeprint([ANSIThemeString("\n[Installing CNI]", "phase")])
	else:
		ansithemeprint([ANSIThemeString("\n[Upgrading CNI]", "phase")])

	__upgrade_cni(cni, "executable", context_name, pod_network_cidr, verbose = verbose)
	__upgrade_cni(cni, "CNI", context_name, pod_network_cidr, verbose = verbose)

	if install_cni:
		ansithemeprint([ANSIThemeString("\nCNI installation successful", "success")])
	else:
		ansithemeprint([ANSIThemeString("\nCNI upgrade successful", "success")])

def __setup_cni(cni: str, context_name: str, cluster_name: str, **kwargs) -> bool:
	"""
	Setup a CNI

		Parameters:
			cni (str): The CNI to configure and install
			context_name (str): The name of the cluster context
			cluster_name (str): The name of the cluster
		Returns:
			result (bool): True on success, False on failure
	"""

	pass_cni = []
	verbose = deep_get(kwargs, DictPath("verbose"), False)

	installation_info = get_installation_info()
	cluster_name = deep_get(installation_info, DictPath("installation_target"))
	installation_info_cni = deep_get(installation_info, DictPath(f"{cluster_name}#cni"))
	if installation_info_cni is None or installation_info_cni in ("none", "<none>"):
		pass_cni = [cni]

	if cni == "none":
		ansithemeprint([ANSIThemeString("Note", "note"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString("none", "argument"),
				ANSIThemeString(" specified; skipping CNI installation.", "default")], stderr = True)
		return True

	if cni not in cni_upgrade_data:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString(f"{cni}", "argument"),
				ANSIThemeString(" is not a valid/supported CNI; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
	kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

	# upgrade_cni doesn't take a context, so we need to set the current context before calling it,
	# otherwise we might end up performing the changes on the wrong cluster
	if not kh.set_context(name = context_name, unchanged_is_success = True):
		ansithemeprint([ANSIThemeString("Warning", "warning"),
				ANSIThemeString(": Failed to change to context ", "default"),
				ANSIThemeString(f"{context_name}", "hostname"),
				ANSIThemeString(" for cluster ", "default"),
				ANSIThemeString(f"{cluster_name}", "hostname"),
				ANSIThemeString("; cannot install/upgrade CNI; skipping.", "default")])
		return False

	# Don't pass CNI as an argument here; installation_info contains that information during installation.
	# upgrade_cni() will assume that the cluster is functional if run with a CNI, and thus tries to get
	# all information from the cluster. This will most likely fail during installation, since the cluster
	# hasn't started fully yet and thus cannot provide the necessary information
	upgrade_cni(options = [("install", ""), ("--verbose", verbose)], args = pass_cni)
	# FIXME
	return True

def check_for_ssh_key() -> bool:
	"""
	Check whether there's an existing public ssh key on the system already

		Returns:
			retval (bool): True if a key exists, False if no key exists
	"""

	retval = False
	files = [file for file in glob(os.path.join(HOMEDIR, ".ssh", "*.pub")) if os.path.isfile(file)]
	for file in files:
		if os.path.isfile(file) and os.path.isfile(file[:-len(".pub")]):
			retval = True
			break
	return retval

def create_ssh_key() -> bool:
	"""
	Create a new ssh key (ECDSA-P521 format)

		Returns:
			retval (bool): True on success, False on failure
	"""

	if not os.path.exists(f"{HOMEDIR}/.ssh/id_ecdsa"):
		args = [SSH_KEYGEN_BIN_PATH] + SSH_KEYGEN_ARGS + ["-f", f"{SSH_DIR}/id_ecdsa"]
		retval = execute_command(args)
	else:
		retval = True
	return retval

def add_ssh_keys_to_authorized_keys() -> bool:
	"""
	Add all public keys for this host to authorized keys on this host;
	in other words, make the host able to SSH to itself

		Returns:
			retval (bool): True on success, False on failure
	"""

	retval = False

	# Since we run create_ssh_key() before this task we can safely assume that .ssh/ exists
	for path in Path(SSH_DIR).iterdir():
		if not path.name.endswith(".pub"):
			continue

		tmp = secure_read_string(FilePath(str(path)))
		if tmp is not None:
			tmplines = tmp.splitlines()
			pubkey = cast(str, tmplines[0])
			if len(pubkey) == 0:
				continue

		exists = False

		authorized_keys_path = FilePath(str(PurePath(SSH_DIR).joinpath("authorized_keys")))

		try:
			tmp = secure_read_string(authorized_keys_path)
			if tmp is not None and len(tmp) > 0:
				for line in tmp:
					if line == pubkey[0]:
						exists = True
						break
		except FilePathAuditError as e:
			if "SecurityStatus.DOES_NOT_EXIST" in str(e):
				pass

		if not exists:
			secure_write_string(authorized_keys_path, f"{pubkey}\n", write_mode = "a")

		# We've added at least one public key
		retval = True

	return retval

# pylint: disable-next=unused-argument
def __task_check_and_create_ssh_key(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that checks whether the system has an ssh-key,
	and creates one if not

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	# FIXME
	confirm = True

	if not check_for_ssh_key():
		if confirm:
			retval = ansithemeinput([ANSIThemeString("Warning", "warning"),
						 ANSIThemeString(": No ssh key found in ", "default"),
						 ANSIThemeString(f"{HOMEDIR}/.ssh", "path"),
						 ANSIThemeString("; create one now? (No will abort the installation) [y/", "default"),
						 ANSIThemeString("N", "emphasis"),
						 ANSIThemeString("]: ", "default")])
			if retval.lower() not in ("y", "yes"):
				ansithemeprint([ANSIThemeString("\nAborting:", "error"),
						ANSIThemeString(" No ssh key available.", "default")], stderr = True)
				sys.exit(errno.ENOENT)
		check_and_print_status(create_ssh_key())

# pylint: disable-next=unused-argument
def __task_scan_and_add_ssh_keys(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that scans all specified control planes for public ssh keys
	and adds them to known hosts

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	cluster_name = installation_info["installation_target"]
	nodes = deep_get(installation_info, DictPath(f"{cluster_name}#nodes"), [])

	controlplanes = get_control_planes()
	hosts = [controlplane[0] for controlplane in controlplanes]
	hosts += [f"{controlplane[0]}.local" for controlplane in controlplanes]
	hosts += [
		"localhost",
	]
	hosts += nodes

	scan_and_add_ssh_keys(hosts)

# pylint: disable-next=unused-argument
def __task_add_ssh_keys_to_inventory(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that adds SSH keys to the Ansible inventory

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	pubkey = None
	d = ansible_get_inventory_dict()
	__vars = deep_get(d, DictPath("all#vars"), {})
	__authorized_keys = deep_get(__vars, DictPath("authorized_keys"), [])
	found_key = False

	for path in Path(SSH_DIR).iterdir():
		if not str(path).endswith(".pub"):
			continue

		tmp = secure_read_string(FilePath(str(path)))
		if tmp is not None:
			tmplines = tmp.splitlines()
			pubkey = tmplines[0]

		if tmp is None or len(pubkey) == 0:
			ansithemeprint([ANSIThemeString("Warning", "warning"),
					ANSIThemeString(": Failed to read a key from ", "default"),
					ANSIThemeString(str(path), "path"),
					ANSIThemeString("; skipping.", "default")], stderr = True)
			continue

		if pubkey not in __authorized_keys:
			__authorized_keys.append(pubkey)

		found_key = True

	if not found_key:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Could not find a valid public key in ", "default"),
				ANSIThemeString(SSH_DIR, "path"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	__vars["authorized_keys"] = __authorized_keys
	ansible_set_vars(ANSIBLE_INVENTORY, "all", __vars)

# pylint: disable-next=unused-argument
def __task_check_and_add_ssh_keys_to_authorized_keys(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that adds SSH keys to authorized keys

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	add_ssh_keys_to_authorized_keys()

def install_ansible_posix() -> bool:
	"""
	Install ansible-posix using ansible-galaxy; this is necessary on systems
	where the version of Ansible is too old to support certain actions.

		Returns:
			(bool): True on success, False on failure
	"""

	# Old versions of ansible-galaxy does not have the list command;
	# if it does not work we just assume that ansible.posix is missing
	args = ["/usr/bin/ansible-galaxy", "collection", "list"]
	result = execute_command_with_response(args)

	if "COLLECTION_ACTION: invalid choice" in result or "ansible.posix" not in result:
		http_proxy = deep_get(cmtlib.cmtconfig, DictPath("Network#http_proxy"), "")
		https_proxy = deep_get(cmtlib.cmtconfig, DictPath("Network#https_proxy"), "")
		no_proxy = deep_get(cmtlib.cmtconfig, DictPath("Network#no_proxy"), "")
		env = {
			"http_proxy": http_proxy,
			"https_proxy": https_proxy,
			"no_proxy": no_proxy,
		}
		args = ["/usr/bin/ansible-galaxy", "collection", "install", "ansible.posix"]
		return execute_command(args, env = env)

	return True

# pylint: disable-next=unused-argument
def __task_check_and_install_ansible_posix(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that installs ansible-posix

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	check_and_print_status(install_ansible_posix())

def update_version_cache() -> bool:
	"""
	Update the version cache

		Returns:
			True on success, False on failure
	"""

	update_version_cache_path = get_playbook_path(FilePath("update_version_cache.yaml"))
	_retval, ansible_results = run_playbook(update_version_cache_path, hosts = ["localhost"])

	if len(ansible_results) == 0:
		return False

	return True

def update_apt_cache() -> bool:
	"""
	Update the APT cache

		Returns:
			True on success, False on failure
	"""

	sudo_path = cmtio.secure_which(FilePath("sudo"), fallback_allowlist = ["/bin", "/usr/bin"],
				       security_policy = SecurityPolicy.ALLOWLIST_STRICT)
	apt_get_path = cmtio.secure_which(FilePath("apt-get"), fallback_allowlist = ["/bin", "/usr/bin"],
					  security_policy = SecurityPolicy.ALLOWLIST_STRICT)
	args = [sudo_path, apt_get_path, "update"]
	return execute_command(args)

def update_zypper_cache() -> bool:
	"""
	Update the Zypper cache

		Returns:
			True on success, False on failure
	"""

	sudo_path = cmtio.secure_which(FilePath("sudo"), fallback_allowlist = ["/bin", "/usr/bin"],
				       security_policy = SecurityPolicy.ALLOWLIST_STRICT)
	apt_get_path = cmtio.secure_which(FilePath("zypper"), fallback_allowlist = ["/bin", "/usr/bin"],
					  security_policy = SecurityPolicy.ALLOWLIST_STRICT)
	args = [sudo_path, apt_get_path, "refresh"]
	return execute_command(args)

def deb_compare_versions(current_version: str, candidate_version: str) -> bool:
	"""
	Compare two package versions

		Returns:
			True if current version < candidate version, else False
	"""

	args = ["/usr/bin/dpkg", "--compare-versions", current_version, "lt", candidate_version]
	return execute_command(args, comparison = 1)

def __get_theme(string: str, default: str) -> str:
	"""
	Return the suitable format reference for a particular string

		Parameters:
			string (str): A string to return the format reference for
			default (str): The default format reference to use if there's no matching translation
		Returns:
			theme (str): A format reference
	"""

	translation = {
		"<none>": "none",
		"<unknown>": "unknown",
	}
	return translation.get(string, default)

def get_latest_kubernetes_upstream_version() -> str:
	"""
	Fetch the upstream version for Kubernetes

		Returns:
			(str): The latest upstream Kubernetes version
	"""

	# We are OK with the file not existing
	security_checks = [
		SecurityChecks.PARENT_RESOLVES_TO_SELF,
		SecurityChecks.OWNER_IN_ALLOWLIST,
		SecurityChecks.PARENT_OWNER_IN_ALLOWLIST,
		SecurityChecks.PERMISSIONS,
		SecurityChecks.PARENT_PERMISSIONS,
		SecurityChecks.IS_FILE,
	]

	kubernetes_upstream_version = None

	try:
		version_cache = secure_read_yaml(FilePath(str(PurePath(VERSION_CACHE_DIR).joinpath("kubernetes_current.yaml"))), checks = security_checks)
	except FileNotFoundError:
		version_cache = None

	if version_cache is not None:
		if len(schedules := deep_get(version_cache, DictPath("schedules"), [])) > 0:
			if len(previous_patches := deep_get(schedules[0], DictPath("previousPatches"), [])) > 0:
				kubernetes_upstream_version = deep_get(previous_patches[0], DictPath("release"), kubernetes_upstream_version)
			else:
				tmp = deep_get(schedules[0], DictPath("release"), "")
				if tmp is not None and len(str(tmp)) > 0:
					tmp = str(tmp)
					if len(tmp.split(".")) < 3:
						tmp = f"{tmp}.0"
					kubernetes_upstream_version = tmp

	return kubernetes_upstream_version

def check_versions(pkg_packages: List[str], version_checks: List[Tuple[str, List[str], str]]) -> Tuple[List[Tuple[str, str, str, List[str]]], List[Tuple[str, str, str, List[str]]]]:
	"""
	Check versions for all relevant software

		Parameters:
			deb_packages (list[str]): A list of debian packages
			version_checks (list[(software, args, regex)]): A list of component, the command needed to check its version, and a regex to extract the version number
		Returns:
			(deb_versions, other_versions): A tuple of utput from check_versions_apt(), (software, installed_version, "")
	"""

	os_distro = identify_distro()

	other_versions: List[Tuple[str, str, str, List[str]]] = []

	if os_distro in ("debian",):
		pkg_versions = check_versions_apt(pkg_packages)
	elif os_distro in ("suse",):
		pkg_versions = check_versions_zypper(pkg_packages)
	elif os_distro in ("fedora", "rhel",):
		pkg_versions = check_versions_yum(pkg_packages)

	kubernetes_installed_version = "<unknown>"
	if (kubernetes_upstream_version := get_latest_kubernetes_upstream_version()) is None:
		kubernetes_upstream_version = "<unknown>"

	# Get the API-server version (if available)
	# This will only work for running clusters
	from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
	kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

	_server_major_version, _server_minor_version, kubernetes_installed_version = kh.get_api_server_version()

	if kubernetes_installed_version == kubernetes_upstream_version:
		kubernetes_upstream_version = ""

	crc_installed_version = ""
	crc_upstream_version = ""

	try:
		crc_path = cmtio.secure_which(FilePath("crc"), fallback_allowlist = ["/bin", "/usr/bin", f"{HOMEDIR}/bin"],
					      security_policy = SecurityPolicy.ALLOWLIST_STRICT)
		args = [crc_path, "version"]
		response = execute_command_with_response(args)
		for line in response.splitlines():
			if (tmp := re.match(r"^CRC version: (\d+\.\d+\.\d+).*", line)) is not None:
				crc_installed_version = tmp[1]
			elif (tmp := re.match(r"^.*A new version \((\d+\.\d+\.\d+)\).*", line)) is not None:
				crc_upstream_version = tmp[1]
	except FileNotFoundError:
		pass
	#
	# Now check versions that need special checks
	for version_check in version_checks:
		tmp_software: str = version_check[0]
		args = version_check[1]
		regex = version_check[2]

		try:
			response = execute_command_with_response(args)
		except FileNotFoundError:
			other_versions.append((tmp_software, "<none>", "", []))
			continue
		except CalledProcessError:
			other_versions.append((tmp_software, "<unknown>", "", []))
			continue

		if regex is None:
			tmp_installed_version = response
		else:
			tmp_match = re.match(regex, response)
			if tmp_match is not None:
				tmp_installed_version = tmp_match[1]
			else:
				tmp_installed_version = "<none>"
		other_versions.append((tmp_software, tmp_installed_version, "", []))

	# Finally, display the gathered version information; find the longest string of each type
	# Create lists of header + all values belonging to that header, and get the length of the longest element
	slen = len(max(["Software:"] + [tmp[0] for tmp in pkg_versions + other_versions], key = len))
	slen = max(slen, len("Kubernetes (upstream)"))
	ilen = len(max(["Installed Version:"] + [tmp[1] for tmp in pkg_versions + other_versions], key = len))

	# Print a header
	ansithemeprint([ANSIThemeString("Software:", "header"),
			ANSIThemeString(f"{''.ljust(slen - len('Software:') + 2)}", "default"),
			ANSIThemeString("Installed Version:", "header"),
			ANSIThemeString(f"{''.ljust(ilen - len('Installed Version:') + 2)}", "default"),
			ANSIThemeString("Candidate Version:", "header")])

	ansithemeprint([ANSIThemeString("Kubernetes ", "default"),
			ANSIThemeString("(upstream)".ljust(slen - len("Kubernetes ") + 2), "note"),
			ANSIThemeString(f"{kubernetes_installed_version}".ljust(ilen + 2), "version"),
			ANSIThemeString(f"{kubernetes_upstream_version}", "version")])

	if len(crc_installed_version) > 0:
		ansithemeprint([ANSIThemeString("CRC ", "default"),
				ANSIThemeString("(upstream)".ljust(slen - len("CRC ") + 2), "note"),
				ANSIThemeString(f"{crc_installed_version}".ljust(ilen + 2), "version"),
				ANSIThemeString(f"{crc_upstream_version}", "version")])

	for software, installed_version, candidate_version, _ in cast(Tuple[str, str, str, List[str]], natsorted(pkg_versions)):
		iformat = __get_theme(installed_version, "version")
		cformat = __get_theme(candidate_version, "version")
		ansithemeprint([ANSIThemeString(f"{software.ljust(slen + 2)}", "default"),
				ANSIThemeString(f"{installed_version.ljust(ilen + 2)}", iformat),
				ANSIThemeString(f"{candidate_version}", cformat)])
	print()
	for software, installed_version, candidate_version, _ in cast(Tuple[str, str, str, List[str]], natsorted(other_versions)):
		iformat = __get_theme(installed_version, "version")
		cformat = __get_theme(candidate_version, "version")
		ansithemeprint([ANSIThemeString(f"{software.ljust(slen + 2)}", "default"),
				ANSIThemeString(f"{installed_version.ljust(ilen + 2)}", iformat),
				ANSIThemeString(f"{candidate_version}", cformat)])

	return pkg_versions, other_versions

# pylint: disable-next=unused-argument
def run_playbook(playbookpath: FilePath, hosts: List[str], extra_values: Optional[Dict] = None, quiet: bool = False, verbose: bool = False) -> Tuple[int, Dict]:
	"""
	Run a playbook

		Parameters:
			playbookpath (FilePath): A path to the playbook to run
			hosts (list[str]): A list of hosts to run the playbook on
			extra_values (dict): A dict of values to set before running the playbook
			quiet (bool): Should the results of the run be printed?
			verbose (bool): If the results are printed, should skipped tasks be printed too?
		Returns:
			retval (int): The return value from ansible_run_playbook_on_selection()
			ansible_results (dict): A dict with the results from the run
	"""

	# Set necessary Ansible keys before running playbooks
	http_proxy = deep_get(cmtlib.cmtconfig, DictPath("Network#http_proxy"), "")
	if http_proxy is None:
		http_proxy = ""
	https_proxy = deep_get(cmtlib.cmtconfig, DictPath("Network#https_proxy"), "")
	if https_proxy is None:
		https_proxy = ""
	no_proxy = deep_get(cmtlib.cmtconfig, DictPath("Network#no_proxy"), "")
	if no_proxy is None:
		no_proxy = ""
	insecure_registries = deep_get(cmtlib.cmtconfig, DictPath("Docker#insecure_registries"), [])
	registry_mirrors = deep_get(cmtlib.cmtconfig, DictPath("Containerd#registry_mirrors"), [])
	retval = 0

	use_proxy = "no"
	if len(http_proxy) > 0 or len(https_proxy) > 0:
		use_proxy = "yes"

	if extra_values is None:
		extra_values = {}

	values = {
		"http_proxy": http_proxy,
		"https_proxy": https_proxy,
		"no_proxy": no_proxy,
		"insecure_registries": insecure_registries,
		"registry_mirrors": registry_mirrors,
		"use_proxy": use_proxy,
	}
	merged_values = { **values, **extra_values }

	retval, ansible_results = ansible_run_playbook_on_selection(playbookpath, selection = hosts, values = merged_values)

	if not quiet:
		ansible_print_play_results(retval, ansible_results, verbose = verbose)

	return retval, ansible_results

def run_playbooks(playbooks: List[Tuple[List[ANSIThemeString], FilePath]], hosts: Optional[List[str]] = None, extra_values: Optional[Dict] = None, verbose: bool = False) -> bool:
	"""
	Run a set of playbooks

		Parameters:
			playbooks (list[(description (list[ANSIThemeString]), playbookpath (FilePath))]): A list of playbooks
			hosts (list[str]): The hosts to run the playbooks on
			extra_values (dict): Variables to set before running the playbooks
			verbose (bool): If the results are printed, should skipped tasks be printed too?
		Returns:
			True on success, False on failure
	"""

	if len(playbooks) == 0 or hosts is None:
		return True

	for string, playbookpath in playbooks:
		ansithemeprint(string)
		retval, _ansible_results = run_playbook(playbookpath, hosts = hosts, extra_values = extra_values, verbose = verbose)

		# We do not want to continue executing playbooks if the first one failed
		if retval != 0:
			break

	return retval == 0

def __playbook_paths_from_path(playbook_path: FilePath) -> List[FilePath]:
	"""
	Scan a directory and return a list of playbook paths

		Parameters:
			playbook_path (str): A path to a directory
		Returns:
			list[FilePath]: A list of paths
	"""

	if playbook_path is None:
		raise ValueError("No path passed to __playbook_paths_from_path(); this is a programming error.")

	playbook_paths = []

	# Populate list of playbooks
	for path in Path(playbook_path).iterdir():
		# Do not process backups, etc.
		if path.name.startswith(("~", ".")):
			continue
		if not path.name.endswith((".yml", ".yaml")):
			continue
		playbook_paths.append(FilePath(str(path)))

	return playbook_paths

# Add all playbooks in the directory
def populate_playbooks_from_dir(path: FilePath) -> List[Tuple[List[ANSIThemeString], FilePath]]:
	"""
	Populate a playbook list from path

		Parameters:
			paths (FilePath): A directory to populate playbooks from
		Returns:
			list[(description, playbookpath)]: A playbook list for use with run_playbooks()
	"""

	playbook_paths = __playbook_paths_from_path(path)

	return populate_playbooks_from_paths(playbook_paths)

# pylint: disable-next=unused-argument
def __task_request_ansible_password(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that requests the ansible password

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	# Check whether ansible_password is defined or not
	if deep_get(ansible_configuration, DictPath("ansible_password")) is None and not no_password:
		ansithemeprint([ANSIThemeString("Attention", "warning"),
				ANSIThemeString(": To be able to run playbooks you need to provide the ansible/ssh password.", "default")])
		ansithemeprint([ANSIThemeString("Since the systems will be reconfigured to use passwordless sudo and ssh keys this is a one-time thing.\n", "default")])
		ansithemeprint([ANSIThemeString("Note", "note"),
				ANSIThemeString(": If the remote host is already configured for passwordless sudo and allows for login using a pre-generated SSH-key you can use “", "default"),
				ANSIThemeString("--no-password", "option"),
				ANSIThemeString("“ to bypass this check.", "default")])
		ansible_password = ansithemeinput_password([ANSIThemeString("\nPassword: ", "default")])
		if len(ansible_password) == 0:
			ansithemeprint([ANSIThemeString("\nError", "error"),
					ANSIThemeString(": Empty password; aborting.", "default")], stderr = True)
			sys.exit(errno.EINVAL)
		else:
			ansible_configuration["ansible_password"] = ansible_password

def __run_playbooks_on_selection(playbooks: List[Tuple[List[ANSIThemeString], FilePath]], selection: List[str], extra_values: Optional[Dict] = None, verbose: bool = False) -> None:
	"""
	A helper that runs a playbook list on a selection

		Parameters:
			playbooks (list[(description, playbookpath)]): A playbook list
			selection (list[str]): A list of hosts
			extra_values (dict): A dict of values to set before running the playbook
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	check_and_print_status(run_playbooks(playbooks, hosts = selection, extra_values = extra_values, verbose = verbose))

def __selection_control_planes() -> List[str]:
	"""
	Return a selection with all control planes

		Returns:
			(list[str]): A list of control planes
	"""

	__controlplanes = get_control_planes(fail_on_empty = False)
	return [controlplane[0] for controlplane in __controlplanes]

def __selection_localhost() -> List[str]:
	"""
	Returns a list with the hostname of localhost

		Returns:
			(list[str]): A list with the hostname of localhost
	"""

	return [socket.gethostname()]

# pylint: disable-next=unused-argument
def __generic_task_run_playbooks_on_selection(selection: List[str], installation_info: Dict, playbook_dir: FilePath, extra_values: Optional[Dict] = None, verbose: bool = False) -> None:
	"""
	A task that runs playbooks on selected hosts

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""
	paths = __playbook_paths_from_path(CMT_PRE_UPGRADE_DIR)
	playbooks = populate_playbooks_from_paths(paths)
	if extra_values is None:
		extra_values = {}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values, verbose = verbose)

# pylint: disable-next=unused-argument
def __task_run_prepreparation_playbooks(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that runs pre-preparation playbooks

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	# The default selection is control planes; the playbooks need to explicitly specify if the play should be run on other hosts
	selection = __selection_control_planes()
	__generic_task_run_playbooks_on_selection(selection = selection, installation_info = installation_info, playbook_dir = [CMT_PRE_PREPARE_DIR], extra_values = {}, verbose = verbose)

# pylint: disable-next=unused-argument
def __task_run_preparation_playbooks_on_localhost(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that runs preparation playbooks on localhost

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	os_distro = identify_distro()
	selection = __selection_localhost()
	playbooks = populate_playbooks_from_paths(cast(List[FilePath], prepare_targets["localhost"]["playbooks"]))

	# The first patch revision that isn't available from the old repositories is 1.28.3;
	# this means that we need to include all minor versions from 28 and up.
	if (kubernetes_upstream_version := get_latest_kubernetes_upstream_version()) is None:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Could not get the latest upstream Kubernetes version; ", "default"),
				ANSIThemeString("this is either a network error or a bug; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	# Split the version tuple
	_upstream_major, upstream_minor, _rest = kubernetes_upstream_version.split(".")
	minor_versions = []
	for minor_version in range(28, int(upstream_minor) + 1):
		minor_versions.append(f"{minor_version}")

	if os_distro in ("debian",):
		packages = deep_get(prepare_targets, DictPath("localhost#deb_packages"), [])
		held_packages = deep_get(prepare_targets, DictPath("localhost#deb_packages_held"), [])
	elif os_distro in ("suse",):
		packages = deep_get(prepare_targets, DictPath("localhost#suse_packages"), [])
		held_packages = deep_get(prepare_targets, DictPath("localhost#suse_packages_held"), [])
	elif os_distro in ("fedora", "rhel",):
		packages = deep_get(prepare_targets, DictPath("localhost#fedora_packages"), [])
		held_packages = deep_get(prepare_targets, DictPath("localhost#fedora_packages_held"), [])

	extra_values = {
		"packages": packages,
		"held_packages": held_packages,
		"ansible_become_pass": deep_get(ansible_configuration, DictPath("ansible_password")),
		"ansible_ssh_pass": deep_get(ansible_configuration, DictPath("ansible_password")),
		"minor_versions": minor_versions,
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values, verbose = verbose)

def __task_run_preparation_playbooks_on_hosts(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that runs preparation playbooks on hosts

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	cluster_name = installation_info["installation_target"]
	k8s_distro = installation_info[cluster_name]["distro"]
	os_distro = identify_distro()
	control_planes = deep_get(installation_info, DictPath(f"{cluster_name}#control_planes"), [])
	nodes = deep_get(installation_info, DictPath(f"{cluster_name}#nodes"), [])
	if len(control_planes) == 0:
		selection = __selection_control_planes()
	else:
		selection = control_planes + nodes
	playbooks = populate_playbooks_from_paths(cast(List[FilePath], prepare_targets[k8s_distro]["playbooks"]))

	# The first patch revision that isn't available from the old repositories is 1.28.3;
	# this means that we need to include all minor versions from 28 and up.
	if (kubernetes_upstream_version := get_latest_kubernetes_upstream_version()) is None:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Could not get the latest upstream Kubernetes version; ", "default"),
				ANSIThemeString("this is either a network error or a bug; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	# Split the version tuple
	_upstream_major, upstream_minor, _rest = kubernetes_upstream_version.split(".")
	minor_versions = []
	for minor_version in range(28, int(upstream_minor) + 1):
		minor_versions.append(f"{minor_version}")

	if os_distro in ("debian",):
		packages = deep_get(prepare_targets, DictPath(f"{k8s_distro}#deb_packages"), [])
		held_packages = deep_get(prepare_targets, DictPath(f"{k8s_distro}#deb_packages_held"), [])
	elif os_distro in ("suse",):
		packages = deep_get(prepare_targets, DictPath(f"{k8s_distro}#suse_packages"), [])
		held_packages = deep_get(prepare_targets, DictPath(f"{k8s_distro}#suse_packages_held"), [])
	elif os_distro in ("fedora", "rhel",):
		packages = deep_get(prepare_targets, DictPath(f"{k8s_distro}#fedora_packages"), [])
		held_packages = deep_get(prepare_targets, DictPath(f"{k8s_distro}#fedora_packages_held"), [])

	extra_values = {
		"packages": packages,
		"held_packages": held_packages,
		"ansible_become_pass": deep_get(ansible_configuration, DictPath("ansible_password")),
		"ansible_ssh_pass": deep_get(ansible_configuration, DictPath("ansible_password")),
		"minor_versions": minor_versions,
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values, verbose = verbose)

# pylint: disable-next=unused-argument
def __task_run_postpreparation_playbooks(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that runs post-preparation playbooks

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	# The default selection is control planes; the playbooks need to explicitly specify if the play should be run on other hosts
	selection = __selection_control_planes()
	__generic_task_run_playbooks_on_selection(selection = selection, installation_info = installation_info, playbook_dir = [CMT_POST_PREPARE_DIR], extra_values = {}, verbose = verbose)

# pylint: disable-next=unused-argument
def __task_setup_bash_completion(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that sets up bash completion

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	secure_mkdir(FilePath(str(PurePath(HOMEDIR).joinpath(".local"))), verbose = True)
	secure_mkdir(FilePath(str(PurePath(HOMEDIR).joinpath(".local", "share"))), verbose = True)
	secure_mkdir(BASH_COMPLETION_BASE_DIR, verbose = True)
	secure_mkdir(BASH_COMPLETION_DIR, verbose = True)

	args = ["/usr/bin/kubectl", "completion", "bash"]
	result = execute_command_with_response(args)
	secure_write_string(FilePath(str(PurePath(BASH_COMPLETION_DIR).joinpath("kubectl"))), result)

def get_cluster_name() -> Optional[str]:
	"""
	Return the name of the cluster

		Returns:
			cluster_name (str): The name of the cluster
	"""
	try:
		d1 = secure_read_yaml(KUBE_CONFIG_FILE)
	except FileNotFoundError:
		return None

	current_context = d1.get("current-context", None)
	if current_context is None:
		return None

	cluster_name = None

	for context in d1.get("contexts", []):
		if context.get("name", "") == current_context:
			cluster_name = context["context"].get("cluster", None)
			break

	return cluster_name

# pylint: disable-next=unused-argument
def __task_run_presetup_playbooks(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that runs pre-setup playbooks

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	# The default selection is control planes; the playbooks need to explicitly specify if the play should be run on other hosts
	selection = __selection_control_planes()
	__generic_task_run_playbooks_on_selection(selection = selection, installation_info = installation_info, playbook_dir = [CMT_PRE_SETUP_DIR], extra_values = {}, verbose = verbose)

def __task_run_setup_playbooks_on_localhost(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that runs playbooks on localhost

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	cluster_name = installation_info["installation_target"]
	pod_network_cidr = installation_info[cluster_name]["pod_network_cidr"]
	os_distro = identify_distro()
	selection = __selection_localhost()
	playbooks = populate_playbooks_from_paths(cast(List[FilePath], setup_control_plane_targets["localhost"]["playbooks"]))

	if os_distro in ("debian",):
		packages = deep_get(setup_control_plane_targets, DictPath("localhost#deb_packages"), [])
		held_packages = deep_get(setup_control_plane_targets, DictPath("localhost#deb_packages_held"), [])
	elif os_distro in ("suse",):
		packages = deep_get(setup_control_plane_targets, DictPath("localhost#suse_packages"), [])
		held_packages = deep_get(setup_control_plane_targets, DictPath("localhost#suse_packages_held"), [])
	elif os_distro in ("fedora", "rhel",):
		packages = deep_get(setup_control_plane_targets, DictPath("localhost#fedora_packages"), [])
		held_packages = deep_get(setup_control_plane_targets, DictPath("localhost#fedora_packages_held"), [])

	extra_values = {
		"cluster_name": cluster_name,
		"pod_network_cidr": pod_network_cidr,
		"packages": packages,
		"held_packages": held_packages,
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values, verbose = verbose)

def __task_run_setup_playbooks_on_control_planes(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that runs playbooks on control planes

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	cluster_name = installation_info["installation_target"]
	k8s_distro = installation_info[cluster_name]["distro"]
	os_distro = identify_distro()
	pod_network_cidr = installation_info[cluster_name]["pod_network_cidr"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(cast(List[FilePath], setup_control_plane_targets[k8s_distro]["playbooks"]))
	cri = installation_info[cluster_name]["cri"]
	cri_socket = deep_get(cri_data[cri], DictPath("socket"))
	extra_values_setup = deep_get(setup_control_plane_targets[k8s_distro], DictPath("extra_values"), {})

	if os_distro in ("debian",):
		packages = deep_get(setup_control_plane_targets, DictPath(f"{k8s_distro}#deb_packages"), [])
		held_packages = deep_get(setup_control_plane_targets, DictPath(f"{k8s_distro}#deb_packages_held"), [])
	elif os_distro in ("suse",):
		packages = deep_get(setup_control_plane_targets, DictPath(f"{k8s_distro}#suse_packages"), [])
		held_packages = deep_get(setup_control_plane_targets, DictPath(f"{k8s_distro}#suse_packages_held"), [])
	elif os_distro in ("fedora", "rhel",):
		packages = deep_get(setup_control_plane_targets, DictPath(f"{k8s_distro}#fedora_packages"), [])
		held_packages = deep_get(setup_control_plane_targets, DictPath(f"{k8s_distro}#fedora_packages_held"), [])

	if k8s_distro == "rke2":
		cri_socket = cri_socket[len("unix://"):]

	extra_values = {
		"cluster_name": cluster_name,
		"pod_network_cidr": pod_network_cidr,
		"cri_socket": cri_socket,
		"packages": packages,
		"held_packages": held_packages,
		**extra_values_setup,
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values, verbose = verbose)

# pylint: disable-next=unused-argument
def __task_run_postsetup_playbooks(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that runs post-setup playbooks

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	# The default selection is control planes; the playbooks need to explicitly specify if the play should be run on other hosts
	selection = __selection_control_planes()
	__generic_task_run_playbooks_on_selection(selection = selection, installation_info = installation_info, playbook_dir = [CMT_POST_SETUP_DIR], extra_values = {}, verbose = verbose)

# pylint: disable-next=unused-argument
def __task_import_kubeconfig(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that merges a Kube config into ~/.kube/config

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	cluster_name = installation_info["installation_target"]
	config_file_name = FilePath(f"{HOMEDIR}/.kube/config.{cluster_name}")
	admin_name = f"kubernetes-admin+{cluster_name}"
	context_name = f"{admin_name}@{cluster_name}"

	# This read must not fail, so no exceptions
	d2 = secure_read_yaml(config_file_name)

	# This file will not exist if this is the first cluster
	security_checks = [
		SecurityChecks.PARENT_RESOLVES_TO_SELF,
		SecurityChecks.OWNER_IN_ALLOWLIST,
		SecurityChecks.PARENT_OWNER_IN_ALLOWLIST,
		SecurityChecks.PERMISSIONS,
		SecurityChecks.PARENT_PERMISSIONS,
		SecurityChecks.IS_FILE,
	]

	try:
		d1 = secure_read_yaml(KUBE_CONFIG_FILE, checks = security_checks)
	except FileNotFoundError:
		d1 = dict(d2)
		# We will be renaming things anyway, so instead of using a lot of special casing below we just empty
		# these fields
		d1["clusters"] = []
		d1["contexts"] = []
		d1["current-context"] = context_name
		d1["users"] = []

	for cluster in d1["clusters"]:
		if cluster_name == cluster["name"]:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": A cluster named ", "default"),
					ANSIThemeString(cluster_name, "hostname"),
					ANSIThemeString(" already exists in ", "default"),
					ANSIThemeString(f"{HOMEDIR}/.kube/config", "path"),
					ANSIThemeString("; manual merge is necessary.", "default")], stderr = True)
			return

	for user in d1["users"]:
		if admin_name == user["name"]:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": A user named ", "default"),
					ANSIThemeString(admin_name, "hostname"),
					ANSIThemeString(" already exists in ", "default"),
					ANSIThemeString(f"{HOMEDIR}/.kube/config", "path"),
					ANSIThemeString("; manual merge is necessary.", "default")], stderr = True)
			return

	for context in d1["contexts"]:
		if context_name == context["name"]:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": A context named ", "default"),
					ANSIThemeString(context_name, "hostname"),
					ANSIThemeString(" already exists in ", "default"),
					ANSIThemeString(f"{HOMEDIR}/.kube/config", "path"),
					ANSIThemeString("; manual merge is necessary.", "default")], stderr = True)
			return

	cad = d2["clusters"][0]["cluster"].get("certificate-authority-data")
	server = d2["clusters"][0]["cluster"]["server"]

	insecure_skip_tls_verify = d2["clusters"][0]["cluster"].get("insecure-skip-tls-verify")
	cluster = {
		"cluster": {
			"server": server,
		},
		"name": cluster_name,
	}
	if cad is not None:
		cluster["cluster"]["certificate-authority-data"] = cad
	if insecure_skip_tls_verify is not None:
		cluster["cluster"]["insecure-skip-tls-verify"] = insecure_skip_tls_verify

	d1["clusters"].append(cluster)

	context = {
		"context": {
			"cluster": cluster_name,
			"user": admin_name,
		},
		"name": context_name,
	}
	d1["contexts"].append(context)

	ccd = d2["users"][0]["user"].get("client-certificate-data")
	ckd = d2["users"][0]["user"].get("client-key-data")
	token = d2["users"][0]["user"].get("token")
	user = {
		"user": {
		},
		"name": admin_name,
	}
	if ccd is not None:
		user["user"]["client-certificate-data"] = ccd
	if ckd is not None:
		user["user"]["client-key-data"] = ckd
	if token is not None:
		user["user"]["token"] = token

	d1["users"].append(user)

	secure_write_yaml(KUBE_CONFIG_FILE, d1, permissions = 0o600, sort_keys = False)

	check_and_print_status(True)

# pylint: disable-next=unused-argument
def __task_adjust_kubeconfig_server_address(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that replaces localhost for the real IP-address of the API-server

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	control_plane_name = __selection_control_planes()[0]
	cluster_name = installation_info["installation_target"]

	try:
		d = secure_read_yaml(KUBE_CONFIG_FILE)
	except FileNotFoundError:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Could not open ", "default"),
				ANSIThemeString(f"{KUBE_CONFIG_FILE}", "path"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	for i, cluster in enumerate(deep_get(d, DictPath("clusters"), [])):
		if deep_get(cluster, DictPath("name"), "") == cluster_name:
			# Is this cluster a localhost?
			server = deep_get(cluster, DictPath("cluster#server"), "")
			if server.startswith("https://127") or server == "::1":
				tmp = re.match(r"^(https://)([^:]+)(:.*)", server)
				if tmp is None:
					ansithemeprint([ANSIThemeString("Error", "error"),
							ANSIThemeString(": Failed to extract server address.", "default")])
					ansithemeprint([ANSIThemeString("This is probably a programming error", "default"),
							ANSIThemeString("; aborting.", "default")], stderr = True)
					sys.exit(errno.EINVAL)

				prefix = tmp[1]
				server_address = tmp[2]
				server_port_and_path = tmp[3]

				# Try to figure out the internal IP of the control plane;
				# this only works if we're running this on the control plane;
				# we should probably do this while fetching the config-file instead
				from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
				kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

				obj = kh.get_ref_by_kind_name_namespace(("Node", ""), control_plane_name, "")
				if obj is None:
					ansithemeprint([ANSIThemeString("Error", "error"),
							ANSIThemeString(": Could not find control plane ", "default"),
							ANSIThemeString(f"{control_plane_name}", "hostname"),
							ANSIThemeString("; aborting.", "default")], stderr = True)
					sys.exit(errno.ENOENT)
				addresses = deep_get(obj, DictPath("status#addresses"), [])
				internal_ip = None
				for address in addresses:
					address_type = deep_get(address, DictPath("type"), "")
					if address_type == "InternalIP":
						internal_ip = deep_get(address, DictPath("address"), "")
						break
				if internal_ip is not None and len(internal_ip) > 0 and internal_ip != server_address:
					d["clusters"][i]["cluster"]["server"] = f"{prefix}{internal_ip}{server_port_and_path}"

	secure_write_yaml(KUBE_CONFIG_FILE, d, permissions = 0o600, sort_keys = False)

# pylint: disable-next=unused-argument
def __task_setup_cni(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that sets up a CNI

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	cluster_name = installation_info["installation_target"]
	cni = installation_info[cluster_name]["cni"]
	admin_name = f"kubernetes-admin+{cluster_name}"
	context_name = f"{admin_name}@{cluster_name}"

	# If everything is successful so far we deploy the pod network
	__setup_cni(cni, context_name, cluster_name)

# pylint: disable-next=unused-argument
def __task_drain_control_planes(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that drains control plains

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	controlplanes = __selection_control_planes()

	# Check if there is an API-server running that will listen to our request;
	# drain is issued during teardown--so if we are resuming a teardown the cluster
	# might already be partially deconfigured
	# XXX: This should be done on the control plane(s), not on localhost
	args = ["/usr/bin/sudo", "/usr/bin/lsof", "-i", "-P", "-n"]
	response = execute_command_with_response(args)
	running = False
	for line in response.splitlines():
		if "6443 (LISTEN)" in line:
			running = True
			break
	if not running:
		check_and_print_status(True)
		return

	kubectl_major_version, kubectl_minor_version, _kubectl_git_version, _server_major_version, _server_minor_version, _server_git_version = kubernetes_helper.kubectl_get_version()
	if kubectl_major_version is None or kubectl_minor_version is None:
		ansithemeprint([ANSIThemeString("Critical", "critical"),
				ANSIThemeString(": Could not extract ", "default"),
				ANSIThemeString("kubectl", "programname"),
				ANSIThemeString(" version; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	# Build the drain command line based on what version of kubectl is installed
	args = ["/usr/bin/kubectl", "drain", "--ignore-daemonsets"]
	if kubectl_major_version >= 1 and kubectl_minor_version >= 20:
		args.append("--delete-emptydir-data")
	else:
		args.append("--delete-local-data")
	if kubectl_major_version >= 1 and kubectl_minor_version >= 18:
		args.append("--disable-eviction")

	for controlplane in controlplanes:
		check_and_print_status(execute_command(args + [controlplane]))

# pylint: disable-next=unused-argument
def __task_uncordon_control_planes(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that uncordons control planes

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	controlplanes = __selection_control_planes()

	from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
	kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

	for controlplane in controlplanes:
		ansithemeprint([ANSIThemeString(f"  {controlplane}:", "hostname")])
		message, status = kh.uncordon_node(controlplane)
		if status in (200, 204):
			ansithemeprint([ANSIThemeString("    Uncordoned", "success")])
			print(message)
		elif status == 42503:
			ansithemeprint([ANSIThemeString("\n  ", "default"),
					ANSIThemeString("Critical", "critical"),
					ANSIThemeString(": Cluster not available; aborting", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		else:
			ansithemeprint([ANSIThemeString("\n  ", "default"),
					ANSIThemeString("Critical", "critical"),
					ANSIThemeString(": API call returned error:", "default")], stderr = True)
			ansithemeprint([ANSIThemeString(f"    {message}", "error")], stderr = True)
			sys.exit(errno.EINVAL)

# pylint: disable-next=unused-argument
def __task_run_preupgrade_playbooks(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that runs pre-upgrade playbooks

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	# The default selection is control planes; the playbooks need to explicitly specify if the play should be run on other hosts
	selection = __selection_control_planes()
	__generic_task_run_playbooks_on_selection(selection = selection, installation_info = installation_info, playbook_dir = [CMT_PRE_UPGRADE_DIR], extra_values = {}, verbose = verbose)

# Run upgrade playbooks on control planes
def __task_run_upgrade_playbooks_on_control_planes(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that runs upgrade playbooks on control planes

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	cluster_name = installation_info["installation_target"]
	k8s_distro = installation_info[cluster_name]["distro"]
	os_distro = identify_distro()
	pod_network_cidr = installation_info[cluster_name]["pod_network_cidr"]
	requested_version = installation_info[cluster_name]["requested_version"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(cast(List[FilePath], upgrade_control_plane_targets[k8s_distro]["playbooks"]))
	cri = installation_info[cluster_name]["cri"]
	cri_socket = deep_get(cri_data[cri], DictPath("socket"))
	extra_values_upgrade = deep_get(upgrade_control_plane_targets[k8s_distro], DictPath("extra_values"), {})

	if os_distro in ("debian",):
		packages = deep_get(upgrade_control_plane_targets, DictPath(f"{k8s_distro}#deb_packages"), [])
		held_packages = deep_get(upgrade_control_plane_targets, DictPath(f"{k8s_distro}#deb_packages_held"), [])
	elif os_distro in ("suse",):
		packages = deep_get(upgrade_control_plane_targets, DictPath(f"{k8s_distro}#suse_packages"), [])
		held_packages = deep_get(upgrade_control_plane_targets, DictPath(f"{k8s_distro}#suse_packages_held"), [])
	elif os_distro in ("fedora", "rhel",):
		packages = deep_get(upgrade_control_plane_targets, DictPath(f"{k8s_distro}#fedora_packages"), [])
		held_packages = deep_get(upgrade_control_plane_targets, DictPath(f"{k8s_distro}#fedora_packages_held"), [])

	extra_values = {
		"cluster_name": cluster_name,
		"pod_network_cidr": pod_network_cidr,
		"cri_socket": cri_socket,
		"packages": packages,
		"held_packages": held_packages,
		"requested_control_plane_k8s_version": requested_version,
		**extra_values_upgrade,
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values, verbose = verbose)

# pylint: disable-next=unused-argument
def __task_run_postupgrade_playbooks(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that runs post-upgrade playbooks

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	# The default selection is control planes; the playbooks need to explicitly specify if the play should be run on other hosts
	selection = __selection_control_planes()
	__generic_task_run_playbooks_on_selection(selection = selection, installation_info = installation_info, playbook_dir = [CMT_POST_UPGRADE_DIR], extra_values = {}, verbose = verbose)

# pylint: disable-next=unused-argument
def __task_verify_that_cluster_has_no_nodes(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that verifies that no non-control plane nodes remain in the cluster

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
	"""

	node_statuses, _kh = __get_node_info()

	if node_statuses is not None:
		for node in node_statuses:
			if "control-plane" not in node["roles"]:
				ansithemeprint([ANSIThemeString("\nPlease delete all nodes (except the ", "warning"),
						ANSIThemeString("control plane", "emphasis"),
						ANSIThemeString(") from the cluster before attempting a teardown.", "warning")])
				sys.exit(errno.EAGAIN)

	ansithemeprint([ANSIThemeString("OK", "ok")])

# pylint: disable-next=unused-argument
def __task_run_preteardown_playbooks(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that runs pre-teardown playbooks

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	# The default selection is control planes; the playbooks need to explicitly specify if the play should be run on other hosts
	selection = __selection_control_planes()
	__generic_task_run_playbooks_on_selection(selection = selection, installation_info = installation_info, playbook_dir = [CMT_PRE_TEARDOWN_DIR], extra_values = {}, verbose = verbose)

# Run teardown playbooks on control planes
def __task_run_teardown_playbooks_on_control_planes(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that runs teardown playbooks on control planes

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	cluster_name = installation_info["installation_target"]
	k8s_distro = installation_info[cluster_name]["distro"]
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(cast(List[FilePath], teardown_control_plane_targets[k8s_distro]["playbooks"]))

	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = {}, verbose = verbose)

# pylint: disable-next=unused-argument
def __task_run_postteardown_playbooks(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that runs post-teardown playbooks

		Parameters:
			installation_info (dict): A dict with installation information (Unused)
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	# The default selection is control planes; the playbooks need to explicitly specify if the play should be run on other hosts
	selection = __selection_control_planes()
	__generic_task_run_playbooks_on_selection(selection = selection, installation_info = installation_info, playbook_dir = [CMT_POST_TEARDOWN_DIR], extra_values = {}, verbose = verbose)

# pylint: disable-next=unused-argument
def __task_remove_kubeconfig(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that removes a cluster configuration from ~/.kube/config

		Parameters:
			installation_info (dict): A dict with installation information
	"""

	if not Path(KUBE_CONFIG_DIR).is_dir():
		check_and_print_status(True)
		return

	cluster_name = installation_info["installation_target"]
	admin_name = f"kubernetes-admin+{cluster_name}"
	context_name = f"{admin_name}@{cluster_name}"
	d1 = None

	if os.path.exists(f"{HOMEDIR}/.kube/config.{cluster_name}"):
		os.remove(f"{HOMEDIR}/.kube/config.{cluster_name}")
	if os.path.exists(f"{HOMEDIR}/.kube/token.{cluster_name}"):
		os.remove(f"{HOMEDIR}/.kube/token.{cluster_name}")
	if os.path.exists(f"{HOMEDIR}/.kube/rke2.config.{cluster_name}.yaml"):
		os.remove(f"{HOMEDIR}/.kube/rke2.config.{cluster_name}.yaml")

	try:
		d1 = secure_read_yaml(KUBE_CONFIG_FILE)

		# This is not perfect--there might be leftover users and contexts belonging to this cluster;
		# but we better not go on a killing spree--better leave cruft behind than remove everything.
		for i in range(0, len(d1["clusters"])):
			if d1["clusters"][i].get("name") == cluster_name:
				d1["clusters"].pop(i)
				break
		for i in range(0, len(d1["users"])):
			if d1["users"][i].get("name") == admin_name:
				d1["users"].pop(i)
				break
		for i in range(0, len(d1["contexts"])):
			if d1["contexts"][i].get("name") == context_name:
				d1["contexts"].pop(i)
				break
	except FileNotFoundError:
		pass

	# If there's no cluster left, remove the config completely
	if d1 is None or len(d1["clusters"]) == 0:
		secure_rm(KUBE_CONFIG_FILE, ignore_non_existing = True)

		_dir = os.listdir(f"{HOMEDIR}/.kube")
		try:
			_dir.remove("cache")
		except ValueError:
			pass
		try:
			_dir.remove("http-cache")
		except ValueError:
			pass

		# If there's nothing else than the cache subdirectories in .kube, remove .kube too
		if len(_dir) == 0:
			shutil.rmtree(f"{HOMEDIR}/.kube")
	else:
		# Set the context to the first remaining context, if any
		if len(d1["contexts"]) > 0:
			d1["current-context"] = d1["contexts"][0]["name"]

		secure_write_yaml(KUBE_CONFIG_FILE, d1, permissions = 0o600, sort_keys = False)

	check_and_print_status(True)

# pylint: disable-next=unused-argument
def __task_run_prepurge_playbooks(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that runs pre-purge playbooks

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	# The default selection is control planes; the playbooks need to explicitly specify if the play should be run on other hosts
	selection = __selection_control_planes()
	__generic_task_run_playbooks_on_selection(selection = selection, installation_info = installation_info, playbook_dir = [CMT_PRE_PURGE_DIR], extra_values = {}, verbose = verbose)

# Run purge playbooks on control planes
def __task_run_purge_playbooks_on_control_planes(installation_info: Dict, verbose: bool = False) -> None:
	"""
	An installer task that runs purge playbooks on control planes

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	cluster_name = installation_info["installation_target"]
	k8s_distro = installation_info[cluster_name]["distro"]
	os_distro = identify_distro()
	selection = __selection_control_planes()
	playbooks = populate_playbooks_from_paths(cast(List[FilePath], purge_control_plane_targets[k8s_distro]["playbooks"]))

	if os_distro in ("debian",):
		packages = deep_get(purge_control_plane_targets, DictPath(f"{k8s_distro}#deb_packages"), [])
		held_packages = deep_get(purge_control_plane_targets, DictPath(f"{k8s_distro}#deb_packages_held"), [])
	elif os_distro in ("suse",):
		packages = deep_get(purge_control_plane_targets, DictPath(f"{k8s_distro}#suse_packages"), [])
		held_packages = deep_get(purge_control_plane_targets, DictPath(f"{k8s_distro}#suse_packages_held"), [])
	elif os_distro in ("fedora", "rhel",):
		packages = deep_get(purge_control_plane_targets, DictPath(f"{k8s_distro}#fedora_packages"), [])
		held_packages = deep_get(purge_control_plane_targets, DictPath(f"{k8s_distro}#fedora_packages_held"), [])

	extra_values = {
		"packages": packages,
		"held_packages": held_packages,
	}
	__run_playbooks_on_selection(playbooks = playbooks, selection = selection, extra_values = extra_values, verbose = verbose)

# pylint: disable-next=unused-argument
def __task_run_postpurge_playbooks(installation_info: Dict, verbose: bool = False) -> None:
	"""
	A task that runs post-purge playbooks

		Parameters:
			installation_info (dict): A dict with installation information
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	# The default selection is control planes; the playbooks need to explicitly specify if the play should be run on other hosts
	selection = __selection_control_planes()
	__generic_task_run_playbooks_on_selection(selection = selection, installation_info = installation_info, playbook_dir = [CMT_POST_PURGE_DIR], extra_values = {}, verbose = verbose)

def __validate_task_index(tasks: List[Tuple[List[ANSIThemeString], Callable[..., None]]], phase: Union[str, int]) -> int:
	"""
	Helper that validates the installer task index
		Parameters:
			tasks (list[tasks]): A list of tasks
			phase (int): An integer index
		Returns:
			phase (int): The integer index on success; exits if the task is out of range
	"""

	try:
		phase = int(phase)
	except ValueError as e:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString("TASK", "argument"),
				ANSIThemeString(f" needs to be an integer index in the range [0, {len(tasks) - 1}]. Aborting.", "default")], stderr = True)
		sys.exit(f"Exception: {e}")

	if phase < 0 or phase >= len(tasks):
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString("TASK", "argument"),
				ANSIThemeString(f" needs to be in the range [0, {len(tasks) - 1}]. Aborting.", "default")], stderr = True)
		sys.exit(errno.ERANGE)
	return phase

def __list_phases(phases: List[Tuple[List[ANSIThemeString], Callable[..., None]]],
		  start_phase: Optional[int] = 0, phase_skiplist: Optional[List] = None) -> None:
	"""
	Helper that lists installation phases
	"""

	if start_phase is None or start_phase == "<none>":
		start_phase = 0
	if phase_skiplist is None:
		phase_skiplist = []

	for i, phase in enumerate(phases):
		if i < start_phase or i in phase_skiplist:
			tmp = [ANSIThemeString(f"{str(i).rjust(2)}: ", "skip")]
			override_formatting = "skip"
		else:
			tmp = [ANSIThemeString(f"{str(i).rjust(2)}: ", "emphasis")]
			override_formatting = None
		tmp += themearray_override_formatting(phase[0], override_formatting)
		ansithemeprint(tmp)

def __expand_index_list(index_list: str) -> Set[int]:
	indexes = set()

	for index in index_list.split(","):
		try:
			if "-" in index:
				tmp_first, tmp_last = index.split("-")
				first = int(tmp_first)
				last = int(tmp_last)
			else:
				first = int(index)
				last = first
		except ValueError as e:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": ", "default"),
					ANSIThemeString(f"{index}", "argument"),
					ANSIThemeString(" is not an integer or range of integers. Aborting.", "default")], stderr = True)
			sys.exit(f"Exception: {e}")
		for i in range(first, last + 1):
			indexes.add(i)
	return indexes

def __format_none(string: Optional[str], fmt: str) -> ANSIThemeString:
	if string is None or string == "<none>":
		__string = ANSIThemeString("<none>", "none")
	else:
		__string = ANSIThemeString(string, fmt)
	return __string

prepare_tasks: List[Tuple[List[ANSIThemeString], Callable[..., None]]] = [
	([ANSIThemeString("Check for ssh host key and create if needed", "action")], __task_check_and_create_ssh_key),
	([ANSIThemeString("Add ssh keys for localhost, control plane(s) and nodes to ", "action"),
	  ANSIThemeString(f"{HOMEDIR}/.ssh/known_hosts", "path")], __task_scan_and_add_ssh_keys),
	([ANSIThemeString("Add public ssh keys to ", "action"),
	  ANSIThemeString(f"{HOMEDIR}/.ssh/authorized_keys", "path")], __task_check_and_add_ssh_keys_to_authorized_keys),
	([ANSIThemeString("Add public ssh keys to inventory", "action")], __task_add_ssh_keys_to_inventory),
	([ANSIThemeString("Request the ansible password if necessary", "action")], __task_request_ansible_password),
	([ANSIThemeString("Install ", "action"),
	  ANSIThemeString("ansible.posix", "programname"),
	  ANSIThemeString(" if necessary", "action")], __task_check_and_install_ansible_posix),
	([ANSIThemeString("Run pre-prepare playbooks", "action")], __task_run_prepreparation_playbooks),
	([ANSIThemeString("Run playbooks on ", "action"),
	  ANSIThemeString("localhost", "hostname")], __task_run_preparation_playbooks_on_localhost),
	([ANSIThemeString("Run playbooks on ", "action"),
	  ANSIThemeString("hosts", "hostname")], __task_run_preparation_playbooks_on_hosts),
	([ANSIThemeString("Run post-prepare playbooks", "action")], __task_run_postpreparation_playbooks),
]

__setup_kubeadm_control_plane_tasks: List[Tuple[List[ANSIThemeString], Callable[..., None]]] = [
	([ANSIThemeString("Run pre-setup playbooks", "action")], __task_run_presetup_playbooks),
	([ANSIThemeString("Run playbooks on ", "action"),
	  ANSIThemeString("localhost", "hostname")], __task_run_setup_playbooks_on_localhost),
	([ANSIThemeString("Setup ", "action"),
	  ANSIThemeString("bash completion", "emphasis"),
	  ANSIThemeString(" for ", "action"),
	  ANSIThemeString("kubectl", "programname")], __task_setup_bash_completion),
	([ANSIThemeString("Run playbooks on ", "action"),
	  ANSIThemeString("control planes", "hostname")], __task_run_setup_playbooks_on_control_planes),
	([ANSIThemeString("Import kubeconfig", "action")], __task_import_kubeconfig),
	([ANSIThemeString("Setup ", "action"),
	  ANSIThemeString("Container Network Interface (CNI)", "action")], __task_setup_cni),
	([ANSIThemeString("Run post-setup playbooks", "action")], __task_run_postsetup_playbooks),
]

__setup_rke2_control_plane_tasks: List[Tuple[List[ANSIThemeString], Callable[..., None]]] = [
	([ANSIThemeString("Run pre-setup playbooks", "action")], __task_run_presetup_playbooks),
	([ANSIThemeString("Run playbooks on ", "action"),
	  ANSIThemeString("localhost", "hostname")], __task_run_setup_playbooks_on_localhost),
	([ANSIThemeString("Setup ", "action"),
	  ANSIThemeString("bash completion", "emphasis"),
	  ANSIThemeString(" for ", "action"),
	  ANSIThemeString("kubectl", "programname")], __task_setup_bash_completion),
	([ANSIThemeString("Run playbooks on ", "action"),
	  ANSIThemeString("control planes", "hostname")], __task_run_setup_playbooks_on_control_planes),
	([ANSIThemeString("Import kubeconfig", "action")], __task_import_kubeconfig),
	([ANSIThemeString("Adjust kubeconfig server-address (if necessary)", "action")], __task_adjust_kubeconfig_server_address),
	([ANSIThemeString("Setup ", "action"),
	  ANSIThemeString("Container Network Interface (CNI)", "action")], __task_setup_cni),
	([ANSIThemeString("Run post-setup playbooks", "action")], __task_run_postsetup_playbooks),
]

setup_control_plane_tasks = __setup_kubeadm_control_plane_tasks

upgrade_control_plane_tasks: List[Tuple[List[ANSIThemeString], Callable[..., None]]] = [
	([ANSIThemeString("Drain the ", "action"),
	  ANSIThemeString("control planes", "hostname")], __task_drain_control_planes),
	([ANSIThemeString("Run pre-upgrade playbooks", "action")], __task_run_preupgrade_playbooks),
	([ANSIThemeString("Run upgrade playbooks on ", "action"),
	  ANSIThemeString("control planes", "hostname")], __task_run_upgrade_playbooks_on_control_planes),
	([ANSIThemeString("Run post-upgrade playbooks", "action")], __task_run_postupgrade_playbooks),
	([ANSIThemeString("Uncordon the ", "action"),
	  ANSIThemeString("control planes", "hostname")], __task_uncordon_control_planes),
]

teardown_control_plane_tasks: List[Tuple[List[ANSIThemeString], Callable[..., None]]] = [
	([ANSIThemeString("Verify that only ", "action"),
	  ANSIThemeString("control planes", "hostname"),
	  ANSIThemeString(" remain in the cluster", "action")], __task_verify_that_cluster_has_no_nodes),
	([ANSIThemeString("Drain the ", "action"),
	  ANSIThemeString("control planes", "hostname")], __task_drain_control_planes),
	([ANSIThemeString("Run pre-teardown playbooks", "action")], __task_run_preteardown_playbooks),
	([ANSIThemeString("Run teardown playbooks on ", "action"),
	  ANSIThemeString("control planes", "hostname")], __task_run_teardown_playbooks_on_control_planes),
	([ANSIThemeString("Remove kube config", "action")], __task_remove_kubeconfig),
	([ANSIThemeString("Run post-teardown playbooks", "action")], __task_run_postteardown_playbooks),
]

purge_control_plane_tasks: List[Tuple[List[ANSIThemeString], Callable[..., None]]] = [
	([ANSIThemeString("Run pre-purge playbooks", "action")], __task_run_prepurge_playbooks),
	([ANSIThemeString("Run purge playbooks on ", "action"),
	  ANSIThemeString("control planes", "hostname")], __task_run_purge_playbooks_on_control_planes),
	([ANSIThemeString("Run post-purge playbooks", "action")], __task_run_postpurge_playbooks),
]

def run_tasks(tasks: List[Tuple[List[ANSIThemeString], Callable[..., None]]],
	      phase: int, phase_skiplist: Set[int], final_state: str, verbose: bool = False) -> None:
	"""
	Run tasks

		Parameters:
			tasks list[(themestring, task)]: A list of tasks containing tuples of describing the task (in form of an ANSIThemeString) and a function reference
			phase (int): The installation phase
			phase_skiplist (set(phase)): A set of phases to skip
			final_state (str): The state to set if the task completes successfully
			verbose (bool): If the results are printed, should skipped tasks be printed too?
	"""

	installation_info = get_installation_info()

	if not isinstance(phase, int):
		phase = 0

	for i in range(phase, len(tasks)):
		ansithemeprint([ANSIThemeString("\n• ", "separator")] + tasks[i][0])
		if i not in set(phase_skiplist):
			tasks[i][1](installation_info, verbose = verbose)
		if i < len(tasks) - 1:
			installation_info = update_installation_info(phase = i)
		else:
			update_installation_info(state = final_state, phase = "<done>")

def __find_requested_version(k8s_distro: str, version: Optional[str] = None) -> str:
	"""
	Based on a provided version, try to find a matching package;
	Passing None will give the latest version, passing major, minor will give the latest patch revision of that version.
	Passing an exact version will give that version.

		Parameters:
			k8s_distro (str): Currently only kubeadm and rke2 are supported
			version (str): The requested version string or version substring
		Returns:
			requested_version (str): The best matching package version
	"""

	os_distro = identify_distro()

	requested_version = None

	if k8s_distro == "kubeadm":
		# If version is an exact match for a package version, use it.
		# If version is a match for a package version with the package revision ("-nn") removed, use the latest matching package revision.
		# If no version is specified, use the latest package revision.
		if os_distro in ("debian",):
			versions = check_versions_apt(["kubeadm"])
		elif os_distro in ("suse",):
			versions = check_versions_zypper([f"kubernetes{version}-kubeadm"])
		elif os_distro in ("fedora", "rhel",):
			versions = check_versions_yum(["kubeadm"])

		if len(versions) == 0:
			ansithemeprint([ANSIThemeString("Critical", "critical"),
					ANSIThemeString(": No candidate version for ", "default"),
					ANSIThemeString("kubeadm", "programname"),
					ANSIThemeString(" available; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		elif version is not None and version != "<none>":
			# The list is sorted in falling order, so the first match is the one we want, since that's the newest package revision.
			# We're only checking versions for kubeadm, so that's always gonna be entry 0 in the list.
			# field 3 is the list of available versions.
			for package_version in versions[0][3]:
				if package_version.split("-")[0] == version:
					requested_version = package_version
					break
				if package_version.split(".")[0] + "." + package_version.split(".")[1] == version:
					requested_version = package_version
					break
				if version.split(".")[0] == version and package_version.split(".")[0] == version:
					requested_version = package_version
					break
		else:
			# If no version was requested, we pick the candidate version
			requested_version = versions[0][2]
			if len(requested_version) == 0:
				requested_version = versions[0][1]

		if requested_version is None:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": Could not find a matching kubeadm package for version ", "default"),
					ANSIThemeString(f"{version}", "version"),
					ANSIThemeString("; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
	elif k8s_distro == "rke2":
		if version is None or version == "<none>":
			return "latest"

		# FIXME: we could fetch the channel file from upstream to get the version list, but for now we just accept any version
		tmp = re.match(r"^v?(\d+\.\d+).*", version)
		if tmp is not None:
			requested_version = tmp[1]
	else:
		raise ValueError(f"No support for distro {k8s_distro} implemented")

	if k8s_distro == "kubeadm":
		# First remove the distro revision
		major_minor_patchrev = requested_version.split("-")
		# Now split the version tuple
		_major, minor, _patchrev = major_minor_patchrev[0].split(".")
	else:
		# Split the version tuple
		_major, minor = requested_version.split(".")
		requested_version = f"v{requested_version}"

	if int(minor) < 15:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Kubernetes versions older than ", "default"),
				ANSIThemeString("1.15", "version"),
				ANSIThemeString(" are not supported by ", "default"),
				ANSIThemeString(f"{about.PROGRAM_SUITE_NAME}", "programname"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)
	elif int(minor) < 18:
		ansithemeprint([ANSIThemeString("Warning", "warning"),
				ANSIThemeString(": Kubernetes versions older than ", "default"),
				ANSIThemeString("1.18", "version"),
				ANSIThemeString(" are not fully supported by ", "default"),
				ANSIThemeString(f"{about.PROGRAM_SUITE_NAME}", "programname"),
				ANSIThemeString(". Some features may be missing or completely broken.", "default")], stderr = True)
	elif int(minor) < 21 and k8s_distro == "rke2":
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": RKE2 versions older than ", "default"),
				ANSIThemeString("1.21", "version"),
				ANSIThemeString(" are not supported by ", "default"),
				ANSIThemeString(f"{about.PROGRAM_SUITE_NAME}", "programname"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	return requested_version

def prepare_installation(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Install and configure pre-requisites for a control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	global no_password  # pylint: disable=global-statement
	confirm = True

	# We do not need a cluster name for --list-tasks, so check this first of all
	if "--list-tasks" in (tmp[0] for tmp in options):
		__list_phases(prepare_tasks)
		sys.exit(0)
	elif len(args) == 0:
		ansithemeprint([ANSIThemeString(f"{about.ADMIN_PROGRAM_NAME}", "programname"),
				ANSIThemeString(": “", "default"),
				ANSIThemeString("prepare", "command"),
				ANSIThemeString("“ requires at least 1 arguments.", "default")], stderr = True)
		ansithemeprint([ANSIThemeString("Try “", "default"),
				ANSIThemeString(f"{about.ADMIN_PROGRAM_NAME} ", "programname"),
				ANSIThemeString("help", "command"),
				ANSIThemeString("“ for more information.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	# Always require the user to specify the name of the cluster to operate against, even when resuming prepare;
	# this avoids a lot of hairy corner-cases and attempts to figure out what cluster the user intended to operate against
	cluster_name = args[0]

	installation_info = get_installation_info(cluster_name = cluster_name)
	k8s_distro = "kubeadm"
	os_distro = identify_distro()
	requested_version = installation_info[cluster_name]["requested_version"]
	state = installation_info[cluster_name]["state"]
	phase: Union[str, int] = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])
	verbose = False
	hide_next_step = False
	nodes = []

	if state is not None and state not in ("<none>", "preparing", "prepared", "torn_down"):
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Invalid installation state; the system cannot be in a configured or semi-configured state when running prepare; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	# The user has restarted preparation
	if phase == "<done>" and state == "preparing":
		phase = 0

	if phase == "<none>" or state in ("prepared", "torn_down") and phase == "<done>":
		phase = 0
		requested_version = None

	hostname = socket.gethostname()

	# default options
	installation_info = update_installation_info(cluster_name = cluster_name, distro = k8s_distro, state = "preparing", phase = phase)

	__controlplanes = get_control_planes(fail_on_empty = False)
	controlplanes = [controlplane[0] for controlplane in __controlplanes]
	if len(controlplanes) == 0 and "--control-plane" not in (tmp[0] for tmp in options):
		retval = ansithemeinput([ANSIThemeString("\nWarning", "warning"),
					 ANSIThemeString(": No control plane defined in the inventory; do you want to add ", "default"),
					 ANSIThemeString(f"{hostname}", "hostname"),
					 ANSIThemeString(" as control plane? (No will abort the installation) [y/", "default"),
					 ANSIThemeString("N", "emphasis"),
					 ANSIThemeString("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			ansithemeprint([ANSIThemeString("\nAborting:", "error"),
					ANSIThemeString(" No available control plane in inventory.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [hostname], group = "controlplane", skip_all = False)
		ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [hostname], group = cluster_name, skip_all = True)

	for opt, optarg in options:
		if opt == "--control-plane":
			ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [optarg], group = "controlplane", skip_all = False)
			ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = [optarg], group = cluster_name, skip_all = True)
		elif opt == "--no-password":
			no_password = True
		elif opt == "--start-at-task":
			phase = __validate_task_index(prepare_tasks, optarg)
			if "--skip-tasks" not in options:
				phase_skiplist = set()
			if phase == 0:
				requested_version = None
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(prepare_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				ansithemeprint([ANSIThemeString("Warning", "warning"),
						ANSIThemeString(": Ignoring request to resume a completed preparation. Exiting.", "default")], stderr = True)
				sys.exit(0)
			phase = __validate_task_index(prepare_tasks, phase)
		elif opt == "--hide-next-step":
			hide_next_step = True
		elif opt == "--nodes":
			nodes = optarg
		elif opt == "--verbose":
			verbose = True
		elif opt == "--save-ansible-logs":
			ansible_configuration["save_logs"] = True
		elif opt == "-Y":
			confirm = False

	installation_info = update_installation_info(cluster_name = cluster_name, control_planes = controlplanes, nodes = nodes)

	if len(args) > 1:
		requested_version = args[1]

		if requested_version in ("kubeadm", "rke2"):
			k8s_distro = requested_version
			requested_version = None
		elif "=" in requested_version:
			k8s_distro, requested_version = requested_version.split("=")
			if k8s_distro not in ("kubeadm", "rke2"):
				ansithemeprint([ANSIThemeString(f"{about.ADMIN_PROGRAM_NAME}", "programname"),
						ANSIThemeString(": “", "default"),
						ANSIThemeString(f"{k8s_distro}", "option"),
						ANSIThemeString("“ is not a supported Kubernetes distribution.", "default")], stderr = True)
				sys.exit(errno.EINVAL)

	if requested_version is not None and requested_version in ("<none>", ""):
		requested_version = None

	if requested_version is None and os_distro == "suse":
		ansithemeprint([ANSIThemeString("\n• ", "separator"),
				ANSIThemeString("Updating version cache", "action")])

		# The first patch revision that isn't available from the old repositories is 1.28.3;
		# this means that we need to include all minor versions from 28 and up.
		if (kubernetes_upstream_version := get_latest_kubernetes_upstream_version()) is None:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": Could not get the latest upstream Kubernetes version; ", "default"),
					ANSIThemeString("this is either a network error or a bug; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOENT)

		# Split the version tuple
		upstream_major, upstream_minor, _rest = kubernetes_upstream_version.split(".")
		requested_version = f"{upstream_major}.{upstream_minor}"

	installation_info = update_installation_info(cluster_name = cluster_name, distro = k8s_distro, phase = phase, phase_skiplist = list(phase_skiplist), requested_version = requested_version)

	show_configuration(action = "Preparing cluster:", tasks = prepare_tasks)

	if confirm:
		retval = ansithemeinput([ANSIThemeString("\nStart control plane preparation? [y/", "default"),
					 ANSIThemeString("N", "emphasis"),
					 ANSIThemeString("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			ansithemeprint([ANSIThemeString("\nAborting:", "error"),
					ANSIThemeString(" User stopped control plane preparation.", "default")], stderr = True)
			os.remove(CMT_INSTALLATION_INFO_FILE)
			sys.exit(errno.EINTR)

	ansithemeprint([ANSIThemeString("\n[Preparing localhost and control plane(s)]", "phase")])

	check_and_print_status(update_version_cache())

	run_tasks(tasks = prepare_tasks, phase = cast(int, phase), phase_skiplist = phase_skiplist, final_state = "prepared", verbose = verbose)

	# Adjust the kube* packages for the control plane(s) and localhost to match the requested cluster version if necessary;
	# we could not do this before since the apt repository was not available then
	if requested_version is not None:
		requested_version = __find_requested_version(k8s_distro, requested_version)
	else:
		requested_version = __find_requested_version(k8s_distro)

	ansithemeprint([ANSIThemeString("\n• ", "separator"),
			ANSIThemeString("Updating installation information", "action")])

	update_installation_info(requested_version = requested_version)

	ansithemeprint([ANSIThemeString("   Requested version: ", "action"),
			ANSIThemeString(requested_version, "version")])

	ansithemeprint([ANSIThemeString("\nControl plane preparation successful", "success")])

	if not hide_next_step:
		print("\nNext step:")
		ansithemeprint([ANSIThemeString("• ", "separator"),
				ANSIThemeString(f"{about.ADMIN_PROGRAM_NAME}", "programname"),
				ANSIThemeString(" setup-control-plane ", "command"),
				ANSIThemeString("[", "separator"),
				ANSIThemeString("CNI", "argument"),
				ANSIThemeString("]", "separator"),
				ANSIThemeString(" [", "separator"),
				ANSIThemeString("POD_NETWORK_CIDR", "argument"),
				ANSIThemeString("]", "separator")])
		ansithemeprint([ANSIThemeString("\nSee “", "separator"),
				ANSIThemeString(f"{about.ADMIN_PROGRAM_NAME}", "programname"),
				ANSIThemeString(" help", "command"),
				ANSIThemeString("“ for more information about valid ", "default"),
				ANSIThemeString("CNI", "argument"),
				ANSIThemeString(" options.\n", "default")])

def import_cluster(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Import an existing cluster to the CMT Ansible inventory

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	global no_password  # pylint: disable=global-statement

	# default options
	confirm = True

	for opt, _optarg in options:
		if opt == "-Y":
			confirm = False
		elif opt == "--no-password":
			no_password = True

	from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
	kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)
	clusters = kh.list_clusters()
	available_clusters = [tmp[0] for tmp in clusters]

	pad = len("Cluster:")
	match = False
	for cluster_name, context in clusters:
		if len(args) > 0 and cluster_name not in args[0].split(","):
			continue
		pad = max(len(cluster_name), pad)
		match = True

	if len(args) > 0:
		for cluster in args[0].split(","):
			if cluster not in available_clusters and match:
				ansithemeprint([ANSIThemeString("Warning", "warning"),
						ANSIThemeString(": Ignoring non-existing cluster ", "default"),
						ANSIThemeString(cluster, "hostname"),
						ANSIThemeString("\n", "default")], stderr = True)

	if not match:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": No matching clusters found; available clusters are:", "default")], stderr = True)
		for cluster in available_clusters:
			ansithemeprint([ANSIThemeString("• ", "separator"),
					ANSIThemeString(cluster, "hostname")])
		ansithemeprint([ANSIThemeString("\nAborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	ansithemeprint([ANSIThemeString("Cluster:", "header"),
			ANSIThemeString("".ljust(pad + 2 - len("Cluster:")), "default"),
			ANSIThemeString("Context:", "header")])
	for cluster_name, context in clusters:
		if len(args) > 0 and cluster_name not in args[0]:
			continue
		ansithemeprint([ANSIThemeString(cluster_name, "hostname"),
				ANSIThemeString("".ljust(pad + 2 - len(cluster_name)), "default"),
				ANSIThemeString(context, "default")])

	if confirm:
		input_retval = ansithemeinput([ANSIThemeString("\nImport the following clusters? [y/", "default"),
					       ANSIThemeString("N", "emphasis"),
					       ANSIThemeString("]: ", "default")])

		if input_retval.lower() not in ("y", "yes"):
			ansithemeprint([ANSIThemeString("\nAborting:", "error"),
					ANSIThemeString(" User stopped cluster import.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	ansithemeprint([ANSIThemeString("\n[Importing cluster(s)]", "phase")])

	# Since the clusters might use different versions of Kubernetes
	# we always install the latest kubectl on localhost, so no need to adjust version

	contexts = kh.list_contexts()
	current_context = None
	for ctx in contexts:
		if ctx[0]:
			current_context = ctx[1]

	for cluster_name, context in clusters:
		if len(args) > 0 and cluster_name not in args[0]:
			continue

		if not kh.set_context(name = context, unchanged_is_success = True):
			ansithemeprint([ANSIThemeString("Warning", "warning"),
					ANSIThemeString(": Failed to change to context ", "default"),
					ANSIThemeString(f"{context}", "hostname"),
					ANSIThemeString(" for cluster ", "default"),
					ANSIThemeString(f"{cluster_name}", "hostname"),
					ANSIThemeString("; skipping.", "default")])
			continue

		vlist, status = kh.get_list_by_kind_namespace(("Node", ""), "")
		if status != 200:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": API-server returned ", "default"),
					ANSIThemeString(f"{status}", "errorvalue"),
					ANSIThemeString("; aborting.", "default")], stderr = True)
			sys.exit(errno.EINVAL)
		if vlist is None:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": API-server did not return any data", "default")], stderr = True)
			sys.exit(errno.EINVAL)

		controlplanes = []
		nodes = []
		controlplane = None

		for node in vlist:
			node_name = deep_get(node, DictPath("metadata#name"))
			node_roles = kh.get_node_roles(cast(Dict, node))
			if "control-plane" in node_roles:
				controlplanes.append(node_name)
				if controlplane is None:
					controlplane = node_name
			else:
				nodes.append(node_name)

		if controlplane is None:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": Could not find a control plane for the cluster ", "default"),
					ANSIThemeString(cluster_name, "hostname"),
					ANSIThemeString("; aborting.", "default")], stderr = True)
			# Remember to restore current-context
			kh.set_context(name = current_context)
			sys.exit(errno.ENOENT)

		__task_request_ansible_password(installation_info = {})

		extra_values = {
			"ansible_become_pass": deep_get(ansible_configuration, DictPath("ansible_password")),
			"ansible_ssh_pass": deep_get(ansible_configuration, DictPath("ansible_password")),
		}

		install_ansible_posix()

		retval, ansible_results = run_playbook(FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("prepare_passwordless_ansible.yaml"))),
						       hosts = [controlplane], extra_values = extra_values, quiet = True)
		if retval != 0:
			break

		tmp_cni = kh.identify_cni()
		if len(tmp_cni) != 1:
			cni = "<unknown>"
		else:
			cni = tmp_cni[0][0]

		pod_network_cidr = kh.get_pod_network_cidr()
		if pod_network_cidr is None:
			pod_network_cidr = "<unknown>"

		get_versions_path = get_playbook_path(FilePath("get_versions.yaml"))
		retval, ansible_results = ansible_run_playbook_on_selection(get_versions_path, selection = [controlplane])

		if len(ansible_results) == 0:
			raise ValueError(f"Error: Failed to get package versions from {controlplane} (retval: {retval}); aborting.")

		k8s_distro = "<unknown>"
		version = "<unknown>"

		for result in deep_get(ansible_results, DictPath(controlplane), []):
			if deep_get(result, DictPath("task"), "") == "Package versions":
				tmp = deep_get(result, DictPath("msg_lines"), [])
				break

		if len(tmp) == 0:
			raise ValueError(f"Error: Received empty version data from {controlplane} (retval: {retval}); aborting.")

		package_version_regex = re.compile(r"^(.*?): (.*)")

		for line in tmp:
			tmp2 = package_version_regex.match(line)
			if tmp2 is None:
				continue
			package = tmp2[1]
			version = tmp2[2]
			if package == "kubeadm":
				k8s_distro = "kubeadm"
				update_installation_info(cluster_name = cluster_name, distro = k8s_distro, version = version, requested_version = "<none>", cni = cni, state = "installed", phase = "<none>", pod_network_cidr = pod_network_cidr, control_planes = controlplanes, nodes = nodes)
				break
		if k8s_distro == "<unknown>":
			ansithemeprint([ANSIThemeString("Warning", "warning"),
					ANSIThemeString(": Failed to import cluster ", "default"),
					ANSIThemeString(f"{cluster_name}", "hostname"),
					ANSIThemeString("; could not identify distro; skipping.", "default")])

	kh.set_context(name = current_context)

	ansithemeprint([ANSIThemeString("\nCluster import successful", "success")])

# pylint: disable-next=unused-argument
def check_for_updates(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Check whether there are newer versions of packages that are related to the cluster

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	os_distro = identify_distro()

	# default options
	update_cache = True

	for opt, _optarg in options:
		if opt == "--no-cache-update":
			update_cache = False

	ansithemeprint([ANSIThemeString("\n[Checking for software updates]", "phase")])
	ansithemeprint([ANSIThemeString("Note", "note"),
			ANSIThemeString(": Currently only local versions are checked.", "default")])

	if update_cache:
		if os_distro in ("debian",):
			ansithemeprint([ANSIThemeString("\n• ", "separator"),
					ANSIThemeString("Updating APT cache", "action")])
			check_and_print_status(update_apt_cache())
		elif os_distro in ("suse",):
			ansithemeprint([ANSIThemeString("\n• ", "separator"),
					ANSIThemeString("Updating Zypper cache", "action")])
			check_and_print_status(update_zypper_cache())
		ansithemeprint([ANSIThemeString("\n• ", "separator"),
				ANSIThemeString("Updating version cache", "action")])
		check_and_print_status(update_version_cache())

	pkg_packages = [
		"ansible",
		"ansible-core",
		"containerd",
		"containerd.io",
		"cri-o",
		"cri-tools",
		"docker-ce",
		"docker-engine",
		"docker.io",
		"kubeadm",
		"kubectl",
		"kubelet",
		"kubernetes-cni",
		"python3-ansible-runner",
		"python3-natsort",
		"python3-paramiko",
		"python3-pip",
		"python3-ujson",
		"python3-urllib3",
		"runc",
	]

	if os_distro == "suse":
		if (kubernetes_upstream_version := get_latest_kubernetes_upstream_version()) is not None:
			_upstream_major, upstream_minor, _rest = kubernetes_upstream_version.split(".")

			for package in ("client", "kubeadm", "kubelet"):
				for i in range(17, int(upstream_minor) + 1):
					pkg_packages.append(f"kubernetes1.{i}-{package}")

	pkg_packages = natsorted(pkg_packages)

	version_checks: List = []

	print()
	check_versions(pkg_packages, version_checks)
	print()

def show_configuration(action: str,
		       tasks: List[Tuple[List[ANSIThemeString], Callable[..., None]]]) -> None:
	"""
	Show cluster configuration

		Parameters:
			action (str): The action to take
			tasks ([([ANSIThemeString], callable, args)])): The tasks list
	"""

	installation_info = get_installation_info()
	cluster_name = deep_get(installation_info, DictPath("installation_target"))
	k8s_distro = deep_get(installation_info, DictPath(f"{cluster_name}#distro"))
	version = deep_get(installation_info, DictPath(f"{cluster_name}#version"))
	requested_version = deep_get(installation_info, DictPath(f"{cluster_name}#requested_version"))
	cni = deep_get(installation_info, DictPath(f"{cluster_name}#cni"))
	pod_network_cidr = deep_get(installation_info, DictPath(f"{cluster_name}#pod_network_cidr"))
	cri = deep_get(installation_info, DictPath(f"{cluster_name}#cri"))
	controlplanes = deep_get(installation_info, DictPath(f"{cluster_name}#control_planes"), [])
	nodes = deep_get(installation_info, DictPath(f"{cluster_name}#nodes"), [])

	failures = {}

	control_plane_info = []
	for controlplane in controlplanes:
		ip = None
		try:
			ip = socket.gethostbyname(controlplane)
		except socket.gaierror as e:
			if str(e) in ("[Errno -2] Name or service not known",
				      "[Errno -3] Temporary failure in name resolution",
				      "[Errno -5] No address associated with hostname"):
				tmp = re.match(r"^\[Errno (-\d+)\] (.+)", str(e))
				if len(deep_get(failures, DictPath(tmp[2]), [])) == 0:
					failures[tmp[2]] = []
				failures[tmp[2]].append(controlplane)
		control_plane_info.append((controlplane, ip))

	node_info = []
	for node in nodes:
		ip = None
		try:
			ip = socket.gethostbyname(node)
		except socket.gaierror as e:
			if str(e) in ("[Errno -2] Name or service not known",
				      "[Errno -3] Temporary failure in name resolution",
				      "[Errno -5] No address associated with hostname"):
				tmp = re.match(r"^\[Errno (-\d+)\] (.+)", str(e))
				if len(deep_get(failures, DictPath(tmp[2]), [])) == 0:
					failures[tmp[2]] = []
				failures[tmp[2]].append(node)
		node_info.append((node, ip))

	# If we fail to get the IP-address of any of the hostnames
	# we output them here and abort.
	if len(failures) > 0:
		ansithemeprint([ANSIThemeString("Errors", "error"),
				ANSIThemeString(":", "default")], stderr = True)
	for _error, hosts in failures.items():
		hosts = ansithemestring_join_tuple_list(hosts, formatting = "hostname", separator = ANSIThemeString(", ", "separator"))
		ansithemeprint([ANSIThemeString(f"  {tmp[2]} (hosts: ", "default")] +
				hosts +
				[ANSIThemeString(")", "default")], stderr = True)
	if len(failures) > 0:
		ansithemeprint([ANSIThemeString("Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	http_proxy = deep_get(cmtlib.cmtconfig, DictPath("Network#http_proxy"), "")
	if http_proxy is not None and http_proxy == "":
		http_proxy = None
	http_proxy_env = os.getenv("http_proxy")
	if http_proxy_env is not None and http_proxy_env == "":
		http_proxy_env = None
	https_proxy = deep_get(cmtlib.cmtconfig, DictPath("Network#https_proxy"), "")
	if https_proxy is not None and https_proxy == "":
		https_proxy = None
	https_proxy_env = os.getenv("https_proxy")
	if https_proxy_env is not None and https_proxy_env == "":
		https_proxy_env = None
	no_proxy = deep_get(cmtlib.cmtconfig, DictPath("Network#no_proxy"), "")
	if no_proxy is not None and no_proxy == "":
		no_proxy = None
	no_proxy_env = os.getenv("no_proxy")
	if no_proxy_env is not None and no_proxy_env == "":
		no_proxy_env = None

	if len(action) > 0:
		ansithemeprint([ANSIThemeString(action, "emphasis")])

	ansithemeprint([ANSIThemeString("\n[Summary]", "phase")])
	ansithemeprint([ANSIThemeString("\n• ", "separator"),
			ANSIThemeString("Configuration:", "action")])
	ansithemeprint([ANSIThemeString("        Cluster Name: ", "action"),
			ANSIThemeString(f"{cluster_name}", "hostname")])
	ansithemeprint([ANSIThemeString("        Distribution: ", "action"),
			ANSIThemeString(f"{k8s_distro}", "programname")])
	ansithemeprint([ANSIThemeString("   Installed Version: ", "action"),
			__format_none(version, "version")])
	if requested_version is not None and requested_version != "<none>":
		ansithemeprint([ANSIThemeString("   Requested Version: ", "action"),
				__format_none(requested_version, "version")])
	if cni is not None and cni != "<none>":
		ansithemeprint([ANSIThemeString("                 CNI: ", "action"),
				ANSIThemeString(f"{cni}", "programname")])
	if pod_network_cidr is not None and pod_network_cidr != "<none>":
		ansithemeprint([ANSIThemeString("    Pod Network CIDR: ", "action"),
				ANSIThemeString(f"{pod_network_cidr}", "emphasis")])
	if cri is not None and cri != "<none>":
		ansithemeprint([ANSIThemeString("                 CRI: ", "action"),
				ANSIThemeString(f"{cri}", "programname")])
	ansithemeprint([ANSIThemeString("          HTTP Proxy: ", "action"),
			__format_none(http_proxy, "url"),
			ANSIThemeString(" (", "default"),
			ANSIThemeString(f"{CMT_CONFIG_FILE}", "path"),
			ANSIThemeString(")", "default")])
	ansithemeprint([ANSIThemeString("          HTTP Proxy: ", "action"),
			__format_none(http_proxy_env, "url"),
			ANSIThemeString(" (Environment)", "default")])
	ansithemeprint([ANSIThemeString("         HTTPS Proxy: ", "action"),
			__format_none(https_proxy, "url"),
			ANSIThemeString(" (", "default"),
			ANSIThemeString(f"{CMT_CONFIG_FILE}", "path"),
			ANSIThemeString(")", "default")])
	ansithemeprint([ANSIThemeString("         HTTPS Proxy: ", "action"),
			__format_none(https_proxy_env, "url"),
			ANSIThemeString(" (Environment)", "default")])
	ansithemeprint([ANSIThemeString("            No Proxy: ", "action"),
			__format_none(no_proxy, "url"),
			ANSIThemeString(" (", "default"),
			ANSIThemeString(f"{CMT_CONFIG_FILE}", "path"),
			ANSIThemeString(")", "default")])
	ansithemeprint([ANSIThemeString("            No Proxy: ", "action"),
			__format_none(no_proxy_env, "url"),
			ANSIThemeString(" (Environment)", "default")])
	if len(control_plane_info) > 0:
		ansithemeprint([ANSIThemeString("\n• ", "separator"),
			ANSIThemeString("Control Plane(s):", "action")])
		for hostname, ip in control_plane_info:
			ansithemeprint([ANSIThemeString("            Hostname: ", "action"),
					ANSIThemeString(f"{hostname} ", "emphasis"),
					ANSIThemeString("(", "default"),
					ANSIThemeString(f"{ip}", "emphasis"),
					ANSIThemeString(")", "default")])
	if len(node_info) > 0:
		ansithemeprint([ANSIThemeString("\n• ", "separator"),
			ANSIThemeString("Node(s):", "action")])
		for hostname, ip in node_info:
			ansithemeprint([ANSIThemeString("            Hostname: ", "action"),
					ANSIThemeString(f"{hostname} ", "emphasis"),
					ANSIThemeString("(", "default"),
					ANSIThemeString(f"{ip}", "emphasis"),
					ANSIThemeString(")", "default")])

	if tasks is not None:
		ansithemeprint([ANSIThemeString("", "default")])
		ansithemeprint([ANSIThemeString("Pending tasks (", "action"),
				ANSIThemeString("Dimmed", "skip"),
				ANSIThemeString(" tasks are either skipped or completed):\n", "action")])

		phase = installation_info[cluster_name]["phase"]
		phase_skiplist = installation_info[cluster_name]["phase_skiplist"]
		__list_phases(tasks, start_phase = phase, phase_skiplist = phase_skiplist)

def __get_configuration_data(configuration_file: str, configuration_type: str, configuration: Dict, default: FilePath) -> FilePath:
	"""
	Given a configuration dict, make sure that it doesn't contains both data and a path.
	If given data write it to a temporary file. Returns the path on success, exists on failure.

		Parameters:
			configuration_file (str): The name of the configuration file; used for error messages
			configuration_type (str): The type of the configuration we're expecting
			configuration (dict): The configuration to verify and return a path to
			default (FilePath): If the configuration is empty use path as fallback
		Returns:
			path (FilePath): The path to a file with the configuration on success
	"""

	data = deep_get(configuration, DictPath(f"{configuration_type}#data"))
	path = deep_get(configuration, DictPath("{configuration_type}#path"))

	if data is None and path is None:
		return default

	if data is not None and path is not None:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString("The configuration in ", "default"),
				ANSIThemeString(f"{configuration_file}", "path"),
				ANSIThemeString(" specifies both data and a path for ", "default"),
				ANSIThemeString(f"{configuration_type}", "command"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if data is not None:
		# pylint: disable-next=consider-using-with
		tf = tempfile.NamedTemporaryFile(suffix = ".yaml.j2", delete = False)
		path = FilePath(tf.name)
		secure_write_string(path, data, temporary = True)

	return FilePath(path)

def add_nodes(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Add nodes to the cluster

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""
	from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
	kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

	cordon_on_join = False
	cri = "containerd"

	installation_info = get_installation_info()
	cluster_name = deep_get(installation_info, DictPath("installation_target"))
	k8s_distro = deep_get(installation_info, DictPath(f"{cluster_name}#distro"))
	control_planes = deep_get(installation_info, DictPath(f"{cluster_name}#control_planes"))

	if k8s_distro == "kubeadm":
		configuration_paths = [
			os.path.join(ANSIBLE_PLAYBOOK_DIR, "templates", "config", "join_configuration.yaml.j2"),
		]
	elif k8s_distro == "rke2":
		configuration_paths = [
			os.path.join(ANSIBLE_PLAYBOOK_DIR, "templates", "etc", "rancher", "rke2", "config.agent.yaml.j2"),
		]

	for opt, optarg in options:
		if opt == "--verbose":
			verbose = True
		elif opt == "--save-ansible-logs":
			ansible_configuration["save_logs"] = True
		elif opt == "--configuration-paths":
			configuration_paths = optarg
		elif opt == "--cordon-on-join":
			cordon_on_join = optarg
		elif opt == "--cri":
			cri = optarg
		elif opt == "--forks":
			ansible_configuration["ansible_forks"] = optarg

	configuration_path = merge_configurations(configuration_paths)

	nodes = args[0]
	groups = args[1]

	control_plane_version = get_control_plane_version(control_planes[0], k8s_distro)

	# First remove the distro revision
	major_minor_patchrev = control_plane_version.split("-")
	# Now split the version tuple
	requested_major, requested_minor, _rest = major_minor_patchrev[0].split(".")

	control_plane_ip, control_plane_port, control_plane_path = kh.get_control_plane_address()
	if control_plane_ip is None:
		ansithemeprint([ANSIThemeString("\nAborting", "error"),
				ANSIThemeString(": Could not get the IP-address for the control plane.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	# Add all nodes to the inventory
	ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = nodes, skip_all = False)

	# Add the CRI to the setup playbooks for the control plane;
	# the list is short enough that doing prepend isn't a performance issue
	crio_version = ""
	if cri == "docker-shim":
		add_playbooks = [FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("setup_docker.io.yaml")))]
	elif cri == "containerd":
		add_playbooks = [FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("setup_containerd.yaml")))]
	elif cri == "cri-o":
		add_playbooks = [FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("setup_cri-o.yaml")))]
		crio_major_version, crio_minor_version = get_crio_version((int(requested_major), int(requested_minor)))

	cri_socket = deep_get(cri_data[cri], DictPath("socket"))

	add_playbooks += [
		# cmtadm does not use run_before/run_after/add_to_groups/remove_from_groups,
		# so we have to do all of that explicitly
		FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("add_kubernetes_repo.yaml"))),
	]
	if k8s_distro == "kubeadm":
		add_playbooks += [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("kubeadm_setup_node.yaml")))
		]
	elif k8s_distro == "rke2":
		add_playbooks += [
			FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("rke2_setup_node.yaml")))
		]

	if int(requested_minor) < 23:
		join_configuration_api_version = "kubeadm.k8s.io/v1beta2"
	else:
		join_configuration_api_version = "kubeadm.k8s.io/v1beta3"

	minor_versions = []
	for minor_version in range(28, int(requested_minor) + 1):
		minor_versions.append(f"{minor_version}")

	extra_values = {
		"ansible_become_pass": deep_get(ansible_configuration, DictPath("ansible_password")),
		"ansible_ssh_pass": deep_get(ansible_configuration, DictPath("ansible_password")),
		"cluster_name": cluster_name,
		"control_plane_ip": control_plane_ip,
		"control_plane_port": control_plane_port,
		"control_plane_path": control_plane_path,
		"cordon_nodes_on_join": cordon_on_join,
		"control_plane_k8s_version": control_plane_version,
		"crio_major_version": crio_major_version,
		"crio_minor_version": crio_major_version,
		"cri_socket": cri_socket,
		"configuration_path": configuration_path,
		"join_configuration_api_version": join_configuration_api_version,
		"kubernetes_major_minor_version": f"{requested_major}.{requested_minor}",
		"minor_versions": minor_versions,
	}

	if k8s_distro == "kubeadm":
		join_token = kh.get_join_token()
		if len(join_token) == 0:
			ansithemeprint([ANSIThemeString("\nAborting", "error"),
					ANSIThemeString(": No join token available.", "default")], stderr = True)
			sys.exit(errno.ENOENT)
		ca_cert_hash = kh.get_ca_cert_hash()
		if len(ca_cert_hash) == 0:
			ansithemeprint([ANSIThemeString("\nAborting", "error"),
					ANSIThemeString(": No CA certificate available.", "default")], stderr = True)
			sys.exit(errno.ENOENT)

		extra_values["join_token"] = join_token
		extra_values["ca_cert_hash"] = ca_cert_hash
	elif k8s_distro == "rke2":
		extra_values["requested_version"] = control_plane_version

	playbooks = populate_playbooks_from_paths(add_playbooks)

	retval = run_playbooks(playbooks = playbooks, hosts = nodes, extra_values = extra_values, verbose = verbose)
	if retval:
		ansithemeprint([ANSIThemeString("OK", "ok")])
	else:
		ansithemeprint([ANSIThemeString("NOT OK", "notok"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	for group in ["nodes"] + groups + [cluster_name]:
		ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = nodes, group = group, skip_all = True)

def set_context(cluster_name: str, context_name: str) -> None:
	"""
	Set context

		Parameters:
			cluster_name (str): The name of the cluster (used for error messages)
			context_name (str): The context to switch to
	"""

	from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
	kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

	if not kh.set_context(name = context_name, unchanged_is_success = True):
		ansithemeprint([ANSIThemeString("Warning", "warning"),
				ANSIThemeString(": Failed to change to context ", "default"),
				ANSIThemeString(f"{context_name}", "hostname"),
				ANSIThemeString(" for cluster ", "default"),
				ANSIThemeString(f"{cluster_name}", "hostname"),
				ANSIThemeString("; aborting.", "default")], stderr= True)
		sys.exit(errno.ENOENT)

def create_cluster(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Create a cluster based on a ClusterDeployment template

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	http_proxy = deep_get(cmtlib.cmtconfig, DictPath("Network#http_proxy"), "")
	https_proxy = deep_get(cmtlib.cmtconfig, DictPath("Network#https_proxy"), "")
	no_proxy = deep_get(cmtlib.cmtconfig, DictPath("Network#no_proxy"), "")
	env = {
		"KUBECONFIG": os.path.join(f"{HOMEDIR}", ".kube", "config"),
		"PATH": deep_get(dict(os.environ), DictPath("PATH"), ""),
		"HOME": f"{HOMEDIR}",
		"http_proxy": http_proxy,
		"https_proxy": https_proxy,
		"no_proxy": no_proxy,
	}

	installation_info = get_installation_info()
	confirm = True
	redeploy = False

	for opt, _optarg in options:
		if opt == "-Y":
			confirm = False
		elif opt == "--redeploy":
			redeploy = True

	cluster_deployment_file = args[0]

	if not os.path.exists(cluster_deployment_file):
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString(f"{cluster_deployment_file}", "path"),
				ANSIThemeString(" does not exist; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)
	elif not os.path.isfile(cluster_deployment_file):
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString(f"{cluster_deployment_file}", "path"),
				ANSIThemeString(" is not a file; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	security_checks = [
		SecurityChecks.OWNER_IN_ALLOWLIST,
		SecurityChecks.PARENT_OWNER_IN_ALLOWLIST,
		SecurityChecks.PERMISSIONS,
		SecurityChecks.PARENT_PERMISSIONS,
		SecurityChecks.IS_FILE,
	]
	cd = secure_read_yaml(cluster_deployment_file, checks = security_checks)
	cd_kind = deep_get(cd, DictPath("kind"), "")
	cd_api_version = deep_get(cd, DictPath("apiVersion"), "")

	# Is this a cluster deployment and do we support this version?
	if cd_kind != "ClusterDeployment":
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString(f"{cluster_deployment_file}", "path"),
				ANSIThemeString(" is not a valid ", "default"),
				ANSIThemeString("ClusterDeployment", "command"),
				ANSIThemeString(" configuration; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if cd_api_version not in ("v1alpha1", "v1alpha2"):
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString("The apiVersion ", "default"),
				ANSIThemeString(f"{cd_api_version}", "version"),
				ANSIThemeString(" used in ", "default"),
				ANSIThemeString(f"{cluster_deployment_file}", "path"),
				ANSIThemeString(" is not supported; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	# Fetch all configuration options
	k8s_distro = deep_get(cd, DictPath("options#distro"), "kubeadm")
	requested_version = deep_get(cd, DictPath("options#version"), "latest")
	verbose = deep_get(cd, DictPath("options#verbose"), False)
	pod_network_cidr = deep_get(cd, DictPath("options#podNetworkCIDR"), "10.244.0.0/16")
	cni = deep_get(cd, DictPath("options#cni"), "cilium")
	prompt_for_password = deep_get(cd, DictPath("options#promptForPassword"), True)
	save_ansible_logs = deep_get(cd, DictPath("options#saveAnsibleLogs"), False)

	control_planes = deep_get(cd, DictPath("cluster#controlPlanes"))
	if control_planes is None or len(control_planes) == 0:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString("The configuration in ", "default"),
				ANSIThemeString(f"{cluster_deployment_file}", "path"),
				ANSIThemeString(" does not specify a control plane; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	cri = deep_get(cd, DictPath("cluster#cri"), "containerd")

	cluster_name = deep_get(cd, DictPath("cluster#clusterName"))
	if cluster_name is None or len(cluster_name) == 0:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString("The configuration in ", "default"),
				ANSIThemeString(f"{cluster_deployment_file}", "path"),
				ANSIThemeString(" does not specify a cluster name; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if deep_get(installation_info, DictPath("installation_target")) != cluster_name:
		installation_info = update_installation_info(installation_target = cluster_name, cluster_name = cluster_name, distro = k8s_distro)

	rke2_configuration_path = __get_configuration_data(cluster_deployment_file,
							   "rke2Configuration",
							   deep_get(cd, DictPath("cluster#configurationTemplates"), {}),
							   os.path.join("templates", "config", "rke2_configuration.yaml.j2"))
	cluster_configuration_path = __get_configuration_data(cluster_deployment_file,
							      "clusterConfiguration",
							      deep_get(cd, DictPath("cluster#configurationTemplates"), {}),
							      os.path.join("templates", "config", "cluster_configuration.yaml.j2"))
	init_configuration_path = __get_configuration_data(cluster_deployment_file,
							   "initConfiguration",
							   deep_get(cd, DictPath("cluster#configurationTemplates"), {}),
							   os.path.join("templates", "config", "init_configuration.yaml.j2"))
	kubelet_configuration_path = __get_configuration_data(cluster_deployment_file,
							      "kubeletConfiguration",
							      deep_get(cd, DictPath("cluster#configurationTemplates"), {}),
							      os.path.join("templates", "config", "kubelet_configuration.yaml.j2"))
	kube_proxy_configuration_path = __get_configuration_data(cluster_deployment_file,
								 "kubeProxyConfiguration",
								 deep_get(cd, DictPath("cluster#configurationTemplates"), {}),
								 os.path.join("templates", "config", "kube_proxy_configuration.yaml.j2"))

	nodes = []

	# Get a list of all nodes in the cluster
	for _node_group, data in deep_get(cd, DictPath("nodes#groups"), {}).items():
		nodes += deep_get(data, DictPath("nodes"), [])

	prepare_options = [
		("--control-plane", control_planes[0]),
		("--hide-next-step", None),
		("--nodes", nodes),
	]
	if not confirm:
		prepare_options.append(("-Y", None))
	if verbose:
		prepare_options.append(("--verbose", None))
	if save_ansible_logs:
		prepare_options.append(("--save-ansible-logs", None))
	if not prompt_for_password:
		prepare_options.append(("--no-password", None))

	prepare_args = [
		cluster_name,
	]

	if requested_version == "latest":
		prepare_args.append(f"{k8s_distro}=")
	else:
		prepare_args.append(f"{k8s_distro}={requested_version}")

	setup_control_plane_options = [
		("-Y", None),
		("--cri", cri),
	]

	if k8s_distro == "kubeadm":
		setup_control_plane_options += [
			("--configuration-paths", [
				cluster_configuration_path,
				init_configuration_path,
				kubelet_configuration_path,
				kube_proxy_configuration_path,
			])
		]
	elif k8s_distro == "rke2":
		setup_control_plane_options += [
			("--configuration-paths", [rke2_configuration_path])
		]

	taint_control_planes = not deep_get(cd, DictPath("cluster#untaintControlPlanes"), False)
	setup_control_plane_options.append(("--extra-values", { "taint_control_plane": taint_control_planes }))

	if verbose:
		setup_control_plane_options.append(("--verbose", None))
	if save_ansible_logs:
		setup_control_plane_options.append(("--save-ansible-logs", None))

	setup_control_plane_args = [
		# Pass "none" as CNI; since we'll potentially be adding nodes
		# we want to postpone deploying the CNI until after those
		# have been added, to avoid extra traffic
		"none",
		pod_network_cidr,
	]

	cluster_name = installation_info["installation_target"]
	state = deep_get(installation_info, DictPath(f"{cluster_name}#state"))
	phase = deep_get(installation_info, DictPath(f"{cluster_name}#phase"))

	if state is None or state in ("<none>", "preparing", "torn_down"):
		# First prepare all hosts
		prepare_installation(prepare_options, prepare_args)

	installation_info = get_installation_info()
	state = deep_get(installation_info, DictPath(f"{cluster_name}#state"))
	phase = deep_get(installation_info, DictPath(f"{cluster_name}#phase"))

	# Now it's time to setup the control plane(s)
	if state in ("prepared", "installing"):
		setup_control_planes(setup_control_plane_options, setup_control_plane_args)
		phase = 0
		state = "adding_nodes"
		installation_info = update_installation_info(cluster_name = cluster_name, state = state, phase = phase)

	state = deep_get(installation_info, DictPath(f"{cluster_name}#state"))
	phase = deep_get(installation_info, DictPath(f"{cluster_name}#phase"))

	admin_name = f"kubernetes-admin+{cluster_name}"
	context_name = f"{admin_name}@{cluster_name}"

	from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
	kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

	# We (hopefully) have a cluster now; change the context to that cluster
	if not kh.set_context(name = context_name, unchanged_is_success = True):
		ansithemeprint([ANSIThemeString("Warning", "warning"),
				ANSIThemeString(": Failed to change to context ", "default"),
				ANSIThemeString(f"{context_name}", "hostname"),
				ANSIThemeString(" for cluster ", "default"),
				ANSIThemeString(f"{cluster_name}", "hostname"),
				ANSIThemeString("; aborting.", "default")])
		sys.exit(errno.ENOENT)

	if state == "installed" and phase == "<done>":
		phase = 0
		if len(nodes) > 0:
			state = "adding_nodes"
			control_plane_version = get_control_plane_version(controlplane = control_planes[0], k8s_distro = k8s_distro)
			installation_info = update_installation_info(cluster_name = cluster_name, state = state, phase = phase, version = control_plane_version)
		else:
			state = "setup_cni"
			installation_info = update_installation_info(cluster_name = cluster_name, state = state, phase = phase)

	if state == "adding_nodes":
		i = 0
		# We (hopefully) don't need to check whether the nodes are part of the cluster already,
		# since we've just setup the control plane...
		ansithemeprint([ANSIThemeString("\n[Adding nodes]", "phase")])

		# Check whether ansible_password is defined or not
		if deep_get(ansible_configuration, DictPath("ansible_password")) is None and not no_password:
			ansithemeprint([ANSIThemeString("Attention", "warning"),
					ANSIThemeString(": To be able to run playbooks you need to provide the ansible/ssh password.", "default")])
			ansithemeprint([ANSIThemeString("Since the systems will be reconfigured to use passwordless sudo and ssh keys this is a one-time thing.\n", "default")])
			ansithemeprint([ANSIThemeString("Note", "note"),
					ANSIThemeString(": If the remote host is already configured for passwordless sudo and allows for login using a pre-generated SSH-key you can use “", "default"),
					ANSIThemeString("--no-password", "option"),
					ANSIThemeString("“ to bypass this check.", "default")])
			ansible_password = ansithemeinput_password([ANSIThemeString("\nPassword: ", "default")])
			if len(ansible_password) == 0:
				ansithemeprint([ANSIThemeString("\nError", "error"),
						ANSIThemeString(": Empty password; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)
			else:
				ansible_configuration["ansible_password"] = ansible_password

		node_global_cri = deep_get(cd, DictPath("nodes#options#cri"), "containerd")
		node_global_forks = deep_get(cd, DictPath("nodes#options#forks"), 5)
		node_global_cordon_on_join = deep_get(cd, DictPath("nodes#options#cordonOnJoin"), False)
		node_global_configuration = deep_get(cd, DictPath("nodes#options#configurationTemplates"), {})

		# We've potentially got multiple groups of nodes,
		# so calling add_nodes() once isn't gonna cut it
		for group, data in deep_get(cd, DictPath("nodes#groups"), {}).items():
			# Don't add node groups again
			if i < phase:
				continue
			nodes = deep_get(data, DictPath("nodes"), [])
			node_cri = deep_get(cd, DictPath("options#cri"), node_global_cri)
			node_forks = deep_get(cd, DictPath("options#forks"), node_global_forks)
			node_cordon_on_join = deep_get(cd, DictPath("options#cordonOnJoin"), node_global_cordon_on_join)

			node_configuration = deep_get(group, DictPath("options#configurationTemplates"), node_global_configuration)
			if k8s_distro == "kubeadm":
				join_configuration_path = __get_configuration_data(cluster_deployment_file,
										   "joinConfiguration",
										   node_configuration,
										   os.path.join("templates", "config", "join_configuration.yaml.j2"))
			elif k8s_distro == "rke2":
				join_configuration_path = __get_configuration_data(cluster_deployment_file,
										   "rke2Configuration",
										   node_configuration,
										   os.path.join("templates", "config", "rke2_configuration.yaml.j2"))

			add_nodes_options = [
				("--cri", node_cri),
				("--configuration-paths", [
					join_configuration_path,
				]),
				("--cordon-on-join", node_cordon_on_join),
				("--forks", node_forks),
			]
			if verbose:
				add_nodes_options.append(("--verbose", None))
			if save_ansible_logs:
				setup_control_plane_options.append(("--save-ansible-logs", None))

			add_nodes_args = [
				# List of nodes
				nodes,
				# Group(s) to add the nodes to
				[group],
			]

			add_nodes(add_nodes_options, add_nodes_args)
			i += 1
			installation_info = update_installation_info(cluster_name = cluster_name, state = state, phase = i)

		ansithemeprint([ANSIThemeString("\nNodes successfully added", "success")])
		phase = 0
		state = "setup_cni"
		installation_info = update_installation_info(cluster_name = cluster_name, state = state, phase = phase)

	# Now we can setup the CNI
	admin_name = f"kubernetes-admin+{cluster_name}"
	context_name = f"{admin_name}@{cluster_name}"

	if state == "setup_cni":
		__setup_cni(cni, context_name, cluster_name)
		phase = 0
		state = "deploy_workloads"
		installation_info = update_installation_info(cluster_name = cluster_name, state = state, phase = phase, cni = cni)

	if redeploy:
		phase = 0
		state = "deploy_workloads"
		installation_info = update_installation_info(cluster_name = cluster_name, state = state, phase = phase)

	# Finally we attempt to deploy workloads
	workloads = deep_get(cd, DictPath("workloads"), [])

	if state in ("deploy_workloads", "deploying") and len(workloads) > 0:
		ansithemeprint([ANSIThemeString("\n[Deploying workloads]", "phase")])

		for i, workload in enumerate(workloads):
			if i < phase:
				continue

			name = deep_get(workload, DictPath("name"))
			skip = deep_get(workload, DictPath("skip"), False)
			if skip:
				installation_info = update_installation_info(cluster_name = cluster_name, state = "deploying", phase = i)
				continue
			description = deep_get(workload, DictPath("description"), "")
			split_description = description.splitlines()
			# For now this is unused
			_error_policy = deep_get(workload, DictPath("errorPolicy"), "ignore")

			if name is None:
				ansithemeprint([ANSIThemeString("Error", "error"),
						ANSIThemeString(": ", "default"),
						ANSIThemeString("name", "emphasis"),
						ANSIThemeString(" is a mandatory field for workloads; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)

			args = []

			ansithemeprint([ANSIThemeString("\n  • ", "separator"),
					ANSIThemeString("Deploying ", "subaction"),
					ANSIThemeString(f"{name}", "argument")])

			if verbose:
				for line in split_description:
					ansithemeprint([ANSIThemeString("    ", "separator"),
							ANSIThemeString(f"{line}", "default")])
				print()

			deployments = deep_get(workload, DictPath("deployments"), [])
			kubectl_path = secure_which(FilePath("/usr/bin/kubectl"),
						    fallback_allowlist = ["/etc/alternatives"],
						    security_policy = SecurityPolicy.ALLOWLIST_RELAXED)
			sudo_path = cmtio.secure_which(FilePath("sudo"), fallback_allowlist = ["/bin", "/usr/bin"],
						       security_policy = SecurityPolicy.ALLOWLIST_STRICT)
			try:
				helm_path = secure_which(FilePath("/usr/bin/helm"),
							 fallback_allowlist = ["/etc/alternatives", "/usr/local/bin", f"{HOMEDIR}/bin"],
							 security_policy = SecurityPolicy.ALLOWLIST_RELAXED)
			except FileNotFoundError:
				helm_path = None

			try:
				git_path = secure_which(FilePath("/usr/bin/git"),
							fallback_allowlist = ["/etc/alternatives", "/usr/lib/git", "/usr/local/bin", f"{HOMEDIR}/bin"],
							security_policy = SecurityPolicy.ALLOWLIST_RELAXED)
			except FileNotFoundError:
				git_path = None

			for data in deployments:
				intersection = {"kubectl", "helm", "git"} & data.keys()
				if len(intersection) != 1:
					ansithemeprint([ANSIThemeString("Error", "error"),
							ANSIThemeString(": The workload ", "default"),
							ANSIThemeString(f"{name}", "argument"),
							ANSIThemeString(" is invalid; ", "default"),
							ANSIThemeString("each deployment must contain exactly one of ", "default"),
							ANSIThemeString("git", "emphasis"),
							ANSIThemeString(", ", "default"),
							ANSIThemeString("kubectl", "emphasis"),
							ANSIThemeString(", or ", "default"),
							ANSIThemeString("helm", "emphasis"),
							ANSIThemeString("; aborting.", "default")], stderr = True)
					sys.exit(errno.EINVAL)

				if "git" in data:
					if git_path is None:
						ansithemeprint([ANSIThemeString("Error", "error"),
								ANSIThemeString(": The workload ", "default"),
								ANSIThemeString(f"{name}", "argument"),
								ANSIThemeString(" uses ", "default"),
								ANSIThemeString("git", "emphasis"),
								ANSIThemeString(", but it's not installed; aborting.", "default")], stderr = True)
						sys.exit(errno.ENOENT)

					deployment = deep_get(data, DictPath("git"), {})
					repo = deep_get(deployment, DictPath("repo"))
					destination = deep_get(deployment, DictPath("destination"))
					if destination.startswith("{HOME}"):
						destination = destination.replace("{HOME}", HOMEDIR, 1)
					branch = deep_get(deployment, DictPath("branch"))
					fetch = deep_get(deployment, DictPath("fetch"), False)

					if destination is None:
						ansithemeprint([ANSIThemeString("Error", "error"),
								ANSIThemeString(": The workload ", "default"),
								ANSIThemeString(f"{name}", "argument"),
								ANSIThemeString(" is invalid; ", "default"),
								ANSIThemeString("destination", "emphasis"),
								ANSIThemeString(" is a mandatory field for ", "default"),
								ANSIThemeString("git", "emphasis"),
								ANSIThemeString(" deployments; aborting.", "default")], stderr = True)
						sys.exit(errno.EINVAL)


					security_checks = [
						SecurityChecks.PARENT_RESOLVES_TO_SELF,
						SecurityChecks.OWNER_IN_ALLOWLIST,
						SecurityChecks.PARENT_OWNER_IN_ALLOWLIST,
						SecurityChecks.PERMISSIONS,
						SecurityChecks.PARENT_PERMISSIONS,
						SecurityChecks.EXISTS,
						SecurityChecks.IS_DIR,
					]
					retval = check_path(destination, checks = security_checks)

					if check_path(destination) == [SecurityStatus.OK]:
						if fetch:
							args = [git_path, "-C", destination, "fetch"]
							check_and_print_status(execute_command(args, env = env))

						if branch is not None:
							args = [git_path, "-C", destination, "checkout", f"tags/{branch}"]
							check_and_print_status(execute_command(args, env = env))
					elif retval == [SecurityStatus.DOES_NOT_EXIST]:
						security_checks = [
							SecurityChecks.PARENT_RESOLVES_TO_SELF,
							SecurityChecks.PARENT_OWNER_IN_ALLOWLIST,
							SecurityChecks.PARENT_PERMISSIONS,
						]

						if check_path(destination, checks = security_checks) != [SecurityStatus.OK]:
							ansithemeprint([ANSIThemeString("Error", "error"),
									ANSIThemeString(": The workload ", "default"),
									ANSIThemeString(f"{name}", "argument"),
									ANSIThemeString(" has an invalid destionation path; aborting.", "default")], stderr = True)
							sys.exit(errno.EINVAL)

						if repo is None or len(repo) == 0:
							ansithemeprint([ANSIThemeString("Error", "error"),
									ANSIThemeString(": No local checkout of the workload ", "default"),
									ANSIThemeString(f"{name}", "argument"),
									ANSIThemeString(" exists, and ", "default"),
									ANSIThemeString("repo", "emphasis"),
									ANSIThemeString(" has not been specified; aborting.", "default")], stderr = True)
							sys.exit(errno.ENOENT)

						if branch is not None:
							args = [git_path, "clone", "--depth", "1", "--branch", branch, repo, destination]
						else:
							args = [git_path, "clone", "--depth", "1", repo, destination]

						check_and_print_status(execute_command(args, env = env))
				elif "kubectl" in data:
					deployment = deep_get(data, DictPath("kubectl"), {})
					method = deep_get(deployment, DictPath("method"), "apply")
					wtype = deep_get(deployment, DictPath("type"), "file")
					uris = deep_get(deployment, DictPath("uri"))
					data = deep_get(deployment, DictPath("data"))
					cert = deep_get(deployment, DictPath("cert"))
					key = deep_get(deployment, DictPath("key"))
					pname = deep_get(deployment, DictPath("name"))
					pnamespace = deep_get(deployment, DictPath("namespace"))
					resource = deep_get(deployment, DictPath("resource"))
					version = deep_get(deployment, DictPath("version"))

					if wtype is None:
						ansithemeprint([ANSIThemeString("Error", "error"),
								ANSIThemeString(": The workload ", "default"),
								ANSIThemeString(f"{name}", "argument"),
								ANSIThemeString(" is invalid; ", "default"),
								ANSIThemeString("type", "emphasis"),
								ANSIThemeString(" is a mandatory field for ", "default"),
								ANSIThemeString("kubectl", "emphasis"),
								ANSIThemeString(" deployments; aborting.", "default")], stderr = True)
						sys.exit(errno.EINVAL)


					if wtype not in ("embedded", "file", "kustomization", "namespace", "secret+tls"):
						ansithemeprint([ANSIThemeString("Error", "error"),
								ANSIThemeString(": The type ", "default"),
								ANSIThemeString(f"{wtype}", "argument"),
								ANSIThemeString(" for the workload ", "default"),
								ANSIThemeString(f"{name}", "argument"),
								ANSIThemeString(" is invalid; only ", "default"),
								ANSIThemeString("embedded", "emphasis"),
								ANSIThemeString(", ", "default"),
								ANSIThemeString("namespace", "emphasis"),
								ANSIThemeString(", ", "default"),
								ANSIThemeString("secret+tls", "emphasis"),
								ANSIThemeString(", and ", "default"),
								ANSIThemeString("file", "emphasis"),
								ANSIThemeString(", and ", "default"),
								ANSIThemeString("kustomization", "emphasis"),
								ANSIThemeString(" are supported for .", "default"),
								ANSIThemeString("kubectl", "emphasis"),
								ANSIThemeString(" deployments; aborting.", "default")], stderr = True)
						sys.exit(errno.EINVAL)

					if method not in ("apply", "create", "patch+strategic", "patch+merge", "patch+json"):
						ansithemeprint([ANSIThemeString("Error", "error"),
								ANSIThemeString(": The method ", "default"),
								ANSIThemeString(f"{method}", "argument"),
								ANSIThemeString(" for the workload ", "default"),
								ANSIThemeString(f"{name}", "argument"),
								ANSIThemeString(" is invalid; only ", "default"),
								ANSIThemeString("apply", "emphasis"),
								ANSIThemeString(", ", "default"),
								ANSIThemeString("create", "emphasis"),
								ANSIThemeString(", ", "default"),
								ANSIThemeString("patch+strategic", "emphasis"),
								ANSIThemeString(", ", "default"),
								ANSIThemeString("patch+merge", "emphasis"),
								ANSIThemeString(", and ", "default"),
								ANSIThemeString("patch+json", "emphasis"),
								ANSIThemeString(" are supported for .", "default"),
								ANSIThemeString("kubectl", "emphasis"),
								ANSIThemeString(" deployments; aborting.", "default")], stderr = True)
						sys.exit(errno.EINVAL)

					if wtype not in ("namespace", "secret+tls") and (uris is None and data is None or uris is not None and data is not None):
						ansithemeprint([ANSIThemeString("Error", "error"),
								ANSIThemeString(": The workload ", "default"),
								ANSIThemeString(f"{name}", "argument"),
								ANSIThemeString(" is invalid; exactly one of ", "default"),
								ANSIThemeString("uri", "emphasis"),
								ANSIThemeString(" or ", "default"),
								ANSIThemeString("data", "emphasis"),
								ANSIThemeString(" is a mandatory field for ", "default"),
								ANSIThemeString("kubectl", "emphasis"),
								ANSIThemeString(" deployments; aborting.", "default")], stderr = True)
						sys.exit(errno.EINVAL)

					if wtype == "secret+tls" and (cert is None or key is None):
						ansithemeprint([ANSIThemeString("Error", "error"),
								ANSIThemeString(": The workload ", "default"),
								ANSIThemeString(f"{name}", "argument"),
								ANSIThemeString(" is invalid; when type is ", "default"),
								ANSIThemeString("secret+tls", "argument"),
								ANSIThemeString(" both ", "default"),
								ANSIThemeString("key", "emphasis"),
								ANSIThemeString(" and ", "default"),
								ANSIThemeString("cert", "emphasis"),
								ANSIThemeString(" are mandatory fields.", "default")], stderr = True)
						sys.exit(errno.EINVAL)

					if uris is None:
						uris = []
					if isinstance(uris, str):
						uris = [uris]

					args = [kubectl_path]
					if method == "create":
						args += ["create"]
					elif method == "apply":
						args += ["apply", "--server-side"]
					elif method == "patch+strategic":
						args += ["patch", resource, pname, "--type", "strategic"]
					elif method == "patch+merge":
						args += ["patch", resource, pname, "--type", "merge"]
					elif method == "patch+json":
						args += ["patch", resource, pname, "--type", "json"]

					if method.startswith("patch"):
						if pnamespace is not None:
							args += ["--namespace", pnamespace]
						args += ["--patch-file"]
					elif wtype in ("embedded", "file"):
						args += ["-f"]
					elif wtype == "kustomization":
						args += ["-k"]
					elif wtype == "namespace":
						args = [kubectl_path, "create", "namespace", pname]
					elif wtype == "secret+tls":
						# secret + tls needs to run as sudo to be able to access /etc/kubernetes/pki
						args = [sudo_path, kubectl_path, "create", "--kubeconfig", KUBE_CONFIG_FILE, "secret", "tls", pname, "--cert", cert, "--key", key]
						if pnamespace is not None:
							args += ["--namespace", pnamespace]

					for uri in uris:
						if not uri.startswith(("file://", "http://", "https://")):
							ansithemeprint([ANSIThemeString("Error", "error"),
									ANSIThemeString(": The URI ", "default"),
									ANSIThemeString(f"{uri}", "argument"),
									ANSIThemeString(" for the workload ", "default"),
									ANSIThemeString(f"{name}", "argument"),
									ANSIThemeString(" is invalid; only ", "default"),
									ANSIThemeString("http://", "emphasis"),
									ANSIThemeString(", ", "default"),
									ANSIThemeString("https://", "emphasis"),
									ANSIThemeString(", and ", "default"),
									ANSIThemeString("file://", "emphasis"),
									ANSIThemeString(" are supported URI-prefixes; aborting.", "default")], stderr = True)
							sys.exit(errno.EINVAL)

						if uri.startswith("file://"):
							uri = uri[len("file://"):]
							if uri.startswith("{HOME}"):
								uri = uri.replace("{HOME}", HOMEDIR, 1)
							_uri_type = "file"
						elif uri.startswith("http://"):
							_uri_type = "http"
						elif uri.startswith("https://"):
							_uri_type = "https"
						if version is not None:
							uri = uri.replace("<<<version>>>", version)

						if verbose:
							check_and_print_status(execute_command(args + [uri], env = env))
						else:
							check_and_print_status(execute_command_with_response(args + [uri], env = env))
					if wtype in ("namespace", "secret+tls"):
						dry_run_result = execute_command_with_response(args + ["--dry-run=server"], env = env)
						if not "already exists" in dry_run_result:
							if verbose:
								check_and_print_status(execute_command(args, env = env))
							else:
								check_and_print_status(execute_command_with_response(args, env = env))
					if data is not None:
						# pylint: disable-next=consider-using-with
						tf = tempfile.NamedTemporaryFile(delete = True)
						path = FilePath(tf.name)
						secure_write_string(path, data, temporary = True)
						if verbose:
							check_and_print_status(execute_command(args + [path], env = env))
						else:
							check_and_print_status(execute_command_with_response(args + [path], env = env))
				elif "helm" in data:
					if helm_path is None:
						ansithemeprint([ANSIThemeString("Warning", "warning"),
								ANSIThemeString(": The workload ", "default"),
								ANSIThemeString(f"{name}", "argument"),
								ANSIThemeString(" uses ", "default"),
								ANSIThemeString("Helm", "emphasis"),
								ANSIThemeString(", but it's not installed; skipping.", "default")], stderr = True)
						continue

					deployment = deep_get(data, DictPath("helm"), {})
					hname = deep_get(deployment, DictPath("name"))
					chart = deep_get(deployment, DictPath("chart"))
					namespace = deep_get(deployment, DictPath("namespace"))
					create_namespace = deep_get(deployment, DictPath("createNamespace"), False)
					repo_url = deep_get(deployment, DictPath("repoURL"))
					repo_name = deep_get(deployment, DictPath("repoName"))
					version = deep_get(deployment, DictPath("version"))

					if None in (hname, chart, namespace, repo_url, repo_name, version):
						ansithemeprint([ANSIThemeString("Error", "error"),
								ANSIThemeString(": The workload ", "default"),
								ANSIThemeString(f"{name}", "argument"),
								ANSIThemeString(" is invalid; the following fields are mandatory for Helm deployments: ", "default"),
								ANSIThemeString("name", "emphasis"),
								ANSIThemeString(", ", "default"),
								ANSIThemeString("chart", "emphasis"),
								ANSIThemeString(", ", "default"),
								ANSIThemeString("namespace", "emphasis"),
								ANSIThemeString(", ", "default"),
								ANSIThemeString("repoURL", "emphasis"),
								ANSIThemeString(", ", "default"),
								ANSIThemeString("repoName", "emphasis"),
								ANSIThemeString(", and ", "default"),
								ANSIThemeString("version", "emphasis"),
								ANSIThemeString("; aborting.", "default")], stderr = True)
						sys.exit(errno.EINVAL)

					# Add helm repo
					args = [helm_path, "repo", "add", repo_name, repo_url]
					if verbose:
						check_and_print_status(execute_command(args))
					else:
						check_and_print_status(execute_command_with_response(args))

					# Check whether the component is already installed
					args = [helm_path, "list", "--namespace", namespace, "--filter", f"^{hname}$", "--no-headers"]
					response = execute_command_with_response(args, env = env)
					tmp = re.match(fr"^{hname}\s.+{version}$", response)
					# We've got an exact match for version and name; for now we just ignore.
					# We might add a remove + install policy later.
					if tmp is not None:
						ansithemeprint([ANSIThemeString("Warning", "warning"),
								ANSIThemeString(": The component ", "default"),
								ANSIThemeString(f"{hname}", "argument"),
								ANSIThemeString(" is already installed using ", "default"),
								ANSIThemeString("Helm", "emphasis"),
								ANSIThemeString(" with the specified version; skipping.", "default")], stderr = True)
						continue

					args = [helm_path, "install", hname, chart, "--namespace", namespace, "--version", version]
					if create_namespace:
						args.append("--create-namespace")

					if verbose:
						check_and_print_status(execute_command(args, env = env))
					else:
						check_and_print_status(execute_command_with_response(args, env = env))

			installation_info = update_installation_info(cluster_name = cluster_name, state = "deploying", phase = i)

		installation_info = update_installation_info(cluster_name = cluster_name, state = "deployed", phase = "<done>")

def merge_configurations(configuration_paths: List[FilePath]) -> FilePath:
	"""
	Given a list of configurations in YAML-format,
	load them all and write them out to a single, temporary, file

		Parameters:
			configuration_paths ([str]): A list of paths to configuration files
	"""

	security_checks = [
		SecurityChecks.PARENT_OWNER_IN_ALLOWLIST,
		SecurityChecks.OWNER_IN_ALLOWLIST,
		SecurityChecks.PERMISSIONS,
		SecurityChecks.IS_FILE,
	]

	configurations = ""
	# pylint: disable-next=consider-using-with
	tf = tempfile.NamedTemporaryFile(suffix = ".yaml.j2", delete = False)

	for path in configuration_paths:
		configuration = secure_read_string(path, checks = security_checks)
		if len(configurations) > 0:
			configurations += "---\n"
		configurations += configuration

	secure_write_string(tf.name, configurations, temporary = True)

	return tf.name

def get_crio_version(kubernetes_version: Tuple[int, int]) -> str:
	"""
	Given a Kubernetes version, return the matching cri-o version

		Parameters:
			kubernetes_version ((int, int)): A version tuple (major, minor)
		Returns:
			(str, str): The cri-o version (major, minor)
	"""

	# cri-o is built/distributed using OBS, hence we need to know the major.minor version
	# Apparently cri-o tries to keep more or less in lock-step with Kubernetes, so don't jump ahead,
	# and if Kubernetes gets ahead, use whatever is the most recent version of cri-o
	requested_major, requested_minor = kubernetes_version

	tmp = get_github_version("https://api.github.com/repos/cri-o/cri-o/releases/latest", r"^v(\d+)\.(\d+)\.\d+$")
	if requested_major < int(tmp[0]) or requested_major == int(tmp[0]) and requested_minor < int(tmp[1]):
		crio_major_version = requested_major
		crio_minor_version = requested_minor
	else:
		crio_version = f"{tmp[0]}.{tmp[1]}"
		crio_major_version = tmp[0]
		crio_minor_version = tmp[1]

	return crio_major_version, crio_minor_version

def setup_control_planes(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Setup a control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	global setup_control_plane_tasks  # pylint: disable=global-statement

	confirm = True
	override_cni = False

	installation_info = get_installation_info()
	cluster_name = deep_get(installation_info, DictPath("installation_target"))
	k8s_distro = deep_get(installation_info, DictPath(f"{cluster_name}#distro"))

	if k8s_distro == "kubeadm":
		setup_control_plane_tasks = __setup_kubeadm_control_plane_tasks
		configuration_paths = [
			os.path.join(ANSIBLE_PLAYBOOK_DIR, "templates", "config", "cluster_configuration.yaml.j2"),
			os.path.join(ANSIBLE_PLAYBOOK_DIR, "templates", "config", "init_configuration.yaml.j2"),
			os.path.join(ANSIBLE_PLAYBOOK_DIR, "templates", "config", "kubelet_configuration.yaml.j2"),
			os.path.join(ANSIBLE_PLAYBOOK_DIR, "templates", "config", "kube_proxy_configuration.yaml.j2"),
		]
	elif k8s_distro == "rke2":
		setup_control_plane_tasks = __setup_rke2_control_plane_tasks
		configuration_paths = [
			os.path.join(ANSIBLE_PLAYBOOK_DIR, "templates", "etc", "rancher", "rke2", "config.yaml.j2"),
		]

	if "--list-tasks" in (tmp[0] for tmp in options):
		__list_phases(setup_control_plane_tasks)
		sys.exit(0)

	requested_version = installation_info[cluster_name]["requested_version"]
	state = installation_info[cluster_name]["state"]
	phase: Union[str, int] = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])
	cni = installation_info[cluster_name]["cni"]
	pod_network_cidr = installation_info[cluster_name]["pod_network_cidr"]
	verbose = False

	if state is None or state in ("<none>", "preparing"):
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": The system is not prepared for installation yet; run ", "default"),
				ANSIThemeString(f"{about.ADMIN_PROGRAM_NAME}", "programname"),
				ANSIThemeString(" prepare", "command"),
				ANSIThemeString(" before continuing. Aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)
	elif state is not None and state not in ("installing", "prepared"):
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Invalid installation state; there is a partial or full installation already; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if state == "prepared":
		phase = 0

	cri = None
	enable_dra = False
	extra_values = {}

	for opt, optarg in options:
		if opt == "--start-at-task":
			phase = __validate_task_index(setup_control_plane_tasks, optarg)
			if "--skip-tasks" not in options:
				phase_skiplist = set()
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(setup_control_plane_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				ansithemeprint([ANSIThemeString("Warning", "warning"),
						ANSIThemeString(": Ignoring request to resume a completed installation. Exiting.", "default")], stderr = True)
				sys.exit(0)
			phase = __validate_task_index(setup_control_plane_tasks, phase)
		elif opt == "--cri":
			if optarg in ("docker-shim", "containerd", "cri-o"):
				cri = optarg
			else:
				ansithemeprint([ANSIThemeString("Error", "error"),
						ANSIThemeString(": Unknown CRI “", "default"),
						ANSIThemeString(f"{optarg}", "argument"),
						ANSIThemeString("“ specified; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)
		elif opt == "--override-cni":
			override_cni = True
		elif opt == "--save-ansible-logs":
			ansible_configuration["save_logs"] = True
		elif opt == "--enable-dra":
			enable_dra = True
		elif opt == "--verbose":
			verbose = True
		elif opt == "-Y":
			confirm = False
		elif opt == "--extra-values":
			extra_values = optarg
		elif opt == "--configuration-paths":
			configuration_paths = optarg

	configuration_path = merge_configurations(configuration_paths)

	setup_control_plane_targets[k8s_distro]["extra_values"] = {
		**extra_values,
		"configuration_path": configuration_path,
	}

	if enable_dra:
		dra_extra_values = {
			"api_server_feature_gates": "DynamicResourceAllocation=true",
			"api_server_runtime_config_api_alpha_enabled": "true",
			"controller_manager_feature_gates": "DynamicResourceAllocation=true",
			"scheduler_feature_gates": "DynamicResourceAllocation=true",
			"kubelet_feature_gates": "{ DynamicResourceAllocation: true }",
			"kubeproxy_feature_gates": "{ DynamicResourceAllocation: true }",
		}
		setup_control_plane_targets[k8s_distro]["extra_values"] = {
			**setup_control_plane_targets[k8s_distro]["extra_values"],
			**dra_extra_values,
		}

		# Override the feature-gate format if the parameters are passed via command-line;
		# e.g. when using RKE2
		if k8s_distro == "rke2":
			setup_control_plane_targets[k8s_distro]["extra_values"]["kubelet_feature_gates"] = "DynamicResourceAllocation=true"
			setup_control_plane_targets[k8s_distro]["extra_values"]["kubeproxy_feature_gates"] = "DynamicResourceAllocation=true"
	else:
		no_dra_extra_values = {
			"api_server_feature_gates": "",
			"api_server_runtime_config_api_alpha_enabled": "false",
			"controller_manager_feature_gates": "",
			"kubelet_feature_gates": "{}",
			"kubeproxy_feature_gates": "{}",
			"scheduler_feature_gates": "",
		}
		setup_control_plane_targets[k8s_distro]["extra_values"] = {
			**setup_control_plane_targets[k8s_distro]["extra_values"],
			**no_dra_extra_values,
		}

		# Override the feature-gate format if the parameters are passed via command-line;
		# e.g. when using RKE2
		if k8s_distro == "rke2":
			setup_control_plane_targets[k8s_distro]["extra_values"]["kubelet_feature_gates"] = ""
			setup_control_plane_targets[k8s_distro]["extra_values"]["kubeproxy_feature_gates"] = ""

	if k8s_distro == "kubeadm":
		# First remove the distro revision
		major_minor_patchrev = requested_version.split("-")
		# Now split the version tuple
		requested_major, requested_minor, _rest = major_minor_patchrev[0].split(".")

		if int(requested_minor) < 23:
			cluster_configuration_api_version = "kubeadm.k8s.io/v1beta2"
			init_configuration_api_version = "kubeadm.k8s.io/v1beta2"
		else:
			cluster_configuration_api_version = "kubeadm.k8s.io/v1beta3"
			init_configuration_api_version = "kubeadm.k8s.io/v1beta3"

		setup_control_plane_targets[k8s_distro]["extra_values"]["cluster_configuration_api_version"] = cluster_configuration_api_version
		setup_control_plane_targets[k8s_distro]["extra_values"]["init_configuration_api_version"] = init_configuration_api_version
		requested_major_minor = f"{requested_major}.{requested_minor}"

		# Add major/minor to extra_values
		setup_control_plane_targets[k8s_distro]["extra_values"]["kubernetes_major_minor_version"] = requested_major_minor
	elif k8s_distro == "rke2":
		if requested_version == "latest":
			if (kubernetes_upstream_version := get_latest_kubernetes_upstream_version()) is None:
				ansithemeprint([ANSIThemeString("Error", "error"),
						ANSIThemeString(": “", "default"),
						ANSIThemeString("latest", "version"),
						ANSIThemeString("“ was specified as version, but latest upstream version could not be found; aborting.", "default")], stderr = True)
				sys.exit(errno.ENOENT)
			version_split = kubernetes_upstream_version.split(".")
			requested_major = version_split[0]
			requested_minor = version_split[1]
			requested_major_minor = f"{requested_major}.{requested_minor}"
			# Add major/minor to extra_values
			setup_control_plane_targets[k8s_distro]["extra_values"]["kubernetes_major_minor_version"] = requested_major_minor
		else:
			# First remove the distro revision, if any
			major_minor_patchrev = requested_version.lstrip("v").split("-")
			# Now split the version tuple
			version_split = major_minor_patchrev[0].split(".")
			requested_major = version_split[0]
			requested_minor = version_split[1]
			requested_major_minor = f"{requested_major}.{requested_minor}"
			# Add major/minor to extra_values
			setup_control_plane_targets[k8s_distro]["extra_values"]["kubernetes_major_minor_version"] = requested_major_minor

		# Add requested_version to extra_values;
		# for rke2 this is either vX.YY or latest
		setup_control_plane_targets["rke2"]["extra_values"]["requested_version"] = requested_version

		# For now at least we disable the cloud controller
		rke2_disable_cloud_controller = True
		setup_control_plane_targets["rke2"]["extra_values"]["disable_cloud_controller"] = rke2_disable_cloud_controller
		# Disable canal since we install the CNI separately
		rke2_disabled_options_list = ["rke2-canal"]
		setup_control_plane_targets["rke2"]["extra_values"]["disabled_options_list"] = rke2_disabled_options_list

	if cri is None:
		if k8s_distro == "rke2":
			cri = "containerd"
		elif int(requested_minor) < 24:
			cri = "docker-shim"
		elif enable_dra:
			cri = "cri-o"
		else:
			cri = "containerd"
	else:
		if k8s_distro == "rke2":
			if cri == "docker-shim":
				ansithemeprint([ANSIThemeString("Error", "error"),
						ANSIThemeString(": CRI cannot be “", "default"),
						ANSIThemeString("docker-shim", "argument"),
						ANSIThemeString("“ for ", "default"),
						ANSIThemeString("RKE2", "argument"),
						ANSIThemeString("; aborting.", "default")], stderr = True)
				sys.exit(errno.ENOTSUP)
		elif int(requested_minor) >= 24 and cri == "docker-shim":
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": CRI cannot be “", "default"),
					ANSIThemeString("docker-shim", "argument"),
					ANSIThemeString("“ for ", "default"),
					ANSIThemeString("Kubernetes ", "programname"),
					ANSIThemeString(">= ", "default"),
					ANSIThemeString("1.24", "version"),
					ANSIThemeString("; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOTSUP)

	installation_info = update_installation_info(cri = cri)

	# Add the CRI to the setup playbooks for the control plane;
	# the list is short enough that doing prepend isn't a performance issue
	if cri == "docker-shim":
		setup_control_plane_targets[k8s_distro]["playbooks"].insert(0, FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("setup_docker.io.yaml"))))
	elif cri == "containerd":
		setup_control_plane_targets[k8s_distro]["playbooks"].insert(0, FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("setup_containerd.yaml"))))
	elif cri == "cri-o":
		setup_control_plane_targets[k8s_distro]["playbooks"].insert(0, FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("setup_cri-o.yaml"))))
		crio_major_version, crio_minor_version = get_crio_version((int(requested_major), int(requested_minor)))
		setup_control_plane_targets[k8s_distro]["extra_values"]["crio_major_version"] = crio_major_version
		setup_control_plane_targets[k8s_distro]["extra_values"]["crio_minor_version"] = crio_minor_version

	if cni is None or cni == "<none>":
		if k8s_distro == "rke2":
			default_cni = "canal"
		else:
			default_cni = DEFAULT_CNI
		if len(args) == 0:
			ansithemeprint([ANSIThemeString("Warning", "warning"),
					ANSIThemeString(": No CNI specified; defaulting to ", "default"),
					ANSIThemeString(f"{default_cni}", "programname"),
					ANSIThemeString(".", "default")], stderr = True)
			cni = default_cni
		elif cni != args[0]:
			cni = args[0]
	else:
		new_cni = cni
		if len(args) > 0:
			new_cni = args[0]

		if new_cni != cni:
			if not override_cni:
				ansithemeprint([ANSIThemeString("Error", "error"),
						ANSIThemeString(": Installation was previous initiated with ", "default"),
						ANSIThemeString(f"{cni}", "programname"),
						ANSIThemeString(" as CNI; ", "default"),
						ANSIThemeString("you can attempt to override this by using ", "default"),
						ANSIThemeString("--override-cni", "option"),
						ANSIThemeString(", but success is not guaranteed. Aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)
			else:
				ansithemeprint([ANSIThemeString("Warning", "warning"),
						ANSIThemeString(": Installation was previous initiated with ", "default"),
						ANSIThemeString(f"{cni}", "programname"),
						ANSIThemeString(" as CNI, ", "default"),
						ANSIThemeString("but ", "default"),
						ANSIThemeString("--override-cni", "option"),
						ANSIThemeString(" was specified; continuing installation.", "default")], stderr = True)
		cni = new_cni

	if cni != "none" and cni not in cni_upgrade_data:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": ", "default"),
				ANSIThemeString(f"{cni}", "argument"),
				ANSIThemeString(" is not a valid/supported CNI; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if len(args) > 1:
		new_pod_network_cidr = args[1]
	else:
		new_pod_network_cidr = DEFAULT_POD_NETWORK_CIDR
	if pod_network_cidr == "<none>" or pod_network_cidr == new_pod_network_cidr or phase == 0:
		pod_network_cidr = new_pod_network_cidr
	else:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Installation was previously initiated with ", "default"),
				ANSIThemeString(f"{pod_network_cidr}", "emphasis"),
				ANSIThemeString(" as Pod Network CIDR;\n", "default"),
				ANSIThemeString("changing this value in the middle of installation is not supported. Aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	update_installation_info(cni = cni, pod_network_cidr = pod_network_cidr, state = "installing", phase = phase, phase_skiplist = list(phase_skiplist))

	show_configuration(action = "Setting up control plane:", tasks = setup_control_plane_tasks)

	if confirm:
		retval = ansithemeinput([ANSIThemeString("\nStart installation? [y/", "default"),
					 ANSIThemeString("N", "emphasis"),
					 ANSIThemeString("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			ansithemeprint([ANSIThemeString("\nAborting:", "error"),
					ANSIThemeString(" User stopped installation.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	ansithemeprint([ANSIThemeString("\n[Setting up control plane]", "phase")])

	# Add the package versions to the package list
	if k8s_distro == "kubeadm":
		setup_control_plane_targets["localhost"]["deb_packages"].remove("kubectl")
		setup_control_plane_targets["localhost"]["deb_packages"].append(f"kubectl={requested_version}")
		setup_control_plane_targets["kubeadm"]["deb_packages"].remove("kubectl")
		setup_control_plane_targets["kubeadm"]["deb_packages"].append(f"kubectl={requested_version}")
		setup_control_plane_targets["kubeadm"]["deb_packages"].remove("kubeadm")
		setup_control_plane_targets["kubeadm"]["deb_packages"].append(f"kubeadm={requested_version}")
		setup_control_plane_targets["kubeadm"]["deb_packages"].remove("kubelet")
		setup_control_plane_targets["kubeadm"]["deb_packages"].append(f"kubelet={requested_version}")

		setup_control_plane_targets["localhost"]["fedora_packages"].remove("kubectl")
		setup_control_plane_targets["localhost"]["fedora_packages"].append(f"kubectl-{requested_version}")
		setup_control_plane_targets["localhost"]["fedora_packages_held"].remove("kubectl")
		setup_control_plane_targets["localhost"]["fedora_packages_held"].append(f"kubectl-{requested_version}")
		setup_control_plane_targets["kubeadm"]["fedora_packages"].remove("kubectl")
		setup_control_plane_targets["kubeadm"]["fedora_packages"].append(f"kubectl-{requested_version}")
		setup_control_plane_targets["kubeadm"]["fedora_packages"].remove("kubeadm")
		setup_control_plane_targets["kubeadm"]["fedora_packages"].append(f"kubeadm-{requested_version}")
		setup_control_plane_targets["kubeadm"]["fedora_packages"].remove("kubelet")
		setup_control_plane_targets["kubeadm"]["fedora_packages"].append(f"kubelet-{requested_version}")
		setup_control_plane_targets["kubeadm"]["fedora_packages_held"].remove("kubectl")
		setup_control_plane_targets["kubeadm"]["fedora_packages_held"].append(f"kubectl-{requested_version}")
		setup_control_plane_targets["kubeadm"]["fedora_packages_held"].remove("kubeadm")
		setup_control_plane_targets["kubeadm"]["fedora_packages_held"].append(f"kubeadm-{requested_version}")
		setup_control_plane_targets["kubeadm"]["fedora_packages_held"].remove("kubelet")
		setup_control_plane_targets["kubeadm"]["fedora_packages_held"].append(f"kubelet-{requested_version}")

		setup_control_plane_targets["localhost"]["suse_packages"].remove("kubectl")
		setup_control_plane_targets["localhost"]["suse_packages"].append(f"kubernetes{requested_major_minor}-client")
		setup_control_plane_targets["localhost"]["suse_packages_held"].remove("kubectl")
		setup_control_plane_targets["localhost"]["suse_packages_held"].append(f"kubernetes{requested_major_minor}-client")
		setup_control_plane_targets["kubeadm"]["suse_packages"].remove("kubectl")
		setup_control_plane_targets["kubeadm"]["suse_packages"].append(f"kubernetes{requested_major_minor}-client")
		setup_control_plane_targets["kubeadm"]["suse_packages"].remove("kubeadm")
		setup_control_plane_targets["kubeadm"]["suse_packages"].append(f"kubernetes{requested_major_minor}-kubeadm")
		setup_control_plane_targets["kubeadm"]["suse_packages"].remove("kubelet")
		setup_control_plane_targets["kubeadm"]["suse_packages"].append(f"kubernetes{requested_major_minor}-kubelet")
		setup_control_plane_targets["kubeadm"]["suse_packages_held"].remove("kubectl")
		setup_control_plane_targets["kubeadm"]["suse_packages_held"].append(f"kubernetes{requested_major_minor}-client")
		setup_control_plane_targets["kubeadm"]["suse_packages_held"].remove("kubeadm")
		setup_control_plane_targets["kubeadm"]["suse_packages_held"].append(f"kubernetes{requested_major_minor}-kubeadm")
		setup_control_plane_targets["kubeadm"]["suse_packages_held"].remove("kubelet")
		setup_control_plane_targets["kubeadm"]["suse_packages_held"].append(f"kubernetes{requested_major_minor}-kubelet")

	run_tasks(tasks = setup_control_plane_tasks, phase = cast(int, phase), phase_skiplist = phase_skiplist, final_state = "installed", verbose = verbose)
	update_installation_info(version = requested_version)

	ansithemeprint([ANSIThemeString("\nControl plane setup successful", "success")])

	if k8s_distro == "rke2":
		ansithemeprint([ANSIThemeString("\nNote", "note")])
		ansithemeprint([ANSIThemeString(": If this is an RKE2 installation you may need to substitute ", "default"),
				ANSIThemeString("127.0.0.1", "hostname")])
		ansithemeprint([ANSIThemeString("in ", "default"),
				ANSIThemeString(f"{KUBE_CONFIG_FILE}", "path"),
				ANSIThemeString(" with the real IP-address of this host.\n", "default")])

def __get_node_info(kh: Optional[kubernetes_helper.KubernetesHelper] = None) -> Tuple[List[Dict], kubernetes_helper.KubernetesHelper]:
	if not Path(KUBE_CONFIG_FILE).is_file():
		ansithemeprint([ANSIThemeString("Critical", "critical"),
				ANSIThemeString(": Could not find ", "default"),
				ANSIThemeString(f"{KUBE_CONFIG_FILE}", "path"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	# The reason for importing inside the function is to avoid slow startup
	# when we do not use the Kubernetes helper
	if kh is None:
		from kubernetes_helper import KubernetesHelper  # pylint: disable=import-outside-toplevel
		kh = KubernetesHelper(about.PROGRAM_SUITE_NAME, about.PROGRAM_SUITE_VERSION, None)

	# If kh is *still* None here something has gone wrong. It is time to exit.
	if kh is None:
		ansithemeprint([ANSIThemeString("Critical", "critical"),
				ANSIThemeString(": Failed to initialise connection to API-server; do you have a running cluster? Aborting.", "default")], stderr = True)
		sys.exit(errno.ENXIO)

	node_statuses = []

	vlist, status = kh.get_list_by_kind_namespace(("Node", ""), "")
	if status != 200:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": API-server returned ", "default"),
				ANSIThemeString(f"{status}", "errorvalue"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)
	if vlist is None:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": API-server did not return any data", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	for node in vlist:
		node_name = deep_get(node, DictPath("metadata#name"))
		node_schedulable = not deep_get(node, DictPath("spec#unschedulable"), False)
		node_roles = kh.get_node_roles(cast(Dict, node))
		node_taints = deep_get(node, DictPath("spec#taints"), [])
		node_statuses.append({
			"name": node_name,
			"schedulable": node_schedulable,
			"roles": node_roles,
			"taints": node_taints,
		})

	return node_statuses, kh

def get_control_planes(fail_on_empty: bool = True) -> List[Tuple[str, str]]:
	"""
	Get a list of control planes defined in the inventory

		Parameters:
			fail_on_empty (bool): If True the action will fail if no control planes are defined in the inventory
		Returns:
			control_planes (list[hostname, ip]): A list of control planes
				hostname (str): The hostname
				ip (str): The IP-address
	"""

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	if cluster_name is None:
		cluster_name = get_cluster_name()
	inventory = ansible_get_inventory_dict()
	__controlplanes = deep_get(inventory, DictPath("controlplane#hosts"), {})
	__clusterhosts = deep_get(inventory, DictPath(f"{cluster_name}#hosts"), {})
	controlplanes = []
	if len(__controlplanes) == 0 and fail_on_empty:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": No control plane(s) defined in the inventory; rebuilding the inventory using “", "default"),
				ANSIThemeString(f"{about.INVENTORY_PROGRAM_NAME} ", "programname"),
				ANSIThemeString("rebuild-inventory", "command"),
				ANSIThemeString("“ might help. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)
	if len(__clusterhosts) == 0 and fail_on_empty:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": The cluster ", "default"),
				ANSIThemeString(f"{cluster_name}", "hostname"),
				ANSIThemeString(" has no hosts in the inventory; rebuilding the inventory using “", "default"),
				ANSIThemeString(f"{about.INVENTORY_PROGRAM_NAME} ", "programname"),
				ANSIThemeString("rebuild-inventory", "command"),
				ANSIThemeString("“ might help. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	for controlplane in __controlplanes:
		# Only include control planes belonging to this cluster
		if controlplane not in __clusterhosts:
			continue
		ip = socket.gethostbyname(controlplane)
		controlplanes.append((controlplane, ip))
	return controlplanes

# pylint: disable-next=unused-argument
def teardown_control_plane(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Teardown an existing control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	confirm = True

	# We do not need a cluster name for --list-tasks, so check this first of all
	if "--list-tasks" in (tmp[0] for tmp in options):
		__list_phases(teardown_control_plane_tasks)
		sys.exit(0)

	if not Path(CMT_INSTALLATION_INFO_FILE).is_file():
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Could not find reliable installation information. Aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	installation_info = get_installation_info()
	cluster_name = deep_get(installation_info, DictPath("installation_target"))
	k8s_distro = deep_get(installation_info, DictPath(f"{cluster_name}#distro"))
	state = deep_get(installation_info, DictPath(f"{cluster_name}#state"))
	phase: Union[str, int] = deep_get(installation_info, DictPath(f"{cluster_name}#phase"))
	phase_skiplist = set(deep_get(installation_info, DictPath(f"{cluster_name}#phase_skiplist")))
	verbose = False

	if k8s_distro is None or k8s_distro == "<none>":
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Could not find reliable installation information. Aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if state is None:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Cannot determine installation state; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)
	elif state in ("preparing", "prepared", "torn_down"):
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": The system has no installed cluster; try ", "default"),
				ANSIThemeString(f"{about.ADMIN_PROGRAM_NAME}", "programname"),
				ANSIThemeString(" purge-control-plane", "command"),
				ANSIThemeString("; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	# If phase is "<done>" it's a holdover from a previous state
	if phase == "<done>":
		phase = 0

	for opt, optarg in options:
		if opt == "--start-at-task":
			phase = __validate_task_index(teardown_control_plane_tasks, optarg)
			if "--skip-tasks" not in options:
				phase_skiplist = set()
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(teardown_control_plane_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				ansithemeprint([ANSIThemeString("Warning", "warning"),
						ANSIThemeString(": Ignoring request to resume a completed teardown. Exiting.", "default")], stderr = True)
				sys.exit(0)
			phase = __validate_task_index(teardown_control_plane_tasks, phase)
		elif opt == "--save-ansible-logs":
			ansible_configuration["save_logs"] = True
		elif opt == "--verbose":
			verbose = True
		elif opt == "-Y":
			confirm = False

	installation_info = update_installation_info(state = "tearing_down", phase = phase, phase_skiplist = list(phase_skiplist))
	show_configuration(action = "Tearing down control plane", tasks = teardown_control_plane_tasks)

	if confirm:
		retval = ansithemeinput([ANSIThemeString("\nStart teardown? [y/", "default"),
					 ANSIThemeString("N", "emphasis"),
					 ANSIThemeString("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			ansithemeprint([ANSIThemeString("\nAborting:", "error"),
					ANSIThemeString(" User stopped teardown.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	ansithemeprint([ANSIThemeString("\n[Tearing down cluster]", "phase")])

	installation_info = update_installation_info(state = "tearing_down", phase = 0)

	run_tasks(tasks = teardown_control_plane_tasks, phase = cast(int, phase), phase_skiplist = phase_skiplist, final_state = "torn_down", verbose = verbose)
	ansithemeprint([ANSIThemeString("\nCluster teardown successful", "success")])

# pylint: disable-next=unused-argument
def purge_control_plane(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Purge an existing control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	confirm = True

	# We do not need a cluster name for --list-tasks, so check this first of all
	if "--list-tasks" in (tmp[0] for tmp in options):
		__list_phases(purge_control_plane_tasks)
		sys.exit(0)

	if not Path(CMT_INSTALLATION_INFO_FILE).is_file():
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Could not find reliable installation information. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	installation_info = get_installation_info()
	cluster_name = installation_info["installation_target"]
	state = installation_info[cluster_name]["state"]
	phase: Union[str, int] = installation_info[cluster_name]["phase"]
	phase_skiplist = set(installation_info[cluster_name]["phase_skiplist"])
	verbose = False

	if state is None or state not in ("prepared", "torn_down", "purging"):
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Invalid installation state; there's no prepared or torn down cluster; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	# If phase is "<done>" it's a holdover from a previous state;
	# if this is the case we need to start from phase 0 and ignore the skiplist
	if len(options) == 0 or phase == "<done>":
		phase = 0
		phase_skiplist = set()

	for opt, optarg in options:
		if opt == "--start-at-task":
			phase = __validate_task_index(purge_control_plane_tasks, optarg)
			if "--skip-tasks" not in options:
				phase_skiplist = set()
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(purge_control_plane_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				ansithemeprint([ANSIThemeString("Warning", "warning"),
						ANSIThemeString(": Ignoring request to resume a completed purge. Exiting.", "default")], stderr = True)
				sys.exit(0)
			phase = __validate_task_index(purge_control_plane_tasks, phase)
		elif opt == "--verbose":
			verbose = True
		elif opt == "--save-ansible-logs":
			ansible_configuration["save_logs"] = True
		elif opt == "-Y":
			confirm = False

	installation_info = update_installation_info(state = "purging", phase = phase, phase_skiplist = list(phase_skiplist))
	show_configuration(action = "Purging control plane:", tasks = purge_control_plane_tasks)

	if confirm:
		retval = ansithemeinput([ANSIThemeString("\nStart purge? [y/", "default"),
					 ANSIThemeString("N", "emphasis"),
					 ANSIThemeString("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			ansithemeprint([ANSIThemeString("\nAborting:", "error"),
					ANSIThemeString(" User stopped purge.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	ansithemeprint([ANSIThemeString("\n\n[Purging cluster configuration and software]", "phase")])

	# If we are purging the control plane we want to leave kubectl behind; if we have a setup with multiple
	# control planes and we run this from one of them, then kubectl will remain on the other two.
	if __selection_localhost() == __selection_control_planes():
		purge_control_plane_targets["kubeadm"]["deb_packages"].remove("kubectl")
		purge_control_plane_targets["kubeadm"]["deb_packages_held"].remove("kubectl")

	installation_info = update_installation_info(state = "purging", phase = 0)

	run_tasks(tasks = purge_control_plane_tasks, phase = cast(int, phase), phase_skiplist = phase_skiplist, final_state = "purged", verbose = verbose)
	secure_rm(CMT_INSTALLATION_INFO_FILE, ignore_non_existing = True)

	ansithemeprint([ANSIThemeString("\nCluster purge successful", "success")])

	ansithemeprint([ANSIThemeString("\nNote", "note"),
			ANSIThemeString(": It is recommended to reboot the control plane(s) after purging the cluster\n", "default")])

def upgrade_control_plane(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Upgrade a control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	confirm = True

	# default options
	update_cache = True
	allow_reinstall = False
	requested_version = None

	# We do not need a cluster name for --list-tasks or --override, so check this first of all
	if "--list-tasks" in (tmp[0] for tmp in options):
		__list_phases(upgrade_control_plane_tasks)
		sys.exit(0)
	elif "--override" in (tmp[0] for tmp in options):
		if Path(CMT_INSTALLATION_INFO_FILE).is_file():
			ansithemeprint([ANSIThemeString("Warning", "warning"),
					ANSIThemeString(": Overriding ", "default"),
					ANSIThemeString(f"{CMT_INSTALLATION_INFO_FILE}", "path"),
					ANSIThemeString("; this may cause issues.", "default")], stderr = True)
		else:
			ansithemeprint([ANSIThemeString("Note", "note"),
					ANSIThemeString(": ", "default"),
					ANSIThemeString(f"{CMT_INSTALLATION_INFO_FILE}", "path"),
					ANSIThemeString(" does not exist; rebuilding.", "default")])
		rebuild_installation_info(state = "upgrading")

	# This is the cluster name according to .kube/config; this is what we care about when upgrading,
	# not whatever is currently set as the target in installation info
	cluster_name = get_cluster_name()
	installation_info = get_installation_info()
	installation_info = update_installation_info(installation_target = cluster_name)

	cluster_name = deep_get(installation_info, DictPath("installation_target"))
	os_distro = identify_distro()
	k8s_distro = deep_get(installation_info, DictPath(f"{cluster_name}#distro"))
	version = deep_get(installation_info, DictPath(f"{cluster_name}#version"))
	requested_version = deep_get(installation_info, DictPath(f"{cluster_name}#requested_version"))
	state = deep_get(installation_info, DictPath(f"{cluster_name}#state"))
	phase: Union[str, int] = deep_get(installation_info, DictPath(f"{cluster_name}#phase"))
	phase_skiplist = set(deep_get(installation_info, DictPath(f"{cluster_name}#phase_skiplist")))
	verbose = False

	if state is None or state == "<none>":
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Unknown installation state; if you believe this is OK (such as when upgrading a cluster not installed using ", "default"),
				ANSIThemeString(f"{about.ADMIN_PROGRAM_NAME}", "programname"),
				ANSIThemeString(" you can try using the “", "default"),
				ANSIThemeString("--override", "option"),
				ANSIThemeString("“ option; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if state in ("preparing", "prepared", "installing", "tearing_down", "torn_down", "purging"):
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Invalid installation state; Kubernetes does not seems to be fully installed; aborting.", "default")], stderr = True)
		sys.exit(errno.EINVAL)

	if state in ("installed", "upgraded"):
		phase = 0

	for opt, optarg in options:
		if opt == "--start-at-task":
			phase = __validate_task_index(upgrade_control_plane_tasks, optarg)
			if "--skip-tasks" not in options:
				phase_skiplist = set()
		elif opt == "--skip-tasks":
			skip_phases = __expand_index_list(optarg)
			for __phase in skip_phases:
				__validate_task_index(upgrade_control_plane_tasks, __phase)
			phase_skiplist = set(skip_phases)
		elif opt == "--resume":
			if phase is None or phase == "<none>":
				phase = 0
			elif phase == "<done>":
				ansithemeprint([ANSIThemeString("Warning", "warning"),
						ANSIThemeString(": Ignoring request to resume a completed upgrade. Exiting.", "default")], stderr = True)
				sys.exit(0)
			phase = __validate_task_index(upgrade_control_plane_tasks, phase)
		elif opt == "--no-cache-update":
			update_cache = False
		elif opt == "--reinstall":
			allow_reinstall = True
		elif opt in ("--override", "--list-tasks"):
			continue
		elif opt == "--verbose":
			verbose = True
		elif opt == "--save-ansible-logs":
			ansible_configuration["save_logs"] = True
		elif opt == "-Y":
			confirm = False

	# XXX: How do we check that nodes are drained? We can check whether they are cordoned
	node_status, _kh = __get_node_info()

	if node_status is None:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": No ", "default"),
				ANSIThemeString(f"{HOMEDIR}/.kube/config", "path"),
				ANSIThemeString(" available; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	ansithemeprint([ANSIThemeString("\n[Preparing upgrade]", "phase")])

	# The first patch revision that isn't available from the old repositories is 1.28.3;
	# this means that we need to include all minor versions from 28 and up.
	if (kubernetes_upstream_version := get_latest_kubernetes_upstream_version()) is None:
		ansithemeprint([ANSIThemeString("Error", "error"),
				ANSIThemeString(": Could not get the latest upstream Kubernetes version; ", "default"),
				ANSIThemeString("this is either a network error or a bug; aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

	# Split the version tuple
	upstream_major, upstream_minor, _rest = kubernetes_upstream_version.split(".")
	minor_versions = []
	for minor_version in range(28, int(upstream_minor) + 1):
		minor_versions.append(f"{minor_version}")

	if update_cache:
		ansithemeprint([ANSIThemeString("\n• ", "separator"),
				ANSIThemeString("Updating version cache", "action")])

		extra_values = {
			"minor_versions": minor_versions,
		}

		ansithemeprint([ANSIThemeString("\n• ", "separator"),
				ANSIThemeString("Updating Kubernetes repository files on localhost and controlplane(s)", "action")])
		selection = __selection_control_planes() + ["localhost"]
		retval, _ansible_results = run_playbook(FilePath(str(PurePath(ANSIBLE_PLAYBOOK_DIR).joinpath("add_kubernetes_repo.yaml"))),
							hosts = selection, extra_values = extra_values, quiet = True)

		if os_distro == "debian" and update_cache:
			ansithemeprint([ANSIThemeString("\n• ", "separator"),
					ANSIThemeString("Updating APT cache", "action")])
			check_and_print_status(update_apt_cache())
		ansithemeprint([ANSIThemeString("\n• ", "separator"),
				ANSIThemeString("Updating version cache", "action")])
		check_and_print_status(update_version_cache())

	if len(args) > 0:
		requested_version = __find_requested_version(k8s_distro, args[0])
	else:
		requested_version = __find_requested_version(k8s_distro, f"{upstream_major}.{upstream_minor}")

	ansithemeprint([ANSIThemeString("\n• ", "separator"),
			ANSIThemeString("Running sanity checks", "action")])

	if k8s_distro == "kubeadm":
		if os_distro in ("debian",):
			pkg_versions = check_versions_apt(["kubeadm"])
		elif os_distro in ("suse",):
			pkg_versions = check_versions_zypper(["kubeadm"])
		elif os_distro in ("fedora", "rhel",):
			pkg_versions = check_versions_yum(["kubeadm"])

		if len(pkg_versions) == 0:
			ansithemeprint([ANSIThemeString("Critical", "critical"),
					ANSIThemeString(": No candidate version for ", "default"),
					ANSIThemeString("kubeadm", "programname"),
					ANSIThemeString(" available; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOENT)

		if requested_version is not None:
			if requested_version not in pkg_versions[0][3]:
				ansithemeprint([ANSIThemeString("Error", "error"),
						ANSIThemeString(": The requested version ", "default"),
						ANSIThemeString(f"{requested_version}", "version"),
						ANSIThemeString(" is not available; aborting.", "default")], stderr = True)
				sys.exit(errno.ENOENT)
			elif requested_version == version:
				if not allow_reinstall:
					ansithemeprint([ANSIThemeString("Warning", "warning"),
							ANSIThemeString(": The requested version ", "default"),
							ANSIThemeString(f"{requested_version}", "version"),
							ANSIThemeString(" is already installed; to reinstall use the option “", "default"),
							ANSIThemeString("--reinstall", "option"),
							ANSIThemeString("“.", "default")], stderr = True)
					sys.exit(errno.EINVAL)
			elif os_distro == "debian" and deb_compare_versions(version, requested_version):
				ansithemeprint([ANSIThemeString("Error", "error"),
						ANSIThemeString(": The requested version ", "default"),
						ANSIThemeString(f"{requested_version}", "version"),
						ANSIThemeString(" is older than than the installed version ", "default"),
						ANSIThemeString(f"{pkg_versions[0][1]}", "version"),
						ANSIThemeString(". Downgrades are not supported; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)
			# FIXME: Implement version checking for Fedora/RHEL packages
		else:
			requested_version = pkg_versions[0][2]
			if len(requested_version) == 0 or requested_version == "<none>":
				ansithemeprint([ANSIThemeString("Note", "note"),
						ANSIThemeString(": The latest version ", "default"),
						ANSIThemeString(f"{pkg_versions[0][1]}", "version"),
						ANSIThemeString(" is already installed.", "default")])
				sys.exit(0)

		# Is this an major, minor, or patchrev upgrade?
		installed_version_tuple = version.split(".")
		requested_version_tuple = requested_version.split(".")

		upgrade_type = None

		if installed_version_tuple[0] != requested_version_tuple[0]:
			ansithemeprint([ANSIThemeString("Error", "error"),
					ANSIThemeString(": Upgrades between ", "default"),
					ANSIThemeString("MAJOR", "emphasis"),
					ANSIThemeString(" versions is currently not supported (installed version: ", "default"),
					ANSIThemeString(f"{pkg_versions[0][1]}", "version"),
					ANSIThemeString(", requested version: ", "default"),
					ANSIThemeString(f"{requested_version}", "version"),
					ANSIThemeString("; aborting.", "default")], stderr = True)
			sys.exit(errno.ENOTSUP)
		elif installed_version_tuple[1] != requested_version_tuple[1]:
			if int(requested_version_tuple[1]) - int(installed_version_tuple[1]) > 1:
				ansithemeprint([ANSIThemeString("Error", "error"),
						ANSIThemeString(": Skipping ", "default"),
						ANSIThemeString("MINOR", "emphasis"),
						ANSIThemeString(" versions is not supported, please perform the following upgrades sequentially:", "default")], stderr = True)
				minor_versions: Dict = {}
				for version in reversed(pkg_versions[0][3]):
					version_tuple = version.split(".")
					major_minor = f"{version_tuple[0]}.{version_tuple[1]}"
					if int(version_tuple[1]) > int(installed_version_tuple[1]) and int(version_tuple[1]) <= int(requested_version_tuple[1]) and (major_minor not in minor_versions or minor_versions[major_minor] < version_tuple[2]):
						minor_versions[major_minor] = version_tuple[2].split("-")[0]
				for version, minor_version in minor_versions.items():
					ansithemeprint([ANSIThemeString("• ", "separator"),
							ANSIThemeString(f"{about.ADMIN_PROGRAM_NAME}", "programname"),
							ANSIThemeString(" upgrade-control-plane", "command"),
							ANSIThemeString(f" {version}.{minor_version}", "version")])
				sys.exit(errno.EINVAL)
			else:
				upgrade_type = "minor"
		else:
			upgrade_type = "patchrev"

		# If this is an upgrade to a new patchrev the cluster does not have to be drained
		if upgrade_type == "minor":
			schedulable_count = 0
			nodes_to_drain = []
			for node in node_status:
				if not node["schedulable"]:
					continue

				if "control-plane" in node["roles"]:
					continue

				if schedulable_count == 0:
					ansithemeprint([ANSIThemeString("\nError", "error"),
							ANSIThemeString(": The following nodes need to be drained; aborting.", "default")])
				schedulable_count += 1
				ansithemeprint([ANSIThemeString("• ", "separator"),
						ANSIThemeString(f"{node['name']}", "emphasis")])
				nodes_to_drain.append(node['name'])

			if schedulable_count > 0:
				ansithemeprint([ANSIThemeString("\nThis can be achieved with: “", "default"),
						ANSIThemeString("kubectl ", "programname"),
						ANSIThemeString("drain ", "command"),
						ANSIThemeString("--ignore-daemonsets --delete-emptydir-data ", "option"),
						ANSIThemeString(f"{' '.join(nodes_to_drain)}", "url"),
						ANSIThemeString("“", "default")])
				sys.exit(errno.EBUSY)

		# First remove the distro revision
		major_minor_patchrev = requested_version.split("-")
		# Now split the version tuple
		requested_major, requested_minor, _rest = major_minor_patchrev[0].split(".")

		if int(requested_minor) < 23:
			cluster_configuration_api_version = "kubeadm.k8s.io/v1beta2"
			init_configuration_api_version = "kubeadm.k8s.io/v1beta2"
		else:
			cluster_configuration_api_version = "kubeadm.k8s.io/v1beta3"
			init_configuration_api_version = "kubeadm.k8s.io/v1beta3"

		upgrade_control_plane_targets[k8s_distro]["extra_values"] = {
			"cluster_configuration_api_version": cluster_configuration_api_version,
			"init_configuration_api_version": init_configuration_api_version,
			# Add major/minor to extra_values
			"kubernetes_major_minor_version": f"{requested_major}.{requested_minor}",
		}

		# Adjust package version for localhost
		upgrade_control_plane_targets["localhost"]["deb_packages"].remove("kubectl")
		upgrade_control_plane_targets["localhost"]["deb_packages"].append(f"kubectl={requested_version}")

		upgrade_control_plane_targets["localhost"]["fedora_packages"].remove("kubectl")
		upgrade_control_plane_targets["localhost"]["fedora_packages"].append(f"kubectl-{requested_version}")
	elif k8s_distro == "rke2":
		# Add requested_version to extra_values;
		# for rke2 this is either vX.YY or latest
		upgrade_control_plane_targets["rke2"]["extra_values"]["requested_version"] = requested_version

	installation_info = update_installation_info(state = "upgrading", requested_version = requested_version, phase = 0)

	# If we got here all the sanity checks were successful
	ansithemeprint([ANSIThemeString("OK", "ok")])

	show_configuration(action = "Upgrading control plane:", tasks = upgrade_control_plane_tasks)

	if confirm:
		retval = ansithemeinput([ANSIThemeString("\nStart upgrade? [y/", "default"),
					 ANSIThemeString("N", "emphasis"),
					 ANSIThemeString("]: ", "default")])
		if retval.lower() not in ("y", "yes"):
			ansithemeprint([ANSIThemeString("\nAborting:", "error"),
					ANSIThemeString(" User stopped upgrade.", "default")], stderr = True)
			sys.exit(errno.EINTR)

	ansithemeprint([ANSIThemeString("\n[Upgrading control plane]", "phase")])

	run_tasks(tasks = upgrade_control_plane_tasks, phase = cast(int, phase), phase_skiplist = phase_skiplist, final_state = "upgraded", verbose = verbose)
	values = {
		"control_plane_k8s_version": requested_version,
	}
	ansible_set_vars(ANSIBLE_INVENTORY, "all", values)
	update_installation_info(version = requested_version)

	ansithemeprint([ANSIThemeString("\nControl plane upgrade successful", "success")])

# pylint: disable-next=unused-argument
def taint_control_plane(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Taint a control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	node_statuses, kh = __get_node_info()

	if node_statuses is None:
		ansithemeprint([ANSIThemeString("Critical", "critical"),
				ANSIThemeString(": Failed to get node information; do you have a running cluster? Aborting.", "default")], stderr = True)
		sys.exit(errno.ENXIO)

	first = True

	for node in node_statuses:
		if "control-plane" in node["roles"] and (len(args) == 0 or node["name"] in args):
			if first:
				ansithemeprint([ANSIThemeString("Tainting control plane(s):", "header")])
				first = False
			ansithemeprint([ANSIThemeString(node["name"], "hostname")])
			_message, status = kh.taint_node(node["name"], node["taints"], ("node-role.kubernetes.io/control-plane", None, None, "NoSchedule"))
			if status == 304:
				ansithemeprint([ANSIThemeString("  Not modified", "none")])
			elif status == 200:
				ansithemeprint([ANSIThemeString("  Tainted", "success")])
			else:
				ansithemeprint([ANSIThemeString("  Failed to modify taint", "error"),
						ANSIThemeString(f"; HTTP error {status}; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)

		if "master" in node["roles"] and (len(args) == 0 or node["name"] in args):
			if first:
				ansithemeprint([ANSIThemeString("Tainting control plane(s):", "header")])
				first = False
			ansithemeprint([ANSIThemeString(node["name"], "hostname")])
			_message, status = kh.taint_node(node["name"], node["taints"], ("node-role.kubernetes.io/master", None, None, "NoSchedule"))
			if status == 304:
				ansithemeprint([ANSIThemeString("  Not modified", "none")])
			elif status == 200:
				ansithemeprint([ANSIThemeString("  Tainted", "success")])
			else:
				ansithemeprint([ANSIThemeString("  Failed to modify taint", "error"),
						ANSIThemeString(f"; HTTP error {status}; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)

	if first:
		ansithemeprint([ANSIThemeString("Warning", "warning"),
				ANSIThemeString(": No matching control planes found. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

# pylint: disable-next=unused-argument
def untaint_control_plane(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Untaint a control plane

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	node_statuses, kh = __get_node_info()

	if node_statuses is None:
		ansithemeprint([ANSIThemeString("Critical", "critical"),
				ANSIThemeString(": Failed to get node information; do you have a running cluster? Aborting.", "default")], stderr = True)
		sys.exit(errno.ENXIO)

	first = True

	for node in node_statuses:
		if "control-plane" in node["roles"] and (len(args) == 0 or node["name"] in args):
			if first:
				ansithemeprint([ANSIThemeString("Untainting control plane(s):", "header")])
				first = False
			ansithemeprint([ANSIThemeString(node["name"], "hostname")])
			_message, status = kh.taint_node(node["name"], node["taints"], ("node-role.kubernetes.io/control-plane", None, None, None))
			if status == 304:
				ansithemeprint([ANSIThemeString("  Not modified", "none")])
			elif status == 200:
				ansithemeprint([ANSIThemeString("  Untainted", "success")])
			else:
				ansithemeprint([ANSIThemeString("  Failed to modify taint", "error"),
						ANSIThemeString(f"; HTTP error {status}; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)

		if "master" in node["roles"] and (len(args) == 0 or node["name"] in args):
			if first:
				ansithemeprint([ANSIThemeString("Untainting control plane(s):", "header")])
				first = False
			ansithemeprint([ANSIThemeString(node["name"], "hostname")])
			_message, status = kh.taint_node(node["name"], node["taints"], ("node-role.kubernetes.io/master", None, None, None))
			if status == 304:
				ansithemeprint([ANSIThemeString("  Not modified", "none")])
			elif status == 200:
				ansithemeprint([ANSIThemeString("  Untainted", "success")])
			else:
				ansithemeprint([ANSIThemeString("  Failed to modify taint", "error"),
						ANSIThemeString(f"; HTTP error {status}; aborting.", "default")], stderr = True)
				sys.exit(errno.EINVAL)

	if first:
		ansithemeprint([ANSIThemeString("Warning", "warning"),
				ANSIThemeString(": No matching control planes found. Aborting.", "default")], stderr = True)
		sys.exit(errno.ENOENT)

# pylint: disable=unused-argument,redefined-outer-name
def run_checks(checks: List[Dict], **kwargs) -> bool:
	"""
	Run a batch of checks, and output the result.
	The checks can return 4 different severities; critical, error, warning, and note.

		Parameters:
			checks (list[dict]): A list with all checks to run
		Return:
			clean_run (bool): True if nothing higher than "note" was returned, False otherwise
	"""

	abort: bool = False
	critical: int = 0
	error: int = 0
	warning: int = 0
	note: int = 0
	skip: int = 0

	user = ""
	cluster_name = ""
	kubeconfig: Dict = {}

	for check in checks:
		preconditions = deep_get(check, DictPath("preconditions"), [])
		if "user" in preconditions and len(user) == 0:
			user = getuser()
		if "clusterinfo" in preconditions and len(kubeconfig) == 0:
			if not Path(KUBE_CONFIG_DIR).is_dir():
				ansithemeprint([ANSIThemeString(deep_get(check, DictPath("description"), ""), "phase")])
				ansithemeprint([ANSIThemeString("  Warning:", "warning"),
						ANSIThemeString(f" {KUBE_CONFIG_DIR} ", "path"),
						ANSIThemeString("does not exist; most likely there's no cluster; skipping.\n", "default")], stderr = True)
				skip += 1
				continue
			if not Path(KUBE_CONFIG_FILE).is_file():
				ansithemeprint([ANSIThemeString(deep_get(check, DictPath("description"), ""), "phase")])
				ansithemeprint([ANSIThemeString("  Warning:", "warning"),
						ANSIThemeString(f" {KUBE_CONFIG_FILE} ", "path"),
						ANSIThemeString("does not exist; most likely there's no cluster; skipping.\n", "default")], stderr = True)
				skip += 1
				continue
			kubeconfig = secure_read_yaml(KUBE_CONFIG_FILE)
			cluster_name = cast(str, get_cluster_name())

		call = deep_get(check, DictPath("call"))
		if call is not None:
			abort, critical, error, warning, note = call(cluster_name, kubeconfig, cmtlib.cmtconfig, user, critical, error, warning, note, **kwargs)
			if abort:
				break

	ansithemeprint([ANSIThemeString("Summary:", "header")])
	ansithemeprint([ANSIThemeString("Critical", "critical"),
			ANSIThemeString(f": {critical}", "error")])
	ansithemeprint([ANSIThemeString(f"  Errors: {error}", "error")])
	ansithemeprint([ANSIThemeString(f"Warnings: {warning}", "warning")])
	ansithemeprint([ANSIThemeString(f" Skipped: {skip}", "emphasis")])
	ansithemeprint([ANSIThemeString(f"   Notes: {note}", "note")])
	if abort:
		ansithemeprint([ANSIThemeString("Testing aborted due to critical error.", "error")])

	return critical + error + warning == 0

security_audit_checks = [
	{
		"description": "Check whether strict host key checking has been disabled",
		"call": checks.check_security_disable_strict_host_key_checking,
	},
	{
		"description": "Check for insecure kubeconfig options",
		"call": checks.check_insecure_kube_config_options,
		"preconditions": [
			"clusterinfo",
		],
	}, {
		"description": "Check for insecure file permissions",
		"call": checks.check_file_permissions,
		"preconditions": [
			"user",
		],
	},
]

# pylint: disable-next=unused-argument
def audit(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Run security audit checks

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	usergroup = ""
	usergroup_autodetect = True

	for opt, optarg in options:
		if opt == "--usergroup":
			usergroup = optarg
		elif opt == "--disable-usergroup-autodetect":
			usergroup_autodetect = False

	# Get the username and group for the user;
	# if they match it's highly likely that the system
	# is configured to use usergroups
	uid = os.getuid()
	username = pwd.getpwuid(uid).pw_name
	gid = pwd.getpwuid(uid).pw_gid
	groupname = grp.getgrgid(gid).gr_name

	if len(usergroup) == 0 and usergroup_autodetect:
		logindefs = secure_read_string(FilePath("/etc/login.defs"))
		usergroups_regex = re.compile(r"^USERGROUPS_ENAB\s+yes")
		for line in logindefs.splitlines():
			tmp = usergroups_regex.match(line)
			if tmp is not None:
				usergroup = groupname

	kwargs = {
		"usergroup": usergroup
	}

	clean_run = run_checks(security_audit_checks, **kwargs)

	if clean_run:
		ansithemeprint([ANSIThemeString("\nImportant", "emphasis"),
				ANSIThemeString(":", "default")])
		ansithemeprint([ANSIThemeString(f"  {about.ADMIN_PROGRAM_NAME}", "programname"),
				ANSIThemeString(" audit", "command"),
				ANSIThemeString(" currently only checks for a very limited set of issues;", "default")])
		ansithemeprint([ANSIThemeString("  a perfect score is not a guarantee that your installation is secure.", "default")])
	elif len(usergroup) == 0:
		if username == groupname:
			ansithemeprint([ANSIThemeString("\nNote", "emphasis"),
					ANSIThemeString(":", "default"),
					ANSIThemeString(" the username for the current user “", "default"),
					ANSIThemeString(f"{username}", "argument"),
					ANSIThemeString("“ is the same", "default")])
			ansithemeprint([ANSIThemeString("as its primary group name. This may be an indication ", "default"),
					ANSIThemeString("that the system", "default")])
			ansithemeprint([ANSIThemeString("is configured to use usergroups; if you're seeing warnings related", "default")])
			ansithemeprint([ANSIThemeString("to file permissions this ", "default"),
					ANSIThemeString("might", "emphasis"),
					ANSIThemeString(" be the cause; if you know (or think) that", "default")])
			ansithemeprint([ANSIThemeString("the system is configured with usergroups you can try:\n", "default")])
			ansithemeprint([ANSIThemeString(f"  {about.ADMIN_PROGRAM_NAME} ", "programname"),
					ANSIThemeString("audit ", "command"),
					ANSIThemeString("--usergroup ", "option"),
					ANSIThemeString(f"{username}", "argument")])
			ansithemeprint([ANSIThemeString("\nto see if that resolves the warnings.", "default")])

preflight_checks = [
	{
		"description": "Check whether permissions for .netrc are strict enough",
		"call": checks.check_netrc_permissions,
		"preconditions": [
			"user",
		],
	}, {
		"description": "Check whether the user can sudo without a password on localhost",
		"call": checks.check_sudo_configuration,
		"preconditions": [
			"user",
		],
	}, {
		"description": "Check whether SSH known_hosts hashing is enabled on localhost",
		"call": checks.check_known_hosts_hashing,
	}, {
		"description": "Check control plane for suitability",
		"call": checks.check_control_plane,
	}
]

def preflight_check(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Run preflight checks before creating a new cluster

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	global no_password  # pylint: disable=global-statement

	for opt, _optarg in options:
		if opt == "--no-password":
			no_password = True

	control_planes = [args[0]]

	ansible_add_hosts(inventory = ANSIBLE_INVENTORY, hosts = control_planes, skip_all = False)

	__task_request_ansible_password(installation_info = {})

	clean_run = run_checks(preflight_checks, hosts = control_planes)

	if clean_run:
		ansithemeprint([ANSIThemeString("\nImportant", "emphasis"),
				ANSIThemeString(":", "default")])
		ansithemeprint([ANSIThemeString(f"  {about.ADMIN_PROGRAM_NAME}", "programname"),
				ANSIThemeString(" preflight-check", "command"),
				ANSIThemeString(" currently only checks for a very limited set of issues;", "default")])
		ansithemeprint([ANSIThemeString("  a perfect score is not a guarantee that installation will succeed.", "default")])

troubleshoot_checks = [
	# First start with the really basic: does the cluster respond?
	# Check no_proxy, perhaps?
	{
		"description": "Check whether client / server versions match",
		"call": checks.check_client_server_version_match,
		"preconditions": [
			"clusterinfo",
		],
	}, {
		"description": "Check kubelet and kube-proxy versions",
		"call": checks.check_kubelet_and_kube_proxy_versions,
		"preconditions": [
			"clusterinfo",
		],
	}, {
		"description": "Check required pods and their statuses",
		"call": checks.check_running_pods,
	},
	# Check kube-controller-manager, kube-scheduler, and cloud-controller-manager;
	# they should match, but can be up to one version older,
	# but must not be newer

	# check whether role bindings and cluster role bindings refer to non-existing roles/cluster roles
]

# pylint: disable-next=unused-argument
def troubleshoot(options: List[Tuple[str, str]], args: List[str]) -> None:
	"""
	Troubleshoot issues in the cluster

		Parameters:
			options (list[(opt, optarg)]): Options to use when executing this action
			args (list[str]): Arguments to use when executing this action
	"""

	clean_run = run_checks(troubleshoot_checks)

	if clean_run:
		ansithemeprint([ANSIThemeString("\nImportant", "emphasis"),
				ANSIThemeString(":", "default")])
		ansithemeprint([ANSIThemeString(f"  {about.ADMIN_PROGRAM_NAME}", "programname"),
				ANSIThemeString(" troubleshoot", "command"),
				ANSIThemeString(" currently only checks for a very limited set of issues;", "default")])
		ansithemeprint([ANSIThemeString("  a perfect score is not a guarantee that your cluster is problem free.", "default")])

COMMANDLINE = {
	"Check Versions": {
		"command": ["check-versions", "cv"],
		"description": [ANSIThemeString("Update the package cache and show software versions", "description")],
		"extended_description": [
			[ANSIThemeString("Note", "note"),
			 ANSIThemeString(": some of the listed software may not be", "description")],
			[ANSIThemeString("relevant to the configuration in use", "description")],
		],
		"options": {
			"--no-cache-update": {
				"description": [ANSIThemeString("Do not update the APT cache", "description")],
			},
		},
		"callback": check_for_updates,
	},
	"Import Cluster": {
		"command": ["import-cluster"],
		"values": [ANSIThemeString("[", "separator"),
			   ANSIThemeString("CLUSTER_NAME", "argument"),
			   ANSIThemeString(",", "separator"),
			   ANSIThemeString("...", "argument"),
			   ANSIThemeString("]", "separator")],
		"description": [ANSIThemeString(f"Import existing cluster(s) for use with {about.PROGRAM_SUITE_NAME}", "description")],
		"extended_description": [
			[ANSIThemeString("If ", "description"),
			 ANSIThemeString("CLUSTER_NAME", "argument"),
			 ANSIThemeString(",", "separator"),
			 ANSIThemeString("...", "argument"),
			 ANSIThemeString(" is not specified", "description")],
			[ANSIThemeString("all clusters in ", "description"),
			 ANSIThemeString("~/.kube/config", "path")],
			[ANSIThemeString("will be imported", "description")],
		],
		"options": {
			"-Y": {
				"description": [ANSIThemeString("Do not ask for confirmation", "description")],
			},
			"--no-password": {
				"description": [ANSIThemeString("Do not prompt for a password", "description")],
				"extended_description": [
					[ANSIThemeString("Use this if the hosts you are importing", "description")],
					[ANSIThemeString("are already configured for login using an SSH key", "description")],
				],
			},
		},
		"optional_args": [
			{
				"name": "clustername",
				"string": [ANSIThemeString("CLUSTER_NAME", "argument")],
				"validation": {
					"validator": "hostname",
					"list_separator": ",",
				},
			},
		],
		"callback": import_cluster,
	},
	"Prepare Installation": {
		"command": ["prepare"],
		"values": [ANSIThemeString("CLUSTER_NAME", "argument"),
			   ANSIThemeString(" [[", "separator"),
			   ANSIThemeString("KUBERNETES_DISTRO", "argument"),
			   ANSIThemeString("=]", "separator"),
			   ANSIThemeString("KUBERNETES_VERSION", "argument"),
			   ANSIThemeString("]", "separator")],
		"description": [ANSIThemeString("Install and configure pre-requisites", "description")],
		"extended_description": [
			[ANSIThemeString("Run this before ", "description"),
			 ANSIThemeString("setup-control-plane", "command"),
			 ANSIThemeString(".", "description")],
			[ANSIThemeString("If ", "description"),
			 ANSIThemeString("KUBERNETES_VERSION", "argument"),
			 ANSIThemeString(" is not specified", "description")],
			[ANSIThemeString("the newest available version will be used.", "description")],
			[ANSIThemeString("Supported versions for ", "description"),
			 ANSIThemeString("KUBERNETES_DISTRO", "argument"),
			 ANSIThemeString(" are:", "description")],
			[ANSIThemeString("kubeadm", "argument"),
			 ANSIThemeString(" (default)", "description")],
			[ANSIThemeString("rke2", "argument")],
		],
		"options": {
			"--control-plane": {
				"values": [ANSIThemeString("HOST", "argument")],
				"extended_description": [
					[ANSIThemeString("Note", "note"),
					 ANSIThemeString(": if possible ", "description"),
					 ANSIThemeString("HOST", "argument"),
					 ANSIThemeString(" should be a resolvable", "description")],
					[ANSIThemeString("hostname; using an IP-address may cause issues", "description")],
				],
				"description": [ANSIThemeString("Use ", "description"),
						ANSIThemeString("HOST", "argument"),
						ANSIThemeString(" as control plane ", "description")],
				"requires_arg": True,
				"validation": {
					"validator": "hostname_or_ip",
				},
			},
			"--resume": {
				"description": [ANSIThemeString("Resume preparation", "description")],
				"extended_description": [
					[ANSIThemeString("This can be used to resume operations", "description")],
					[ANSIThemeString("if preparation was aborted", "description")],
				],
			},
			"--start-at-task": {
				"values": [ANSIThemeString("TASK", "argument")],
				"description": [ANSIThemeString("Start at ", "description"),
						ANSIThemeString("TASK", "argument"),
						ANSIThemeString(" instead of running all tasks", "description")],
				"requires_arg": True,
				"validation": {
					"validator": "int",
					"valid_range": (0, None),
				},
			},
			"--skip-tasks": {
				"values": [ANSIThemeString("TASK", "argument"),
					   ANSIThemeString(",", "separator"),
					   ANSIThemeString("...", "argument")],
				"description": [ANSIThemeString("Skip ", "description"),
						ANSIThemeString("TASK", "argument"),
						ANSIThemeString(",", "separator"),
						ANSIThemeString("...", "argument")],
				"requires_arg": True,
				"validation": {
					"validator": "int",
					"valid_range": (0, None),
					"list_separator": ",",
				},
			},
			"--list-tasks": {
				"description": [ANSIThemeString("List valid values for ", "description"),
						ANSIThemeString("TASK", "argument")],
				"extended_description": [
					       [ANSIThemeString("List valid values to use with ", "description"),
						ANSIThemeString("--start-at-task", "option")],
					       [ANSIThemeString("and ", "description"),
						ANSIThemeString("--skip-tasks", "option")],
				],
			},
			"--no-password": {
				"description": [ANSIThemeString("Do not prompt for a password", "description")],
				"extended_description": [
					[ANSIThemeString("Use this if the hosts you are preparing", "description")],
					[ANSIThemeString("are already configured for login using an SSH key", "description")],
				],
			},
			"--save-ansible-logs": {
				"description": [ANSIThemeString("Save logs from Ansible runs", "description")],
				"extended_description": [
					       [ANSIThemeString("The logs can be viewed using “", "description"),
						ANSIThemeString("cmu", "programname"),
						ANSIThemeString(" logs", "command"),
						ANSIThemeString("“", "description")]
				],
			},
			"--verbose": {
				"description": [ANSIThemeString("Be more verbose", "description")],
			},
			"-Y": {
				"description": [ANSIThemeString("Do not ask for confirmation", "description")],
			},
		},
		"required_args": [
			{
				"name": "clustername",
				"string": [ANSIThemeString("CLUSTER_NAME", "argument")],
				"validation": {
					"validator": "regex",
					"regex": r"^[a-z_][a-z0-9_]*$",
				},
			},
		],
		"optional_args": [
			{
				"name": "version",
				"string": [ANSIThemeString("KUBERNETES_VERSION", "argument")],
				"validation": {
					"validator": "regex",
					"regex": r"^(kubeadm=|rke2=v?|)\d+\.\d+(\.\d+-\d+|\.\d+|)$"
				},
			},
		],
		"callback": prepare_installation,
	},
	"Create cluster": {
		"command": ["create-cluster"],
		"values": [
			ANSIThemeString("PATH", "argument"),
		],
		"description": [ANSIThemeString("Create a cluster based on template in ", "description"),
				ANSIThemeString("PATH", "path")],
		"extended_description": [
			[ANSIThemeString("Create a cluster based on a ", "description"),
			 ANSIThemeString("ClusterDeployment", "command")],
			[ANSIThemeString("template.", "description")],
			[ANSIThemeString("This combines all the necessary steps to prepare", "description")],
			[ANSIThemeString("and setup control planes and worker nodes,", "description")],
			[ANSIThemeString("as well as CNI for a cluster.", "description")],
		],
		"options": {
			"--redeploy": {
				"description": [ANSIThemeString("Redeploy workloads", "description")],
			},
			"-Y": {
				"description": [ANSIThemeString("Do not ask for confirmation", "description")],
			},
		},
		"required_args": [
			{
				"name": "path",
				"string": [ANSIThemeString("PATH", "argument")],
				"validation": {
					"validator": "path",
				},
			},
		],
		"callback": create_cluster,
	},
	"Setup Control Plane": {
		"command": ["setup-control-plane"],
		"values": [
			ANSIThemeString("[", "separator"),
			ANSIThemeString("CNI", "argument"),
			ANSIThemeString("]", "separator"),
			ANSIThemeString(" [", "separator"),
			ANSIThemeString("POD_NETWORK_CIDR", "argument"),
			ANSIThemeString("]", "separator"),
		],
		"description": [ANSIThemeString("Setup and launch the control plane", "description")],
		"extended_description": [
			[ANSIThemeString("Valid options for CNI", "description")],
			[ANSIThemeString("(Container Network Interface, aka Pod Network): ", "description")],
			[ANSIThemeString("antrea", "argument"),
			 ANSIThemeString(", ", "separator"),
			 ANSIThemeString("calico", "argument"),
			 ANSIThemeString(", ", "separator"),
			 ANSIThemeString("canal", "argument"),
			 ANSIThemeString(", ", "separator"),
			 ANSIThemeString("cilium", "argument"),
			 ANSIThemeString(",", "separator")],
			[ANSIThemeString("flannel", "argument"),
			 ANSIThemeString(", ", "separator"),
			 ANSIThemeString("kube-router", "argument"),
			 ANSIThemeString(", ", "separator"),
			 ANSIThemeString("weave", "argument"),
			 ANSIThemeString(", ", "separator"),
			 ANSIThemeString("none", "argument")],
			[ANSIThemeString("By default ", "description"),
			 ANSIThemeString("cilium", "argument"),
			 ANSIThemeString(" will be used as CNI", "description")],
			[ANSIThemeString("and ", "description"),
			 ANSIThemeString("10.244.0.0/16", "argument"),
			 ANSIThemeString(" will be used as pod network CIDR.", "description")],
			[ANSIThemeString("If you wish to postpone the choice of CNI", "description")],
			[ANSIThemeString("you can specify ", "description"),
			 ANSIThemeString("none", "argument")],
		],
		"options": {
			"--resume": {
				"description": [ANSIThemeString("Resume setup", "description")],
				"extended_description": [
					[ANSIThemeString("This can be used to resume operations", "description")],
					[ANSIThemeString("if control plane setup was aborted", "description")],
				],
			},
			"--start-at-task": {
				"values": [ANSIThemeString("TASK", "argument")],
				"description": [ANSIThemeString("Start at ", "description"),
						ANSIThemeString("TASK", "argument"),
						ANSIThemeString(" instead of running all tasks", "description")],
				"requires_arg": True,
				"validation": {
					"validator": "int",
					"valid_range": (0, None),
				},
			},
			"--skip-tasks": {
				"values": [ANSIThemeString("TASK", "argument"),
					   ANSIThemeString(",", "separator"),
					   ANSIThemeString("...", "argument")],
				"description": [ANSIThemeString("Skip ", "description"),
						ANSIThemeString("TASK", "argument"),
						ANSIThemeString(",", "separator"),
						ANSIThemeString("...", "argument")],
				"requires_arg": True,
				"validation": {
					"validator": "int",
					"valid_range": (0, None),
					"list_separator": ",",
				},
			},
			"--list-tasks": {
				"description": [ANSIThemeString("List valid values for ", "description"),
						ANSIThemeString("TASK", "argument")],
				"extended_description": [
					       [ANSIThemeString("List valid values to use with ", "description"),
						ANSIThemeString("--start-at-task", "option")],
					       [ANSIThemeString("and ", "description"),
						ANSIThemeString("--skip-tasks", "option")],
				],
			},
			"--save-ansible-logs": {
				"description": [ANSIThemeString("Save logs from Ansible runs", "description")],
				"extended_description": [
					       [ANSIThemeString("The logs can be viewed using “", "description"),
						ANSIThemeString("cmu", "programname"),
						ANSIThemeString(" logs", "command"),
						ANSIThemeString("“", "description")]
				],
			},
			"--cri": {
				"values": [ANSIThemeString("CRI", "argument")],
				"description": [ANSIThemeString("Use ", "description"),
						ANSIThemeString("CRI", "argument"),
						ANSIThemeString(" instead of the default CRI", "description")],
				"extended_description": [
					[ANSIThemeString("Valid options for CRI", "description")],
					[ANSIThemeString("(Container Runtime Interface) are:", "description")],
					[ANSIThemeString("docker-shim", "argument"),
					 ANSIThemeString(" (", "description"),
					 ANSIThemeString("Kubernetes", "programname"),
					 ANSIThemeString(" < ", "description"),
					 ANSIThemeString("1.24", "version"),
					 ANSIThemeString(")", "description"),
					 ANSIThemeString(", ", "separator")],
					[ANSIThemeString("containerd", "argument"),
					 ANSIThemeString(", ", "separator"),
					 ANSIThemeString("cri-o", "argument"),
					],
					[ANSIThemeString("Default CRI:", "description")],
					[ANSIThemeString("containerd", "argument"),
					 ANSIThemeString(" (", "description"),
					 ANSIThemeString("rke2", "argument"),
					 ANSIThemeString("), ", "description")],
					[ANSIThemeString("docker-shim", "argument"),
					 ANSIThemeString(" (", "description"),
					 ANSIThemeString("Kubernetes", "programname"),
					 ANSIThemeString(" < ", "description"),
					 ANSIThemeString("1.24", "version"),
					 ANSIThemeString(")", "description"),
					 ANSIThemeString(", ", "separator")],
					[ANSIThemeString("containerd", "argument"),
					 ANSIThemeString(" (", "description"),
					 ANSIThemeString("Kubernetes", "programname"),
					 ANSIThemeString(" >= ", "description"),
					 ANSIThemeString("1.24", "version"),
					 ANSIThemeString(")", "description"),
					 ANSIThemeString(", ", "separator")],
					[ANSIThemeString("cri-o", "argument"),
					 ANSIThemeString(" (", "description"),
					 ANSIThemeString("Kubernetes", "programname"),
					 ANSIThemeString(" >= ", "description"),
					 ANSIThemeString("1.24", "version"),
					 ANSIThemeString(" with ", "description"),
					 ANSIThemeString("--enable-dra", "option"),
					 ANSIThemeString(")", "description")],
					[ANSIThemeString("Note", "note"),
					 ANSIThemeString(": ", "description"),
					 ANSIThemeString("Kubernetes", "programname"),
					 ANSIThemeString(" >= ", "description"),
					 ANSIThemeString("1.26", "version"),
					 ANSIThemeString(" requires", "description")],
					[ANSIThemeString("containerd", "programname"),
					 ANSIThemeString(" >= ", "description"),
					 ANSIThemeString("1.6", "version"),
					 ANSIThemeString(" or ", "description"),
					 ANSIThemeString("cri-o", "programname")],
				],
				"requires_arg": True,
				"validation": {
					"validator": "allowlist",
					"allowlist": ["containerd", "cri-o", "docker-shim"],
				},
			},
			"--enable-dra": {
				"description": [ANSIThemeString("Enable DRA", "description")],
				"extended_description": [
					[ANSIThemeString("Enables the feature gates necessary to use", "description")],
					[ANSIThemeString("Dynamic Resource Allocation (DRA).", "description")],
					[ANSIThemeString("Currently only ", "description"),
					 ANSIThemeString("cri-o", "argument"),
					 ANSIThemeString(" supports DRA", "description")],
				],
			},
			"--override-cni": {
				"description": [ANSIThemeString("Override CNI", "description")],
				"extended_description": [
					[ANSIThemeString("Allow a change of CNI even if installation", "description")],
					[ANSIThemeString("started with a different CNI", "description")],
				],
			},
			"--verbose": {
				"description": [ANSIThemeString("Be more verbose", "description")],
			},
			"-Y": {
				"description": [ANSIThemeString("Do not ask for confirmation", "description")],
			},
		},
		"optional_args": [
			{
				"name": "cni",
				"string": [ANSIThemeString("CNI", "argument")],
				"validation": {
					"validator": "allowlist",
					"allowlist": ["antrea", "calico", "canal", "cilium", "flannel", "kube-router", "weave", "none"],
				},
			},
			{
				"name": "pod_network_cidr",
				"string": [ANSIThemeString("POD_NETWORK_CIDR", "argument")],
				"validation": {
					"validator": "cidr",
				},
			},
		],
		"callback": setup_control_planes,
	},
	"Setup CNI": {
		"command": ["setup-cni"],
		"values": [ANSIThemeString("[", "separator"),
			   ANSIThemeString("CNI", "argument"),
			   ANSIThemeString("]", "separator")],
		"description": [ANSIThemeString("Install and configure CNI", "description")],
		"extended_description": [
			[ANSIThemeString("Valid options for CNI", "description")],
			[ANSIThemeString("(Container Network Interface, aka Pod Network): ", "description")],
			[ANSIThemeString("antrea", "argument"),
			 ANSIThemeString(", ", "separator"),
			 ANSIThemeString("calico", "argument"),
			 ANSIThemeString(", ", "separator"),
			 ANSIThemeString("canal", "argument"),
			 ANSIThemeString(", ", "separator"),
			 ANSIThemeString("cilium", "argument"),
			 ANSIThemeString(", ", "separator")],
			[ANSIThemeString("flannel", "argument"),
			 ANSIThemeString(", ", "separator"),
			 ANSIThemeString("kube-router", "argument"),
			 ANSIThemeString(", ", "separator"),
			 ANSIThemeString("weave", "argument"),
			],
			[ANSIThemeString("By default ", "description"),
			 ANSIThemeString("cilium", "argument"),
			 ANSIThemeString(" will be used as CNI", "description")],
		],
		"options": {
			"--reinstall": {
				"description": [ANSIThemeString("Try to reinstall the already installed CNI", "description")],
			},
			"-Y": {
				"description": [ANSIThemeString("Do not ask for confirmation", "description")],
			},
			"--verbose": {
				"description": [ANSIThemeString("Be more verbose", "description")],
			},
		},
		"optional_args": [
			{
				"name": "cni",
				"string": [ANSIThemeString("CNI", "argument")],
				"validation": {
					"validator": "allowlist",
					"allowlist": ["antrea", "calico", "canal", "cilium", "flannel", "kube-router", "weave"],
				},
				"default": DEFAULT_CNI,
			},
		],
		"callback": setup_cni,
	},
	"Uninstall CNI": {
		"command": ["uninstall-cni"],
		"description": [ANSIThemeString("Uninstall the CNI", "description")],
		"extended_description": [
			[ANSIThemeString("This should be used in case", "description")],
			[ANSIThemeString("you want to switch to another CNI", "description")],
		],
		"options": {
			"--cni-version": {
				"values": [ANSIThemeString("CNI_VERSION", "argument")],
				"description": [ANSIThemeString("The installed CNI version", "description")],
				"extended_description": [
					[ANSIThemeString("Use this option to specify", "description")],
					[ANSIThemeString("the version in case it cannot", "description")],
					[ANSIThemeString("be autodetected", "description")],
				],
				"requires_arg": True,
				"validation": {
					"validator": "regex",
					"regex": "[a-zA-Z0-9+-]+",
				},
			},
			"-Y": {
				"description": [ANSIThemeString("Do not ask for confirmation", "description")],
			},
			"--verbose": {
				"description": [ANSIThemeString("Be more verbose", "description")],
			},
		},
		"callback": teardown_cni,
	},
	"Upgrade CNI": {
		"command": ["upgrade-cni"],
		"values": [ANSIThemeString("[", "separator"),
			   ANSIThemeString("CNI", "argument"),
			   ANSIThemeString("]", "separator")],
		"description": [ANSIThemeString("Upgrade the CNI", "description")],
		"options": {
			"--verbose": {
				"description": [ANSIThemeString("Be more verbose", "description")],
			},
		},
		"optional_args": [
			{
				"name": "cni",
				"string": [ANSIThemeString("CNI", "argument")],
				"validation": {
					"validator": "allowlist",
					"allowlist": ["antrea", "calico", "canal", "cilium", "flannel", "kube-router", "weave"],
				},
			},
		],
		"callback": upgrade_cni,
	},
	"Upgrade Control Plane": {
		"command": ["upgrade-control-plane"],
		"values": [ANSIThemeString("[", "separator"),
			   ANSIThemeString("KUBERNETES_VERSION", "argument"),
			   ANSIThemeString("]", "separator")],
		"description": [ANSIThemeString("Upgrade the control plane", "description")],
		"extended_description": [
			[ANSIThemeString("If ", "description"),
			 ANSIThemeString("KUBERNETES_VERSION", "argument"),
			 ANSIThemeString(" is not specified", "description")],
			[ANSIThemeString("the newest available version will be used.", "description")],
			[ANSIThemeString("Upgrading requires all nodes to be drained first.", "description")],
			[ANSIThemeString("Once the control plane has been uppgraded you ", "description"),
			 ANSIThemeString("must", "emphasis")],
			[ANSIThemeString("upgrade all nodes to the same version.", "description")],
			[ANSIThemeString("Important", "emphasis"),
			 ANSIThemeString(": skipping PATCH REVISIONS is acceptable,", "description")],
			[ANSIThemeString("but when upgrading to a newer MINOR version", "description")],
			[ANSIThemeString("all intermediate MINOR versions must be", "description")],
			[ANSIThemeString("installed first; this applies to nodes too.", "description")],
		],
		"options": {
			"--no-cache-update": {
				"description": [ANSIThemeString("Do not update the APT cache", "description")],
			},
			"--resume": {
				"description": [ANSIThemeString("Resume upgrade", "description")],
				"extended_description": [
					[ANSIThemeString("This can be used to resume operations", "description")],
					[ANSIThemeString("if upgrade was aborted", "description")],
				],
			},
			"--start-at-task": {
				"values": [ANSIThemeString("TASK", "argument")],
				"description": [ANSIThemeString("Start at ", "description"),
						ANSIThemeString("TASK", "argument"),
						ANSIThemeString(" instead of running all tasks", "description")],
				"requires_arg": True,
				"validation": {
					"validator": "int",
					"valid_range": (0, None),
				},
			},
			"--skip-tasks": {
				"values": [ANSIThemeString("TASK", "argument"),
					   ANSIThemeString(",", "separator"),
					   ANSIThemeString("...", "argument")],
				"description": [ANSIThemeString("Skip ", "description"),
						ANSIThemeString("TASK", "argument"),
						ANSIThemeString(",", "separator"),
						ANSIThemeString("...", "argument")],
				"requires_arg": True,
				"validation": {
					"validator": "int",
					"valid_range": (0, None),
					"list_separator": ",",
				},
			},
			"--list-tasks": {
				"description": [ANSIThemeString("List valid values for ", "description"),
						ANSIThemeString("TASK", "argument")],
				"extended_description": [
					       [ANSIThemeString("List valid values to use with ", "description"),
						ANSIThemeString("--start-at-task", "option")],
					       [ANSIThemeString("and ", "description"),
						ANSIThemeString("--skip-tasks", "option")],
				],
			},
			"--reinstall": {
				"description": [ANSIThemeString("Allow installing the same version", "description")],
				"extended_description": [
					       [ANSIThemeString("This option allows you to install the same", "description")],
					       [ANSIThemeString("version that's already running in the cluster", "description")],
				],
			},
			"--override": {
				"description": [ANSIThemeString("Override/rebuild installation info", "description")],
			},
			"--save-ansible-logs": {
				"description": [ANSIThemeString("Save logs from Ansible runs", "description")],
				"extended_description": [
					       [ANSIThemeString("The logs can be viewed using “", "description"),
						ANSIThemeString("cmu", "programname"),
						ANSIThemeString(" logs", "command"),
						ANSIThemeString("“", "description")]
				],
			},
			"--verbose": {
				"description": [ANSIThemeString("Be more verbose", "description")],
			},
			"-Y": {
				"description": [ANSIThemeString("Do not ask for confirmation", "description")],
			},
		},
		"optional_args": [
			{
				"name": "version",
				"string": [ANSIThemeString("KUBERNETES_VERSION", "argument")],
				"validation": {
					"validator": "regex",
					"regex": r"^\d+\.\d+(\.\d+-\d+|\.\d+|)$"
				},
			},
		],
		"callback": upgrade_control_plane,
	},
	"Teardown Control Plane": {
		"command": ["teardown-control-plane"],
		"description": [ANSIThemeString("Tear down the control plane", "description")],
		"extended_description": [
			[ANSIThemeString("Note", "emphasis"),
			 ANSIThemeString(": Before running this command all nodes", "description")],
			[ANSIThemeString("must have been removed first.", "description")],
			[ANSIThemeString("The configuration for the control plane", "description")],
			[ANSIThemeString("and any software installed during setup", "description")],
			[ANSIThemeString("will NOT be removed", "description")],

		],
		"options": {
			"--resume": {
				"description": [ANSIThemeString("Resume teardown", "description")],
				"extended_description": [
					[ANSIThemeString("This can be used to resume operations", "description")],
					[ANSIThemeString("if teardown was aborted", "description")],
				],
			},
			"--start-at-task": {
				"values": [ANSIThemeString("TASK", "argument")],
				"description": [ANSIThemeString("Start at ", "description"),
						ANSIThemeString("TASK", "argument"),
						ANSIThemeString(" instead of running all tasks", "description")],
				"requires_arg": True,
				"validation": {
					"validator": "int",
					"valid_range": (0, None),
				},
			},
			"--skip-tasks": {
				"values": [ANSIThemeString("TASK", "argument"),
					   ANSIThemeString(",", "separator"),
					   ANSIThemeString("...", "argument")],
				"description": [ANSIThemeString("Skip ", "description"),
						ANSIThemeString("TASK", "argument"),
						ANSIThemeString(",", "separator"),
						ANSIThemeString("...", "argument")],
				"requires_arg": True,
				"validation": {
					"validator": "int",
					"valid_range": (0, None),
					"list_separator": ",",
				},
			},
			"--list-tasks": {
				"description": [ANSIThemeString("List valid values for ", "description"),
						ANSIThemeString("TASK", "argument")],
				"extended_description": [
					       [ANSIThemeString("List valid values to use with ", "description"),
						ANSIThemeString("--start-at-task", "option")],
					       [ANSIThemeString("and ", "description"),
						ANSIThemeString("--skip-tasks", "option")],
				],
			},
			"--save-ansible-logs": {
				"description": [ANSIThemeString("Save logs from Ansible runs", "description")],
				"extended_description": [
					       [ANSIThemeString("The logs can be viewed using “", "description"),
						ANSIThemeString("cmu", "programname"),
						ANSIThemeString(" logs", "command"),
						ANSIThemeString("“", "description")]
				],
			},
			"--verbose": {
				"description": [ANSIThemeString("Be more verbose", "description")],
			},
			"-Y": {
				"description": [ANSIThemeString("Do not ask for confirmation", "description")],
			},
		},
		"callback": teardown_control_plane,
	},
	"Purge Control Plane": {
		"command": ["purge-control-plane"],
		"description": [ANSIThemeString("Purge configuration and packages", "description")],
		"extended_description": [
			[ANSIThemeString("Software and configuration needed", "description")],
			[ANSIThemeString("for ", "description"),
			 ANSIThemeString(f"{about.PROGRAM_SUITE_NAME}", "programname"),
			 ANSIThemeString(" itself will not be purged", "description")],
		],
		"options": {
			"--resume": {
				"description": [ANSIThemeString("Resume purge; can be used if purge was aborted", "description")],
			},
			"--start-at-task": {
				"values": [ANSIThemeString("TASK", "argument")],
				"description": [ANSIThemeString("Start at ", "description"),
						ANSIThemeString("TASK", "argument"),
						ANSIThemeString(" instead of running all tasks", "description")],
				"requires_arg": True,
				"validation": {
					"validator": "int",
					"valid_range": (0, None),
				},
			},
			"--skip-tasks": {
				"values": [ANSIThemeString("TASK", "argument"),
					   ANSIThemeString(",", "separator"),
					   ANSIThemeString("...", "argument")],
				"description": [ANSIThemeString("Skip ", "description"),
						ANSIThemeString("TASK", "argument"),
						ANSIThemeString(",", "separator"),
						ANSIThemeString("...", "argument")],
				"requires_arg": True,
				"validation": {
					"validator": "int",
					"valid_range": (0, None),
					"list_separator": ",",
				},
			},
			"--list-tasks": {
				"description": [ANSIThemeString("List valid values for ", "description"),
						ANSIThemeString("TASK", "argument")],
				"extended_description": [
					       [ANSIThemeString("List valid values to use with ", "description"),
						ANSIThemeString("--start-at-task", "option")],
					       [ANSIThemeString("and ", "description"),
						ANSIThemeString("--skip-tasks", "option")],
				],
			},
			"--save-ansible-logs": {
				"description": [ANSIThemeString("Save logs from Ansible runs", "description")],
				"extended_description": [
					       [ANSIThemeString("The logs can be viewed using “", "description"),
						ANSIThemeString("cmu", "programname"),
						ANSIThemeString(" logs", "command"),
						ANSIThemeString("“", "description")]
				],
			},
			"--verbose": {
				"description": [ANSIThemeString("Be more verbose", "description")],
			},
			"-Y": {
				"description": [ANSIThemeString("Do not ask for confirmation", "description")],
			},
		},
		"callback": purge_control_plane,
	},
	"Taint Control Plane": {
		"command": ["taint-control-plane"],
		"values": [ANSIThemeString("[", "separator"),
			   ANSIThemeString("CONTROLPLANE", "argument"),
			   ANSIThemeString(",", "separator"),
			   ANSIThemeString("...", "argument"),
			   ANSIThemeString("]", "separator")],
		"description": [ANSIThemeString("Mark control plane(s) as tainted", "description")],
		"extended_description": [
			[ANSIThemeString("If you have previously marked your control plane(s)", "description")],
			[ANSIThemeString("as untainted you can mark them as tainted", "description")],
			[ANSIThemeString("using this command.", "description")],
			[ANSIThemeString("If ", "description"),
			 ANSIThemeString("CONTROLPLANE", "argument"),
			 ANSIThemeString(",", "separator"),
			 ANSIThemeString("...", "argument"),
			 ANSIThemeString(" is not specified", "description")],
			[ANSIThemeString("all control planes will be tainted", "description")],
		],
		"optional_args": [
			{
				"name": "controlplane",
				"string": [ANSIThemeString("CONTROLPLANE", "argument")],
				"validation": {
					"validator": "hostname_or_ip",
					"list_separator": ",",
				},
			},
		],
		"callback": taint_control_plane,
	},
	"Untaint Control Plane": {
		"command": ["untaint-control-plane"],
		"values": [ANSIThemeString("[", "separator"),
			   ANSIThemeString("CONTROLPLANE", "argument"),
			   ANSIThemeString(",", "separator"),
			   ANSIThemeString("...", "argument"),
			   ANSIThemeString("]", "separator")],
		"description": [ANSIThemeString("Mark control plane(s) as untainted", "description")],
		"extended_description": [
			[ANSIThemeString("By default control planes are marked as tainted;", "description")],
			[ANSIThemeString("workloads that lack tolerations will not be", "description")],
			[ANSIThemeString("scheduled to control planes. If you are running", "description")],
			[ANSIThemeString("a single-node cluster, or if the control plane", "description")],
			[ANSIThemeString("is very powerful it might be useful to permit", "description")],
			[ANSIThemeString("workloads on control plane(s) too.", "description")],
			[ANSIThemeString("If ", "description"),
			 ANSIThemeString("CONTROLPLANE", "argument"),
			 ANSIThemeString(",", "separator"),
			 ANSIThemeString("...", "argument"),
			 ANSIThemeString(" is not specified", "description")],
			[ANSIThemeString("all control planes will be untainted", "description")],

		],
		"optional_args": [
			{
				"name": "controlplane",
				"string": [ANSIThemeString("CONTROLPLANE", "argument")],
				"validation": {
					"validator": "hostname_or_ip",
					"list_separator": ",",
				},
			},
		],
		"callback": untaint_control_plane,
	},
	"Audit": {
		"command": ["audit"],
		"description": [ANSIThemeString("Search for potential security issues in the cluster", "description")],
		"extended_description": [
			[ANSIThemeString("Note", "emphasis"),
			 ANSIThemeString(": If the system is configured", "description")],
			[ANSIThemeString("to use ", "description"),
			 ANSIThemeString("usergroups", "emphasis"),
			 ANSIThemeString(" (every user have their own group", "description")],
			[ANSIThemeString("that only they belong to); if the name of that", "description")],
			[ANSIThemeString("group differs from the username be sure to specify", "description")],
			[ANSIThemeString("that group using the ", "description"),
			 ANSIThemeString("--usergroup ", "option"),
			 ANSIThemeString("USERGROUP", "argument"),
			 ANSIThemeString(" option,", "description")],
			[ANSIThemeString("to prevent the permission checker", "description")],
			[ANSIThemeString("from complaining about insecure permissions", "description")],
		],
		"options": {
			"--disable-usergroup-autodetect": {
				"description": [ANSIThemeString("Disable usergroup autodetect", "description")],
				"extended_description": [
					[ANSIThemeString("Note", "emphasis"),
					 ANSIThemeString(": the audit command attempts", "description")],
					[ANSIThemeString("to autodetect whether ", "description"),
					 ANSIThemeString("usergroups", "emphasis"),
					 ANSIThemeString(" are in use;", "description")],
					[ANSIThemeString("use this option to disable autodetect", "description")],
				],
			},
			"--usergroup": {
				"values": [ANSIThemeString("USERGROUP", "argument")],
				"description": [ANSIThemeString("The name of the usergroup", "description")],
				"requires_arg": True,
				"validation": {
					"validator": "regex",
					# regex taken from debian; other distros might be stricter or possible more permissive
					"regex": r"^[a-z_][a-z0-9_-]*[$]?$",
				},
			},
		},
		"callback": audit,
	},
	"Preflight Check": {
		"command": ["preflight-check"],
		"values": [ANSIThemeString("CONTROLPLANE", "argument")],
		"description": [ANSIThemeString("Preflight check", "description")],
		"extended_description": [
			[ANSIThemeString("Check for potential pitfalls that may prevent", "description")],
			[ANSIThemeString("preparation or setup from succeeding", "description")],
		],
		"options": {
			"--no-password": {
				"description": [ANSIThemeString("Do not prompt for a password", "description")],
				"extended_description": [
					[ANSIThemeString("Use this if the hosts you are preparing", "description")],
					[ANSIThemeString("are already configured for login using an SSH key", "description")],
				],
			},
		},
		"required_args": [
			{
				"name": "controlplane",
				"string": [ANSIThemeString("CONTROLPLANE", "argument")],
				"validation": {
					"validator": "hostname_or_ip",
				},
			},
		],
		"callback": preflight_check,
	},
	"Troubleshoot": {
		"command": ["troubleshoot"],
		"description": [ANSIThemeString("Search for potential problems in the cluster", "description")],
		"callback": troubleshoot,
	},
	"spacer1": {
		"command": [""],
		"description": [ANSIThemeString("", "description")],
	},
}

def main() -> None:
	"""
	Main function for the program
	"""

	# Before doing anything else, make sure that the user is not running as root
	if os.geteuid() == 0:
		sys.exit("CRITICAL: This program should not be run as the root user; aborting.")

	# Then initialise the configuration file
	read_cmtconfig()

	command, options, args = parse_commandline(about.ADMIN_PROGRAM_NAME, about.ADMIN_PROGRAM_VERSION, PROGRAMDESCRIPTION, PROGRAMAUTHORS, sys.argv,
						   COMMANDLINE, theme = DEFAULT_THEME_FILE)
	major_minor_patchrev = get_latest_kubernetes_upstream_version()
	requested_major, requested_minor, _rest = major_minor_patchrev.split(".", maxsplit = 3)
	crio_major_version, crio_minor_version = get_crio_version((int(requested_major), int(requested_minor)))

	# Used by the ansible module
	ansible_configuration["ansible_forks"] = deep_get(cmtlib.cmtconfig, DictPath("Ansible#forks"), 10)
	ansible_user = deep_get(cmtlib.cmtconfig, DictPath("Ansible#ansible_user"))
	if ansible_user is None or len(ansible_user) == 0:
		ansible_user = getuser()
	ansible_configuration["ansible_user"] = ansible_user
	ansible_password = deep_get(cmtlib.cmtconfig, DictPath("Ansible#ansible_password"))
	if ansible_password is not None and len(ansible_password) > 0:
		ansible_configuration["ansible_password"] = ansible_password
	ansible_configuration["disable_strict_host_key_checking"] = deep_get(cmtlib.cmtconfig, DictPath("Nodes#disablestricthostkeychecking"), False)
	ansible_configuration["save_logs"] = deep_get(cmtlib.cmtconfig, DictPath("Ansible#save_logs"), False)

	return command(options, args)

if __name__ == "__main__":
	main()
